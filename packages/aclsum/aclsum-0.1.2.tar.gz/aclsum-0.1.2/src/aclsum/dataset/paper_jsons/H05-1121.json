{
    "paper_id": "H05-1121",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:53:25.829977Z"
    },
    "title": "Query Expansion with the Minimum User Feedback by Transductive Learning",
    "authors": [
        {
            "first": "Masayuki",
            "middle": [],
            "last": "Okabe",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Toyohashi University of Technology Aichi",
                "location": {
                    "postCode": "441-8580",
                    "country": "Japan"
                }
            },
            "email": "okabe@imc.tut.ac.jp"
        },
        {
            "first": "Kyoji",
            "middle": [],
            "last": "Umemura",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Toyohashi University of Technology Aichi",
                "location": {
                    "postCode": "441-8580",
                    "country": "Japan"
                }
            },
            "email": "umemura@tutics.tut.ac.jp"
        },
        {
            "first": "Seiji",
            "middle": [],
            "last": "Yamada",
            "suffix": "",
            "affiliation": {},
            "email": ""
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Query expansion techniques generally select new query terms from a set of top ranked documents. Although a user's manual judgment of those documents would much help to select good expansion terms, it is difficult to get enough feedback from users in practical situations. In this paper we propose a query expansion technique which performs well even if a user notifies just a relevant document and a non-relevant document. In order to tackle this specific condition, we introduce two refinements to a well-known query expansion technique. One is application of a transductive learning technique in order to increase relevant documents. The other is a modified parameter estimation method which laps the predictions by multiple learning trials and try to differentiate the importance of candidate terms for expansion in relevant documents. Experimental results show that our technique outperforms some traditional query expansion methods in several evaluation measures.",
    "pdf_parse": {
        "paper_id": "H05-1121",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Query expansion techniques generally select new query terms from a set of top ranked documents. Although a user's manual judgment of those documents would much help to select good expansion terms, it is difficult to get enough feedback from users in practical situations. In this paper we propose a query expansion technique which performs well even if a user notifies just a relevant document and a non-relevant document. In order to tackle this specific condition, we introduce two refinements to a well-known query expansion technique. One is application of a transductive learning technique in order to increase relevant documents. The other is a modified parameter estimation method which laps the predictions by multiple learning trials and try to differentiate the importance of candidate terms for expansion in relevant documents. Experimental results show that our technique outperforms some traditional query expansion methods in several evaluation measures.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Query expansion is a simple but very useful technique to improve search performance by adding some terms to an initial query. While many query expansion techniques have been proposed so far, a standard method of performing is to use relevance information from a user (Ruthven, 2003) . If we can use more relevant documents in query expansion, the likelihood of selecting query terms achieving high search improvement increases. However it is impractical to expect enough relevance information. Some researchers said that a user usually notifies few relevance feedback or nothing (Dumais and et al., 2003) .",
                "cite_spans": [
                    {
                        "start": 267,
                        "end": 282,
                        "text": "(Ruthven, 2003)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 579,
                        "end": 604,
                        "text": "(Dumais and et al., 2003)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper we investigate the potential performance of query expansion under the condition that we can utilize little relevance information, especially we only know a relevant document and a nonrelevant document. To overcome the lack of relevance information, we tentatively increase the number of relevant documents by a machine learning technique called Transductive Learning. Compared with ordinal inductive learning approach, this learning technique works even if there is few training examples. In our case, we can use many documents in a hit-list, however we know the relevancy of few documents. When applying query expansion, we use those increased documents as if they were true relevant ones. When applying the learning, there occurs some difficult problems of parameter settings. We also try to provide a reasonable resolution for the problems and show the effectiveness of our proposed method in experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The point of our query expansion method is that we focus on the availability of relevance information in practical situations. There are several researches which deal with this problem. Pseudo relevance feedback which assumes top n documents as relevant ones is one example. This method is simple and relatively effective if a search engine returns a hit-list which contains a certain number of relative documents in the upper part. However, unless this assumption holds, it usually gives a worse ranking than the initial search. Thus several researchers propose some specific procedure to make pseudo feedback be effective (Yu and et al, 2003; Lam-Adesina and Jones, 2001) . In another way, Onoda (Onoda et al., 2004) tried to apply one-class SVM (Support Vector Machine) to relevance feedback. Their purpose is to improve search performance by using only nonrelevant documents. Though their motivation is similar to ours in terms of applying a machine learning method to complement the lack of relevance information, the assumption is somewhat different. Our assumption is to utilizes manual but the minimum relevance judgment.",
                "cite_spans": [
                    {
                        "start": 624,
                        "end": 644,
                        "text": "(Yu and et al, 2003;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 645,
                        "end": 673,
                        "text": "Lam-Adesina and Jones, 2001)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 698,
                        "end": 718,
                        "text": "(Onoda et al., 2004)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Transductive leaning has already been applied in the field of image retrieval (He and et al., 2004) . In this research, they proposed a transductive method called the manifold-ranking algorithm and showed its effectiveness by comparing with active learning based Support Vector Machine. However, their setting of relevance judgment is not different from many other traditional researches. They fix the total number of images that are marked by a user to 20. As we have already claimed, this setting is not practical because most users feel that 20 is too much for judgment. We think none of research has not yet answered the question. For relevance judgment, most of the researches have adopted either of the following settings. One is the setting of \"Enough relevant documents are available\", and the other is \"No relevant document is available\". In contrast to them, we adopt the setting of \"Only one relevant document is available\". Our aim is to achieve performance improvement with the minimum effort of judging relevancy of documents.",
                "cite_spans": [
                    {
                        "start": 78,
                        "end": 99,
                        "text": "(He and et al., 2004)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The reminder of this paper is structured as follows. Section 2 describes two fundamental techniques for our query expansion method. Section 3 explains a technique to complement the smallness of manual relevance judgment. Section 4 introduces a whole procedure of our query expansion method step by step. Section 5 shows empirical evidence of the effectiveness of our method compared with two traditional query expansion methods. Section 6 investigates the experimental results more in detail. Finally, Section 7 summarizes our findings.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "So far, many query expansion techniques have been proposed. While some techniques focus on the domain specific search which prepares expansion terms in advance using some domain specific training documents (Flake and et al, 2002; Oyama and et al, 2001) , most of techniques are based on relevance feedback which is given automatically or manually.",
                "cite_spans": [
                    {
                        "start": 206,
                        "end": 229,
                        "text": "(Flake and et al, 2002;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 230,
                        "end": 252,
                        "text": "Oyama and et al, 2001)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "In this technique, expansion terms are selected from relevant documents by a scoring function. The Robertson's wpq method (Ruthven, 2003) is often used as such a scoring function in many researches (Yu and et al, 2003; Lam-Adesina and Jones, 2001) . We also use it as our basic scoring function. It calculates the score of each term by the following formula.",
                "cite_spans": [
                    {
                        "start": 122,
                        "end": 137,
                        "text": "(Ruthven, 2003)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 198,
                        "end": 218,
                        "text": "(Yu and et al, 2003;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 219,
                        "end": 247,
                        "text": "Lam-Adesina and Jones, 2001)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "wpqt = ( rt R - nt -rt N -R ) * log rt/(R -rt) (nt -rt)/(N -nt -R + rt) (1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "where r t is the number of seen relevant documents containing term t. n t is the number of documents containing t. R is the number of seen relevant documents for a query. N is the number of documents in the collection. The second term of this formula is called the Robertson/Spark Jones weight (Robertson, 1990 ) which is the core of the term weighting function in the Okapi system (Robertson, 1997) . This formula is originated in the following formula.",
                "cite_spans": [
                    {
                        "start": 294,
                        "end": 310,
                        "text": "(Robertson, 1990",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 382,
                        "end": 399,
                        "text": "(Robertson, 1997)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "wpq t = (p t -q t ) log p t (1 -q t ) q t (1 -p t )",
                        "eq_num": "(2)"
                    }
                ],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "where p t is the probability that a term t appears in relevant documents. q t is the probability that a term t appears in non-relevant documents. We can easily notice that it is very important how the two probability of p t and q t should be estimated. The first formula estimates p t with rt R and q t with Nt-Rt N -R . For the good estimation of p t and q t , plenty of relevant document is necessary. Although pseudo feedback which automatically assumes top n documents as relevant is one method and is often used, its performance heavily depends on the quality of an initial search. As we show later, pseudo feedback has limited performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "We here consider a query expansion technique which uses manual feedback. It is no wonder manual feedback shows excellent and stable performance if enough relevant documents are available, hence the challenge is how it keeps high performance with less amount of manual relevance judgment. In particular, we restrict the manual judgment to the minimum amount, namely only a relevant document and a non-relevant document. In this assumption, the problem is how to find more relevant documents based on a relevant document and a non-relevant document. We use transductive learning technique which is suitable for the learning problem where there is small training examples.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Query Expansion",
                "sec_num": "2.1"
            },
            {
                "text": "Transductive learning is a machine learning technique based on the transduction which directly derives the classification labels of test data without making any approximating function from training data (Vapnik, 1998) . Because it does not need to make approximating function, it works well even if the number of training data is small.",
                "cite_spans": [
                    {
                        "start": 203,
                        "end": 217,
                        "text": "(Vapnik, 1998)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "The learning task is defined on a data set X of n points. X consists of training data set L = (\u20d7 x 1 , \u20d7 x 2 , ..., \u20d7 x l ) and test data set U = (\u20d7 x l+1 , \u20d7 x l+2 , ..., \u20d7 x l+u ); typically l \u226a u. The purpose of the learning is to assign a label to each data point in U under the condition that the label of each data point in L are given.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "Recently, transductive learning or semisupervised learning is becoming an attractive subject in the machine learning field. Several algorithms have been proposed so far (Joachims, 1999; Zhu and et al., 2003; Blum and et al., 2004) and they show the advantage of this approach in various learning tasks. In order to apply transductive learning to our query expansion, we select an algorithm called \"Spectral Graph Transducer (SGT)\" (Joachims, 2003) , which is one of the state of the art and the best transductive learning algorithms. SGT formalizes the problem of assigning labels to U with an optimization problem of the constrained ratiocut. By solving the relaxed problem, it produces an approximation to the original solution.",
                "cite_spans": [
                    {
                        "start": 169,
                        "end": 185,
                        "text": "(Joachims, 1999;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 186,
                        "end": 207,
                        "text": "Zhu and et al., 2003;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 208,
                        "end": 230,
                        "text": "Blum and et al., 2004)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 431,
                        "end": 447,
                        "text": "(Joachims, 2003)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "When applying SGT to query expansion, X corresponds to a set of top n ranked documents in a hit-list. X does not corresponds to a whole document collection because the number of documents in a collection is too huge1 for any learning system to process. L corresponds to two documents with manual judgments, a relevant document and a non-relevant document. Furthermore, U corresponds to the documents of X \u2229 L whose relevancy is unknown. SGT is used to produce the relevancy of documents in U . SGT actually assigns values around \u03b3 + -\u03b8 for documents possibly being relevant and \u03b3 --\u03b8 for documents possibly being non-relevant.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "\u03b3 + = + \u221a 1-fp fp , \u03b3 -= - \u221a fp 1-fp , \u03b8 = 1 2 (\u03b3 + + \u03b3 -)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": ", and f p is the fraction of relevant documents in X. We cannot know the true value of f p in advance, thus we have to estimate its approximation value before applying SGT.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "According to Joachims, parameter k (the number of k-nearest points of a data \u20d7 x) and d (the number of eigen values to ...) give large influence to SGT's learning performance. Of course those two parameters should be set carefully. However, besides them, f p is much more important for our task because it controls the learning performance. Since extremely small L (actually |L| = 2 is our setting) give no information to estimate the true value of f p , we do not strain to estimate its single approximation value but propose a new method to utilize the results of learning with some promising f p . We describe the method in the next section.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transductive Learning",
                "sec_num": "2.2"
            },
            {
                "text": "Multiple SGT Predictions five times or the difference converges less than 0.01. This method is neither works well because the convergence is not guaranteed at all.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimations based on",
                "sec_num": "3"
            },
            {
                "text": "Presetting of f p is primarily very difficult problem and consequently we take another approach which laps the predictions of multiple SGT trials with some sampled f p instead of setting a single f p . This approach leads to represent a relevant document by not a binary value but a real value between 0 and 1. The sampling procedure for f p is illustrated in Figure 1 . In this procedure, sampling interval changes according to the number of training examples. In our preliminary test, the number of sampling points should be around 10. However this number is adhoc one, thus we may need another value for another corpus.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 367,
                        "end": 368,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Parameter Estimations based on",
                "sec_num": "3"
            },
            {
                "text": "Once we get a set of sampling points S = {f i p : i = 1 \u223c 10}, we run SGT with each f i p and laps each resultant of prediction to calculate p t and q t as follows.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modified estimations for p t and q t",
                "sec_num": "3.2"
            },
            {
                "text": "p t = \u2211 i r i t \u2211 i R i (3) q t = \u2211 i n t -r i t \u2211 i N -R i (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modified estimations for p t and q t",
                "sec_num": "3.2"
            },
            {
                "text": "Here, R i is the number of documents which SGT predicts as relevant with ith value of f i p , and r i t is the number of documents in R i where a term t appears. In each trial, SGT predicts the relevancy of documents by binary value of 1 (for relevant) and 0 (for non-relevant), yet by lapping multiple resultant of predictions, the binary prediction value changes to a real value which can represents the relevancy of documents in more detail. The main merit of this approach in comparison with fixing f p to a single value, it can differentiate a value of p t if N tr is small.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modified estimations for p t and q t",
                "sec_num": "3.2"
            },
            {
                "text": "We here explain a whole procedure of our query expansion method step by step.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expansion Procedures",
                "sec_num": "4"
            },
            {
                "text": "1. Initial Search: A retrieval starts by inputting a query for a topic to an IR system.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expansion Procedures",
                "sec_num": "4"
            },
            {
                "text": "Hit-List: The IR system returns a hit-list for the initial query. Then the hit-list is scanned to check whether each document is relevant or non-relevant in descending order of the ranking. In our assumption, this reviewing process terminates when a relevant document and a non-relevant one are found.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relevance Judgment for Documents in a",
                "sec_num": "2."
            },
            {
                "text": "3. Finding more relevant documents by transductive learning: Because only two judged documents are too few to estimate p t and q t correctly, our query expansion tries to increase the number of relevant documents for the wpq formula using the SGT transductive learning algorithm. As shown in Figure2, SGT assigns a value of the possibility to be relevant for the topic to each document with no relevance judgment (documents under the dashed line in the Our query expansion method calculates the score of each term appearing in relevant documents (including documents judged as relevant by SGT) using wpq formula, and then selects a certain number of expansion terms according to the ranking of the score. Selected terms are added to the initial query. Thus an expanded query consists of the initial terms and added terms.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relevance Judgment for Documents in a",
                "sec_num": "2."
            },
            {
                "text": "The expanded query is inputted to the IR system and a new hit-list will be returned. One cycle of query expansion finishes at this step.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Next Search with an expanded query:",
                "sec_num": "5."
            },
            {
                "text": "In the above procedures, we naturally introduced transductive learning into query expansion as the effective way in order to automatically find some relevant documents. Thus we do not need to modify a basic query expansion procedure and can fully utilize the potential power of the basic query expansion.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Next Search with an expanded query:",
                "sec_num": "5."
            },
            {
                "text": "The computational cost of transductive learning is not so much. Actually transductive learning takes a few seconds to label 100 unlabeled documents and query expansion with all the labeled documents also takes a few seconds. Thus our system can expand queries sufficiently quick in practical applications.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Next Search with an expanded query:",
                "sec_num": "5."
            },
            {
                "text": "This section provides empirical evidence on how our query expansion method can improve the performance of information retrieval. We compare our method with other traditional methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "We use the TREC-8 data set (Voorhees and Harman, 1999) for our experiment. The document corpus contains about 520,000 news articles. Each document is preprocessed by removing stopwords and stemming. We also use fifty topics and relevance judgments which are prepared for adhoc task in the TREC-8. Queries for an initial search are nouns extracted from the title tag in each topic.",
                "cite_spans": [
                    {
                        "start": 27,
                        "end": 54,
                        "text": "(Voorhees and Harman, 1999)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data set",
                "sec_num": "5.1.1"
            },
            {
                "text": "We use two representative retrieval models which are bases of the Okapi (Robertson, 1997) and SMART systems. They showed highest performance in the TREC-8 competition.",
                "cite_spans": [
                    {
                        "start": 72,
                        "end": 89,
                        "text": "(Robertson, 1997)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "Okapi : The weight function in Okapi is BM25. It calculates each document's score by the following formula.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "score(d) = \u2211 T \u2208Q w (1) \u2022 (k1 + 1)tf (k3 + 1)qtf (K + tf )(k3 + qtf ) (5) w (1) = log (rt + 0.5)/(R -rt + 0.5) (nt -rt + 0.5)/(N -nt -R + rt + 0.5) (6) K = k1 ( (1 -b) + b dl avdl ) (7)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "where Q is a query containing terms T , tf is the term's frequency in a document, qtf is the term's frequency in a text from which Q was derived. r t and n t are described in section 2. K is calculated by ( 7), where dl and avdl denote the document length and the average document length. In our experiments, we set k 1 = 1.2, k 3 = 1000, b = 0.75, and avdl = 135.6. Terms for query expansion are ranked in decreasing order of r t \u00d7 w (1) for the following Okapi's retrieval tests without SGT (Okapi manual and Okapi pseudo) to make conditions the same as of TREC-8. SMART : The SMART's weighting function is as follows 2 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "score(d) = \u2211 T \u2208Q {1 + ln(1 + ln(tf ))} * log( N + 1 df ) * pivot (8) pivot = 1 0.8 + 0.2 \u00d7 dl avdl (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "df is the term's document frequency. tf , dl and avdl are the same as Okapi. When doing relevance feedback, a query vector is modified by the following Rocchio's method (with parame- D rel and D nrel are sets of seen relevant and non-relevant documents respectively. Terms for query expansion are ranked in decreasing order of the above Rocchio's formula.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "ters \u03b1 = 3, \u03b2 = 2, \u03b3 = 2). \u20d7 Qnew = \u03b1 \u20d7 Q old + \u03b2 |D rel | \u2211 D rel \u20d7 d- \u03b3 |D nrel | \u2211 D nrel \u20d7 d (10)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "Table 1 shows their initial search results of Okapi (Okapi ini) and SMART (SMART ini). We adopt five evaluation measures. Their meanings are as follows (Voorhees and Harman, 1999) . P10 : The precision after the first 10 documents are retrieved.",
                "cite_spans": [
                    {
                        "start": 152,
                        "end": 179,
                        "text": "(Voorhees and Harman, 1999)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "P30 : The precision after the first 30 documents are retrieved.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Retrieval Models",
                "sec_num": "5.1.2"
            },
            {
                "text": "The precision after the first R documents are retrieved, where R is the number of relevant documents for the current topic.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "R-Prec :",
                "sec_num": null
            },
            {
                "text": "MAP : Mean average precision (MAP) is the average precision for a single topic is the mean of the precision obtained after each relevant document is retrieved (using zero as the precision for relevant documents that are not retrieved).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "R-Prec :",
                "sec_num": null
            },
            {
                "text": "R05P : Recall at the rank where precision first dips below 0.5 (after at least 10 documents have been retrieved).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "R-Prec :",
                "sec_num": null
            },
            {
                "text": "The performance of query expansion or relevance feedback is usually evaluated on a residual collection where seen documents are removed. However we compare our method with pseudo feedback based ones, thus we do not use residual collection in the following experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "R-Prec :",
                "sec_num": null
            },
            {
                "text": "For manual feedback, we set an assumption that a user tries to find relevant and non-relevant documents within only top 10 documents in the result of an initial search. If a topic has no relevant document or no non-relevant document in the top 10 documents, we do not apply manual feedback, instead we consider the result of the initial search for such topics. There are 8 topics3 which we do not apply manual feedback methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings of Manual Feedback",
                "sec_num": "5.1.3"
            },
            {
                "text": "Firstly, we evaluate the basic performance of our query expansion method by changing the number of training examples. Since our method is based on Okapi model, we represent it as Okapi sgt (with parameters k = 0.5 * N tr , d = 0.8 * N tr . k is the number of nearest neighbors, d is the number of eigen values to use and N tr is the number of training examples). Table 2 -5 shows five evaluation measures of Okapi sgt when the number of expansion terms changes. We test 20, 50 and 100 as the number of training examples and 5, 10 15 and 20 for the number of expansion terms. As for the number of training examples, performance of 20 and 50 does not differ so much in all the number of expansion terms. However performance of 100 is clearly worse than of 20 and 50. The number of expansion terms does not effect so much in every evaluation measures. In the following experiments, we compare the results of Okapi sgt when the number of training examples is 50 with other query expansion methods. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 369,
                        "end": 370,
                        "text": "2",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Basic Performance",
                "sec_num": "5.2"
            },
            {
                "text": "We next compare our query expansion method with the following manual feedback methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with other Manual Feedback Methods",
                "sec_num": "5.3"
            },
            {
                "text": "Okapi man : This method simply uses only one relevant document judged by hand. This is called incremental relevance feedback (Aalbersberg, 1992; Allan, 1996; Iwayama, 2000) .",
                "cite_spans": [
                    {
                        "start": 125,
                        "end": 144,
                        "text": "(Aalbersberg, 1992;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 145,
                        "end": 157,
                        "text": "Allan, 1996;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 158,
                        "end": 172,
                        "text": "Iwayama, 2000)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with other Manual Feedback Methods",
                "sec_num": "5.3"
            },
            {
                "text": "SMART man : This method is SMART's manual relevance feedback (with parameters \u03b1 = 3, \u03b2 = 2, \u03b3 = 0). \u03b3 is set to 0 because the performance is terrible if \u03b3 is set to 2.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with other Manual Feedback Methods",
                "sec_num": "5.3"
            },
            {
                "text": "Table 6 shows the mean average precision of three methods when the number of expansion terms changes. Since the number of feedback documents is extremely small, two methods except for Okapi sgt get worse than their initial searches. Okapi man slightly decreases as the number of expansion terms increases. Contrary, SMART man do not change so much as the number of expansion terms increases. Table 7 shows another evaluation measures with 10 terms expanded. It is clear that Okapi sgt outperforms the other two methods.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "6",
                        "ref_id": "TABREF4"
                    },
                    {
                        "start": 398,
                        "end": 399,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Comparison with other Manual Feedback Methods",
                "sec_num": "5.3"
            },
            {
                "text": "We finally compare our query expansion method with the following pseudo feedback methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with Pseudo Feedback Methods",
                "sec_num": "5.4"
            },
            {
                "text": "Okapi pse : This is a pseudo version of Okapi which assumes top 10 documents in the initial search as relevant ones as well as TREC-8 settings. It also assumes top 10 documents as relevant ones. In addition, it assumes top 500-1000 documents as non-relevant ones.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with Pseudo Feedback Methods",
                "sec_num": "5.4"
            },
            {
                "text": "In TREC-8, above two methods uses TREC1-5 disks for query expansion and a phase extraction technique. However we do not adopt these methods in our experiments4 . Since these methods showed the highest performance in the TREC-8 adhoc task, it is reasonable to compare our method with them as competitors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparison with Pseudo Feedback Methods",
                "sec_num": "5.4"
            },
            {
                "text": "Table 8 shows the mean average precision of three methods when the number of expansion terms changes. Performance does not differ so much if the number of expansion terms changes. Okapi sgt outperforms at any number of expansion. Table 9 shows the results in other evaluation measures. Okapi sgt also outperforms except for R05P. In particular, performance in P10 is quite well. It is preferable behavior for the use in practical situations.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "8",
                        "ref_id": "TABREF5"
                    },
                    {
                        "start": 236,
                        "end": 237,
                        "text": "9",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Comparison with Pseudo Feedback Methods",
                "sec_num": "5.4"
            },
            {
                "text": "In the experiments, the feedback documents for Okapi sgt is top ranked ones. However some users do not select such documents. They may choose another relevant and non-relevant documents which rank in top 10. Thus we test an another experiment where relevant and non-relevant documents are selected randomly from top 10 rank. Table 10 shows the result. Compared with table 2, the performance seems to become slightly worse. This shows that a ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 331,
                        "end": 333,
                        "text": "10",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "6"
            },
            {
                "text": "In this paper we proposed a novel query expansion method which only use the minimum manual judgment. To complement the lack of relevant documents, this method utilizes the SGT transductive learning algorithm to predict the relevancy of unjudged documents. Since the performance of SGT much depends on an estimation of the fraction of relevant documents, we propose a method to sample some good fraction values. We also propose a method to laps the predictions of multiple SGT trials with above sampled fraction values and try to differentiate the importance of candidate terms for expansion in relevant documents. The experimental results showed our method outperforms other query expansion methods in the evaluations of several criteria.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            },
            {
                "text": "Normally it is more than ten thousand.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In this paper, we use AT&T's method(Singhal et al., 1999) applied in TREC-8",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Topic numbers are",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "409, 410, 424, 425, 431, 432, 437 and 450",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Thus the performance in our experiments is a bit worse than the result of TREC-8",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Incremental relevance feedback",
                "authors": [
                    {
                        "first": "I",
                        "middle": [
                            "J"
                        ],
                        "last": "Aalbersberg",
                        "suffix": ""
                    }
                ],
                "year": 1992,
                "venue": "Proceedings of SIGIR '92",
                "volume": "",
                "issue": "",
                "pages": "11--22",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "I. J. Aalbersberg. 1992. Incremental relevance feedback. In Proceedings of SIGIR '92, pages 11-22.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Incremental relevance feedback for information filtering",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Allan",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Proceedings of SIGIR '96",
                "volume": "",
                "issue": "",
                "pages": "270--278",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Allan. 1996. Incremental relevance feedback for infor- mation filtering. In Proceedings of SIGIR '96, pages 270-278.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Semi-supervised learning using randomized mincuts",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Blum",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Blum and et al. 2004. Semi-supervised learning using randomized mincuts. In Proceedings of ICML 2004.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Sigir 2003 workshop report: Implicit measures of user interests and preferences",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Dumais",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Dumais and et al. 2003. Sigir 2003 workshop report: Implicit measures of user interests and preferences. In SIGIR Forum.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Extracting query modification from nonlinear svms",
                "authors": [
                    {
                        "first": "G",
                        "middle": [
                            "W"
                        ],
                        "last": "Flake",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of WWW",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. W. Flake and et al. 2002. Extracting query modifi- cation from nonlinear svms. In Proceedings of WWW 2002.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Manifold-ranking based image retrieval",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of Multimedia 2004",
                "volume": "",
                "issue": "",
                "pages": "9--13",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. He and et al. 2004. Manifold-ranking based image retrieval. In Proceedings of Multimedia 2004, pages 9-13. ACM.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Relevance feedback with a small number of relevance judgements: Incremental relevance feedback vs. document clustering",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Iwayama",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Proceedings of SIGIR 2000",
                "volume": "",
                "issue": "",
                "pages": "10--16",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. Iwayama. 2000. Relevance feedback with a small number of relevance judgements: Incremental rele- vance feedback vs. document clustering. In Proceed- ings of SIGIR 2000, pages 10-16.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Transductive inference for text classification using support vector machines",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Joachims",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Proceedings of ICML '99",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. Joachims. 1999. Transductive inference for text clas- sification using support vector machines. In Proceed- ings of ICML '99.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Transductive learning via spectral graph partitioning",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Joachims",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of ICML 2003",
                "volume": "",
                "issue": "",
                "pages": "143--151",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. Joachims. 2003. Transductive learning via spectral graph partitioning. In Proceedings of ICML 2003, pages 143-151.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Applying summarization techniques for term selection in relevance feedback",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "M"
                        ],
                        "last": "Lam-Adesina",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [
                            "J F"
                        ],
                        "last": "Jones",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Proceedings of SIGIR 2001",
                "volume": "",
                "issue": "",
                "pages": "1--9",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. M. Lam-Adesina and G. J. F. Jones. 2001. Applying summarization techniques for term selection in rele- vance feedback. In Proceedings of SIGIR 2001, pages 1-9.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Nonrelevance feedback document retrieva",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Onoda",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Murata",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Yamada",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of CIS 2004",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. Onoda, H. Murata, and S. Yamada. 2004. Non- relevance feedback document retrieva. In Proceedings of CIS 2004. IEEE.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "keysword spices: A new method for building domain-specific web search engines",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Oyama",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Proceedings of IJCAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Oyama and et al. 2001. keysword spices: A new method for building domain-specific web search en- gines. In Proceedings of IJCAI 2001.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "On term selection for query expansion",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "E"
                        ],
                        "last": "Robertson",
                        "suffix": ""
                    }
                ],
                "year": 1990,
                "venue": "Journal of Documentation",
                "volume": "46",
                "issue": "4",
                "pages": "359--364",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. E. Robertson. 1990. On term selection for query ex- pansion. Journal of Documentation, 46(4):359-364.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Overview of the okapi projects",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "E"
                        ],
                        "last": "Robertson",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Journal of the American Society for Information Science",
                "volume": "53",
                "issue": "1",
                "pages": "3--7",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. E. Robertson. 1997. Overview of the okapi projects. Journal of the American Society for Information Sci- ence, 53(1):3-7.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Re-examining the potential effectiveness of interactive query expansion",
                "authors": [
                    {
                        "first": "I",
                        "middle": [],
                        "last": "Ruthven",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of SIGIR 2003",
                "volume": "",
                "issue": "",
                "pages": "213--220",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "I. Ruthven. 2003. Re-examining the potential effective- ness of interactive query expansion. In Proceedings of SIGIR 2003, pages 213-220.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Statistical learning theory",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Vapnik",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "V Vapnik. 1998. Statistical learning theory. Wiley.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Overview of the eighth text retrieval conference",
                "authors": [
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Voorhees",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Harman",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "E. Voorhees and D. Harman. 1999. Overview of the eighth text retrieval conference.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Improving pseud-relevance feedback in web information retrieval using web page segmentation",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of WWW 2003",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Yu and et al. 2003. Improving pseud-relevance feed- back in web information retrieval using web page seg- mentation. In Proceedings of WWW 2003.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Semi-supervised learning using gaussian fields and harmonic functions",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of ICML 2003",
                "volume": "",
                "issue": "",
                "pages": "912--914",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X Zhu and et al. 2003. Semi-supervised learning using gaussian fields and harmonic functions. In Proceed- ings of ICML 2003, pages 912-914.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Fig) based on two judged documents (documents above the dashed line in the Figure).",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: A method to find tentative relevant documents",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>SGT prepares 2 estimation methods to set f p au-tomatically. One is to estimate from the fraction of positive examples in training examples. This method is not suitable for our task because f p is always fixed to 0.5 by this method if the number of training examples changes despite the number of relevant documents is small in many practical situa-tions. The other is to estimate with a heuristic that the difference between a setting of f p and the frac-tion of positive examples actually assigned by SGT should be as small as possible. The procedure pro-vided by SGT starts from f Input N tr // the number of training examples Output S // a set of sampling points piv = ln(N tr ); // sampling interval nsp = 0; // the number of sampling points for(i = piv; i \u2264 N tr -1; i+ = piv){ add i to ; nsp++; if(nsp == 10){ exit; } } Figure 1: Pseudo code of sampling procedure for f p</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>Okapi ini</td><td colspan=\"2\">0.466 0.345</td><td>0.286</td><td>0.239 0.195</td></tr><tr><td>SMART ini</td><td colspan=\"2\">0.460 0.336</td><td>0.271</td><td>0.229 0.187</td></tr></table>",
                "type_str": "table",
                "text": "Results of Initial Search",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>20</td><td colspan=\"2\">0.516 0.381</td><td>0.308</td><td>0.277 0.233</td></tr><tr><td>50</td><td colspan=\"2\">0.494 0.380</td><td>0.286</td><td>0.265 0.207</td></tr><tr><td>100</td><td colspan=\"2\">0.436 0.345</td><td>0.283</td><td>0.253 0.177</td></tr></table>",
                "type_str": "table",
                "text": "Results of Okapi sgt (5 terms expanded)",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>20</td><td colspan=\"2\">0.508 0.383</td><td>0.301</td><td>0.271 0.216</td></tr><tr><td>50</td><td colspan=\"2\">0.520 0.387</td><td>0.294</td><td>0.273 0.208</td></tr><tr><td>100</td><td colspan=\"2\">0.494 0.365</td><td>0.283</td><td>0.261 0.190</td></tr><tr><td colspan=\"5\">Table 4: Results of Okapi sgt (15 terms expanded)</td></tr><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>20</td><td colspan=\"2\">0.538 0.381</td><td>0.298</td><td>0.274 0.223</td></tr><tr><td>50</td><td colspan=\"2\">0.528 0.387</td><td>0.298</td><td>0.283 0.222</td></tr><tr><td>100</td><td colspan=\"2\">0.498 0.363</td><td>0.280</td><td>0.259 0.197</td></tr><tr><td colspan=\"5\">Table 5: Results of Okapi sgt (20 terms expanded)</td></tr><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>20</td><td colspan=\"2\">0.546 0.387</td><td>0.307</td><td>0.289 0.235</td></tr><tr><td>50</td><td colspan=\"2\">0.520 0.385</td><td>0.299</td><td>0.282 0.228</td></tr><tr><td>100</td><td colspan=\"2\">0.498 0.369</td><td>0.272</td><td>0.255 0.188</td></tr></table>",
                "type_str": "table",
                "text": "Results of Okapi sgt (10 terms expanded)",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td/><td/><td>5</td><td>10</td><td>15</td><td>20</td></tr><tr><td>Okapi sgt</td><td/><td colspan=\"3\">0.265 0.273 0.274 0.282</td></tr><tr><td>Okapi man</td><td/><td colspan=\"3\">0.210 0.189 0.172 0.169</td></tr><tr><td colspan=\"2\">SMART man</td><td colspan=\"3\">0.209 0.222 0.220 0.219</td></tr><tr><td colspan=\"5\">Table 7: Results of Manual Feedback Methods (10</td></tr><tr><td colspan=\"2\">terms expanded)</td><td/><td/></tr><tr><td/><td/><td>P10</td><td>P30</td><td>RPREC MAP R05P</td></tr><tr><td>Okapi sgt</td><td colspan=\"3\">0.520 0.387</td><td>0.294</td><td>0.273 0.208</td></tr><tr><td>Okapi man</td><td colspan=\"3\">0.420 0.285</td><td>0.212</td><td>0.189 0.132</td></tr><tr><td>SMART man</td><td colspan=\"3\">0.434 0.309</td><td>0.250</td><td>0.222 0.174</td></tr></table>",
                "type_str": "table",
                "text": "Results of Manual Feedback Methods  (MAP)",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td colspan=\"5\">: Results of Pseudo Feedback Methods</td></tr><tr><td>(MAP)</td><td/><td/><td/></tr><tr><td/><td/><td>5</td><td>10</td><td>15</td><td>20</td></tr><tr><td>Okapi sgt</td><td/><td colspan=\"3\">0.265 0.273 0.274 0.282</td></tr><tr><td>Okapi pse</td><td/><td colspan=\"3\">0.253 0.249 0.247 0.246</td></tr><tr><td colspan=\"2\">SMART pse</td><td colspan=\"3\">0.236 0.243 0.242 0.242</td></tr><tr><td colspan=\"5\">Table 9: Results of Pseudo Feedback Methods (10</td></tr><tr><td colspan=\"2\">terms expanded)</td><td/><td/></tr><tr><td/><td>P10</td><td>P30</td><td/><td>RPREC MAP R05P</td></tr><tr><td>Okapi sgt</td><td colspan=\"2\">0.520 0.387</td><td/><td>0.294</td><td>0.273 0.208</td></tr><tr><td>Okapi pse</td><td colspan=\"2\">0.478 0.369</td><td/><td>0.279</td><td>0.249 0.206</td></tr><tr><td>SMART pse</td><td colspan=\"2\">0.466 0.359</td><td/><td>0.272</td><td>0.243 0.187</td></tr><tr><td colspan=\"5\">SMART pse : This is a pseudo version of SMART.</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table><tr><td/><td>P10</td><td>P30</td><td colspan=\"2\">RPREC MAP R05P</td></tr><tr><td>20</td><td colspan=\"2\">0.498 0.372</td><td>0.288</td><td>0.265 0.222</td></tr><tr><td>50</td><td colspan=\"2\">0.456 0.359</td><td>0.294</td><td>0.268 0.200</td></tr><tr><td>100</td><td colspan=\"2\">0.452 0.335</td><td>0.270</td><td>0.246 0.186</td></tr><tr><td colspan=\"5\">user should select higher ranked documents for rel-</td></tr><tr><td colspan=\"2\">evance feedback.</td><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Results of Okapi sgt with random feedback (5 terms expanded)",
                "html": null,
                "num": null
            }
        }
    }
}