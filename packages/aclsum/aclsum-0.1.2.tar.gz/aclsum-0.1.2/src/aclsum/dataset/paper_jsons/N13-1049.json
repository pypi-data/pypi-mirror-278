{
    "paper_id": "N13-1049",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:58:56.074700Z"
    },
    "title": "Automatic Morphological Enrichment of a Morphologically Underspecified Treebank",
    "authors": [
        {
            "first": "Sarah",
            "middle": [],
            "last": "Alkuhlani",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Columbia University",
                "location": {}
            },
            "email": "salkuhlani@ccls.columbia.edu"
        },
        {
            "first": "Nizar",
            "middle": [],
            "last": "Habash",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Columbia University",
                "location": {}
            },
            "email": "habash@ccls.columbia.edu"
        },
        {
            "first": "Ryan",
            "middle": [],
            "last": "Roth",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Columbia University",
                "location": {}
            },
            "email": "ryanr@ccls.columbia.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "In this paper, we study the problem of automatic enrichment of a morphologically underspecified treebank for Arabic, a morphologically rich language. We show that we can map from a tagset of size six to one with 485 tags at an accuracy rate of 94%-95%. We can also identify the unspecified lemmas in the treebank with an accuracy over 97%. Furthermore, we demonstrate that using our automatic annotations improves the performance of a state-of-the-art Arabic morphological tagger. Our approach combines a variety of techniques from corpus-based statistical models to linguistic rules that target specific phenomena. These results suggest that the cost of treebanking can be reduced by designing underspecified treebanks that can be subsequently enriched automatically.",
    "pdf_parse": {
        "paper_id": "N13-1049",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "In this paper, we study the problem of automatic enrichment of a morphologically underspecified treebank for Arabic, a morphologically rich language. We show that we can map from a tagset of size six to one with 485 tags at an accuracy rate of 94%-95%. We can also identify the unspecified lemmas in the treebank with an accuracy over 97%. Furthermore, we demonstrate that using our automatic annotations improves the performance of a state-of-the-art Arabic morphological tagger. Our approach combines a variety of techniques from corpus-based statistical models to linguistic rules that target specific phenomena. These results suggest that the cost of treebanking can be reduced by designing underspecified treebanks that can be subsequently enriched automatically.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Collections of manually-annotated morphological and syntactic analyses of sentences, or treebanks, are an important resource for building statistical parsing models or for syntax-aware approaches to applications such as machine translation. Rich treebank annotations have also been used for a variety of natural language processing (NLP) applications such as tokenization, diacritization, part-of-speech (POS) tagging, morphological disambiguation, base phrase chunking, and semantic role labeling.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The development of a treebank with rich annotations is demanding in time and money, especially for morphologically complex languages. Consequently, the richer the annotation, the slower the annotation process and the smaller the size of the treebank. As such, a tradeoff is usually made between the size of the treebank and the richness of its annotations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we investigate the possibility of automatically enriching the morphologically underspecified Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009; Habash et al., 2009) with the more complex POS tags and lemmas used in the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) . We employ a variety of techniques that range from corpus-based statistical models to handwritten rules based on linguistic observations. Our best method reaches accuracy rates of 94%-95% on full POS tag identification. We can also identify the unspecified lemmas in CATiB with an accuracy over 97%. 37% of our POS tag errors are due to gold tree or gold POS errors. A learning curve experiment to evaluate the dependence of our method on annotated data shows that while the quality of some components may reduce sharply with less data (12% absolute reduction in accuracy when using 1 32 of the data or some 10K annotated words), the overall effect is a lot smaller (2% absolute drop). These results suggest that the cost of treebanking can be reduced by designing underspecified treebanks that can be subsequently enriched automatically.",
                "cite_spans": [
                    {
                        "start": 141,
                        "end": 164,
                        "text": "(Habash and Roth, 2009;",
                        "ref_id": null
                    },
                    {
                        "start": 165,
                        "end": 185,
                        "text": "Habash et al., 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 268,
                        "end": 291,
                        "text": "(Maamouri et al., 2004)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The rest of this paper is structured as follows: Section 2 presents related work; Section 3 details various language background facts about Arabic and its treebanking; Section 4 explains our approach; and Section 5 presents and discusses our results.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Arabic Treebanking There has been a lot work on building treebanks for different languages. In the case of Modern Standard Arabic (MSA), there are three efforts that vary in terms of richness and representation choice. The Penn Arabic Treebank (PATB) (Maamouri et al., 2004; Maamouri et al., 2009b; Maamouri et al., 2009a) , the Prague Arabic Dependency Treebank (PADT) (Smr\u017e and Haji\u010d, 2006; Smr\u017e et al., 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009; Habash et al., 2009) . The PATB uses phrase structure representation, while the other two use two different dependency representations. The PATB and PADT representations are quite detailed. The PATB not only provides tokenization, complex POS tags (485 tags in our data set), and syntactic structure; it also provides empty categories, diacritization, lemma choices, glosses and some semantic tags. In comparison CATiB only provides tokenization, six POS tags and eight dependency relations. The tradeoff is speed: CATiB's complete POS and syntax annotation rate is 540 tokens/hour (and annotator training takes two months), a much higher speed than reported for complete (POS and syntax) annotation in PATB (around 250-300 tokens/hour and 6-12 months for annotator training) and PADT (around 75 tokens/hour) (Habash and Roth, 2009) . An important recent addition to the family of Arabic treebanks is the Quran Treebank, which targets the Classical Arabic language of the Quran, not MSA (Dukes and Buckwalter, 2010).",
                "cite_spans": [
                    {
                        "start": 251,
                        "end": 274,
                        "text": "(Maamouri et al., 2004;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 275,
                        "end": 298,
                        "text": "Maamouri et al., 2009b;",
                        "ref_id": null
                    },
                    {
                        "start": 299,
                        "end": 322,
                        "text": "Maamouri et al., 2009a)",
                        "ref_id": null
                    },
                    {
                        "start": 370,
                        "end": 392,
                        "text": "(Smr\u017e and Haji\u010d, 2006;",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 393,
                        "end": 411,
                        "text": "Smr\u017e et al., 2008)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 453,
                        "end": 476,
                        "text": "(Habash and Roth, 2009;",
                        "ref_id": null
                    },
                    {
                        "start": 477,
                        "end": 497,
                        "text": "Habash et al., 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 1286,
                        "end": 1309,
                        "text": "(Habash and Roth, 2009)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Treebank Enrichment There has been a number of efforts on developing treebanks with rich representations and on treebank enrichment for many languages, such Danish, English, German, Italian and Spanish (Oepen et al., 2002; Hinrichs et al., 2004; M\u00fcller, 2010) . Additionally, there has been some work on Arabic treebank enrichment that built on the PATB by manually extending its already rich annotations or automatically converting them to new formalisms. The Arabic Propbank (Propositional Bank) (Palmer et al., 2008) and the OntoNotes project (Hovy et al., 2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case.",
                "cite_spans": [
                    {
                        "start": 202,
                        "end": 222,
                        "text": "(Oepen et al., 2002;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 223,
                        "end": 245,
                        "text": "Hinrichs et al., 2004;",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 246,
                        "end": 259,
                        "text": "M\u00fcller, 2010)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 498,
                        "end": 519,
                        "text": "(Palmer et al., 2008)",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 546,
                        "end": 565,
                        "text": "(Hovy et al., 2006)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 613,
                        "end": 640,
                        "text": "Alkuhlani and Habash (2011)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 733,
                        "end": 744,
                        "text": "Diab (2012)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 796,
                        "end": 816,
                        "text": "Tounsi et al. (2009)",
                        "ref_id": null
                    },
                    {
                        "start": 915,
                        "end": 937,
                        "text": "Habash and Roth (2009)",
                        "ref_id": null
                    },
                    {
                        "start": 1160,
                        "end": 1181,
                        "text": "Habash et al. (2007a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Haji\u010d et al., 2005; Roth et al., 2008; Habash et al., 2013) . These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information.",
                "cite_spans": [
                    {
                        "start": 113,
                        "end": 132,
                        "text": "(Diab et al., 2004;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 133,
                        "end": 157,
                        "text": "Habash and Rambow, 2005;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 158,
                        "end": 177,
                        "text": "Smith et al., 2005;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 178,
                        "end": 197,
                        "text": "Haji\u010d et al., 2005;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 198,
                        "end": 216,
                        "text": "Roth et al., 2008;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 217,
                        "end": 237,
                        "text": "Habash et al., 2013)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic parsing. Using morphological features such as case has also improved parsing for Russian, Turkish and Hindi (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009) . Other work has shown value for morphology in the context of Arabic named entity recognition (Benajiba et al., 2009) . These results support the value of our goal of enriching resources with morphological information, which then can be used to improve different NLP applications.",
                "cite_spans": [
                    {
                        "start": 112,
                        "end": 132,
                        "text": "Marton et al. (2011)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 283,
                        "end": 303,
                        "text": "(Nivre et al., 2008;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 304,
                        "end": 325,
                        "text": "Eryigit et al., 2008;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 326,
                        "end": 338,
                        "text": "Nivre, 2009)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 433,
                        "end": 456,
                        "text": "(Benajiba et al., 2009)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "In this section, we present some relevant general linguistic facts about Arabic and then discuss the specifics of the tagsets we work with in this paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "Arabic Linguistic Facts The Arabic language poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional and cliticizational morphology, e.g., the word A\u00d3 E\u00d2J . \u21e3 J\u222bJ \u2326 \u00c9\uf8ff w+s+y-ktb-wn+hA1 'and they will write it' has two proclitics, one prefix, one suffix and one pronominal enclitic. Additionally, Arabic has a high degree of ambigiouty due to the absence of the diacritics and inconsistent spelling of letters such as Alif, @ \u00c2 and Ya \u2326 y. The Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) , which is used in the PATB, produces an average of 12 analyses per word.",
                "cite_spans": [
                    {
                        "start": 543,
                        "end": 561,
                        "text": "(Buckwalter, 2004)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "In this paper, we work with gold tokenized Arabic as it appears in the PATB and CATiB treebanks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "As such, the words are partially disambiguated with regards to possible tokenizable clitics and Alif/Ya spelling forms. That said, there is still a lot of ambiguity remaining especially because diacritics are not marked. Words in the treebank may be ambiguous in terms of their POS, lemmas and inflectional features. The inflectional features include gender, number, person, case, state, mood, voice, aspect and the presence of the determiner +\u00bb@ Al+ 'the', which is not tokenized off in the treebanks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "Arabic has a well known discrepancy in form and function that appears most commonly in the form of irregular plurals, called Broken Plurals, which although functionally are plural, have singular suffixes. We will not discuss form and function discrepancy in this paper except as needed. For more on this see Habash (2010) .",
                "cite_spans": [
                    {
                        "start": 308,
                        "end": 321,
                        "text": "Habash (2010)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "The Buckwalter Tagset The Buckwalter POS tagset is perhaps one of the most commonly used tagsets for Arabic NLP research. The tagset's popularity is in part due to its use in the PATB. Buckwalter tags can be used for tokenized and untokenized text. The untokenized tags are produced by BAMA (Buckwalter, 2004) and consist of 485 tags. The tokenized tags, which are used in the PATB, are derived from the untokenized tags and can reach thousands of tags. Both variants use the same basic 70 or so sub-tag symbols (such as DET 'determiner', NSUFF 'nominal suffix', ADJ 'adjective' and ACC 'accusative') (Maamouri et al., 2009a) . These sub-tags are combined to form around 170 morpheme tags such as NSUFF_FEM_SG 'feminine singular nominal suffix' and CASE_DEF_ACC 'accusative definite'. The word tags are constructed out of one or more morpheme tags, e.g. DET+NOUN_PROP+CASE_DEF_NOM for the word \u2022 \u2326 \u00ed\u00c0@ Al+Siyn+u 'China'.",
                "cite_spans": [
                    {
                        "start": 291,
                        "end": 309,
                        "text": "(Buckwalter, 2004)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 601,
                        "end": 625,
                        "text": "(Maamouri et al., 2009a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "CATiB Trees and POS Tags CATiB uses the same basic tokenization scheme used by PATB and PADT. However, the CATiB POS tagset is much smaller. Whereas in practice PATB uses 485 Buckwalter tags specifying every aspect of Arabic word morphology such as definiteness, gender, number, person, mood, voice and case, CATiB uses 6 POS tags: NOM (non-proper nominals including nouns, pronouns, adjectives and adverbs), PROP (proper nouns), VRB (verbs), VRB-PASS (passive-voice verbs), PRT (particles such as prepositions or con-",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "VRB \u2026\u00c9Q \u21e3 K trsl --- IV3FS+IV+IVSUFF_MOOD:I \u2026\u00c9 @ >arsal 'send' MOD PRT + s+ --- FUT_PART + sa+ 'will' SBJ PROP \u2022 \u2326 \u00ed\u00c0@ AlSyn --- DET+NOUN_PROP +CASE_DEF_NOM \u2022 \u2326 \u00ec Siyn 'China' OBJ NOM @ Q' \u21e3 \u00d8 qmrA --- NOUN +CASE_INDEF_ACC Q' \u21e3 \u00d8 qamar 'moon' MOD NOM AJ \u2326 \u00b4A J\u00a2\u00ec@ <STnAEyA --- ADJ +CASE_INDEF_ACC \u02d9\u2326\u00b4A J\u00a2\u00ec@ <iSTinAEy 'artificial' MOD PRT \u02d9\u00d5@ <lY --- PREP \u02d9\u00d5@ <lY 'to' OBJ PROP t \u21e2' \u2326Q\u00f7 oe@ Almryx --- DET+NOUN_PROP +CASE_DEF_GEN",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "t \u21e2' \u2326Q\" mar iyx 'Mars' Figure 1 : An example dependency tree for the sentence t \u21e2' \u2326Q\u00f7 oe@ \u02d9\u00d5@ AJ \u2326 \u00b4A J\u00a2\u00ec@ @ Q' \u21e3 \u00d8 Y J\u00cd\u00c0@ \u2026\u00c9 Q \u21e3 \u00c9 s+trsl Alhnd qmrA <STnAEyA <lY Almryx 'India will send a satellite to Mars [in 2013]'. In every tree node, the terms above the line are part of the CATiB annotations: the word, POS (VRB = verb, PRT = particle, PROP = proper noun, NOM = nominal) and relation (MOD = modifier, SBJ = subject, OBJ = object). The terms under the line are the Buckwalter POS tag, the lemma and the gloss, respectively.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 31,
                        "end": 32,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "analyses as a constraint on the space from which we will select the appropriate in context tag. The approach is quite similar to how MADA (morphological analysis and disambiguation for Arabic) (Habash and Rambow, 2005) works except that we are using the CATiB tree as the context in which we disambiguate. Given the degree of richness of the tree, we expect to outperform basic disambiguation on text.",
                "cite_spans": [
                    {
                        "start": 193,
                        "end": 218,
                        "text": "(Habash and Rambow, 2005)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "In the rest of this section, we discuss our general strategy, followed by a detailed presentation of our approach: morphological disambiguation and morphological filtering.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Background",
                "sec_num": "3"
            },
            {
                "text": "In CATiB trees, different pieces of information can be relevant to different disambiguation tasks. We analyzed the data we have and obtained the following observations which we use to devise our strategy for how to address different types of ambiguity:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 Words in CATiB treebank are tokenized. This resolves many ambiguous cases: analyses involving cliticized prepositions or conjunctions are dismissed. Further more, separated clitics are marked, which restricts their reading.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 The CATiB POS tag, although two orders of magnitude smaller than the Buckwalter tag set, provides a lot of information. It resolves ambiguity amongst verbs (active or passive), nominals, particles, proper nouns and punctuation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 The CATiB tags NOM or PRT are the most ambiguous. They are challenging because there are both lexical and morphosyntactic features at play. We rely on our training data to learn models of how to disambiguate them. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "t \u21e2' \u2326 Q\u00f7oe@ \u02d9\u00d5@ AJ \u2326 \u00b4A J\u00a2\u00ec@ @ Q' \u21e3 \u00d8 \u2022 \u2326 \u00ed\u00c0@ \u2026\u00c9 Q \u21e3 \u00c9 s+trsl AlSyn qmrA",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u01cdSTnA yA \u01cdl\u00fd Almryx 'China will send a satellite to Mars'. In every tree node, the terms above the line are part of the CATiB annotations: the word, POS (VRB, PRT, PROP, NOM) and relation (MOD, SBJ, OBJ). The terms under the line are the Buckwalter POS tag, the lemma and the gloss, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "junctions) and PNX (punctuation). CATiB uses a dependency representation that models predicateargument structure (subject, object, etc.) and Arabic nominal structure (idafa, tamyiz, modification (Habash and Roth, 2009) . A detailed dis-cussion of CATiB guidelines and further comparison with PATB appears in (Habash et al., 2009) .",
                "cite_spans": [
                    {
                        "start": 195,
                        "end": 218,
                        "text": "(Habash and Roth, 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 308,
                        "end": 329,
                        "text": "(Habash et al., 2009)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "In this paper, we target the enrichment of CATiB with the morphological information used in the PATB: Buckwalter POS tags and lemmas. We do not address other kinds of rich information. Figure 1 presents an example of a CATiB tree with the extensions we predict automatically for each word.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 192,
                        "end": 193,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "We define our task as assigning a Buckwalter POS tag and lemma to each word in a CATiB syntactic tree, i.e., disambiguating the CATiB POS tag in terms of the finer grained Buckwalter tag in context. Our approach utilizes a variety of corpus-based and rule-based techniques. We use corpus-based techniques that exploit available training data in the form of portions of the PATB that are automatically converted to CATiB style trees. We also use rule-based solutions that allow us to apply linguistic knowledge and insights. An important tool that we use is a morphological analyzer which generates for every word all possible out-of-context analyses. We use these analyses as a constraint on the space from which we will select the appropriate in-context tag. The approach is quite similar to how MADA (Morphological Analysis and Disambiguation for Arabic) (Habash and Rambow, 2005) works except that we are using the CATiB tree as the context in which we disambiguate. Given the degree of richness of the tree, we expect to outperform basic disambiguation on text.",
                "cite_spans": [
                    {
                        "start": 857,
                        "end": 882,
                        "text": "(Habash and Rambow, 2005)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": "4"
            },
            {
                "text": "In the rest of this section, we discuss our general strategy, followed by a detailed presentation of our approach: morphological disambiguation and morphological filtering.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": "4"
            },
            {
                "text": "In CATiB trees, different pieces of information can be relevant to different disambiguation tasks. We analyzed a sample of the data we have and obtained the following observations which we use to devise our strategy for how to address different types of ambiguity:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 Words in the CATiB treebank are tokenized. This resolves many ambiguous cases: analyses involving cliticized prepositions or conjunctions are dismissed. Further more, sepa-rated clitics are marked, which restricts their reading. The ambiguity in terms of the number of lemmas per word reduces from 2.7 for untokenized words to just 1.1 for tokenized words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 The CATiB POS tagset, although two orders of magnitude smaller than the Buckwalter tagset, provides a lot of information. It resolves ambiguity amongst verbs (active or passive), nominals, particles, proper nouns and punctuation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 The CATiB tags NOM and PRT are the most ambiguous. They are challenging because there are both lexical and morphosyntactic features at play. We rely on our training data to learn models of how to disambiguate them. The CATiB treebank annotation does not deterministically allow us to identify the finer grained tag using the POS and relations alone: e.g., the NOM child of an NOM parent (with the relation MOD) can be an ADJ (67% probability) or a NOUN (21%).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 Case, state, mood and to a lesser degree aspect are syntactically dependent features, for which we use the CATiB tree and linguistic rules to disambiguate the correct value in context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 Gender, number and person are expressed using affixes that highly limit the feature-value possibilities, e.g., the suffix \u21e3 \u00cb+ +h deterministically selects for +NSUFF_FEM_SG suffix tag.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "From CATiB to Buckwalter: Devising a Strategy",
                "sec_num": "4.1"
            },
            {
                "text": "We use the morphological analyzer BAMA to get a list of all possible analyses for a word. BAMA returns unranked analyses for untokenized text only.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Morphological Analysis & Disambiguation",
                "sec_num": "4.2"
            },
            {
                "text": "Since we know that the input is already tokenized, we built an extension to BAMA that handles clitics and accepts analyses that are consistent with the tokenization of the input, discarding all other analyses. We use both the morphological analyzer BAMA and a training set from the PATB to predict the Buckwalter tag for a given word. We use BAMA to get a list of all possible Buckwalter tag and lemma pairs for each word. We then rank these choices using one of the following two methods: a maximum likelihood estimate model (MLE) conditioned on specific features in the CATiB tree or a MADA-like suite of classifiers that select for specific POS tag features such as gender or number.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Morphological Analysis & Disambiguation",
                "sec_num": "4.2"
            },
            {
                "text": "The MLE model ranks the set of choices from BAMA returning the most probable analysis. We consider two models:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Maximum Likelihood Model",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 MLE Baseline 1 selects the Buckwalter tag with the highest unconditioned probability in the training data, P(BW), among the set of BAMA choices for the word whose tag we want to determine.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Maximum Likelihood Model",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 MLE Baseline 2 selects the Buckwalter tag with the highest probability conditioned on the word and CATiB tag: P(BW|word,CATiB). This model backs off to the Buckwalter tag with the highest probability conditioned on the CATiB tag, i.e., P(BW|CATiB), and then backs off to MLE Baseline 1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Maximum Likelihood Model",
                "sec_num": "4.2.1"
            },
            {
                "text": "We retrained the MADA system (Habash and Rambow, 2005) using a tokenized version of the PATB. We call the new version TADA: Tokenized Analysis and Disambiguation of Arabic. TADA takes tokenized text, and returns a ranked list of analyses for each tokenized word and clitic. Just like MADA, TADA uses BAMA to identify possible analyses of the word. It then uses a suite of classifiers to predict inflectional and lexical features that are used to rank the possible analyses.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Disambiguation of Tokenized Arabic",
                "sec_num": "4.2.2"
            },
            {
                "text": "As expected, TADA outperforms the simple MLE models described earlier; however, its performance is not high enough since it makes no use of tree features. The results are presented in Section 5. However, we will present here a preliminary error analysis of TADA's output to motivate the morphological filters presented next (Section 4.3).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Disambiguation of Tokenized Arabic",
                "sec_num": "4.2.2"
            },
            {
                "text": "We considered the first 100 errors in the Buckwalter tags in our development set. About half of the errors involved a problem in case (42%), state (13%) or mood (3%). Case and state errors had many overlaps. All of these errors are syntactically determinable using the tree representation in a manner similar to Habash et al. (2007a) . In 17% of the cases, a POS error can be resolved using the CATiB tag, (e.g., proper noun vs adjective or verb). In 2% of the cases, the error involved an orthographic normalization (Alifform) that led to an undesirable solution (e.g., \u21e3 \u00c8 J\u00c7\u00c0 @",
                "cite_spans": [
                    {
                        "start": 312,
                        "end": 333,
                        "text": "Habash et al. (2007a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TADA Preliminary Error Analysis",
                "sec_num": null
            },
            {
                "text": "\u00c2lsnh 'tongues' vs \u21e3 \u00c8 J\u00c7\u00c0@ Alsnh 'the-year'). These cases should be resolved by enforcing the CATiB tree word form. Ambiguity in CATiB tags was a problem for nominal forms 15% of the time (e.g., NOUN vs ADJ), particles 10% of the time (e.g., +\uf8ff w+ 'and' can be CONJ or SUB_CONJ), and pronouns 5% of the time (e.g., -\u00ce+ +hm 'them' can be IVSUFF_DO:3MP or PVSUFF_DO:3MP [attached to an imperfective or perfective verb]).2 In 1% of the cases, there was an error involving ambiguity in number (dual/plural). And finally, in 3% of the cases, we determined that the gold POS tag was actually incorrect. Within the same set of sentences studied, we found 18 lemma choice errors. Almost all, except for three cases, involve a nominal form ambiguity resulting from diacrtic absence, e.g., XY\u00cd\" muhad\u21e0id 'threatening' or muhad\u21e0ad 'threatened'. Eight of the 18 cases (or 44%) happened without an accompanying POS error. Overall, the accuracy of lemma choice is highly dependent on the correctness of the chosen core Buckwalter tag; lemma accuracy when the tag is correct is 97.9%, but it drops to 71.3% when the tag is wrong.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TADA Preliminary Error Analysis",
                "sec_num": null
            },
            {
                "text": "We implemented a set of filters that take the list of ranked analyses produced by TADA and discard any analyses that are inconsistent with the filters' decisions in the tree context. TADA ranking is preserved among the remaining analyses.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Morphological Filters",
                "sec_num": "4.3"
            },
            {
                "text": "TADA returns all analyses for word, including different forms of the word (i.e., different Alif/Ya forms as part of BAMA's back-off mode). For example, when given the word \u02d9OE\u00b4 l\u00fd, TADA returns analyses for both the words \u02d9OE\u00b4 l\u00fd 'on' and \u02d9\u2326OE \u00b4 ly 'Ali'. Since the input to our system is the gold word form from CATiB trees, the CATiB filter will discard analyses that do not match the given word form.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "CATiB Filter",
                "sec_num": "4.3.1"
            },
            {
                "text": "The CATiB filter also resolves some POS ambiguity given information in the CATiB POS tag. For example, the CATiB POS tags NOM or VRB can easily decide whether the ambiguous word I .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "CATiB Filter",
                "sec_num": "4.3.1"
            },
            {
                "text": "\u21e3 KA\u00f8 kAtb is a noun (kAtib 'writer') or a verb (kAtab 'to correspond').",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "CATiB Filter",
                "sec_num": "4.3.1"
            },
            {
                "text": "The pronominal filter (PRON) selects the pronouns that are consistent with the verbs they are attached to. A pronoun attached to a verb could either be IVSUFF_DO, PVSUFF_DO or CVSUFF_DO depending on whether the verb is imperfective (IV), perfective (PV), or imperative (CV).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pronominal Filter",
                "sec_num": "4.3.2"
            },
            {
                "text": "The noun/adjective (NOUN/ADJ) filter is applied to words with the CATiB tag NOM. It uses a nominal classifier, which classifies CATiB NOM words into one of the following Buckwalter noun/adjective classes: NOUN, NOUN.VN, NOUN_QUANT, NOUN_NUM, ADJ, ADJ.VN, ADV_COMP, ADV_NUM. The NA (notapplicable) tag is assigned to all other words. For example, the classifier will decide whether \u21e3 \u00cb Q \u2326 J . \u00aa kbyrh is a noun 'abomination' or an adjective 'great [feminine singular]' based on the context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Noun/Adjective Filter",
                "sec_num": "4.3.3"
            },
            {
                "text": "To build the nominal classifier, we use Yamcha (Kudo and Matsumoto, 2003) , a support-vectormachine-based sequence tagger trained on our PATB training data. We use the following set of features: the word form, CATiB POS tag, parent features (word form, CATiB POS tag), dependency relation, order of appearance (the word comes before or after its parent), the distance between the word and its parent, and different types of relation-child POS (REL-CTB) features. The REL-CTB features state whether a word has a child with a CATiB POS (CTB) under a dependency relation (REL). A word can have 0 or more children. We have six CATiB POS tags and eight dependency relations and thus up to 48 different REL-CTB binary learning features. An example of this feature is a PRT that has a child NOM under a dependency relation OBJ. In this case, the value of the feature OBJ-NOM is 1. We also add a window of two words before and two words after the word being tagged as static features, and the tag of the previous two words as dynamic features. The nominal classifier predicts the correct nominal class with an accuracy of 97.70%.",
                "cite_spans": [
                    {
                        "start": 47,
                        "end": 73,
                        "text": "(Kudo and Matsumoto, 2003)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Noun/Adjective Filter",
                "sec_num": "4.3.3"
            },
            {
                "text": "The particle filter (PRT) selects the specific Buckwalter POS for a particle. For example, the particle A\" mA can be the negative particle 'not', the relative pronoun 'that' or the interrogative pronoun 'what?'. The PRT filter uses a particle classifier that uses the same learning features and training data as the nominal classifier. The particle classifier predicts the correct particle class with an accuracy of 99.54%.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Particle Filter",
                "sec_num": "4.3.4"
            },
            {
                "text": "The Buckwalter POS tags for verbs have three markers for aspect: imperfective (IV), perfective (PV), and imperative (CV); and three markers for mood: jussive (J), subjunctive (S) and indicative (I). We apply our rule-based mood-and-aspect filter (MOOD/ASPECT) to words that have the CATiB tag VRB or VRB-PASS.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Verbal Mood and Aspect Filter",
                "sec_num": "4.3.5"
            },
            {
                "text": "If the verb is preceded by a jussive, subjunctive or future particle then it is imperfective in aspect and its mood is determined by the particle. The mood is indicative if the verb is preceded by a future particle such as \u00a8\u00d2\u00c9 swf 'will'; it is jussive if the verb is preceded by a jussive particle such as '\u00c0 lm 'not+past', +\u00bb l+ 'for'; and it is subjunctive if the verb is preceded by a subjunctive particle such as \u2021 @ \u00c2n 'that', \u2022\u00c0 ln 'not+future', \u02d9\u2326\u00aa ky 'so as to', and \u02d9\u21e3 \u00cak Ht\u00fd 'until'. This is also valid when a negating B lA intervenes between the subjunctive particle and the verb.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Verbal Mood and Aspect Filter",
                "sec_num": "4.3.5"
            },
            {
                "text": "If the verb is proceeded with the particle Y \u21e3 AE\u00c0 lqd 'already', then the verb is perfective. Otherwise, the verb could be either imperfective (with an indicative mood), perfective or imperative (all allowed through the filter).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Verbal Mood and Aspect Filter",
                "sec_num": "4.3.5"
            },
            {
                "text": "The Buckwalter POS tags have three nominal state markers: INDEF, DEF and POSS. 3 The nominal state filter (STATE) applies the following rules: If the word is head of an idafa (IDF), then we exclude the INDEF analyses. Otherwise, we exclude the POSS and the non-Al/DET determined DEF analysis (which are only used for IDF heads).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal State Filter",
                "sec_num": "4.3.6"
            },
            {
                "text": "The nominal case filter (CASE) assigns the values nom (nominative), acc (accusative) or gen (genitive) to each NOM/PROP word primarily based on the CATiB dependency relation label that describes the type of relation between the word and its parent. The nominal case filter extends the case predictor in Habash et al. (2007a) . The following four rules are applied in sequence.",
                "cite_spans": [
                    {
                        "start": 303,
                        "end": 324,
                        "text": "Habash et al. (2007a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal Case Filter",
                "sec_num": "4.3.7"
            },
            {
                "text": "\u2022 RULE 1: Assign acc to all NOM/PROP words as a default.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal Case Filter",
                "sec_num": "4.3.7"
            },
            {
                "text": "\u2022 RULE 2: Assign nom to NOM/PROP words that (a) head the tree, (b) have the label TPC, (c) have the label SBJ but are not headed by a particle from the closed class of Inna and its sisters (Habash et al., 2007a) , or (d) have the label PRD but is not headed by a verb or deverbal noun. Exempt words in the closed class of adverb-like nouns such as \u21e3 \u00dc\u00d2 \u00d8 fwq 'over', \u2026J . \u21e3 \u00d8 qbl 'before', and \u00bb\u00d2k Hwl 'around'.",
                "cite_spans": [
                    {
                        "start": 189,
                        "end": 211,
                        "text": "(Habash et al., 2007a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal Case Filter",
                "sec_num": "4.3.7"
            },
            {
                "text": "\u2022 RULE 3: Assign gen to NOM/PROP words that have the label OBJ under a preposition, or that have the label IDF.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal Case Filter",
                "sec_num": "4.3.7"
            },
            {
                "text": "\u2022 RULE 4: All children of NOM/PROP parents whose label is MOD, and NOM/PROP children of conjunctions whose label is OBJ, copy the case of their parent. Conjunctions carry the case temporarily to pass on agreement.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Nominal Case Filter",
                "sec_num": "4.3.7"
            },
            {
                "text": "We added an MLE-based component to override answers that are provided by our final system. We used a no-BAMA version of the MLE Baseline 2. The difference between the MLE override component and MLE Baseline 2 is that it takes into account all possible Buckwalter POS tags that appear in the training set for a specific word regardless of whether they are provided by BAMA or not. This MLE override component is trained on the same training set and returns the most common Buckwalter tag and lemma pair for a given word form and CATiB POS tag pair. BAMA is not used here since the reason behind this additional step is to overcome any limitation caused by using BAMA to start with. These limitations include primarily cases of BAMA failure to produce analyses (OOV) or minor version differences between BAMA and the PATB. If a Buckwalter tag and lemma pair appear above a threshold of n times and always with the same word-lemma pair, then we override our answer with the new answer from the MLE. When we override, we only override the core part of the Buckwalter tag. We do not override the state, case, and mood features since they are syntactic features. We tried different values for the threshold and got the best results when n = 4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MLE Override",
                "sec_num": "4.3.8"
            },
            {
                "text": "TADA provides an initial list of ranked analyses. Then, the morphological filters discard analyses that are not consistent with the CATiB tree information. The analysis with the highest TADA rank among the remaining analyses is selected as the answer.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Putting it All Together",
                "sec_num": "4.4"
            },
            {
                "text": "We apply our filters in the following order. We first apply the CATiB filter. After that, we apply the pronominal, noun/adjective and particle filters. These three filters can be applied in any order since they are applied on disjoint sets of words. The next filter is the mood/aspect filter which has to be applied after the particle filter since it depends on the particle choice in predicting the mood of the following verb. At this point, we freeze the lemma choice for the word. The next two filters, state and case, look at syntactic features and should not affect the choice of the lemma.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Putting it All Together",
                "sec_num": "4.4"
            },
            {
                "text": "We use two back-off mechanisms. The first one is with the application of each filter. If the effect of applying a filter results in an empty set (no match found) then we undo the effect of the filter and pass the list of analyses as is to the next filter. The second mechanism is using the MLE override at the end of the pipeline. TADA, the noun/adjective and particle filters, and the MLE override use corpus-based components while all other filters are rule-based.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Putting it All Together",
                "sec_num": "4.4"
            },
            {
                "text": "We use a CATiB version of the PATB part 3v3.1 and part 2v3.0 released by the Linguistic Data Consortium (LDC) (Maamouri et al., 2004) . We use the train/development/test (80/10/10) splits of Marton et al. (2010) for PATB part 3v3.1 (16.6K sentences; 400K tokens): we use their train as our training data, their development as the tuning data for TADA and their test as our development set. For our blind test, we use the first 1000 sentences in PATB part 2v3.0 (38K tokens).",
                "cite_spans": [
                    {
                        "start": 110,
                        "end": 133,
                        "text": "(Maamouri et al., 2004)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 191,
                        "end": 211,
                        "text": "Marton et al. (2010)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": "We report all results in terms of token accuracy on the full Buckwalter tag, reduced Buckwalter tag and the lemma. The reduced Buckwalter tag is the Buckwalter tag without case, state, and mood. The number of tags is reduced to 220 tags (compared to 485 tags for the full Buckwalter tagset).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": "In cases of gold full Buckwalter tags that are underspecified for case, state or mood, we do not penalize our systems if our more specific predicted ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": "Table 1 shows the results of our experiments on the development set. Considering the baseline systems, we see that using both the CATiB POS tag and the word form in MLE Baseline 2 gives us a 20.5% absolute increase above MLE Baseline 1. Using TADA improves the performance significantly (adding 8.46% absolute over MLE Baseline 2). Every additional morphological filter has a positive impact and the improvement of the accuracy for full Buckwalter with each new filter ranged between 0.22% and 1.18% absolute except for the case filter, which adds almost 5%. Adding the MLE override has a positive impact on the accuracy of the full and reduced Buckwalter tags and the lemma.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.2"
            },
            {
                "text": "We apply our baselines, TADA, TADA+filters and TADA+filters+MLE to the blind test set (see Table 2). The test set is a bit harder than the development set, but the results are consistent with those seen for the development set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.2"
            },
            {
                "text": "We conducted an analysis of the errors in the output of the final system TADA+filters+MLE on the development set. We considered 100 randomly selected error cases and examined them in the CATiB trees ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "5.3"
            },
            {
                "text": "The non-rule-based components of our approach, namely TADA, NOUN/ADJ and PRT filters, and MLE override depend on the existence of an annotated treebank in rich format. To understand the degree of dependence, we ran a series of experiments on different sizes of the training data:1 2 , 1 4 , 1 8 , 1 16 , and 1 32 of the full training set (341.1K words). These data sets were used to train new versions of TADA, the NOUN/ADJ and PRT filters, and the MLE override. The results of running TADA and the final system on the development set using the different data sets are summarized in Tables 3 and 4 , respectively. As expected, when the training data size goes down the accuracy goes down. Our final system, which adds filters on top of TADA, had a significant effect on the performance as shown in Table 4 . Using only 10.6K of annotated words, the quality of TADA reduces sharply (12.12% absolute reduction in accuracy) while the overall effect on our full system is a lot smaller (2.03% absolute drop). Similarly, the performance of the nominal and particle classifiers degrade when trained on less data. When we use on the full training data, which may not be optimal for smaller data sets. The contribution of our full system over TADA when using 1 32 of the full training data is over 19% absolute (on full Buckwalter tag determination) compared to 9% when using the full training data. The morph analysis (out of context) is the same for all experiments and that this provides a lot of stability to the results. The high lemma accuracy overall is a result of disambiguating tokenized words, where the average numbers of lemmas per word is only 1.1 as mentioned above. These results suggest that our approach is usable even in the early stages of developing new richly annotated treebanks.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 590,
                        "end": 591,
                        "text": "3",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 596,
                        "end": 597,
                        "text": "4",
                        "ref_id": "TABREF4"
                    },
                    {
                        "start": 804,
                        "end": 805,
                        "text": "4",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Learning Curve Study",
                "sec_num": "5.4"
            },
            {
                "text": "We applied our automatic enrichment to the underspecified CATiB treebank (as opposed to the parts of PATB, which we used throughout the paper to simulate CATiB). We evaluate the added value of these annotations by using them to extend the training data for the morphological tagger MADA (Habash and Rambow, 2005) , which is used on untokenized text. We train a new set of MADA classifier models using a combination of the original MADA (v 3.2) training data (578K words taken from PATBs 1, 2 and 3) and the enriched CATiB data (218K words). We apply the new MADA system to our development set and evaluate on several metrics. As a baseline, we process the same development set using MADA (v 3.2). Other than the training data used to construct the classifier models, there are no differences between the two systems. The CATiB-enriched system results in a Buckwalter POS tag accuracy of 85.6% (a 2.2% error reduction over the baseline). When evaluating on the set of 14 MADA morphological features, the new system results in a 85.7% accuracy (2.4% error reduction). The new system also improves PATB segmentation accuracy (99.2%, a 5.4% error reduction). In the future, we will evaluate the contribution of the additional annotations in the context of other applications, such as syntactic parsing.",
                "cite_spans": [
                    {
                        "start": 287,
                        "end": 312,
                        "text": "(Habash and Rambow, 2005)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extrinsic Evaluation",
                "sec_num": "5.5"
            },
            {
                "text": "We have demonstrated that an underspecified version of an Arabic treebank can be fully specified for Arabic's rich morphology automatically at an accuracy rate of 94%-95% for POS tags and 97% for lemmas. Our approach combines a variety of techniques from corpus-based statistical models (which require some rich annotations) to linguistic rules that target specific phenomena. Since the underspecified treebank is much faster to manually annotate than its fully specified version, these results suggest that the cost of treebanking can be reduced by designing underspecified treebanks that can be subsequently enriched automatically.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "In the future, we plan to extend the automatic enrichment effort to include more complex features such as empty nodes and semantic labels. We also plan to take the insights from this effort and apply them to treebanks of other languages. A small portion of a treebank that is fully annotated in rich format will of course be needed before we can apply these insights to other languages.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme(Habash et al.,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "2007b): (in alphabetical order) Abt jHxd\u00f0rzs\u0161SDT \u010e fqklmnhwy and the additional symbols: ' Z, \u00c2 @, \u01cd @ , \u0100 @, \u0175 \uf8ff', \u0177 Z\u00af', h \u21e3 \u00cb, \u00fd \u00af.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This is a peculiarity of the tagset used in PATB. The distinction does not seem to be necessary to our knowledge, but we still consider it the gold goal.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "These values do not exactly match the functional values for state in Arabic(Smr\u017e, 2007).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "32 of the training data, the correct nominal class is predicted at an accuracy of 90.49% (7.21% absolute drop), while the correct particle class is predicted at an accuracy of 96.59% (2.95% absolute drop). We used the MLE override threshold determined based",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "The first author was funded by a scholarship from the Saudi Arabian Ministry of Higher Education. The rest of the work was funded under DARPA projects number HR0011-08-C-0004 and HR0011-12-C-0014. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "AWATIF: A Multi-Genre Corpus for Modern Standard Arabic Subjectivity and Sentiment Analysis. The 8th International Conference on Language Resources and Evaluation",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Abdul-Mageed",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Diab",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. Abdul-Mageed and M. Diab. 2012. AWATIF: A Multi-Genre Corpus for Modern Standard Arabic Sub- jectivity and Sentiment Analysis. The 8th Interna- tional Conference on Language Resources and Eval- uation (LREC2012).",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality",
                "authors": [
                    {
                        "first": "Sarah",
                        "middle": [],
                        "last": "Alkuhlani",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL'11)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sarah Alkuhlani and Nizar Habash. 2011. A Corpus for Modeling Morpho-Syntactic Agreement in Ara- bic: Gender, Number and Rationality. In Proceed- ings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL'11), Portland, Ore- gon, USA.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Arabic Named Entity Recognition: A Feature-driven Study",
                "authors": [
                    {
                        "first": "Yassine",
                        "middle": [],
                        "last": "Benajiba",
                        "suffix": ""
                    },
                    {
                        "first": "Mona",
                        "middle": [],
                        "last": "Diab",
                        "suffix": ""
                    },
                    {
                        "first": "Paolo",
                        "middle": [],
                        "last": "Rosso",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "IEEE Transactions on Audio, Speech & Language Processing",
                "volume": "17",
                "issue": "5",
                "pages": "926--934",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yassine Benajiba, Mona Diab, and Paolo Rosso. 2009. Arabic Named Entity Recognition: A Feature-driven Study. IEEE Transactions on Audio, Speech & Lan- guage Processing, 17(5):926-934.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Buckwalter Arabic Morphological Analyzer Version 2.0. LDC catalog number LDC2004L02",
                "authors": [
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tim Buckwalter. 2004. Buckwalter Arabic Morpho- logical Analyzer Version 2.0. LDC catalog number LDC2004L02, ISBN 1-58563-324-0.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Automatic tagging of Arabic text: From raw text to base phrase chunks",
                "authors": [
                    {
                        "first": "Mona",
                        "middle": [],
                        "last": "Diab",
                        "suffix": ""
                    },
                    {
                        "first": "Kadri",
                        "middle": [],
                        "last": "Hacioglu",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In Proceedings of the 5th Meet- ing of the North American Chapter of the Associa- tion for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04), Boston, MA. Kais Dukes and Tim Buckwalter. 2010. A Depen- dency Treebank of the Quran using Traditional Ara- bic Grammar. In Proceedings of the 7th international conference on Informatics and Systems (INFOS 2010), Cairo, Egypt.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Dependency Parsing of Turkish",
                "authors": [
                    {
                        "first": "G\u00fclsen",
                        "middle": [],
                        "last": "Eryigit",
                        "suffix": ""
                    },
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    },
                    {
                        "first": "Kemal",
                        "middle": [],
                        "last": "Oflazer",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Computational Linguistics",
                "volume": "34",
                "issue": "3",
                "pages": "357--389",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G\u00fclsen Eryigit, Joakim Nivre, and Kemal Oflazer. 2008. Dependency Parsing of Turkish. Computational Lin- guistics, 34(3):357-389.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)",
                "volume": "",
                "issue": "",
                "pages": "573--580",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash and Owen Rambow. 2005. Arabic Tok- enization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Com- putational Linguistics (ACL'05), pages 573-580, Ann Arbor, Michigan.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "CATiB: The Columbia Arabic Treebank",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers",
                "volume": "",
                "issue": "",
                "pages": "221--224",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash and Ryan Roth. 2009. CATiB: The Columbia Arabic Treebank. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 221-224, Suntec, Singapore.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Determining Case in Arabic: Learning Complex Linguistic Behavior Requires Complex Linguistic Features",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Gabbard",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    },
                    {
                        "first": "Seth",
                        "middle": [],
                        "last": "Kulick",
                        "suffix": ""
                    },
                    {
                        "first": "Mitch",
                        "middle": [],
                        "last": "Marcus",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)",
                "volume": "",
                "issue": "",
                "pages": "1084--1092",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Ryan Gabbard, Owen Rambow, Seth Kulick, and Mitch Marcus. 2007a. Determining Case in Arabic: Learning Complex Linguistic Behavior Re- quires Complex Linguistic Features. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1084-1092.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "On Arabic Transliteration",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Abdelhadi",
                        "middle": [],
                        "last": "Soudi",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Arabic Computational Morphology: Knowledge-based and Empirical Methods",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007b. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Meth- ods. Springer.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Syntactic Annotation in the Columbia Arabic Treebank",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Reem",
                        "middle": [],
                        "last": "Faraj",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of MEDAR International Conference on Arabic Language Resources and Tools",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syn- tactic Annotation in the Columbia Arabic Treebank. In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskan- der, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceed- ings of the 2013 Conference of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies (NAACL-HLT), Atlanta, GA.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Introduction to Arabic Natural Language Processing",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan & Claypool Publish- ers.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Feature-based tagger of approximations of functional Arabic morphology",
                "authors": [
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Haji\u010d",
                        "suffix": ""
                    },
                    {
                        "first": "Otakar",
                        "middle": [],
                        "last": "Smr\u017e",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    },
                    {
                        "first": "Hubert",
                        "middle": [],
                        "last": "Jin",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the Workshop on Treebanks and Linguistic Theories (TLT)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jan Haji\u010d, Otakar Smr\u017e, Tim Buckwalter, and Hubert Jin. 2005. Feature-based tagger of approximations of functional Arabic morphology. In Proceedings of the Workshop on Treebanks and Linguistic Theories (TLT), Barcelona, Spain.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Recent Developments in Linguistic Annotations of the T\u00fcBa-D/Z Treebank",
                "authors": [
                    {
                        "first": "Erhard",
                        "middle": [],
                        "last": "Hinrichs",
                        "suffix": ""
                    },
                    {
                        "first": "Sandra",
                        "middle": [],
                        "last": "K\u00fcbler",
                        "suffix": ""
                    },
                    {
                        "first": "Karin",
                        "middle": [],
                        "last": "Naumann",
                        "suffix": ""
                    },
                    {
                        "first": "Heike",
                        "middle": [],
                        "last": "Telljohann",
                        "suffix": ""
                    },
                    {
                        "first": "Julia",
                        "middle": [],
                        "last": "Trushkina",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of the Third Workshop on Treebanks and Linguistic Theories",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Erhard Hinrichs, Sandra K\u00fcbler, Karin Naumann, Heike Telljohann, and Julia Trushkina. 2004. Recent Devel- opments in Linguistic Annotations of the T\u00fcBa-D/Z Treebank. In Proceedings of the Third Workshop on Treebanks and Linguistic Theories.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "OntoNotes: The 90% Solution",
                "authors": [
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    },
                    {
                        "first": "Mitchell",
                        "middle": [],
                        "last": "Marcus",
                        "suffix": ""
                    },
                    {
                        "first": "Martha",
                        "middle": [],
                        "last": "Palmer",
                        "suffix": ""
                    },
                    {
                        "first": "Lance",
                        "middle": [],
                        "last": "Ramshaw",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Weischedel",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "NAACL '06: Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers on XX",
                "volume": "",
                "issue": "",
                "pages": "57--60",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In NAACL '06: Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers on XX, pages 57-60, Morristown, NJ, USA.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Fast Methods for Kernel-Based Text Analysis",
                "authors": [
                    {
                        "first": "Taku",
                        "middle": [],
                        "last": "Kudo",
                        "suffix": ""
                    },
                    {
                        "first": "Yuji",
                        "middle": [],
                        "last": "Matsumoto",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "24--31",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Taku Kudo and Yuji Matsumoto. 2003. Fast Methods for Kernel-Based Text Analysis. In Erhard Hinrichs and Dan Roth, editors, Proceedings of ACL, pages 24-31.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus",
                "authors": [
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Maamouri",
                        "suffix": ""
                    },
                    {
                        "first": "Ann",
                        "middle": [],
                        "last": "Bies",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    },
                    {
                        "first": "Wigdan",
                        "middle": [],
                        "last": "Mekki",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Creating a Methodology for Large-Scale Correction of Treebank Annotation: The Case of the Arabic Treebank",
                "authors": [
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Maamouri",
                        "suffix": ""
                    },
                    {
                        "first": "Ann",
                        "middle": [],
                        "last": "Bies",
                        "suffix": ""
                    },
                    {
                        "first": "Seth",
                        "middle": [],
                        "last": "Kulick",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of MEDAR International Conference on Arabic Language Resources and Tools",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohamed Maamouri, Ann Bies, and Seth Kulick. 2009b. Creating a Methodology for Large-Scale Correction of Treebank Annotation: The Case of the Arabic Tree- bank. In Proceedings of MEDAR International Con- ference on Arabic Language Resources and Tools, Cairo, Egypt.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Improving Arabic Dependency Parsing with Lexical and Inflectional Morphological Features",
                "authors": [
                    {
                        "first": "Yuval",
                        "middle": [],
                        "last": "Marton",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages",
                "volume": "",
                "issue": "",
                "pages": "13--21",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yuval Marton, Nizar Habash, and Owen Rambow. 2010. Improving Arabic Dependency Parsing with Lexical and Inflectional Morphological Features. In Proceed- ings of the NAACL HLT 2010 First Workshop on Sta- tistical Parsing of Morphologically-Rich Languages, pages 13-21, Los Angeles, CA, USA, June.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Improving Arabic Dependency Parsing with Formbased and Functional Morphological Features",
                "authors": [
                    {
                        "first": "Yuval",
                        "middle": [],
                        "last": "Marton",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL'11)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yuval Marton, Nizar Habash, and Owen Rambow. 2011. Improving Arabic Dependency Parsing with Form- based and Functional Morphological Features. In Pro- ceedings of the 49th Annual Meeting of the Associ- ation for Computational Linguistics (ACL'11), Port- land, Oregon, USA.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Annotation of Morphology and NP Structure in the Copenhagen Dependency Treebanks (CDT)",
                "authors": [
                    {
                        "first": "Henrik",
                        "middle": [],
                        "last": "M\u00fcller",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the Ninth International Workshop on Treebanks and Linguistic Theories",
                "volume": "",
                "issue": "",
                "pages": "151--162",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Henrik M\u00fcller. 2010. Annotation of Morphology and NP Structure in the Copenhagen Dependency Tree- banks (CDT). In Proceedings of the Ninth Interna- tional Workshop on Treebanks and Linguistic Theo- ries, pages 151-162.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Parsing the SynTagRus Treebank of Russian",
                "authors": [
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    },
                    {
                        "first": "Igor",
                        "middle": [
                            "M"
                        ],
                        "last": "Boguslavsky",
                        "suffix": ""
                    },
                    {
                        "first": "Leonid",
                        "middle": [
                            "L"
                        ],
                        "last": "Iomdin",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "COLING '08: Proceedings of the 22nd International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "641--648",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joakim Nivre, Igor M. Boguslavsky, and Leonid L. Iomdin. 2008. Parsing the SynTagRus Treebank of Russian. In COLING '08: Proceedings of the 22nd International Conference on Computational Linguis- tics, pages 641-648, Stroudsburg, PA, USA. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Parsing Indian Languages with MaltParser",
                "authors": [
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing",
                "volume": "",
                "issue": "",
                "pages": "12--18",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joakim Nivre. 2009. Parsing Indian Languages with MaltParser. Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing, pages 12-18.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "LinGO Redwoods -A Rich and Dynamic Treebank for HPSG",
                "authors": [
                    {
                        "first": "Stephan",
                        "middle": [],
                        "last": "Oepen",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Flickinger",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    },
                    {
                        "first": "Christoper",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "LREC workshop on parsing evaluation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stephan Oepen, Dan Flickinger, Kristina Toutanova, and Christoper D. Manning. 2002. LinGO Redwoods - A Rich and Dynamic Treebank for HPSG. In LREC workshop on parsing evaluation, Las Palmas, Spain.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "A Pilot Arabic Propbank",
                "authors": [
                    {
                        "first": "Martha",
                        "middle": [],
                        "last": "Palmer",
                        "suffix": ""
                    },
                    {
                        "first": "Olga",
                        "middle": [],
                        "last": "Babko-Malaya",
                        "suffix": ""
                    },
                    {
                        "first": "Ann",
                        "middle": [],
                        "last": "Bies",
                        "suffix": ""
                    },
                    {
                        "first": "Mona",
                        "middle": [],
                        "last": "Diab",
                        "suffix": ""
                    },
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Maamouri",
                        "suffix": ""
                    },
                    {
                        "first": "Aous",
                        "middle": [],
                        "last": "Mansouri",
                        "suffix": ""
                    },
                    {
                        "first": "Wajdi",
                        "middle": [],
                        "last": "Zaghouani",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of LREC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Martha Palmer, Olga Babko-Malaya, Ann Bies, Mona Diab, Mohamed Maamouri, Aous Mansouri, and Wa- jdi Zaghouani. 2008. A Pilot Arabic Propbank. In Proceedings of LREC, Marrakech, Morocco, May.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Mona",
                        "middle": [],
                        "last": "Diab",
                        "suffix": ""
                    },
                    {
                        "first": "Cynthia",
                        "middle": [],
                        "last": "Rudin",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of ACL-08: HLT, Short Papers",
                "volume": "",
                "issue": "",
                "pages": "117--120",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic Morphological Tag- ging, Diacritization, and Lemmatization Using Lex- eme Models and Feature Ranking. In Proceedings of ACL-08: HLT, Short Papers, pages 117-120, Colum- bus, Ohio.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Context-Based Morphological Disambiguation with Random Fields",
                "authors": [
                    {
                        "first": "Noah",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "Roy",
                        "middle": [],
                        "last": "Tromble",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 2005 Conference on Empirical Methods in Natural Language Processing (EMNLP05)",
                "volume": "",
                "issue": "",
                "pages": "475--482",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Noah Smith, David Smith, and Roy Tromble. 2005. Context-Based Morphological Disambiguation with Random Fields. In Proceedings of the 2005 Con- ference on Empirical Methods in Natural Language Processing (EMNLP05), pages 475-482, Vancouver, Canada.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "The Other Arabic Treebank: Prague Dependencies and Functions",
                "authors": [
                    {
                        "first": "Otakar",
                        "middle": [],
                        "last": "Smr\u017e",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Arabic Computational Linguistics: Current Implementations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Otakar Smr\u017e and Jan Haji\u010d. 2006. The Other Arabic Treebank: Prague Dependencies and Functions. In Ali Farghaly, editor, Arabic Computational Linguis- tics: Current Implementations. CSLI Publications.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Prague Arabic Dependency Treebank: A Word on the Million Words",
                "authors": [
                    {
                        "first": "Otakar",
                        "middle": [],
                        "last": "Smr\u017e",
                        "suffix": ""
                    },
                    {
                        "first": "Viktor",
                        "middle": [],
                        "last": "Bielick\u00fd",
                        "suffix": ""
                    },
                    {
                        "first": "Iveta",
                        "middle": [],
                        "last": "Kou\u0159ilov\u00e1",
                        "suffix": ""
                    },
                    {
                        "first": "Jakub",
                        "middle": [],
                        "last": "Kr\u00e1\u010dmar",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Haji\u010d",
                        "suffix": ""
                    },
                    {
                        "first": "Petr",
                        "middle": [],
                        "last": "Zem\u00e1nek",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the Workshop on Arabic and Local Languages (LREC 2008)",
                "volume": "",
                "issue": "",
                "pages": "16--23",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Otakar Smr\u017e, Viktor Bielick\u00fd, Iveta Kou\u0159ilov\u00e1, Jakub Kr\u00e1\u010dmar, Jan Haji\u010d, and Petr Zem\u00e1nek. 2008. Prague Arabic Dependency Treebank: A Word on the Mil- lion Words. In Proceedings of the Workshop on Ara- bic and Local Languages (LREC 2008), pages 16-23, Marrakech, Morocco.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Automatic Treebank-Based Acquisition of Arabic LFG Dependency Structures",
                "authors": [
                    {
                        "first": "Otakar",
                        "middle": [],
                        "last": "Smr\u017e",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages",
                "volume": "",
                "issue": "",
                "pages": "45--52",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Otakar Smr\u017e. 2007. Functional Arabic Morphology. For- mal System and Implementation. Ph.D. thesis, Charles University in Prague, Prague, Czech Republic. Lamia Tounsi, Mohammed Attia, and Josef van Gen- abith. 2009. Automatic Treebank-Based Acquisi- tion of Arabic LFG Dependency Structures. In Pro- ceedings of the EACL 2009 Workshop on Computa- tional Approaches to Semitic Languages, pages 45-52, Athens, Greece.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: An example dependency tree for the sentence",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "TABREF1": {
                "content": "<table><tr><td/><td colspan=\"2\">Full Reduced</td><td/><td/></tr><tr><td/><td>BW</td><td>BW</td><td colspan=\"2\">Diff Lemma</td></tr><tr><td>MLE Baseline 1</td><td>57.19</td><td>73.44</td><td colspan=\"2\">16.25 90.87</td></tr><tr><td>MLE Baseline 2</td><td>77.69</td><td>93.27</td><td colspan=\"2\">15.58 94.31</td></tr><tr><td>TADA</td><td>86.15</td><td>94.04</td><td>7.89</td><td>96.97</td></tr><tr><td>++ CATiB</td><td>87.33</td><td>95.50</td><td>8.17</td><td>97.72</td></tr><tr><td>++ PRON</td><td>88.16</td><td>96.32</td><td>8.16</td><td>97.72</td></tr><tr><td>++ NOUN/ADJ</td><td>88.93</td><td>97.26</td><td>8.33</td><td>97.72</td></tr><tr><td>++ PRT</td><td>89.24</td><td>97.57</td><td>8.33</td><td>97.72</td></tr><tr><td colspan=\"2\">++ MOOD/ASPECT 89.46</td><td>97.60</td><td>8.14</td><td>97.74</td></tr><tr><td>++ STATE</td><td>89.92</td><td>97.61</td><td>7.69</td><td>97.74</td></tr><tr><td>++ CASE</td><td>94.90</td><td>97.61</td><td>2.71</td><td>97.74</td></tr><tr><td>++ MLE override</td><td>95.27</td><td>98.00</td><td>2.73</td><td>97.81</td></tr><tr><td colspan=\"5\">tag otherwise matches the gold tag. Words whose</td></tr><tr><td colspan=\"5\">lemmas are unknown (nolemma, TBupdate) or has</td></tr><tr><td colspan=\"5\">the lemma DEFAULT (including digits and punc-</td></tr><tr><td colspan=\"5\">tuation) are excluded from the evaluation, but not</td></tr><tr><td colspan=\"5\">training: in the development set, 4,498 out of 25,446</td></tr><tr><td colspan=\"3\">words were excluded (\u21e018%).</td><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Accuracy of enriching CATiB trees with Buckwalter (BW) tags and lemmas on the development set. Reduced Buckwalter is similar to Buckwalter, but ignores case, mood and state. The Difference between the two metrics highlights the errors from case, mood and state.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td/><td colspan=\"2\">Full Reduced</td><td/><td/></tr><tr><td/><td>BW</td><td>BW</td><td colspan=\"2\">Diff Lemma</td></tr><tr><td colspan=\"2\">MLE Baseline 1 55.96</td><td>71.88</td><td colspan=\"2\">15.92 90.77</td></tr><tr><td colspan=\"2\">MLE Baseline 2 77.15</td><td>92.88</td><td colspan=\"2\">15.73 94.03</td></tr><tr><td>TADA</td><td>86.49</td><td>94.42</td><td>7.93</td><td>96.63</td></tr><tr><td>++ All filters</td><td>93.44</td><td>97.25</td><td>3.81</td><td>97.13</td></tr><tr><td colspan=\"2\">++ MLE override 93.61</td><td>97.43</td><td>3.82</td><td>97.17</td></tr><tr><td colspan=\"5\">to assess the source of the error. About 37% of all</td></tr><tr><td colspan=\"5\">errors are due to gold treebank errors: 21% are gold</td></tr><tr><td colspan=\"5\">tree structure/relation errors and 16% are gold POS</td></tr><tr><td colspan=\"5\">errors. The rest of the errors result from failures in</td></tr><tr><td colspan=\"5\">our system. The most common error is in NOM dis-</td></tr><tr><td colspan=\"5\">ambiguation: NOUN/NOUN_NUM, NOUN/ADJ,</td></tr><tr><td colspan=\"5\">NOUN/NOUN_QUANT, etc. The NOM errors ac-</td></tr><tr><td colspan=\"5\">counted for 33% of all errors. Case comes sec-</td></tr><tr><td colspan=\"5\">ond with 12% errors, then PRT and gender-number-</td></tr><tr><td colspan=\"5\">person errors with 5% each. State errors contribute</td></tr><tr><td colspan=\"2\">to 3% of total errors.</td><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Accuracy of enriching CATiB trees with Buckwalter (BW) tags and lemmas on the blind test set.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td/><td>Size</td><td colspan=\"4\">Full BW Reduced BW Diff Lemma</td></tr><tr><td colspan=\"2\">1/32 10.6K</td><td>74.03</td><td>88.78</td><td colspan=\"2\">14.75 93.41</td></tr><tr><td colspan=\"2\">1/16 21.3K</td><td>77.16</td><td>90.30</td><td colspan=\"2\">13.14 94.37</td></tr><tr><td>1/8</td><td>42.6K</td><td>79.76</td><td>91.63</td><td colspan=\"2\">11.87 95.56</td></tr><tr><td>1/4</td><td>85.3K</td><td>81.91</td><td>92.80</td><td colspan=\"2\">10.89 96.22</td></tr><tr><td colspan=\"2\">1/2 170.7K</td><td>84.12</td><td>93.62</td><td>9.50</td><td>96.74</td></tr><tr><td>1</td><td>341.1K</td><td>86.15</td><td>94.04</td><td>7.89</td><td>96.97</td></tr><tr><td/><td>Size</td><td colspan=\"4\">Full BW Reduced BW Diff Lemma</td></tr><tr><td colspan=\"2\">1/32 10.6K</td><td>93.24</td><td>95.81</td><td colspan=\"2\">2.57 95.68</td></tr><tr><td colspan=\"2\">1/16 21.3K</td><td>93.67</td><td>96.28</td><td colspan=\"2\">2.61 96.27</td></tr><tr><td>1/8</td><td>42.6K</td><td>94.14</td><td>96.79</td><td colspan=\"2\">2.65 96.94</td></tr><tr><td>1/4</td><td>85.3K</td><td>94.56</td><td>97.26</td><td colspan=\"2\">2.70 97.22</td></tr><tr><td colspan=\"2\">1/2 170.7K</td><td>94.96</td><td>97.66</td><td colspan=\"2\">2.70 97.61</td></tr><tr><td>1</td><td>341.1K</td><td>95.27</td><td>98.00</td><td colspan=\"2\">2.73 97.81</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy of enriching CATiB trees with Buckwalter (BW) tags and lemmas using TADA only for different training sizes on the development set.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Accuracy of enriching CATiB trees with Buckwalter (BW) tags and lemmas using our best performing system for different training sizes on the development set.",
                "html": null,
                "num": null
            }
        }
    }
}