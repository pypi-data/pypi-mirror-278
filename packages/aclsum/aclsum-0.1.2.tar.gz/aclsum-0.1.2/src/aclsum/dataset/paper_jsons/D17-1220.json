{
    "paper_id": "D17-1220",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:53:27.403937Z"
    },
    "title": "Break it Down for Me: A Study in Automated Lyric Annotation",
    "authors": [
        {
            "first": "Lucas",
            "middle": [],
            "last": "Sterckx",
            "suffix": "",
            "affiliation": {
                "laboratory": "IDLab",
                "institution": "Ghent University -imec",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Jason",
            "middle": [],
            "last": "Naradowsky",
            "suffix": "",
            "affiliation": {
                "laboratory": "Language Technology Lab",
                "institution": "University of Cambridge",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Bill",
            "middle": [],
            "last": "Byrne",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Cambridge",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Thomas",
            "middle": [],
            "last": "Demeester",
            "suffix": "",
            "affiliation": {
                "laboratory": "IDLab",
                "institution": "Ghent University -imec",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Chris",
            "middle": [],
            "last": "Develder",
            "suffix": "",
            "affiliation": {
                "laboratory": "IDLab",
                "institution": "Ghent University -imec",
                "location": {}
            },
            "email": ""
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike. This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation.\nWe introduce the task of automated lyric annotation (ALA). Like text simplification, a goal of ALA is to rephrase the original text in a more easily understandable manner. However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics. We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation. We find that each model captures a unique type of information important to the task.",
    "pdf_parse": {
        "paper_id": "D17-1220",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike. This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "We introduce the task of automated lyric annotation (ALA). Like text simplification, a goal of ALA is to rephrase the original text in a more easily understandable manner. However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics. We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation. We find that each model captures a unique type of information important to the task.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Song lyrics and poetry often make use of ambiguity, symbolism, irony, and other stylistic elements to evoke emotive responses. These characteristics sometimes make it challenging to interpret obscure lyrics, especially for readers or listeners who are unfamiliar with the genre. To address this problem, several online lyric databases have been created where users can explain, contextualize, or discuss lyrics. Examples include MetroLyrics1 and Genius.com2 . We refer to such How does it feel? To be without a home Like a complete unknown,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The proverb \"A rolling stone gathers no moss\" refers to people who are always on the move, never putting down roots or accumulating responsibilities and cares. commentary as a lyric annotation (Figure 1 ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 201,
                        "end": 202,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Like a rolling stone",
                "sec_num": null
            },
            {
                "text": "In this work we introduce the task of automated lyric annotation (ALA). Compared to many traditional NLP systems, which are trained on newswire or similar text, an automated system capable of explaining abstract language, or finding alternative text expressions for slang (and other unknown terms) would exhibit a deeper understanding of the nuances of language. As a result, research in this area may open the door to a variety of interesting use cases. In addition to providing lyric annotations, such systems can lead to improved NLP analysis of informal text (blogs, social media, novels and other literary works of fiction), better handling of genres with heavy use of jargon (scientific texts, product manuals), and increased robustness to textual variety in more traditional NLP tasks and genres.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Like a rolling stone",
                "sec_num": null
            },
            {
                "text": "Our contributions are as follows: 1. To aid in the study of ALA we present a corpus of 803,720 crowdsourced lyric annotation pairs suitable for training models for this task.3 2. We present baseline systems using statistical machine translation (SMT), neural trans- lation (Seq2Seq), and information retrieval. 3. We establish an evaluation procedure which adopts measures from machine translation, paraphrase generation, and text simplification. Evaluation is conducted using both human and automated means, which we perform and report across all baselines.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Like a rolling stone",
                "sec_num": null
            },
            {
                "text": "We collect a dataset of crowdsourced annotations, generated by users of the Genius online lyric database. For a given song, users can navigate to a particular stanza or line, view existing annotations for the target lyric, or provide their own annotation. Discussion between users acts to improve annotation quality, as it does with other collaborative online databases like Wikipedia. This process is gamified: users earn IQ points for producing high quality annotations. We collect 736,423 lyrics having a total 1,404,107 lyric annotation pairs from all subsections (rap, poetry, news, etc.) of Genius. We limit the initial release of the annotation data to be English-only, and filter out non-English annotations using a pre-trained language identifier. We also remove annotations which are solely links to external resources, and do not provide useful textual annotations. This reduces the dataset to 803,720 lyric annotation pairs. We list several properties of the collected dataset in Table 1 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 998,
                        "end": 999,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "The Genius ALA Dataset",
                "sec_num": "2"
            },
            {
                "text": "Mining annotations from a collaborative humancurated website presents additional challenges worth noting. For instance, while we are able to generate large quantities of parallel text from Genius, users operate without a single, predefined and shared global goal other than to maximize their own IQ points. As such, there is no motivation to provide annotations for a song in its entirety, or independent of previous annotations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Context Independent Annotation",
                "sec_num": "2.1"
            },
            {
                "text": "For this reason we distinguish between two types of annotations: context independent (CI) annotations are independent of their surrounding context and can be interpreted without it, e.g., explain specific metaphors or imagery or provide narrative while normalizing slang language. Contrastively, context sensitive (CS) annotations provide broader context beyond the song lyric excerpt, e.g., background information on the artist.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Context Independent Annotation",
                "sec_num": "2.1"
            },
            {
                "text": "To estimate contribution from both types to the dataset, we sample 2,000 lyric annotation pairs and label them as either CI or CS. Based on this sample, an estimated 34.8% of all annotations is independent of context. Table 2 shows examples of both types.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 224,
                        "end": 225,
                        "text": "2",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Context Independent Annotation",
                "sec_num": "2.1"
            },
            {
                "text": "While the goal of ALA is to generate annotations of all types, it is evident from our analysis that CS annotations can not be generated by models trained solely on parallel text. That is, these annotations cannot be generated without background knowledge or added context. Therefore, in this preliminary work we focus on predicting CI lyric annotations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Context Independent Annotation",
                "sec_num": "2.1"
            },
            {
                "text": "We experiment with three baseline models used for text simplification and paraphrase generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "3"
            },
            {
                "text": "One approach is to treat the task as one of translation, and to use established statistical machine translation (SMT) methods (Quirk et al., 2004) to produce them. We train a standard phrase-based SMT model to translate lyrics to annotations, using GIZA++ (Josef Och and Ney, 2003) for word alignment and Moses (Koehn et al., 2007) for phrasal alignment, training, and decoding.",
                "cite_spans": [
                    {
                        "start": 126,
                        "end": 146,
                        "text": "(Quirk et al., 2004)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 256,
                        "end": 281,
                        "text": "(Josef Och and Ney, 2003)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 311,
                        "end": 331,
                        "text": "(Koehn et al., 2007)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 Statistical Machine Translation (SMT):",
                "sec_num": null
            },
            {
                "text": "\u2022 Seq2Seq: Sequence-to-sequence models (Sutskever et al., 2014) offer an alternative to SMT systems, and have been applied successfully to a variety of tasks including machine translation. In Seq2Seq, a recurrent neural network (RNN) encodes the source sequence to a single vector representation. A separate decoder RNN generates the translation conditioned on this representation of the source sequence's semantics. We utilize Seq2Seq with attention (Bahdanau et al., 2014) , which allows the model to additionally condition on tokens from the input sequence during decoding.",
                "cite_spans": [
                    {
                        "start": 39,
                        "end": 63,
                        "text": "(Sutskever et al., 2014)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 451,
                        "end": 474,
                        "text": "(Bahdanau et al., 2014)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 Statistical Machine Translation (SMT):",
                "sec_num": null
            },
            {
                "text": "\u2022 Retrieval: In practice, similar lyrics may reappear in different contexts with exchangeable annotations. We treat the training corpus as a database of lyrics' excerpts with corresponding annotations, and at test time select the annotation assigned to the most similar lyric. This baseline is referred to as the retrieval model. We use standard TF-IDF weighted cosine distance as similarity measure between lyrics' excerpts.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 Statistical Machine Translation (SMT):",
                "sec_num": null
            },
            {
                "text": "We evaluate automatic annotators on a selection of 354 CI annotations and partition the rest of the annotations into 2,000 instances for development and the full remainder for training. It is important to note that the annotations used for training and development include CI as well as CS annotations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "4.1"
            },
            {
                "text": "Annotations often include multiple sentences or even paragraphs for a single lyrics excerpt (which does not include end marks), while machine translation models need aligned corpora at sentence level to perform well (Xu et al., 2016) . We therefore transform training data by including each sentence from the annotation as a single training instance with the same lyric, resulting in a total of 1,813,350 sentence pairs.",
                "cite_spans": [
                    {
                        "start": 216,
                        "end": 233,
                        "text": "(Xu et al., 2016)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "4.1"
            },
            {
                "text": "We use this collection of sentence pairs (denoted as sent. in results) to train the SMT model. Seq2Seq models are trained using sentence pairs as well as full annotations. Interestingly, techniques encouraging alignment by matching length and thresholding cosine distance between lyric and annotation did not improve performance during development.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "4.1"
            },
            {
                "text": "For automated evaluation, we use measures commonly used to evaluate translation systems (BLEU, METEOR), paraphrase generation (iBLEU) and text simplification (SARI).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Measures",
                "sec_num": "4.2"
            },
            {
                "text": "BLEU (Papineni et al., 2002) uses a modified form of precision to compare generated annotations against references from Genius. ME-TEOR (Denkowski and Lavie, 2011 ) is based on the harmonic mean of precision and recall and, along with exact word matching, includes stemming and synonymy matching. iBLEU (Sun and Zhou, 2012 ) is an extension of the BLEU metric to measure diversity as well as adequacy of the annotation, iBLEU = 0.9 \u00d7 BLEU(Annotation, Reference) -0.1 \u00d7 BLEU(Annotation, Lyric). SARI (Xu et al., 2016) measures precision and recall of words that are added, kept, or deleted separately and averages their arithmetic means.",
                "cite_spans": [
                    {
                        "start": 5,
                        "end": 28,
                        "text": "(Papineni et al., 2002)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 136,
                        "end": 162,
                        "text": "(Denkowski and Lavie, 2011",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 303,
                        "end": 322,
                        "text": "(Sun and Zhou, 2012",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 499,
                        "end": 516,
                        "text": "(Xu et al., 2016)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Measures",
                "sec_num": "4.2"
            },
            {
                "text": "We also measure quality by crowdsourcing ratings via the online platform CrowdFlower. 4 We present collaborators with a song lyric excerpt annotated with output from the annotation generators as well as a reference annotation from Genius. Collaborators assign a 5-point rating for Fluency which rates the quality of the generated language, and Information which measures the added clarification by the annotation, a key aspect of this task. For each lyric annotation pair, we gather ratings from three different collaborators and take the average.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Measures",
                "sec_num": "4.2"
            },
            {
                "text": "Here we describe implementation and some of the optimizations used when training the models. For Seq2Seq models, we use OpenNMT (Klein et al., 2017) and optimize for perplexity on the development set. Vocabulary for both lyrics and annotations is reduced to the 50,000 most frequent tokens and are embedded in a 500-dimensional space.",
                "cite_spans": [
                    {
                        "start": 128,
                        "end": 148,
                        "text": "(Klein et al., 2017)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Hyperparameters and Optimization",
                "sec_num": "4.3"
            },
            {
                "text": "We use two layers of stacked bi-directional LSTMs with hidden states of 1024 dimensions. We regularize using dropout (keep probability of 0.7) and train using stochastic gradient descent with batches of 64 samples for 13 epochs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Hyperparameters and Optimization",
                "sec_num": "4.3"
            },
            {
                "text": "The decoder of the SMT model is tuned for optimal BLEU scores on the development set using minimum error rate training (Bertoldi et al., 2009) .",
                "cite_spans": [
                    {
                        "start": 119,
                        "end": 142,
                        "text": "(Bertoldi et al., 2009)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Hyperparameters and Optimization",
                "sec_num": "4.3"
            },
            {
                "text": "To measure agreement between collaborators, we compute the kappa statistic (Fleiss, 1971) . Kappa statistics for fluency and information are 0.05 and 0.07 respectively, which indicates low agreement. The task of evaluating lyric annotations was difficult for CrowdFlower collaborators as was apparent from their evaluation of the task. For evaluation in future work, we recommend recruitment of expert collaborators familiar with the Genius platform and song lyrics.",
                "cite_spans": [
                    {
                        "start": 75,
                        "end": 89,
                        "text": "(Fleiss, 1971)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Table 3 shows examples of lyrics with annota-tions from Genius and those generated by baseline models.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "A notable observation is that translation models learn to take the role of narrator, as is common in CI annotations, and recognize slang language while simplifying it to more standard English.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Automatic and human evaluation scores are shown in Table 4 . Next to evaluation metrics, we show two properties of automatically generated annotations; the average annotation length relative to the lyric and the occurrence of profanity per token in annotations, using a list of 343 swear words.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 57,
                        "end": 58,
                        "text": "4",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "The SMT model scores high on BLEU, ME-TEOR and SARI but shows a large drop in performance for iBLEU, which penalizes lexical similarity between lyrics and generated annotations as apparent from the amount profanity remaining in the generated annotations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Standard SMT rephrases the song lyric from a third person perspective but is conservative in lexical substitutions and keeps close to the grammar of the lyric. A more appropriate objective function for tuning the decoder which promotes lexical dissimilarity as done for paraphrase generation, would be beneficial for this approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Seq2Seq models generate annotations more dissimilar to the song lyric and obtain higher iBLEU and Information scores. To visualize some of the alignments learned by the translation models, Fig. 2 shows word-by-word attention scores for a translation by the Seq2Seq model.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 194,
                        "end": 195,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "While the retrieval model obtains quality annotations when test lyrics are highly similar to lyrics from the training set, retrieved annotations are often unrelated to the test lyric or specific to the song lyric it is retrieved from.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Out of the unsupervised metrics, METEOR obtained the highest Pearson correlation (Pearson, 1895) with human ratings for Information with a coefficient of 0.15.",
                "cite_spans": [
                    {
                        "start": 81,
                        "end": 96,
                        "text": "(Pearson, 1895)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Work on modeling of social annotations has mainly focused on the use of topic models (Iwata et al., 2009; Das et al., 2014) in which annotations are assumed to originate from topics. They can be used as a preprocessing step in machine learning tasks such as text classification and image recognition but do not generate language as required in our ALA task.",
                "cite_spans": [
                    {
                        "start": 85,
                        "end": 105,
                        "text": "(Iwata et al., 2009;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 106,
                        "end": 123,
                        "text": "Das et al., 2014)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "6"
            },
            {
                "text": "Text simplification and paraphrase generation have been widely studied. Recent work has highlighted the need for large text collections (Xu et al., 2015) as well as more appropriate evaluation measures (Xu et al., 2016; Galley et al., 2015) . They indicated that especially informal language, with its high degree of lexical variation, e.g., as used in social media or lyrics, poses serious challenges (Xu et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 136,
                        "end": 153,
                        "text": "(Xu et al., 2015)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 202,
                        "end": 219,
                        "text": "(Xu et al., 2016;",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 220,
                        "end": 240,
                        "text": "Galley et al., 2015)",
                        "ref_id": null
                    },
                    {
                        "start": 402,
                        "end": 419,
                        "text": "(Xu et al., 2013)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "6"
            },
            {
                "text": "Text generation for artistic purposes, such as poetry and lyrics, has been explored most commonly using templates and constraints (Barbieri et al., 2012) . In regard to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that is meant to be a response to a single line of input. Most recent work is that of Zhang et al. (2014) and Potash et al. (2015) , who show the effectiveness of RNNs for the generation of poetry and lyrics.",
                "cite_spans": [
                    {
                        "start": 130,
                        "end": 153,
                        "text": "(Barbieri et al., 2012)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 181,
                        "end": 197,
                        "text": "Wu et al. (2013)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 364,
                        "end": 383,
                        "text": "Zhang et al. (2014)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 388,
                        "end": 408,
                        "text": "Potash et al. (2015)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "6"
            },
            {
                "text": "The task of annotating song lyrics is also related to metaphor processing. As annotators often explain metaphors used in song lyrics, the Genius dataset can serve as a resource to study computational modeling of metaphors (Shutova and Teufel, 2010) .",
                "cite_spans": [
                    {
                        "start": 222,
                        "end": 248,
                        "text": "(Shutova and Teufel, 2010)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "6"
            },
            {
                "text": "We presented and released the Genius dataset to study the task of Automated Lyric Annotation. As a first investigation, we studied automatic generation of context independent annotations as machine translation and information retrieval. Our baseline system tests indicate that our corpus is suitable to train machine translation systems.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "7"
            },
            {
                "text": "Standard SMT models are capable of rephrasing and simplifying song lyrics but tend to keep close to the structure of the song lyric. Seq2Seq models demonstrated potential to generate more fluent and informative text, dissimilar to the lyric.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "7"
            },
            {
                "text": "A large fraction of the annotations is heavily based on context and background knowledge (CS), one of their most appealing aspects. As future work we suggest injection of structured and unstructured external knowledge (Ahn et al., 2016) and explicit modeling of references (Yang et al., 2016) .",
                "cite_spans": [
                    {
                        "start": 218,
                        "end": 236,
                        "text": "(Ahn et al., 2016)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 273,
                        "end": 292,
                        "text": "(Yang et al., 2016)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "7"
            },
            {
                "text": "http://www.metrolyrics.com",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://genius.com",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "To obtain the data collection please contact the first author of this paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://www.crowdflower.com/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "The authors wish to thank the anonymous reviewers for their helpful comments. This work was supported by the Research Foundation -Flanders (FWO) and the U.K. Engineering and Physical Sciences Research Council (EPSRC grant EP/L027623/1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            },
            {
                "text": "and when I slept, I dream g's, son I need some Human:he dreams about large amounts of money because he is in need of it . SMT:and when he slept, and he's dream, g's son, he needs some Seq2Seq: when he sleeps , he dreams of getting money. Retrieval: g's refer to the ghetto gangsters in london that the kid has become involved with Lyric:Mossberg pump I'm ridin' shotgun literally Human:riding shotgun means to ride up front in the passenger seat SMT:Mossberg pump -action shotgun, he's saying he's ridin' shotgun literally. Seq2Seq: Mossberg is a firearms manufacturer. He is riding shotgun with his shotgun. Retrieval: he fully respects the people mentioned earlier and is riding for them.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Lyric:",
                "sec_num": null
            },
            {
                "text": "and my eyes red cause of all that haze Human:his eyes turn red due to lack of hydration from the weed one smokes (in this case , smoking purple haze) SMT:and his eyes are red because of all that haze. Seq2Seq: his eyes are red because of all the weed he smokes. Retrieval: his eyes are red as a sign of the fatigue of travel and , possibly , from drugs and alcohol .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Lyric:",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "A Neural Knowledge Language Model",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Ahn",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "P\u00e4rnamaa",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Ahn, H. Choi, T. P\u00e4rnamaa, and Y. Bengio. 2016. A Neural Knowledge Language Model. ArXiv e-prints https://arxiv.org/abs/1608.00318.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Neural machine translation by jointly learning to align and translate",
                "authors": [
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. CoRR abs/1409.0473. http://arxiv.org/abs/1409.0473.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Including Prestigious Applications of Artificial Intelligence (PAIS-2012) System Demonstrations Track",
                "authors": [
                    {
                        "first": "Gabriele",
                        "middle": [],
                        "last": "Barbieri",
                        "suffix": ""
                    },
                    {
                        "first": "Pierre",
                        "middle": [],
                        "last": "Franc \u00b8ois Pachet",
                        "suffix": ""
                    },
                    {
                        "first": "Mirko",
                        "middle": [],
                        "last": "Roy",
                        "suffix": ""
                    },
                    {
                        "first": "Esposti",
                        "middle": [],
                        "last": "Degli",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "ECAI 2012 -20th European Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "115--120",
                "other_ids": {
                    "DOI": [
                        "10.3233/978-1-61499-098-7-115"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Gabriele Barbieri, Franc \u00b8ois Pachet, Pierre Roy, and Mirko Degli Esposti. 2012. Markov constraints for generating lyrics with style. In ECAI 2012 -20th European Conference on Artificial Intelli- gence. Including Prestigious Applications of Arti- ficial Intelligence (PAIS-2012) System Demonstra- tions Track, Montpellier, France, August 27-31 , 2012. pages 115-120. https://doi.org/10.3233/978- 1-61499-098-7-115.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Improved minimum error rate training in moses",
                "authors": [
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Bertoldi",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Haddow",
                        "suffix": ""
                    },
                    {
                        "first": "Jean-Baptiste",
                        "middle": [],
                        "last": "Fouet",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Prague Bull. Math. Linguistics",
                "volume": "91",
                "issue": "",
                "pages": "7--16",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nicola Bertoldi, Barry Haddow, and Jean-Baptiste Fouet. 2009. Improved minimum error rate training in moses. Prague Bull. Math. Linguistics 91:7-16. http://ufal.mff.cuni.cz/pbml/91/art-bertoldi.pdf.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Going beyond corr-lda for detecting specific comments on news & blogs",
                "authors": [
                    {
                        "first": "Kanti",
                        "middle": [],
                        "last": "Mrinal",
                        "suffix": ""
                    },
                    {
                        "first": "Trapit",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Chiranjib",
                        "middle": [],
                        "last": "Bansal",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bhattacharyya",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Seventh ACM International Conference on Web Search and Data Mining",
                "volume": "",
                "issue": "",
                "pages": "483--492",
                "other_ids": {
                    "DOI": [
                        "10.1145/2556195.2556231"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Mrinal Kanti Das, Trapit Bansal, and Chiranjib Bhat- tacharyya. 2014. Going beyond corr-lda for de- tecting specific comments on news & blogs. In Seventh ACM International Conference on Web Search and Data Mining, WSDM 2014, New York, NY, USA, February 24-28, 2014. pages 483-492. https://doi.org/10.1145/2556195.2556231.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Proceedings of the sixth workshop on statistical machine translation pages",
                "authors": [
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Denkowski",
                        "suffix": ""
                    },
                    {
                        "first": "Alon",
                        "middle": [],
                        "last": "Lavie",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "85--91",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael Denkowski and Alon Lavie. 2011. Proceedings of the sixth workshop on sta- tistical machine translation pages 85-91. http://aclweb.org/anthology/W11-2107.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Measuring nominal scale agreement among many raters",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Joseph",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Fleiss",
                        "suffix": ""
                    }
                ],
                "year": 1971,
                "venue": "Psychological bulletin",
                "volume": "76",
                "issue": "5",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joseph L Fleiss. 1971. Measuring nominal scale agree- ment among many raters. Psychological bulletin 76(5):378.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Chris Quirk, Margaret Mitchell, Jianfeng Gao, and Bill Dolan. 2015. deltableu: A discriminative metric for generation tasks with intrinsically diverse targets",
                "authors": [
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Alessandro",
                        "middle": [],
                        "last": "Sordoni",
                        "suffix": ""
                    },
                    {
                        "first": "Yangfeng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing",
                "volume": "2",
                "issue": "",
                "pages": "445--450",
                "other_ids": {
                    "DOI": [
                        "10.3115/v1/P15-2073"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Michel Galley, Chris Brockett, Alessandro Sordoni, Yangfeng Ji, Michael Auli, Chris Quirk, Mar- garet Mitchell, Jianfeng Gao, and Bill Dolan. 2015. deltableu: A discriminative metric for generation tasks with intrinsically diverse targets. In Proceed- ings of the 53rd Annual Meeting of the Associa- tion for Computational Linguistics and the 7th In- ternational Joint Conference on Natural Language Processing (Volume 2: Short Papers). Associa- tion for Computational Linguistics, pages 445-450. https://doi.org/10.3115/v1/P15-2073.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Modeling social annotation data with content relevance using a topic model",
                "authors": [
                    {
                        "first": "Tomoharu",
                        "middle": [],
                        "last": "Iwata",
                        "suffix": ""
                    },
                    {
                        "first": "Takeshi",
                        "middle": [],
                        "last": "Yamada",
                        "suffix": ""
                    },
                    {
                        "first": "Naonori",
                        "middle": [],
                        "last": "Ueda",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held",
                "volume": "",
                "issue": "",
                "pages": "835--843",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomoharu Iwata, Takeshi Yamada, and Naonori Ueda. 2009. Modeling social annotation data with content relevance using a topic model. In Advances in Neural Information Processing Sys- tems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancou- ver, British Columbia, Canada.. pages 835-843. http://papers.nips.cc/paper/3773-modeling-social- annotation-data-with-content-relevance-using-a- topic-model.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "A systematic comparison of various statistical alignment models",
                "authors": [
                    {
                        "first": "Josef",
                        "middle": [],
                        "last": "Franz",
                        "suffix": ""
                    },
                    {
                        "first": "Hermann",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ney",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Computational Linguistics",
                "volume": "29",
                "issue": "1",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, Volume 29, Number 1, March 2003 http://aclweb.org/anthology/J03-1002.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Senellart",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "M"
                        ],
                        "last": "Rush",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Klein, Y. Kim, Y. Deng, J. Senellart, and A.M. Rush. 2017. OpenNMT: Open-Source Toolkit for Neural Machine Translation. ArXiv e-prints https://arxiv.org/abs/1701.02810.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Moses: Open source toolkit for statistical machine translation",
                "authors": [
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Hieu",
                        "middle": [],
                        "last": "Hoang",
                        "suffix": ""
                    },
                    {
                        "first": "Alexandra",
                        "middle": [],
                        "last": "Birch",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Marcello",
                        "middle": [],
                        "last": "Federico",
                        "suffix": ""
                    },
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Bertoldi",
                        "suffix": ""
                    },
                    {
                        "first": "Brooke",
                        "middle": [],
                        "last": "Cowan",
                        "suffix": ""
                    },
                    {
                        "first": "Wade",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "Christine",
                        "middle": [],
                        "last": "Moran",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Zens",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "Ondrej",
                        "middle": [],
                        "last": "Bojar",
                        "suffix": ""
                    },
                    {
                        "first": "Alexandra",
                        "middle": [],
                        "last": "Constantin",
                        "suffix": ""
                    },
                    {
                        "first": "Evan",
                        "middle": [],
                        "last": "Herbst",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
                "volume": "",
                "issue": "",
                "pages": "177--180",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the As- sociation for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Ses- sions. Association for Computational Linguistics, pages 177-180. http://aclweb.org/anthology/P07- 2045.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "authors": [
                    {
                        "first": "Kishore",
                        "middle": [],
                        "last": "Papineni",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    },
                    {
                        "first": "Todd",
                        "middle": [],
                        "last": "Ward",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Jing",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for au- tomatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. http://aclweb.org/anthology/P02-1040.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Note on regression and inheritance in the case of two parents",
                "authors": [
                    {
                        "first": "Karl",
                        "middle": [],
                        "last": "Pearson",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the Royal Society of London",
                "volume": "58",
                "issue": "",
                "pages": "240--242",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Karl Pearson. 1895. Note on regression and inheritance in the case of two parents. Proceedings of the Royal Society of London 58:240-242.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Ghostwriter: Using an lstm for automatic rap lyric generation",
                "authors": [
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Potash",
                        "suffix": ""
                    },
                    {
                        "first": "Alexey",
                        "middle": [],
                        "last": "Romanov",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Rumshisky",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1919--1924",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D15-1221"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Peter Potash, Alexey Romanov, and Anna Rumshisky. 2015. Ghostwriter: Using an lstm for au- tomatic rap lyric generation. In Proceedings of the 2015 Conference on Empirical Meth- ods in Natural Language Processing. Association for Computational Linguistics, pages 1919-1924. https://doi.org/10.18653/v1/D15-1221.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Proceedings of the 2004 conference on empirical methods in natural language processing",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Quirk",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Quirk, Chris Brockett, and William Dolan. 2004. Proceedings of the 2004 conference on empirical methods in natural language processing. http://aclweb.org/anthology/W04-3219.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Metaphor corpus annotated for source -target domain mappings",
                "authors": [
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    },
                    {
                        "first": "Simone",
                        "middle": [],
                        "last": "Teufel",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC'10)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ekaterina Shutova and Simone Teufel. 2010. Metaphor corpus annotated for source -target domain map- pings. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC'10). European Languages Resources Asso- ciation (ELRA). http://aclweb.org/anthology/L10- 1419.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Joint learning of a dual smt system for paraphrase generation",
                "authors": [
                    {
                        "first": "Hong",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics",
                "volume": "2",
                "issue": "",
                "pages": "38--42",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hong Sun and Ming Zhou. 2012. Joint learning of a dual smt system for paraphrase generation. In Pro- ceedings of the 50th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguis- tics, pages 38-42. http://aclweb.org/anthology/P12- 2008.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Sequence to sequence learning with neural networks",
                "authors": [
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "Oriol",
                        "middle": [],
                        "last": "Vinyals",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Quoc",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Le",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "3104--3112",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural net- works. In Advances in Neural Information Process- ing Systems 27: Annual Conference on Neural In- formation Processing Systems 2014, December 8- 13 2014, Montreal, Quebec, Canada. pages 3104- 3112. http://papers.nips.cc/paper/5346-sequence- to-sequence-learning-with-neural-networks.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Learning to freestyle: Hip hop challenge-response induction via transduction rule segmentation",
                "authors": [
                    {
                        "first": "Dekai",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Karteek",
                        "middle": [],
                        "last": "Addanki",
                        "suffix": ""
                    },
                    {
                        "first": "Markus",
                        "middle": [],
                        "last": "Saers",
                        "suffix": ""
                    },
                    {
                        "first": "Meriem",
                        "middle": [],
                        "last": "Beloucif",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "102--112",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dekai Wu, Karteek Addanki, Markus Saers, and Meriem Beloucif. 2013. Learning to freestyle: Hip hop challenge-response induction via trans- duction rule segmentation. In Proceedings of the 2013 Conference on Empirical Meth- ods in Natural Language Processing. Associa- tion for Computational Linguistics, pages 102-112. http://aclweb.org/anthology/D13-1011.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Problems in current text simplification research: New data can help",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Transactions of the Association of Computational Linguistics",
                "volume": "3",
                "issue": "",
                "pages": "283--297",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Xu, Chris Callison-Burch, and Courtney Napoles. 2015. Problems in current text simplification re- search: New data can help. Transactions of the As- sociation of Computational Linguistics 3:283-297. http://aclweb.org/anthology/Q15-1021.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Optimizing statistical machine translation for text simplification",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    },
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    },
                    {
                        "first": "Quanze",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Transactions of the Association of Computational Linguistics",
                "volume": "4",
                "issue": "",
                "pages": "401--415",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016. Op- timizing statistical machine translation for text simplification. Transactions of the Associ- ation of Computational Linguistics 4:401-415. http://aclweb.org/anthology/Q16-1029.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Proceedings of the sixth workshop on building and using comparable corpora. Association for Computational Linguistics",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [],
                        "last": "Ritter",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Grishman",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "121--128",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Xu, Alan Ritter, and Ralph Grishman. 2013. Proceedings of the sixth workshop on build- ing and using comparable corpora. Associa- tion for Computational Linguistics, pages 121-128. http://aclweb.org/anthology/W13-2515.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Reference-Aware Language Models",
                "authors": [
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Blunsom",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Z. Yang, P. Blunsom, C. Dyer, and W. Ling. 2016. Reference-Aware Language Models. ArXiv e-prints https://arxiv.org/abs/1611.01628.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Chinese poetry generation with recurrent neural networks",
                "authors": [
                    {
                        "first": "Xingxing",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "670--680",
                "other_ids": {
                    "DOI": [
                        "10.3115/v1/D14-1074"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Xingxing Zhang and Mirella Lapata. 2014. Chi- nese poetry generation with recurrent neural networks. In Proceedings of the 2014 Con- ference on Empirical Methods in Natural Lan- guage Processing (EMNLP). Association for Computational Linguistics, pages 670-680. https://doi.org/10.3115/v1/D14-1074.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: A lyric annotation for \"Like A Rolling Stone\" by Bob Dylan.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Attention visualization of Seq2Seq models for ALA.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td># Lyric Annotation pairs</td><td>803,720</td></tr><tr><td>Tokens per Lyric</td><td>15</td></tr><tr><td>Tokens per Annotation</td><td>43</td></tr><tr><td>|V lyrics |</td><td>124,022</td></tr><tr><td>|V annot |</td><td>260,427</td></tr></table>",
                "type_str": "table",
                "text": "Properties of gathered dataset (V lyrics and V annot denote the vocabulary for lyrics and annotations, denotes the average amount).",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>Type</td><td>% of annotations</td><td colspan=\"2\">Examples</td></tr><tr><td>CI</td><td>34.8%</td><td colspan=\"2\">[L] Gotta patch a lil kid tryna get at this cabbage</td></tr><tr><td>(Context</td><td/><td colspan=\"2\">[A] He's trying to ignore the people trying to get at his money.</td></tr><tr><td colspan=\"4\">independent) [L] CS 65.2% [L] Cause we ain't break up, more like broke down</td></tr><tr><td>(Context</td><td/><td colspan=\"2\">[A] The song details Joe's break up with former girlfriend Esther.</td></tr><tr><td>sensitive)</td><td/><td colspan=\"2\">[L] If I quit this season, I still be the greatest, funk</td></tr><tr><td/><td/><td>[A]</td><td>Kendrick has dropped two classic albums and pushed the artistic envelope fur-ther.</td></tr></table>",
                "type_str": "table",
                "text": "You know it's beef when a smart brother gets stupid [A] You know an argument is serious when an otherwise rational man loses rational.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Examples of context independent and dependent pairs of lyrics [L] and annotations [A].",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td/><td/><td>Properties</td><td/><td colspan=\"2\">Automated Evaluation</td><td/><td colspan=\"2\">Human Evaluation</td></tr><tr><td/><td colspan=\"2\">Length Ratio Profanity/Tok.</td><td colspan=\"4\">BLEU iBLEU METEOR SARI</td><td colspan=\"2\">Fluency Information</td></tr><tr><td>Human</td><td>1.19</td><td>0.0027</td><td>-</td><td>-</td><td>-</td><td>-</td><td>3.93</td><td>3.53</td></tr><tr><td>SMT (Sent.)</td><td>1.23</td><td>0.0068</td><td>6.22</td><td>1.44</td><td>12.20</td><td>38.42</td><td>3.82</td><td>3.31</td></tr><tr><td>Seq2Seq (Sent.)</td><td>1.05</td><td>0.0023</td><td>5.33</td><td>3.64</td><td>9.28</td><td>36.52</td><td>3.76</td><td>3.25</td></tr><tr><td>Seq2Seq</td><td>1.32</td><td>0.0022</td><td>5.15</td><td>3.46</td><td>10.56</td><td>36.86</td><td>3.83</td><td>3.34</td></tr><tr><td>Retrieval</td><td>1.18</td><td>0.0038</td><td>2.82</td><td>2.27</td><td>5.10</td><td>32.76</td><td>3.93</td><td>2.98</td></tr></table>",
                "type_str": "table",
                "text": "Lyrics excerpts with annotations from Genius ('Human') and automated annotators.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Quantitative evaluation of different automated annotators.",
                "html": null,
                "num": null
            }
        }
    }
}