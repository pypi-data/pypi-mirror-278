{
    "paper_id": "P18-1181",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:17:07.423380Z"
    },
    "title": "Deep-speare: A joint neural model of poetic language, meter and rhyme",
    "authors": [
        {
            "first": "Jey",
            "middle": [
                "Han"
            ],
            "last": "Lau",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The University of Melbourne",
                "location": {}
            },
            "email": "jeyhan.lau@gmail.com"
        },
        {
            "first": "Trevor",
            "middle": [],
            "last": "Cohn",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The University of Melbourne",
                "location": {}
            },
            "email": "t.cohn@unimelb.edu.au"
        },
        {
            "first": "Timothy",
            "middle": [],
            "last": "Baldwin",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The University of Melbourne",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Julian",
            "middle": [],
            "last": "Brooke",
            "suffix": "",
            "affiliation": {},
            "email": "julian.brooke@gmail.com"
        },
        {
            "first": "Adam",
            "middle": [],
            "last": "Hammond",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Toronto",
                "location": {}
            },
            "email": "adam.hammond@utoronto.ca"
        },
        {
            "first": "Ibm",
            "middle": [
                "Research"
            ],
            "last": "Australia",
            "suffix": "",
            "affiliation": {},
            "email": ""
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "In this paper, we propose a joint architecture that captures language, rhyme and meter for sonnet modelling. We assess the quality of generated poems using crowd and expert judgements. The stress and rhyme models perform very well, as generated poems are largely indistinguishable from human-written poems. Expert evaluation, however, reveals that a vanilla language model captures meter implicitly, and that machine-generated poems still underperform in terms of readability and emotion. Our research shows the importance expert evaluation for poetry generation, and that future research should look beyond rhyme/meter and focus on poetic language.",
    "pdf_parse": {
        "paper_id": "P18-1181",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "In this paper, we propose a joint architecture that captures language, rhyme and meter for sonnet modelling. We assess the quality of generated poems using crowd and expert judgements. The stress and rhyme models perform very well, as generated poems are largely indistinguishable from human-written poems. Expert evaluation, however, reveals that a vanilla language model captures meter implicitly, and that machine-generated poems still underperform in terms of readability and emotion. Our research shows the importance expert evaluation for poetry generation, and that future research should look beyond rhyme/meter and focus on poetic language.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "With the recent surge of interest in deep learning, one question that is being asked across a number of fronts is: can deep learning techniques be harnessed for creative purposes? Creative applications where such research exists include the composition of music (Humphrey et al., 2013; Sturm et al., 2016; Choi et al., 2016), the design of sculptures (Lehman et al., 2016), and automatic choreography (Crnkovic-Friis and Crnkovic-Friis, 2016). In this paper, we focus on a creative textual task: automatic poetry composition.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "A distinguishing feature of poetry is its aesthetic forms, e.g. rhyme and rhythm/meter. 1 In this work, we treat the task of poem generation as a constrained language modelling task, such that lines of a given poem rhyme, and each line follows a canonical meter and has a fixed number 1 Noting that there are many notable divergences from this in the work of particular poets (e.g. Walt Whitman) and poetry types (such as free verse or haiku).",
                "cite_spans": [
                    {
                        "start": 88,
                        "end": 89,
                        "text": "1",
                        "ref_id": null
                    },
                    {
                        "start": 285,
                        "end": 286,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Shall I compare thee to a summer's day? Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And summer's lease hath all too short a date: of stresses. Specifically, we focus on sonnets and generate quatrains in iambic pentameter (e.g. see Figure 1 ), based on an unsupervised model of language, rhyme and meter trained on a novel corpus of sonnets.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 281,
                        "end": 282,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our findings are as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 our proposed stress and rhyme models work very well, generating sonnet quatrains with stress and rhyme patterns that are indistinguishable from human-written poems and rated highly by an expert; \u2022 a vanilla language model trained over our sonnet corpus, surprisingly, captures meter implicitly at human-level performance; \u2022 while crowd workers rate the poems generated by our best model as nearly indistinguishable from published poems by humans, an expert annotator found the machine-generated poems to lack readability and emotion, and our best model to be only comparable to a vanilla language model on these dimensions; \u2022 most work on poetry generation focuses on meter (Greene et al., 2010; Ghazvininejad et al., 2016; Hopkins and Kiela, 2017); our results suggest that future research should look beyond meter and focus on improving readability.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this, we develop a new annotation framework for the evaluation of machine-generated poems, and release both a novel data of sonnets and the full source code associated with this research.2 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Early poetry generation systems were generally rule-based, and based on rhyming/TTS dictionaries and syllable counting (Gerv\u00e1s, 2000; Wu et al., 2009; Netzer et al., 2009; Colton et al., 2012; Toivanen et al., 2013). The earliest attempt at using statistical modelling for poetry generation was Greene et al. (2010), based on a language model paired with a stress model. Neural networks have dominated recent research. Zhang and Lapata (2014) use a combination of convolutional and recurrent networks for modelling Chinese poetry, which Wang et al. (2016) later simplified by incorporating an attention mechanism and training at the character level. For English poetry, Ghazvininejad et al. (2016) introduced a finite-state acceptor to explicitly model rhythm in conjunction with a recurrent neural language model for generation. Hopkins and Kiela (2017) improve rhythm modelling with a cascade of weighted state transducers, and demonstrate the use of character-level language model for English poetry. A critical difference over our work is that we jointly model both poetry content and forms, and unlike previous work which use dictionaries (Ghazvininejad et al., 2016) or heuristics (Greene et al., 2010) for rhyme, we learn it automatically.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "The sonnet is a poem type popularised by Shakespeare, made up of 14 lines structured as 3 quatrains (4 lines) and a couplet (2 lines);3 an example quatrain is presented in Figure 1 . It follows a number of aesthetic forms, of which two are particularly salient: stress and rhyme.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 179,
                        "end": 180,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "A sonnet line obeys an alternating stress pattern, called the iambic pentameter, e.g.:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "S -S + S -S + S -S + S -S + S -S + Shall I compare thee to a summer's day? where S -and S + denote unstressed and stressed syllables, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "A sonnet also rhymes, with a typical rhyming scheme being ABAB CDCD EFEF GG. There are a number of variants, however, mostly seen in the quatrains; e.g. AABB or ABBA are also common.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "We build our sonnet dataset from the latest image of Project Gutenberg. 4 We first create a (generic) poetry document collection using the GutenTag tool (Brooke et al., 2015), based on its inbuilt poetry classifier and rule-based structural tagging of individual poems.",
                "cite_spans": [
                    {
                        "start": 72,
                        "end": 73,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "Given the poems, we use word and character statistics derived from Shakespeare's 154 sonnets to filter out all non-sonnet poems (to form the \"BACKGROUND\" dataset), leaving the sonnet corpus (\"SONNET\"). 5 Based on a small-scale manual analysis of SONNET, we find that the approach is sufficient for extracting sonnets with high precision. BACKGROUND serves as a large corpus (34M words) for pre-training word embeddings, and SONNET is further partitioned into training, development and testing sets. Statistics of SON-NET are given in Table 1 . 6 ",
                "cite_spans": [
                    {
                        "start": 202,
                        "end": 203,
                        "text": "5",
                        "ref_id": null
                    },
                    {
                        "start": 544,
                        "end": 545,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 540,
                        "end": 541,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Sonnet Structure and Dataset",
                "sec_num": "3"
            },
            {
                "text": "We propose modelling both content and forms jointly with a neural architecture, composed of 3 components: (1) a language model; (2) a pentameter model for capturing iambic pentameter; and (3) a rhyme model for learning rhyming words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Architecture",
                "sec_num": "4"
            },
            {
                "text": "Given a sonnet line, the language model uses standard categorical cross-entropy to predict the next word, and the pentameter model is similarly trained to learn the alternating iambic stress patterns. 7 The rhyme model, on the other hand, uses a margin-based loss to separate rhyming word pairs from non-rhyming word pairs in a quatrain. For generation we use the language model to generate one word at a time, while applying the pentame- 5 The following constraints were used to select sonnets: 8.0 mean words per line 11.5; 40 mean characters per line 51.0; min/max number of words per line of 6/15; min/max number of characters per line of 32/60; and min letter ratio per line 0.59. 6 The sonnets in our collection are largely in Modern English, with possibly a small number of poetry in Early Modern English. The potentially mixed-language dialect data might add noise to our system, and given more data it would be worthwhile to include time period as a factor in the model. 7 There are a number of variations in addition to the standard pattern (Greene et al., 2010), but our model uses only the standard pattern as it is the dominant one. ",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 202,
                        "text": "7",
                        "ref_id": null
                    },
                    {
                        "start": 439,
                        "end": 440,
                        "text": "5",
                        "ref_id": null
                    },
                    {
                        "start": 686,
                        "end": 687,
                        "text": "6",
                        "ref_id": null
                    },
                    {
                        "start": 980,
                        "end": 981,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Architecture",
                "sec_num": "4"
            },
            {
                "text": "The language model is a variant of an LSTM encoder-decoder model with attention (Bahdanau et al., 2015), where the encoder encodes the preceding context (i.e. all sonnet lines before the current line) and the decoder decodes one word at a time for the current line, while attending to the preceding context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "In the encoder, we embed context words z i using embedding matrix W wrd to yield w i , and feed them to a biLSTM9 to produce a sequence of encoder hidden states h i = [ h i ; h i ]. Next we apply a selective mechanism (Zhou et al., 2017) to each h i . By defining the representation of the whole context h = [ h C ; h 1 ] (where C is the number of words in the context), the selective mechanism filters the hidden states h i using h as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "h i = h i \u03c3(W a h i + U a h + b a )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "where denotes element-wise product. Hereinafter W, U and b are used to refer to model parameters. The intuition behind this procedure is to selectively filter less useful elements from the context words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "In the decoder, we embed words x t in the current line using the encoder-shared embedding matrix (W wrd ) to produce w t . In addition to the word embeddings, we also embed the characters of a word using embedding matrix W chr to produce c t,i , and feed them to a bidirectional (character-level) LSTM:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "u t,i = LSTM f (c t,i , u t,i-1 ) u t,i = LSTM b (c t,i , u t,i+1 )",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "We represent the character encoding of a word by concatenating the last forward and first back-",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "ward hidden states u t = [ u t,L ; u t,1 ],",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "where L is the length of the word. We incorporate character encodings because they provide orthographic information, improve representations of unknown words, and are shared with the pentameter model (Section 4.2). 10 The rationale for sharing the parameters is that we see word stress and language model information as complementary.",
                "cite_spans": [
                    {
                        "start": 215,
                        "end": 217,
                        "text": "10",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "Given the word embedding w t and character encoding u t , we concatenate them together and feed them to a unidirectional (word-level) LSTM to produce the decoding states:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "s t = LSTM([w t ; u t ], s t-1 )",
                        "eq_num": "(2)"
                    }
                ],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "We attend s t to encoder hidden states h i and compute the weighted sum of h i as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "e t i = v b tanh(W b h i + U b s t + b b ) a t = softmax(e t ) h * t = i a t i h i",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "To combine s t and h * t , we use a gating unit similar to a GRU (Cho et al., 2014; Chung et al., 2014):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "s t = GRU(s t , h * t )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": ". We then feed s t to a linear layer with softmax activation to produce the vocabulary distribution (i.e. softmax(W out s t + b out ), and optimise the model with standard categorical cross-entropy loss. We use dropout as regularisation (Srivastava et al., 2014), and apply it to the encoder/decoder LSTM outputs and word embedding lookup. The same regularisation method is used for the pentameter and rhyme models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "As our sonnet data is relatively small for training a neural language model (367K words; see Table 1 ), we pre-train word embeddings and reduce parameters further by introducing weight-sharing between output matrix W out and embedding matrix W wrd via a projection matrix W prj (Inan et al., 2016; Paulus et al., 2017; Press and Wolf, 2017):",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 99,
                        "end": 100,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "W out = tanh(W wrd W prj )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "4.1"
            },
            {
                "text": "This component is designed to capture the alternating iambic stress pattern. Given a sonnet line, 10 We initially shared the character encodings with the rhyme model as well, but found sub-par performance for the rhyme model. This is perhaps unsurprising, as rhyme and stress are qualitatively very different aspects of forms.",
                "cite_spans": [
                    {
                        "start": 98,
                        "end": 100,
                        "text": "10",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "the pentameter model learns to attend to the appropriate characters to predict the 10 binary stress symbols sequentially.11 As punctuation is not pronounced, we preprocess each sonnet line to remove all punctuation, leaving only spaces and letters. Like the language model, the pentameter model is fashioned as an encoder-decoder network.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "In the encoder, we embed the characters using the shared embedding matrix W chr and feed them to the shared bidirectional character-level LSTM (Equation ( 1)) to produce the character encodings for the sentence:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "u j = [ u j ; u j ].",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "In the decoder, it attends to the characters to predict the stresses sequentially with an LSTM:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "g t = LSTM(u * t-1 , g t-1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": ") where u * t-1 is the weighted sum of character encodings from the previous time step, produced by an attention network which we describe next,12 and g t is fed to a linear layer with softmax activation to compute the stress distribution.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "The attention network is designed to focus on stress-producing characters, whose positions are monotonically increasing (as stress is predicted sequentially). We first compute \u00b5 t , the mean position of focus:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "\u00b5 t = \u03c3(v c tanh(W c g t + U c \u00b5 t-1 + b c )) \u00b5 t = M \u00d7 min(\u00b5 t + \u00b5 t-1 , 1.0)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "where M is the number of characters in the sonnet line. Given \u00b5 t , we can compute the (unnormalised) probability for each character position:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "p t j = exp -(j -\u00b5 t ) 2 2T 2",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "where standard deviation T is a hyper-parameter. We incorporate this position information when computing u * t :13 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "u j = p t j u j d t j = v d tanh(W d u j + U d g t + b d ) f t = softmax(d t + log p t ) u * t = j b t j u j",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "Intuitively, the attention network incorporates the position information at two points, when computing: (1) d t j by weighting the character encodings; and (2) f t by adding the position log probabilities. This may appear excessive, but preliminary experiments found that this formulation produces the best performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "In a typical encoder-decoder model, the attended encoder vector u * t would be combined with the decoder state g t to compute the output probability distribution. Doing so, however, would result in a zero-loss model as it will quickly learn that it can simply ignore u * t to predict the alternating stresses based on g t . For this reason we use only u * t to compute the stress probability:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "P (S -) = \u03c3(W e u * t + b e )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "which gives the loss L ent = t -log P (S t ) for the whole sequence, where S t is the target stress at time step t.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "We find the decoder still has the tendency to attend to the same characters, despite the incorporation of position information. To regularise the model further, we introduce two loss penalties: repeat and coverage loss.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "The repeat loss penalises the model when it attends to previously attended characters (See et al., 2017), and is computed as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "L rep = t j min(f t j , t-1 t=1 f t j )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "By keeping a sum of attention weights over all previous time steps, we penalise the model when it focuses on characters that have non-zero history weights.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "The repeat loss discourages the model from focussing on the same characters, but does not assure that the appropriate characters receive attention. Observing that stresses are aligned with the vowels of a syllable, we therefore penalise the model when vowels are ignored:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "L cov = j\u2208V ReLU(C - 10 t=1 f t j )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "where V is a set of positions containing vowel characters, and C is a hyper-parameter that defines the minimum attention threshold that avoids penalty.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "To summarise, the pentameter model is optimised with the following loss:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "L pm = L ent + \u03b1L rep + \u03b2L cov (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "where \u03b1 and \u03b2 are hyper-parameters for weighting the additional loss terms.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "4.2"
            },
            {
                "text": "Two reasons motivate us to learn rhyme in an unsupervised manner:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "(1) we intend to extend the current model to poetry in other languages (which may not have pronunciation dictionaries); and (2) the language in our SONNET data is not Modern English, and so contemporary dictionaries may not accurately reflect the rhyme of the data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "Exploiting the fact that rhyme exists in a quatrain, we feed sentence-ending word pairs of a quatrain as input to the rhyme model and train it to learn how to separate rhyming word pairs from non-rhyming ones. Note that the model does not assume any particular rhyming scheme -it works as long as quatrains have rhyme.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "A training example consists of a number of word pairs, generated by pairing one target word with 3 other reference words in the quatrain, i.e. {(x t , x r ), (x t , x r+1 ), (x t , x r+2 )}, where x t is the target word and x r+i are the reference words. 14 We assume that in these 3 pairs there should be one rhyming and 2 non-rhyming pairs. From preliminary experiments we found that we can improve the model by introducing additional non-rhyming or negative reference words. Negative reference words are sampled uniform randomly from the vocabulary, and the number of additional negative words is a hyper-parameter.",
                "cite_spans": [
                    {
                        "start": 255,
                        "end": 257,
                        "text": "14",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "For each word x in the word pairs we embed the characters using the shared embedding matrix W chr and feed them to an LSTM to produce the character states u j . 15 Unlike the language and pentameter models, we use a unidirectional forward LSTM here (as rhyme is largely determined by the final characters), and the LSTM parameters are not shared. We represent the encoding of the whole word by taking the last state u = u L , where L is the character length of the word.",
                "cite_spans": [
                    {
                        "start": 161,
                        "end": 163,
                        "text": "15",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "Given the character encodings, we use a margin-based loss to optimise the model:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "Q = {cos(u t , u r ), cos(u t , u r+1 ), ...} L rm = max(0, \u03b4 -top(Q, 1) + top(Q, 2))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "where top(Q, k) returns the k-th largest element in Q, and \u03b4 is a margin hyper-parameter.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "Intuitively, the model is trained to learn a sufficient margin (defined by \u03b4) that separates the best pair with all others, with the second-best being used to quantify all others. This is the justification used in the multi-class SVM literature for a similar objective (Wang and Xue, 2014).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "With this network we can estimate whether two words rhyme by computing the cosine similarity score during generation, and resample words as necessary to enforce rhyme.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "4.3"
            },
            {
                "text": "We focus on quatrain generation in this work, and so the aim is to generate 4 lines of poetry. During generation we feed the hidden state from the previous time step to the language model's decoder to compute the vocabulary distribution for the current time step. Words are sampled using a temperature between 0.6 and 0.8, and they are resampled if the following set of words is generated: (1) UNK token; (2) non-stopwords that were generated before; 16 (3) any generated words with a frequency 2; (4) the preceding 3 words; and (5) a number of symbols including parentheses, single and double quotes. 17 The first sonnet line is generated without using any preceding context.",
                "cite_spans": [
                    {
                        "start": 451,
                        "end": 453,
                        "text": "16",
                        "ref_id": null
                    },
                    {
                        "start": 602,
                        "end": 604,
                        "text": "17",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Procedure",
                "sec_num": "4.4"
            },
            {
                "text": "We next describe how to incorporate the pentameter model for generation. Given a sonnet line, the pentameter model computes a loss L pm (Equation (3)) that indicates how well the line conforms to the iambic pentameter. We first generate 10 candidate lines (all initialised with the same hidden state), and then sample one line from the candidate lines based on the pentameter loss values (L pm ). We convert the losses into probabilities by taking the softmax, and a sentence is sampled with temperature = 0.1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Procedure",
                "sec_num": "4.4"
            },
            {
                "text": "To enforce rhyme, we randomly select one of the rhyming schemes (AABB, ABAB or ABBA) and resample sentence-ending words as necessary. Given a pair of words, the rhyme model produces a cosine similarity score that estimates how well the two words rhyme. We resample the second word of a rhyming pair (e.g. when generating the second A in AABB) until it produces a cosine similarity 0.9. We also resample the second word of a nonrhyming pair (e.g. when generating the first B in AABB) by requiring a cosine similarity 0.7. 18 When generating in the forward direction we can never be sure that any particular word is the last word of a line, which creates a problem for resampling to produce good rhymes. This problem is resolved in our model by reversing the direction of the language model, i.e. generating the last word of each line first. We apply this inversion trick at the word level (character order of a word is not modified) and only to the language model; the pentameter model receives the original word order as input.",
                "cite_spans": [
                    {
                        "start": 521,
                        "end": 523,
                        "text": "18",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Procedure",
                "sec_num": "4.4"
            },
            {
                "text": "We assess our sonnet model in two ways: (1) component evaluation of the language, pentameter and rhyme models; and (2) poetry generation evaluation, by crowd workers and an English literature expert. A sample of machine-generated sonnets are included in the supplementary material.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "We tune the hyper-parameters of the model over the development data (optimal configuration in the supplementary material). Word embeddings are initialised with pre-trained skip-gram embeddings (Mikolov et al., 2013a,b) on the BACKGROUND dataset, and are updated during training. For optimisers, we use Adagrad (Duchi et al., 2011) for the language model, and Adam (Kingma and Ba, 2014) for the pentameter and rhyme models. We truncate backpropagation through time after 2 sonnet lines, and train using 30 epochs, resetting the network weights to the weights from the previous epoch whenever development loss worsens.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "We use standard perplexity for evaluating the language model. In terms of model variants, we have: 19 \u2022 LM: Vanilla LSTM language model; \u2022 LM * : LSTM language model that incorporates character encodings (Equation (2)); Table 2 : Component evaluation for the language model (\"Ppl\" = perplexity), pentameter model (\"Stress Acc\"), and rhyme model (\"Rhyme F1\").",
                "cite_spans": [
                    {
                        "start": 99,
                        "end": 101,
                        "text": "19",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 226,
                        "end": 227,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "5.1.1"
            },
            {
                "text": "Each number is an average across 10 runs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "5.1.1"
            },
            {
                "text": "\u2022 LM * * : LSTM language model that incorporates both character encodings and preceding context; \u2022 LM * * -C: Similar to LM * * , but preceding context is encoded using convolutional networks, inspired by the poetry model of Zhang and Lapata (2014); 20 \u2022 LM * * +PM+RM: the full model, with joint training of the language, pentameter and rhyme models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "5.1.1"
            },
            {
                "text": "Perplexity on the test partition is detailed in Table 2. Encouragingly, we see that the incorporation of character encodings and preceding context improves performance substantially, reducing perplexity by almost 10 points from LM to LM * * . The inferior performance of LM * * -C compared to LM * * demonstrates that our approach of processing context with recurrent networks with selective encoding is more effective than convolutional networks. The full model LM * * +PM+RM, which learns stress 20 In Zhang and Lapata (2014), the authors use a series of convolutional networks with a width of 2 words to convert 5/7 poetry lines into a fixed size vector; here we use a standard convolutional network with max-pooling operation (Kim, 2014) to process the context. and rhyme patterns simultaneously, also appears to improve the language model slightly.",
                "cite_spans": [
                    {
                        "start": 498,
                        "end": 500,
                        "text": "20",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Language Model",
                "sec_num": "5.1.1"
            },
            {
                "text": "To assess the pentameter model, we use the attention weights to predict stress patterns for words in the test data, and compare them against stress patterns in the CMU pronunciation dictionary. 21 Words that have no coverage or have nonalternating patterns given by the dictionary are discarded. We use accuracy as the metric, and a predicted stress pattern is judged to be correct if it matches any of the dictionary stress patterns.",
                "cite_spans": [
                    {
                        "start": 194,
                        "end": 196,
                        "text": "21",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "To extract a stress pattern for a word from the model, we iterate through the pentameter (10 time steps), and append the appropriate stress (e.g. 1st time step = S -) to the word if any of its characters receives an attention 0.20.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "For the baseline (Stress-BL) we use the pretrained weighted finite state transducer (WFST) provided by Hopkins and Kiela (2017). 22 The WFST maps a sequence word to a sequence of stresses by assuming each word has 1-5 stresses and the full word sequence produces iambic pentameter. It is trained using the EM algorithm on a sonnet corpus developed by the authors.",
                "cite_spans": [
                    {
                        "start": 129,
                        "end": 131,
                        "text": "22",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "We present stress accuracy in Table 2 . LM * * +PM+RM performs competitively, and informal inspection reveals that a number of mistakes are due to dictionary errors. To understand the predicted stresses qualitatively, we display attention heatmaps for the the first quatrain of Shakespeare's Sonnet 18 in Figure 3 . The y-axis represents the ten stresses of the iambic pentameter, and Examples on the left (right) side are rhyming (non-rhyming) word pairs -determined using the CMU dictionary -that have low (high) cosine similarity. \"Cos\" denote the system predicted cosine similarity for the word pair.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 36,
                        "end": 37,
                        "text": "2",
                        "ref_id": null
                    },
                    {
                        "start": 312,
                        "end": 313,
                        "text": "3",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "x-axis the characters of the sonnet line (punctuation removed). The attention network appears to perform very well, without any noticeable errors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "The only minor exception is lovely in the second line, where it predicts 2 stresses but the second stress focuses incorrectly on the character e rather than y. Additional heatmaps for the full sonnet are provided in the supplementary material.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pentameter Model",
                "sec_num": "5.1.2"
            },
            {
                "text": "We follow a similar approach to evaluate the rhyme model against the CMU dictionary, but score based on F1 score. Word pairs that are not included in the dictionary are discarded. Rhyme is determined by extracting the final stressed phoneme for the paired words, and testing if their phoneme patterns match.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "5.1.3"
            },
            {
                "text": "We predict rhyme for a word pair by feeding them to the rhyme model and computing cosine similarity; if a word pair is assigned a score 0.8,23 it is considered to rhyme. As a baseline (Rhyme-BL), we first extract for each word the last vowel and all following consonants, and predict a word pair as rhyming if their extracted sequences match. The extracted sequence can be interpreted as a proxy for the last syllable of a word. Reddy and Knight (2011) propose an unsupervised model for learning rhyme schemes in poems via EM. There are two latent variables: \u03c6 specifies the distribution of rhyme schemes, and \u03b8 defines the pairwise rhyme strength between two words. The model's objective is to maximise poem likelihood over all possible rhyme scheme assignments under the latent variables \u03c6 and \u03b8. We train this model (Rhyme-EM) on our data24 and use the learnt \u03b8 to decide whether two words rhyme. 25 Table 2 details the rhyming results. The rhyme model performs very strongly at F1 > 0.90, well above both baselines. Rhyme-EM performs poorly because it operates at the word level (i.e. it ignores character/orthographic information) and hence does not generalise well to unseen words and word pairs. 26 To better understand the errors qualitatively, we present a list of word pairs with their predicted cosine similarity in Table 3 . Examples on the left side are rhyming word pairs as determined by the CMU dictionary; right are non-rhyming pairs. Looking at the rhyming word pairs (left), it appears that these words tend not to share any wordending characters. For the non-rhyming pairs, we spot several CMU errors: (sire, ire) and (queen, been) clearly rhyme.",
                "cite_spans": [
                    {
                        "start": 900,
                        "end": 902,
                        "text": "25",
                        "ref_id": null
                    },
                    {
                        "start": 1203,
                        "end": 1205,
                        "text": "26",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 909,
                        "end": 910,
                        "text": "2",
                        "ref_id": null
                    },
                    {
                        "start": 1333,
                        "end": 1334,
                        "text": "3",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Rhyme Model",
                "sec_num": "5.1.3"
            },
            {
                "text": "Following Hopkins and Kiela (2017), we present a pair of quatrains (one machine-generated and one human-written, in random order) to crowd workers on CrowdFlower, and ask them to guess which is the human-written poem. Generation quality is estimated by computing the accuracy of workers at correctly identifying the human-written poem (with lower values indicate better results for the model).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Crowdworker Evaluation",
                "sec_num": "5.2.1"
            },
            {
                "text": "We generate 50 quatrains each for LM, LM * * and LM * * +PM+RM (150 in total), and as a control, generate 30 quatrains with LM trained for one epoch. An equal number of human-written quatrains was sampled from the training partition. A HIT contained 5 pairs of poems (of which one is a control), and workers were paid $0.05 for each HIT. Workers who failed to identify the human-written poem in the control pair reliably (minimum accuracy = 70%) were removed by CrowdFlower automati- cally, and they were restricted to do a maximum of 3 HITs. To dissuade workers from using search engines to identify real poems, we presented the quatrains as images.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Crowdworker Evaluation",
                "sec_num": "5.2.1"
            },
            {
                "text": "Accuracy is presented in Table 4 . We see a steady decrease in accuracy (= improvement in model quality) from LM to LM * * to LM * * +PM+RM, indicating that each model generates quatrains that are less distinguishable from human-written ones. Based on the suspicion that workers were using rhyme to judge the poems, we tested a second model, LM * * +RM, which is the full model without the pentameter component. We found identical accuracy (0.532), confirming our suspicion that crowd workers depend on only rhyme in their judgements. These observations demonstrate that meter is largely ignored by lay persons in poetry evaluation.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 31,
                        "end": 32,
                        "text": "4",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Crowdworker Evaluation",
                "sec_num": "5.2.1"
            },
            {
                "text": "To better understand the qualitative aspects of our generated quatrains, we asked an English literature expert (a Professor of English literature at a major English-speaking university; the last author of this paper) to directly rate 4 aspects: meter, rhyme, readability and emotion (i.e. amount of emotion the poem evokes). All are rated on an ordinal scale between 1 to 5 (1 = worst; 5 = best). In total, 120 quatrains were annotated, 30 each for LM, LM * * , LM * * +PM+RM, and human-written poems (Human). The expert was blind to the source of each poem. The mean and standard deviation of the ratings are presented in Table 5 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 629,
                        "end": 630,
                        "text": "5",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Expert Judgement",
                "sec_num": "5.2.2"
            },
            {
                "text": "We found that our full model has the highest ratings for both rhyme and meter, even higher than human poets. This might seem surprising, but in fact it is well established that real poets regularly break rules of form to create other effects (Adams, 1997). Despite excellent form, the output of our model can easily be distinguished from humanwritten poetry due to its lower emotional impact and readability. In particular, there is evidence here that our focus on form actually hurts the readability of the resulting poems, relative even to the simpler language models. Another surprise is how well simple language models do in terms of their grasp of meter: in this expert evaluation, we see only marginal benefit as we increase the sophistication of the model. Taken as a whole, this evaluation suggests that future research should look beyond forms, towards the substance of good poetry.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expert Judgement",
                "sec_num": "5.2.2"
            },
            {
                "text": "We propose a joint model of language, meter and rhyme that captures language and form for modelling sonnets. We provide quantitative analyses for each component, and assess the quality of generated poems using judgements from crowdworkers and a literature expert. Our research reveals that vanilla LSTM language model captures meter implicitly, and our proposed rhyme model performs exceptionally well. Machine-generated generated poems, however, still underperform in terms of readability and emotion.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "https://github.com/jhlau/deepspeare",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "There are other forms of sonnets, but the Shakespearean sonnet is the dominant one. Hereinafter \"sonnet\" is used to specifically mean Shakespearean sonnets.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://www.gutenberg.org/.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We stress that although the components appear to be disjointed, the shared parameters allow the components to mutually influence each other during joint training. To exemplify this, we found that the pentameter model performs very poorly when we train each component",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "separately.9 We use a single layer for all LSTMs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "That is, given the input line Shall I compare thee to a summer's day? the model is required to output S -S + S - S + S -S + S -S + S -S + , based on the syllable boundaries from Section 3.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "12 Initial input (u * 0 ) and state (g0) is a trainable vector and zero vector",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "respectively.13 Spaces are masked out, so they always yield zero attention weights.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "E.g. for the quatrain in Figure1, a training example is {(day, temperate), (day, may), (day, date)}.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The character embeddings are the only shared parameters in this model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We use the NLTK stopword list(Bird et al., 2009).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We add these constraints to prevent the model from being too repetitive, in generating the same words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Maximum number of resampling steps is capped at 1000. If the threshold is exceeded the model is reset to generate from scratch again.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "All models use the same (applicable) hyper-parameter configurations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www.speech.cs.cmu.edu/cgi-bin/ cmudict. Note that the dictionary provides 3 levels of stresses: 0, 1 and 2; we collapse 1 and 2 to S + .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/JackHopkins/ ACLPoetry",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "0.8 is empirically found to be the best threshold based on development data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We use the original authors' implementation: https: //github.com/jvamvas/rhymediscovery.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "A word pair is judged to rhyme if \u03b8w 1 ,w 2 0.02; the threshold (0.02) is selected based on development performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "26 Word pairs that did not co-occur in a poem in the training data have rhyme strength of zero.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Poetic designs: An introduction to meters, verse forms, and figures of speech",
                "authors": [
                    {
                        "first": "Stephen",
                        "middle": [],
                        "last": "Adams",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stephen Adams. 1997. Poetic designs: An introduc- tion to meters, verse forms, and figures of speech. Broadview Press.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Neural machine translation by jointly learning to align and translate",
                "authors": [
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In International Con- ference on Learning Representations, San Diego, USA.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Natural Language Processing with Python -Analyzing Text with the Natural Language Toolkit",
                "authors": [
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bird",
                        "suffix": ""
                    },
                    {
                        "first": "Ewan",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    },
                    {
                        "first": "Edward",
                        "middle": [],
                        "last": "Loper",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python -An- alyzing Text with the Natural Language Toolkit. O'Reilly Media, Sebastopol, USA.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "GutenTag: An NLP-driven tool for digital humanities research in the Project Gutenberg corpus",
                "authors": [
                    {
                        "first": "Julian",
                        "middle": [],
                        "last": "Brooke",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Hammond",
                        "suffix": ""
                    },
                    {
                        "first": "Graeme",
                        "middle": [],
                        "last": "Hirst",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 4nd Workshop on Computational Literature for Literature (CLFL '15)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Julian Brooke, Adam Hammond, and Graeme Hirst. 2015. GutenTag: An NLP-driven tool for digital hu- manities research in the Project Gutenberg corpus. In Proceedings of the 4nd Workshop on Computa- tional Literature for Literature (CLFL '15).",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "On the properties of neural machine translation: Encoder-decoder approaches",
                "authors": [
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Bart",
                        "middle": [],
                        "last": "Van Merrienboer",
                        "suffix": ""
                    },
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",
                "volume": "",
                "issue": "",
                "pages": "103--111",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bah- danau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoder-decoder ap- proaches. In Proceedings of SSST-8, Eighth Work- shop on Syntax, Semantics and Structure in Statisti- cal Translation, pages 103-111, Doha, Qatar.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Text-based LSTM networks for automatic music composition",
                "authors": [
                    {
                        "first": "Keunwoo",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "George",
                        "middle": [],
                        "last": "Fazekas",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Sandler",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 1st Conference on Computer Simulation of Musical Creativity",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Keunwoo Choi, George Fazekas, and Mark Sandler. 2016. Text-based LSTM networks for automatic music composition. In Proceedings of the 1st Con- ference on Computer Simulation of Musical Creativ- ity, Huddersfield, UK.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
                "authors": [
                    {
                        "first": "Junyoung",
                        "middle": [],
                        "last": "Chung",
                        "suffix": ""
                    },
                    {
                        "first": "Caglar",
                        "middle": [],
                        "last": "Gulcehre",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "NIPS Deep Learning and Representation Learning Workshop",
                "volume": "",
                "issue": "",
                "pages": "103--111",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence mod- eling. In NIPS Deep Learning and Representa- tion Learning Workshop, pages 103-111, Montreal, Canada.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Full face poetry generation",
                "authors": [
                    {
                        "first": "Simon",
                        "middle": [],
                        "last": "Colton",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Goodwin",
                        "suffix": ""
                    },
                    {
                        "first": "Tony",
                        "middle": [],
                        "last": "Veale",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the Third International Conference on Computational Creativity",
                "volume": "",
                "issue": "",
                "pages": "95--102",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Simon Colton, Jacob Goodwin, and Tony Veale. 2012. Full face poetry generation. In Proceedings of the Third International Conference on Computational Creativity, pages 95-102.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Generative choreography using deep learning",
                "authors": [
                    {
                        "first": "Luka",
                        "middle": [],
                        "last": "Crnkovic",
                        "suffix": ""
                    },
                    {
                        "first": "-Friis",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Louise",
                        "middle": [],
                        "last": "Crnkovic-Friis",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 7th International Conference on Computational Creativity",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Luka Crnkovic-Friis and Louise Crnkovic-Friis. 2016. Generative choreography using deep learning. In Proceedings of the 7th International Conference on Computational Creativity, Paris, France.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Adaptive subgradient methods for online learning and stochastic optimization",
                "authors": [
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Duchi",
                        "suffix": ""
                    },
                    {
                        "first": "Elad",
                        "middle": [],
                        "last": "Hazan",
                        "suffix": ""
                    },
                    {
                        "first": "Yoram",
                        "middle": [],
                        "last": "Singer",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Journal of Machine Learning Research",
                "volume": "12",
                "issue": "",
                "pages": "2121--2159",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121-2159.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Wasp: Evaluation of different strategies for the automatic generation of spanish verse",
                "authors": [
                    {
                        "first": "Pablo",
                        "middle": [],
                        "last": "Gerv\u00e1s",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Proceedings of the AISB-00 Symposium on Creative & Cultural Aspects of AI",
                "volume": "",
                "issue": "",
                "pages": "93--100",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pablo Gerv\u00e1s. 2000. Wasp: Evaluation of different strategies for the automatic generation of spanish verse. In Proceedings of the AISB-00 Symposium on Creative & Cultural Aspects of AI, pages 93-100.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Generating topical poetry",
                "authors": [
                    {
                        "first": "Marjan",
                        "middle": [],
                        "last": "Ghazvininejad",
                        "suffix": ""
                    },
                    {
                        "first": "Xing",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "1183--1191",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marjan Ghazvininejad, Xing Shi, Yejin Choi, and Kevin Knight. 2016. Generating topical poetry. pages 1183-1191, Austin, Texas.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Automatic analysis of rhythmic poetry with applications to generation and translation",
                "authors": [
                    {
                        "first": "Erica",
                        "middle": [],
                        "last": "Greene",
                        "suffix": ""
                    },
                    {
                        "first": "Tugba",
                        "middle": [],
                        "last": "Bodrumlu",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010)",
                "volume": "",
                "issue": "",
                "pages": "524--533",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Erica Greene, Tugba Bodrumlu, and Kevin Knight. 2010. Automatic analysis of rhythmic poetry with applications to generation and translation. In Pro- ceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010), pages 524-533, Massachusetts, USA.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Automatically generating rhythmic verse with neural networks",
                "authors": [
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Hopkins",
                        "suffix": ""
                    },
                    {
                        "first": "Douwe",
                        "middle": [],
                        "last": "Kiela",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017)",
                "volume": "",
                "issue": "",
                "pages": "168--178",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jack Hopkins and Douwe Kiela. 2017. Automatically generating rhythmic verse with neural networks. In Proceedings of the 55th Annual Meeting of the Asso- ciation for Computational Linguistics (ACL 2017), pages 168-178, Vancouver, Canada.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Feature learning and deep architectures: new directions for music informatics",
                "authors": [
                    {
                        "first": "Eric",
                        "middle": [
                            "J"
                        ],
                        "last": "Humphrey",
                        "suffix": ""
                    },
                    {
                        "first": "Juan",
                        "middle": [
                            "P"
                        ],
                        "last": "Bello",
                        "suffix": ""
                    },
                    {
                        "first": "Yann",
                        "middle": [],
                        "last": "Lecun",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Journal of Intelligent Information Systems",
                "volume": "41",
                "issue": "3",
                "pages": "461--481",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eric J. Humphrey, Juan P. Bello, and Yann LeCun. 2013. Feature learning and deep architectures: new directions for music informatics. Journal of Intelli- gent Information Systems, 41(3):461-481.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Tying word vectors and word classifiers: A loss framework for language modeling",
                "authors": [
                    {
                        "first": "Hakan",
                        "middle": [],
                        "last": "Inan",
                        "suffix": ""
                    },
                    {
                        "first": "Khashayar",
                        "middle": [],
                        "last": "Khosravi",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hakan Inan, Khashayar Khosravi, and Richard Socher. 2016. Tying word vectors and word classifiers: A loss framework for language modeling. CoRR, abs/1611.01462.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Convolutional neural networks for sentence classification",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1746--1751",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Kim. 2014. Convolutional neural networks for sen- tence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP 2014), pages 1746- 1751, Doha, Qatar.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Adam: A method for stochastic optimization",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Diederik",
                        "suffix": ""
                    },
                    {
                        "first": "Jimmy",
                        "middle": [],
                        "last": "Kingma",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ba",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Diederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. CoRR, abs/1412.6980.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Creative generation of 3D objects with deep learning and innovation engines",
                "authors": [
                    {
                        "first": "Joel",
                        "middle": [],
                        "last": "Lehman",
                        "suffix": ""
                    },
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Risi",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Clune",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 7th International Conference on Computational Creativity",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joel Lehman, Sebastian Risi, and Jeff Clune. 2016. Creative generation of 3D objects with deep learn- ing and innovation engines. In Proceedings of the 7th International Conference on Computational Creativity, Paris, France.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Efficient estimation of word representations in vector space",
                "authors": [
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Corrado",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Dean",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of Workshop at the International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word represen- tations in vector space. In Proceedings of Workshop at the International Conference on Learning Repre- sentations, 2013, Scottsdale, USA.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Distributed representations of words and phrases and their compositionality",
                "authors": [
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [
                            "S"
                        ],
                        "last": "Corrado",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Dean",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "3111--3119",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor- rado, and Jeff Dean. 2013b. Distributed representa- tions of words and phrases and their compositional- ity. In Advances in Neural Information Processing Systems, pages 3111-3119.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Gaiku: Generating haiku with word associations norms",
                "authors": [
                    {
                        "first": "Yael",
                        "middle": [],
                        "last": "Netzer",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Gabay",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Elhadad",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the Workshop on Computational Approaches to Linguistic Creativity",
                "volume": "",
                "issue": "",
                "pages": "32--39",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yael Netzer, David Gabay, Yoav Goldberg, and Michael Elhadad. 2009. Gaiku: Generating haiku with word associations norms. In Proceedings of the Workshop on Computational Approaches to Linguis- tic Creativity, pages 32-39.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A deep reinforced model for abstractive summarization",
                "authors": [
                    {
                        "first": "Romain",
                        "middle": [],
                        "last": "Paulus",
                        "suffix": ""
                    },
                    {
                        "first": "Caiming",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Romain Paulus, Caiming Xiong, and Richard Socher. 2017. A deep reinforced model for abstractive sum- marization. CoRR, abs/1705.04304.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Using the output embedding to improve language models",
                "authors": [],
                "year": 2017,
                "venue": "Proceedings of the 15th Conference of the EACL (EACL 2017)",
                "volume": "",
                "issue": "",
                "pages": "157--163",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ofir Press and Lior Wolf. 2017. Using the output em- bedding to improve language models. In Proceed- ings of the 15th Conference of the EACL (EACL 2017), pages 157-163, Valencia, Spain.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Unsupervised discovery of rhyme schemes",
                "authors": [
                    {
                        "first": "Sravana",
                        "middle": [],
                        "last": "Reddy",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011)",
                "volume": "",
                "issue": "",
                "pages": "77--82",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sravana Reddy and Kevin Knight. 2011. Unsupervised discovery of rhyme schemes. In Proceedings of the 49th Annual Meeting of the Association for Com- putational Linguistics: Human Language Technolo- gies (ACL HLT 2011), pages 77-82, Portland, Ore- gon, USA.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Get to the point: Summarization with pointergenerator networks",
                "authors": [
                    {
                        "first": "Abigail",
                        "middle": [],
                        "last": "See",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [
                            "J"
                        ],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1073--1083",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Abigail See, Peter J. Liu, and Christopher D. Manning. 2017. Get to the point: Summarization with pointer- generator networks. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics (ACL 2017), pages 1073-1083, Vancou- ver, Canada.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Dropout: A simple way to prevent neural networks from overfitting",
                "authors": [
                    {
                        "first": "Nitish",
                        "middle": [],
                        "last": "Srivastava",
                        "suffix": ""
                    },
                    {
                        "first": "Geoffrey",
                        "middle": [],
                        "last": "Hinton",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Krizhevsky",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "Ruslan",
                        "middle": [],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Journal of Machine Learning Research",
                "volume": "15",
                "issue": "",
                "pages": "1929--1958",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Re- search, 15:1929-1958.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Music transcription modelling and composition using deep learning",
                "authors": [
                    {
                        "first": "Bob",
                        "middle": [
                            "L"
                        ],
                        "last": "Sturm",
                        "suffix": ""
                    },
                    {
                        "first": "Jo",
                        "middle": [],
                        "last": "Ao",
                        "suffix": ""
                    },
                    {
                        "first": "Felipe",
                        "middle": [],
                        "last": "Santos",
                        "suffix": ""
                    },
                    {
                        "first": "Oded",
                        "middle": [],
                        "last": "Ben-Tal",
                        "suffix": ""
                    },
                    {
                        "first": "Iryna",
                        "middle": [],
                        "last": "Korshunova",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 1st Conference on Computer Simulation of Musical Creativity",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bob L. Sturm, Jo ao Felipe Santos, Oded Ben-Tal, and Iryna Korshunova. 2016. Music transcription mod- elling and composition using deep learning. In Pro- ceedings of the 1st Conference on Computer Simu- lation of Musical Creativity, Huddersfield, UK.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Harnessing constraint programming for poetry composition",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Jukka",
                        "suffix": ""
                    },
                    {
                        "first": "Matti",
                        "middle": [],
                        "last": "Toivanen",
                        "suffix": ""
                    },
                    {
                        "first": "Hannu",
                        "middle": [],
                        "last": "J\u00e4rvisalo",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Toivonen",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the Fourth International Conference on Computational Creativity",
                "volume": "",
                "issue": "",
                "pages": "160--160",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jukka M. Toivanen, Matti J\u00e4rvisalo, and Hannu Toivo- nen. 2013. Harnessing constraint programming for poetry composition. In Proceedings of the Fourth International Conference on Computational Cre- ativity, pages 160-160.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Chinese song iambics generation with neural attention-based model",
                "authors": [
                    {
                        "first": "Qixin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Tianyi",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "Dong",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Chao",
                        "middle": [],
                        "last": "Xing",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 25nd International Joint Conference on Artificial Intelligence (IJCAI-2016)",
                "volume": "",
                "issue": "",
                "pages": "23--48",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qixin Wang, Tianyi Luo, Dong Wang, and Chao Xing. 2016. Chinese song iambics generation with neural attention-based model. In Proceedings of the 25nd International Joint Conference on Artificial Intelli- gence (IJCAI-2016), pages 2943-2949, New York, USA. Zhe Wang and Xiangyang Xue. 2014. In Support Vec- tor Machines Applications, pages 23-48. Springer.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Newhitch haiku: An interactive renku poem composition supporting tool applied for sightseeing navigation system",
                "authors": [
                    {
                        "first": "Xiaofeng",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Naoko",
                        "middle": [],
                        "last": "Tosa",
                        "suffix": ""
                    },
                    {
                        "first": "Ryohei",
                        "middle": [],
                        "last": "Nakatsu",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Entertainment Computing-ICEC 2009",
                "volume": "",
                "issue": "",
                "pages": "191--196",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiaofeng Wu, Naoko Tosa, and Ryohei Nakatsu. 2009. Newhitch haiku: An interactive renku poem compo- sition supporting tool applied for sightseeing naviga- tion system. Entertainment Computing-ICEC 2009, pages 191-196.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Chinese poetry generation with recurrent neural networks",
                "authors": [
                    {
                        "first": "Xingxing",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "670--680",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xingxing Zhang and Mirella Lapata. 2014. Chinese poetry generation with recurrent neural networks. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014), pages 670-680, Doha, Qatar.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Selective encoding for abstractive sentence summarization",
                "authors": [
                    {
                        "first": "Qingyu",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Furu",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017)",
                "volume": "",
                "issue": "",
                "pages": "1095--1104",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qingyu Zhou, Nan Yang, Furu Wei, and Ming Zhou. 2017. Selective encoding for abstractive sentence summarization. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics (ACL 2017), pages 1095-1104, Vancouver, Canada.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: 1st quatrain of Shakespeare's Sonnet 18.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Architecture of the language, pentameter and rhyme models. Colours denote shared weights.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "s h a l l i c o m p a re t he e t o a s um m e r s d a y t ho u a rt m o re lov e ly a nd m o re te m pe ra te rough w inds do shake the darling buds of may and summer s lease hath all too short a date",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 3: Character attention weights for the first quatrain of Shakespeare's Sonnet 18.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td colspan=\"3\">Partition #Sonnets #Words</td></tr><tr><td>Train</td><td>2685</td><td>367K</td></tr><tr><td>Dev</td><td>335</td><td>46K</td></tr><tr><td>Test</td><td>335</td><td>46K</td></tr></table>",
                "type_str": "table",
                "text": "SONNET dataset statistics.",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>CMU Rhyming Pairs</td><td>CMU Non-Rhyming Pairs</td></tr><tr><td>Word Pair Cos</td><td>Word Pair Cos</td></tr><tr><td>(endeavour, never) 0.028</td><td>(blood, stood) 1.000</td></tr><tr><td>(nowhere, compare) 0.098</td><td>(mood, stood) 1.000</td></tr><tr><td colspan=\"2\">(supply, sigh) 0.164 (overgrown, frown) 1.000</td></tr><tr><td colspan=\"2\">(sky, high) 0.164 (understood, food) 1.000</td></tr><tr><td>(me, maybe) 0.165</td><td>(brood, wood) 1.000</td></tr><tr><td>(cursed, burst) 0.172</td><td>(rove, love) 0.999</td></tr><tr><td>(weigh, way) 0.200</td><td>(sire, ire) 0.999</td></tr><tr><td>(royally, we) 0.217</td><td>(moves, shoves) 0.998</td></tr><tr><td>(use, juice) 0.402</td><td>(afraid, said) 0.998</td></tr><tr><td>(dim, limb) 0.497</td><td>(queen, been) 0.996</td></tr></table>",
                "type_str": "table",
                "text": "Rhyming errors produced by the model.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td/><td>Model</td><td colspan=\"2\">Accuracy</td><td/></tr><tr><td/><td>LM</td><td/><td>0.742</td><td/></tr><tr><td/><td>LM  *  *</td><td/><td>0.672</td><td/></tr><tr><td/><td colspan=\"2\">LM  *  *  +PM+RM</td><td>0.532</td><td/></tr><tr><td/><td>LM  *  *  +RM</td><td/><td>0.532</td><td/></tr><tr><td>Model</td><td>Meter</td><td>Rhyme</td><td>Read.</td><td>Emotion</td></tr><tr><td>LM</td><td colspan=\"4\">4.00\u00b10.73 1.57\u00b10.67 2.77\u00b10.67 2.73\u00b10.51</td></tr><tr><td>LM  *  *</td><td colspan=\"4\">4.07\u00b11.03 1.53\u00b10.88 3.10\u00b11.04 2.93\u00b10.93</td></tr><tr><td colspan=\"5\">LM  *  *  +PM+RM 4.10\u00b10.91 4.43\u00b10.56 2.70\u00b10.69 2.90\u00b10.79</td></tr><tr><td>Human</td><td colspan=\"4\">3.87\u00b11.12 4.10\u00b11.35 4.80\u00b10.48 4.37\u00b10.71</td></tr></table>",
                "type_str": "table",
                "text": "Crowdworker accuracy performance.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Expert mean and standard deviation ratings on several aspects of the generated quatrains.",
                "html": null,
                "num": null
            }
        }
    }
}