{
    "paper_id": "P10-1139",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:20:33.067763Z"
    },
    "title": "A Unified Graph Model for Sentence-based Opinion Retrieval",
    "authors": [
        {
            "first": "Binyang",
            "middle": [],
            "last": "Li",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Chinese University of Hong Kong",
                "location": {}
            },
            "email": "byli@se.cuhk.edu.hk"
        },
        {
            "first": "Lanjun",
            "middle": [],
            "last": "Zhou",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Chinese University of Hong Kong",
                "location": {}
            },
            "email": "ljzhou@se.cuhk.edu.hk"
        },
        {
            "first": "Shi",
            "middle": [],
            "last": "Feng",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Chinese University of Hong Kong",
                "location": {}
            },
            "email": "sfeng@se.cuhk.edu.hk"
        },
        {
            "first": "Kam-Fai",
            "middle": [],
            "last": "Wong",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Chinese University of Hong Kong",
                "location": {}
            },
            "email": "kfwong@se.cuhk.edu.hk"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "There is a growing research interest in opinion retrieval as on-line users' opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user's query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representation, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement.",
    "pdf_parse": {
        "paper_id": "P10-1139",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "There is a growing research interest in opinion retrieval as on-line users' opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user's query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representation, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "In recent years, there is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. These opinions cannot only help independent users make decisions, but also obtain valuable feedbacks (Pang et al., 2008) . Opinion oriented research, including sentiment classifica-tion, opinion extraction, opinion question answering, and opinion summarization, etc. are receiving growing attention (Wilson, et al., 2005; Liu et al., 2005; Oard et al., 2006) . However, most existing works concentrate on analyzing opinions expressed in the documents, and none on how to represent the information needs required to retrieve opinionated documents. In this paper, we focus on opinion retrieval, whose goal is to find a set of documents containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval.",
                "cite_spans": [
                    {
                        "start": 253,
                        "end": 272,
                        "text": "(Pang et al., 2008)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 451,
                        "end": 473,
                        "text": "(Wilson, et al., 2005;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 474,
                        "end": 491,
                        "text": "Liu et al., 2005;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 492,
                        "end": 510,
                        "text": "Oard et al., 2006)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006) . The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007) , or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009) . Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents.",
                "cite_spans": [
                    {
                        "start": 252,
                        "end": 279,
                        "text": "(Macdonald and Ounis, 2007;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 280,
                        "end": 298,
                        "text": "Oard et al., 2006)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 403,
                        "end": 423,
                        "text": "(Zhang and Yu, 2007)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 495,
                        "end": 515,
                        "text": "(Amati et al., 2007;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 516,
                        "end": 536,
                        "text": "Hannah et al., 2007;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 537,
                        "end": 553,
                        "text": "Na et al., 2009)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion in each relevant document, but it cannot determine the relevance pairing of individual opinion to its target. In general, by simply representing a document in bag-of-word, contextual information i.e. the corresponding target of an opinion, is neglected. This may result in possible mismatch between an opinion and a target and in turn affects opinion retrieval performance. By the same token, the effect to documents consisting of mul-tiple topics, which is common in blogs and on-line reviews, is also significant. In this setting, even if a document is regarded opinionated, it cannot ensure that all opinions in the document are indeed relevant to the target concerned. Therefore, we argue that existing information representation i.e. bag-of-word, cannot satisfy the information needs for opinion retrieval.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we propose to handle opinion retrieval in the granularity of sentence. It is observed that a complete opinion is always expressed in one sentence, and the relevant target of the opinion is mostly the one found in it. Therefore, it is crucial to maintain the associative information between an opinion and its target within a sentence. We define the notion of a topic-sentiment word pair, which is composed of a topic term (i.e. the target) and a sentiment word (i.e. opinion) of a sentence. Word pairs can maintain intra-sentence contextual information to express the potential relevant opinions. In addition, inter-sentence contextual information is also captured by word pairs to represent the relationship among opinions on the same topic. In practice, the inter-sentence information reflects the degree of a word pair. Finally, we combine both intra-sentence and inter-sentence contextual information to construct a unified undirected graph to achieve effective opinion retrieval.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The rest of the paper is organized as follows. In Section 2, we describe the motivation of our approach. Section 3 presents a novel unified graph-based model for opinion retrieval. We evaluated our model and the results are presented in Section 4. We review related works on opinion retrieval in Section 5. Finally, in Section 6, the paper is concluded and future work is suggested.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this section, we start from briefly describing the objective of opinion retrieval. We then illustrate the limitations of current opinion retrieval approaches, and analyze the motivation of our method.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "2"
            },
            {
                "text": "Opinion retrieval was first presented in the TREC 2006 Blog track, and the objective is to retrieve documents that express an opinion about a given target. The opinion target can be a \"traditional\" named entity (e.g. a name of person, location, or organization, etc.), a concept (e.g. a type of technology), or an event (e.g. presidential election). The topic of the document is not required to be the same as the target, but an opinion about the target has to be presented in the document or one of the comments to the document (Macdonald and Ounis, 2006) . Therefore, in this paper we regard the information needs for opinion retrieval as relevant opinion.",
                "cite_spans": [
                    {
                        "start": 529,
                        "end": 556,
                        "text": "(Macdonald and Ounis, 2006)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formal Description of Problem",
                "sec_num": "2.1"
            },
            {
                "text": "In traditional information retrieval (IR) bag-of-word representation is the most common way to express information needs. However, in opinion retrieval, information need target at relevant opinion, and this renders bag-of-word representation ineffective.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "Consider the example in Figure 1 . There are three sentences A, B, and C in a document d i . Now given an opinion-oriented query Q related to 'Avatar'. According to the conventional 2-stage opinion retrieval approach, d i is represented by a bag-of-word. Among the words, there is a topic term Avatar (t 1 ) occurring twice, i.e. Avatar in A and Avatar in C, and two sentiment words comfortable (o 1 ) and favorite (o 2 ) (refer to Figure 2 (a) ). In order to rank this document, an overall score of the document d i is computed by a simple combination of the relevant score (",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 31,
                        "end": 32,
                        "text": "1",
                        "ref_id": null
                    },
                    {
                        "start": 439,
                        "end": 444,
                        "text": "2 (a)",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": ") and the opinion score (",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "), e.g. equal weighted linear combination, as follows.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "For simplicity, we let , and be computed by using lexicon-based method:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "\u210e \u210e",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": ".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "Figure 1: A retrieved document d i on the target 'Avatar'.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 9,
                        "text": "1:",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "Although bag-of-word representation achieves good performance in retrieving relevant documents, our study shows that it cannot satisfy the information needs for retrieval of relevant opinion. It suffers from the following limitations:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "(1) It cannot maintain contextual information; thus, an opinion may not be related to the target of the retrieved document is neglected. In this example, only the opinion favorite (o 2 ) on Avatar in C is the relevant opinion. But due to loss of contextual information between the opinion and its corresponding target, Avatar in A and com-A. \u963f\u51e1\u8fbe\u660e\u65e5\u5c06\u5728\u4e2d\u56fd\u4e0a\u6620\u3002 Tomorrow, Avatar will be shown in China. B. \u6211\u9884\u8ba2\u5230\u4e86 IMAX \u5f71\u9662\u4e2d\u6700\u8212\u670d\u7684\u4f4d\u5b50\u3002 I've reserved a comfortable seat in IMAX. C. \u963f\u51e1\u8fbe\u662f\u6211\u6700\u559c\u6b22\u7684\u4e00\u90e8 3D \u7535\u5f71\u3002 Avatar is my favorite 3D movie. fortable (o 1 ) are also regarded as relevant opinion mistakenly, creating a false positive. In reality comfortable (o 1 ) describes \"the seats in IMAX\", which is an irrelevant opinion, and sentence A is a factual statement rather than an opinion statement. (1) Current approaches cannot capture the relationship among opinions about the same topic. Suppose there is another document including sentence C which expresses the same opinion on Avatar. Existing information representation simply does not cater for the two identical opinions from different documents. In addition, if many documents contain opinions on Avatar, the relationship among them is not clearly represented by existing approaches.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "In this paper, we process opinion retrieval in the granularity of sentence as we observe that a complete opinion always exists within a sentence (refer to Figure 2 (b) ). To represent a relevant opinion, we define the notion of topic-sentiment word pair, which consists of a topic term and a sentiment word. A word pair maintains the associative information between the two words, and enables systems to draw up the relationship among all the sentences with the same opinion on an identical target. This relationship information can identify all documents with sentences including the sentiment words and to determine the contributions of such words to the target (topic term). Furthermore, based on word pairs, we designed a unified graph-based method for opinion retrieval (see later in Section 3).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 162,
                        "end": 167,
                        "text": "2 (b)",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "3 Graph-based model",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation of Our Approach",
                "sec_num": "2.2"
            },
            {
                "text": "Different from existing approaches which simply make use of document relevance to reflect the relevance of opinions embedded in them, our approach concerns more on identifying the relevance of individual opinions. Intuitively, we believed that the more relevant opinions appear in a document, the more relevant is that document for subsequent opinion analysis operations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Idea",
                "sec_num": "3.1"
            },
            {
                "text": "Further, since the lexical scope of an opinion does not usually go beyond a sentence, we propose to handle opinion retrieval in the granularity of sentence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Idea",
                "sec_num": "3.1"
            },
            {
                "text": "Without loss of generality, we assume that there is a document set , , , , , and a specific query , , , , , where , , , , are query keywords. Opinion retrieval aims at retrieving documents from with relevant opinion about the query . In addition, we construct a sentiment word lexicon and a topic term lexicon (see Section 4). To maintain the associative information between the target and the opinion, we consider the document set as a bag of sentences, and define a sentence set as , , , ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Idea",
                "sec_num": "3.1"
            },
            {
                "text": ". For each sentence, we capture the intra-sentence information through the topic-sentiment word pair. Definition 1. topic-sentiment word pair consists of two elements, one is from , and the other one is from .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Idea",
                "sec_num": "3.1"
            },
            {
                "text": ". The topic term from determines relevance by the query term matching, and the sentiment word from is used to express an opinion. We use the word pair to maintain the associative information between the topic term and the opinion word (also referred to as sentiment word). The word pair is used to identify a relevant opinion in a sentence. In Figure 2 (b), t 1, i.e. Avatar in C, is a topic term relevant to the query, and o 2 ('favorite') is supposed to be an opinion; and the word pair < t 1 , o 2 > indicates sentence C contains a relevant opinion. Similarly, we map each sentence in word pairs by the following rule, and express the intra-sentence information using word pairs.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 351,
                        "end": 352,
                        "text": "2",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": "For each sentiment word of a sentence, we choose the topic term with minimum distance as the other element of the word pair:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": ", | min , for each",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": "According to the mapping rule, although a sentence may give rise to a number of word pairs, only the pair with the minimum word distance is selected. We do not take into consideration of the other words in a sentence as relevant opinions are generally formed in close proximity. A sentence is regarded non-opinionated unless it contains at least one word pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": "In practice, not all word pairs carry equal weights to express a relevant opinion as the contribution of an opinion word differs from different target topics, and vice versa. For example, the word pair < t 1 , o 2 > should be more probable as a relevant opinion than < t 1 , o 1 >. To consider that, inter-sentence contextual information is explored. This is achieved by assigning a weight to each word pair to measure their associative degrees to different queries. We believe that the more a word pair appears the higher should be the weight between the opinion and the target in the context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": "We will describe how to utilize intra-sentence contextual information to express relevant opinion, and inter-sentence information to measure the degree of each word pair through a graph-based model in the following section.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": ", | ,",
                "sec_num": null
            },
            {
                "text": "We propose an opinion retrieval model based on HITS, a popular graph ranking algorithm (Kleinberg, 1999) . By considering both intra-sentence information and inter-sentence information, we can determine the weight of a word pair and rank the documents.",
                "cite_spans": [
                    {
                        "start": 87,
                        "end": 104,
                        "text": "(Kleinberg, 1999)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "HITS algorithm distinguishes hubs and authorities in objects. A hub object has links to many authorities. An authority object, which has high-quality content, would have many hubs linking to it. The hub scores and authority scores are computed in an iterative way. Our proposed opinion retrieval model contains two layers. The upper level contains all the topic-sentiment word pairs",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ", | ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ". The lower level contains all the documents to be retrieved. Figure 3 gives the bipartite graph representation of the HITS model. For our purpose, the word pairs layer is considered as hubs and the documents layer authorities. If a word pair occurs in one sentence of a document, there will be an edge between them. In Figure 3 , we can see that the word pair that has links to many documents can be assigned a high weight to denote a strong associative degree between the topic term and a sentiment word, and it likely expresses a relevant opinion. On the other hand, if a document has links to many word pairs, the document is with many relevant opinions, and it will result in high ranking.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 69,
                        "end": 70,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 327,
                        "end": 328,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "Formally, the representation for the bipartite graph is denoted as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ", ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ", where is the set of all pairs of topic words and sentiment words, which appear in one sentence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "is the set of documents.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "| , corresponds to the connection between documents and topic-sentiment word pairs. Each edge is associated with a weight 0,1 denoting the contribution of to the document . The weight is computed by the contribution of word pair in all sentences of as follows: ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "| | \u2211 \u2022 , 1 , 1 | | is",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ", is the number of appears in , and log .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "(3) where is the number of sentences that the word appears in.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": ", is the contribution of in which belongs to . is the vector of hub scores for the word pairs at iteration. In order to ensure convergence of the iterative form, and are normalized in each iteration cycle.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "For computation of the final scores, the initial scores of all documents are set to \u221a , and topic-sentiment word pairs are set to \u221a . The above iterative steps are then used to compute the new scores until convergence. Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any nodes falls below a given threshold (Wan et al., 2008; Li et al., 2009; Erkan and Radev, 2004 ). In our model, we use the hub scores to denote the associative degree of each word pair and the authority scores as the total scores. The documents are then ranked based on the total scores.",
                "cite_spans": [
                    {
                        "start": 403,
                        "end": 421,
                        "text": "(Wan et al., 2008;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 422,
                        "end": 438,
                        "text": "Li et al., 2009;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 439,
                        "end": 460,
                        "text": "Erkan and Radev, 2004",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HITS Model",
                "sec_num": "3.2"
            },
            {
                "text": "We performed the experiments on the Chinese benchmark dataset to verify our proposed approach for opinion retrieval. We first tested the effect of the parameter of our model. To demonstrate the effectiveness of our opinion retrieval model, we compared its performance with the same of other approaches. In addition, we studied each individual query to investigate the influence of query to our model. Furthermore, we showed the top-5 highest weight word pairs of 5 queries to further demonstrate the effect of word pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment",
                "sec_num": "4"
            },
            {
                "text": "Our experiments are based on the Chinese benchmark dataset, COAE08 (Zhao et al., 2008) . COAE dataset is the benchmark data set for the opinion retrieval track in the Chinese Opinion Analysis Evaluation (COAE) workshop, consisting of blogs and reviews. 20 queries are provided in COAE08. In our experiment, we created relevance judgments through pooling method, where documents are ranked at different levels: irrelevant, relevant but without opinion, and relevant with opinion. Since polarity is not considered, all relevant documents with opinion are classified into the same level.",
                "cite_spans": [
                    {
                        "start": 67,
                        "end": 86,
                        "text": "(Zhao et al., 2008)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Benchmark Datasets",
                "sec_num": "4.1.1"
            },
            {
                "text": "In our experiment, the sentiment lexicon is composed by the following resources (Xu et al., 2007) :",
                "cite_spans": [
                    {
                        "start": 80,
                        "end": 97,
                        "text": "(Xu et al., 2007)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentiment Lexicon",
                "sec_num": "4.1.2"
            },
            {
                "text": "(1) The Lexicon of Chinese Positive Words, which consists of 5,054 positive words and the Lexicon of Chinese Negative Words, which consists of 3,493 negative words;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentiment Lexicon",
                "sec_num": "4.1.2"
            },
            {
                "text": "(2) The opinion word lexicon provided by National Taiwan University which consists of 2,812 positive words and 8,276 negative words;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentiment Lexicon",
                "sec_num": "4.1.2"
            },
            {
                "text": "(3) Sentiment word lexicon and comment word lexicon from Hownet. It contains 1836 positive sentiment words, 3,730 positive comments, 1,254 negative sentiment words and 3,116 negative comment words. The different graphemes corresponding to Traditional Chinese and Simplified Chinese are both considered so that the sentiment lexicons from different sources are applicable to process Simplified Chinese text. The lexicon was manually verified.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentiment Lexicon",
                "sec_num": "4.1.2"
            },
            {
                "text": "In order to acquire the collection of topic terms, we adopt two expansion methods, dictionary-based method and pseudo relevance feedback method.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Topic Term Collection",
                "sec_num": "4.1.3"
            },
            {
                "text": "The dictionary-based method utilizes Wikipedia (Popescu and Etzioni, 2005) to find an entry page for a phrase or a single term in a query. If such an entry exists, all titles of the entry page are extracted as synonyms of the query concept. For example, if we search \"\u7eff\u575d\" (Green Tsunami, a firewall) in Wikipedia, it is re-directed to an entry page titled \"\u82b1\u5b63\u62a4\u822a\" (Youth Escort). This term is then added as a synonym of \"\u7eff\u575d\" (Green Tsunami) in the query. Synonyms are treated the same as the original query terms in a retrieval process. The content words in the entry page are ranked by their frequencies in the page. The top-k terms are returned as potential expanded topic terms.",
                "cite_spans": [
                    {
                        "start": 47,
                        "end": 74,
                        "text": "(Popescu and Etzioni, 2005)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Topic Term Collection",
                "sec_num": "4.1.3"
            },
            {
                "text": "The second query expansion method is a web-based method. It is similar to the pseudo relevance feedback expansion but using web documents as the document collection. The query is submitted to a web search engine, such as Google, which returns a ranked list of documents. In the top-n documents, the top-m topic terms which are highly correlated to the query terms are returned.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Topic Term Collection",
                "sec_num": "4.1.3"
            },
            {
                "text": "We first studied how the parameter (see Equation 1) influenced the mean average precision (MAP) in our model. The result is given in Best MAP performance was achieved in COAE08 evaluation, when was set between 0.4 and 0.6. Therefore, in the following experiments, we set 0.4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Tuning",
                "sec_num": "4.2.1"
            },
            {
                "text": "To demonstrate the effectiveness of our proposed model, we compared it with the following models using different evaluation metrics:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Opinion Retrieval Model Comparison",
                "sec_num": "4.2.2"
            },
            {
                "text": "(1) IR: We adopted a classical information retrieval model, and further assumed that all retrieved documents contained relevant opinions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Opinion Retrieval Model Comparison",
                "sec_num": "4.2.2"
            },
            {
                "text": "(2) Doc: The 2-stage document-based opinion retrieval model was adopted. The model used sentiment lexicon-based method for opinion identification and a conventional information retrieval method for relevance detection.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Opinion Retrieval Model Comparison",
                "sec_num": "4.2.2"
            },
            {
                "text": "(3) ROSC: This was the model which achieved the best run in TREC Blog 07. It employed machine learning method to identify opinions for each sentence, and to determine the target topic by a NEAR operator. ( 4) ROCC: This model was similar to ROSC, but it considered the factor of sentence and regarded the count of relevant opinionated sentence to be the opinion score (Zhang and Yu, 2007) . In our experiment, we treated this model as the evaluation baseline.",
                "cite_spans": [
                    {
                        "start": 368,
                        "end": 388,
                        "text": "(Zhang and Yu, 2007)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Opinion Retrieval Model Comparison",
                "sec_num": "4.2.2"
            },
            {
                "text": "(5) GORM: our proposed graph-based opinion retrieval model. Most of the above models were originally designed for opinion retrieval in English, and re-designed them to handle Chinese opinionated documents. We incorporated our own Chinese sentiment lexicon for this purpose. In our experiments, in addition to MAP, other metrics such as R-precision (R-prec), binary Preference (bPref) and Precision at 10 documents (P@10) were also used. The evaluation results based on these metrics are shown in Table 1 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 502,
                        "end": 503,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Opinion Retrieval Model Comparison",
                "sec_num": "4.2.2"
            },
            {
                "text": "Table 1 summarized the results obtained. We found that GORM achieved the best performance in all the evaluation metrics. Our baseline, ROSC and GORM which were sentence-based approaches achieved better performance than the document-based approaches by 20% in average. Moreover, our GORM approach did not use machine learning techniques, but it could still achieve outstanding performance.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": null
            },
            {
                "text": "To study GORM influenced by different queries, the MAP from median average precision on individual topic was shown in Figure 5 . As shown in Figure 5 , the MAP performance was very low on topic 8 and topic 11. Topic 8, i.e. '\u6210\u9f99' (Jackie Chan), it was influenced by topic 7, i.e. '\u674e\u8fde\u6770' (Jet Lee) as there were a number of similar relevant targets for the two topics, and therefore many word pairs ended up the same. As a result, documents belonging to topic 7 and topic 8 could not be differentiated, and they both performed badly. In order to solve this problem, we extracted the topic term with highest relevant weight in the sentence to form word pairs so that it reduce the impact on the topic terms in common. 24% and 30% improvement were achieved, respectively.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 125,
                        "end": 126,
                        "text": "5",
                        "ref_id": "FIGREF5"
                    },
                    {
                        "start": 148,
                        "end": 149,
                        "text": "5",
                        "ref_id": "FIGREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": null
            },
            {
                "text": "As to topic 11, i.e. '\u6307\u73af\u738b' (Lord of King), there were only 8 relevant documents without any opinion and 14 documents with relevant opinions. As a result, the graph constructed by insufficient documents worked ineffectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": null
            },
            {
                "text": "Except for the above queries, GORM performed well in most of the others. To further investigate the effect of word pair, we summarized the top-5 word pairs with highest weight of 5 queries in Table 2 . Table 2 : Top-5 highest weight word pairs for 5 queries in COAE08 dataset.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 198,
                        "end": 199,
                        "text": "2",
                        "ref_id": null
                    },
                    {
                        "start": 208,
                        "end": 209,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": null
            },
            {
                "text": "Table 2 showed that most word pairs could represent the relevant opinions about the corresponding queries. This showed that inter-sentence information was very helpful to identify the associative degree of a word pair. Furthermore, since word pairs can indicate relevant opinions effectively, it is worth further study on how they could be applied to other opinion oriented applications, e.g. opinion summarization, opinion prediction, etc.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": null
            },
            {
                "text": "Our research focuses on relevant opinion rather than on relevant document retrieval. We, therefore, review related works in opinion identification research. Furthermore, we do not support the conventional 2-stage opinion retrieval approach. We conducted literature review on unified opinion retrieval models and related work in this area is presented in the section.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "5"
            },
            {
                "text": "Different from traditional IR, opinion retrieval focuses on the opinion nature of documents. During the last three years, NTICR and TREC evaluations have shown that sentiment lexicon-based methods led to good performance in opinion identification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Lexicon-based Opinion Identification",
                "sec_num": "5.1"
            },
            {
                "text": "A lightweight lexicon-based statistical approach was proposed by Hannah et al. (2007) . In this method, the distribution of terms in relevant opinionated documents was compared to their distribution in relevant fact-based documents to calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007) . This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate the opinion score of a document (Na et al., 2009) . This method was shown to be very effective in TREC evaluations (Lee et al., 2008) . More recently, Huang and Croft (2009) proposed an effective relevance model, which integrated both query-independent and query-dependent sentiment words into a mixture model.",
                "cite_spans": [
                    {
                        "start": 65,
                        "end": 85,
                        "text": "Hannah et al. (2007)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 413,
                        "end": 433,
                        "text": "(Amati et al., 2007)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 718,
                        "end": 735,
                        "text": "(Na et al., 2009)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 801,
                        "end": 819,
                        "text": "(Lee et al., 2008)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 837,
                        "end": 859,
                        "text": "Huang and Croft (2009)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Lexicon-based Opinion Identification",
                "sec_num": "5.1"
            },
            {
                "text": "In our approach, we also adopt sentiment lexicon-based method for opinion identification. Unlike the above methods, we generate a weight to a sentiment word for each target (associated topic term) rather than assign a unified weight or an equal weight to the sentiment word for the whole topics. Besides, in our model no training data is required. We just utilize the structure of our graph to generate a weight to reflect the associative degree between the two elements of a word pair in different context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Lexicon-based Opinion Identification",
                "sec_num": "5.1"
            },
            {
                "text": "In addition to conventional 2-stage approach, there has been some research on unified opinion retrieval models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "Eguchi and Lavrenko proposed an opinion retrieval model in the framework of generative language modeling (Eguchi and Lavrenko, 2006) . They modeled a collection of natural language documents or statements, each of which consisted of some topic-bearing and some sentiment-bearing words. The sentiment was either represented by a group of predefined seed words, or extracted from a training sentiment corpus. This model was shown to be effective on the MPQA corpus.",
                "cite_spans": [
                    {
                        "start": 105,
                        "end": 132,
                        "text": "(Eguchi and Lavrenko, 2006)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "Mei et al. tried to build a fine-grained opinion retrieval system for consumer products (Mei et al., 2007) . The opinion score for a product was a mixture of several facets. Due to the difficulty in associating sentiment with products and facets, the system was only tested using small scale text collections.",
                "cite_spans": [
                    {
                        "start": 88,
                        "end": 106,
                        "text": "(Mei et al., 2007)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "Zhang and Ye proposed a generative model to unify topic relevance and opinion generation (Zhang and Ye, 2008) . This model led to satisfactory performance, but an intensive computation load was inevitable during retrieval, since for each possible candidate document, an opinion score was summed up from the generative probability of thousands of sentiment words.",
                "cite_spans": [
                    {
                        "start": 89,
                        "end": 109,
                        "text": "(Zhang and Ye, 2008)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "Huang and Croft proposed a unified opinion retrieval model according to the Kullback-Leibler divergence between the two probability distributions of opinion relevance model and document model (Huang and Croft, 2009) . They divided the sentiment words into query-dependent and query-independent by utilizing several sentiment expansion techniques, and integrated them into a mixed model. However, in this model, the contribution of a sentiment word was its corresponding incremental mean average precision value. This method required that large amount of training data and manual labeling.",
                "cite_spans": [
                    {
                        "start": 192,
                        "end": 215,
                        "text": "(Huang and Croft, 2009)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "Different from the above opinion retrieval approaches, our proposed graph-based model processes opinion retrieval in the granularity of sentence. Instead of bag-of-word, the sentence is split into word pairs which can maintain the contextual information. On the one hand, word pair can identify the relevant opinion according to intra-sentence contextual information. On the other hand, it can measure the degree of a relevant opinion by considering the inter-sentence contextual information.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Unified Opinion Retrieval Model",
                "sec_num": "5.2"
            },
            {
                "text": "In this work we focus on the problem of opinion retrieval. Different from existing approaches, which regard document relevance as the key indicator of opinion relevance, we propose to explore the relevance of individual opinion. To do that, opinion retrieval is performed in the granularity of sentence. We define the notion of word pair, which can not only maintain the association between the opinion and the corresponding target in the sentence, but it can also build up the relationship among sentences through the same word pair. Furthermore, we convert the relationships between word pairs and sentences into a unified graph, and use the HITS algorithm to achieve document ranking for opinion retrieval. Finally, we compare our approach with existing methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "Experimental results show that our proposed model performs well on COAE08 dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "The novelty of our work lies in using word pairs to represent the information needs for opinion retrieval. On the one hand, word pairs can identify the relevant opinion according to intra-sentence contextual information. On the other hand, word pairs can measure the degree of a relevant opinion by taking inter-sentence contextual information into consideration. With the help of word pairs, the information needs for opinion retrieval can be represented appropriately.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "In the future, more research is required in the following directions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            },
            {
                "text": "(1) Since word pairs can indicate relevant opinions effectively, it is worth further study on how they could be applied to other opinion oriented applications, e.g. opinion summarization, opinion prediction, etc. (2) The characteristics of blogs will be taken into consideration, i.e., the post time, which could be helpful to create a more time sensitivity graph to filter out fake opinions. (3) Opinion holder is another important role of an opinion, and the identification of opinion holder is a main task in NTCIR. It would be interesting to study opinion holders, e.g. its seniority, for opinion retrieval.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "6"
            }
        ],
        "back_matter": [
            {
                "text": "Acknowledgements: This work is partially supported by the Innovation and Technology Fund of Hong Kong SAR (No. ITS/182/08) and National 863 program (No. 2009AA01Z150).Special thanks to Xu Hongbo for providing the Chinese sentiment resources. We also thank Bo Chen, Wei Gao, Xu Han and anonymous reviewers for their helpful comments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "acknowledgement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Retrieval and novelty detection at the sentence level",
                "authors": [
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Allan",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Wade",
                        "suffix": ""
                    },
                    {
                        "first": "Alvaro",
                        "middle": [],
                        "last": "Bolivar",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": "",
                "issue": "",
                "pages": "314--321",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "James Allan, Courtney Wade, and Alvaro Bolivar. 2003. Retrieval and novelty detection at the sen- tence level. In SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval, pages 314-321. ACM.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog Track",
                "authors": [
                    {
                        "first": "Giambattista",
                        "middle": [],
                        "last": "Amati",
                        "suffix": ""
                    },
                    {
                        "first": "Edgardo",
                        "middle": [],
                        "last": "Ambrosi",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Bianchi",
                        "suffix": ""
                    },
                    {
                        "first": "Carlo",
                        "middle": [],
                        "last": "Gaibisso",
                        "suffix": ""
                    },
                    {
                        "first": "Giorgio",
                        "middle": [],
                        "last": "Gambosi",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Giambattista Amati, Edgardo Ambrosi, Marco Bianc- hi, Carlo Gaibisso, and Giorgio Gambosi. 2007. FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog Track. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Sentiment retrieval using generative models",
                "authors": [
                    {
                        "first": "Koji",
                        "middle": [],
                        "last": "Eguchi",
                        "suffix": ""
                    },
                    {
                        "first": "Victor",
                        "middle": [],
                        "last": "Lavrenko",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "EMNLP '06, Proceedings of 2006 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "345--354",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Koji Eguchi and Victor Lavrenko. Sentiment retrieval using generative models. 2006. In EMNLP '06, Proceedings of 2006 Conference on Empirical Me- thods in Natural Language Processing, page 345-354.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Lexpagerank: Prestige in multi-document text summarization",
                "authors": [
                    {
                        "first": "Gunes",
                        "middle": [],
                        "last": "Erkan",
                        "suffix": ""
                    },
                    {
                        "first": "Dragomir",
                        "middle": [
                            "R"
                        ],
                        "last": "Radev",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "EMNLP '04, Proceedings of 2004 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gunes Erkan and Dragomir R. Radev. 2004. Lexpa- gerank: Prestige in multi-document text summariza- tion. In EMNLP '04, Proceedings of 2004 Confe- rence on Empirical Methods in Natural Language Processing.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "University of Glasgow at TREC 2007: Experiments in Blog and Enterprise Tracks with Terrier",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Hannah",
                        "suffix": ""
                    },
                    {
                        "first": "Craig",
                        "middle": [],
                        "last": "Macdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Hannah, Craig Macdonald, Jie Peng, Ben He, and Iadh Ounis. 2007. University of Glasgow at TREC 2007: Experiments in Blog and Enterprise Tracks with Terrier. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "A Unified Relevance Model for Opinion Retrieval",
                "authors": [
                    {
                        "first": "Xuanjing",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [
                            "Bruce"
                        ],
                        "last": "Croft",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of CIKM",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuanjing Huang, William Bruce Croft. 2009. A Uni- fied Relevance Model for Opinion Retrieval. In Proceedings of CIKM.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Authoritative sources in a hyperlinked environment",
                "authors": [
                    {
                        "first": "Jon",
                        "middle": [
                            "M"
                        ],
                        "last": "Kleinberg",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "J. ACM",
                "volume": "46",
                "issue": "5",
                "pages": "604--632",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. J. ACM, 46(5): 604-632.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "KLE at TREC 2008 Blog Track: Blog Post and Feed Retrieval",
                "authors": [
                    {
                        "first": "Yeha",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Seung-Hoon",
                        "middle": [],
                        "last": "Na",
                        "suffix": ""
                    },
                    {
                        "first": "Jungi",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Sang-Hyob",
                        "middle": [],
                        "last": "Nam",
                        "suffix": ""
                    },
                    {
                        "first": "Hun-Young",
                        "middle": [],
                        "last": "Jung",
                        "suffix": ""
                    },
                    {
                        "first": "Jong-Hyeok",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yeha Lee, Seung-Hoon Na, Jungi Kim, Sang-Hyob Nam, Hun-young Jung, Jong-Hyeok Lee. 2008. KLE at TREC 2008 Blog Track: Blog Post and Feed Retrieval. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Answering Opinion Questions with Random Walks on Graphs",
                "authors": [
                    {
                        "first": "Fangtao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Minlie",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "ACL '09, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan Zhu. 2009. Answering Opinion Questions with Random Walks on Graphs. In ACL '09, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Opinion observer: Analyzing and comparing opinion s on the web",
                "authors": [
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Minqing",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Junsheng",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "WWW '05: Proceedings of the 14 th International Conference on World Wide Web",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and comparing opi- nion s on the web. In WWW '05: Proceedings of the 14 th International Conference on World Wide Web.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Overview of the TREC-2007 Blog Track",
                "authors": [
                    {
                        "first": "Craig",
                        "middle": [],
                        "last": "Macdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Iadh",
                        "middle": [],
                        "last": "Ounis",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Craig Macdonald and Iadh Ounis. 2007. Overview of the TREC-2007 Blog Track. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Overview of the TREC-2006 Blog Track",
                "authors": [
                    {
                        "first": "Craig",
                        "middle": [],
                        "last": "Macdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Iadh",
                        "middle": [],
                        "last": "Ounis",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 14 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Craig Macdonald and Iadh Ounis. 2006. Overview of the TREC-2006 Blog Track. In Proceedings of the 14 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Topic sentiment mixture: Modeling facets and opinions in weblogs",
                "authors": [
                    {
                        "first": "Qiaozhu",
                        "middle": [],
                        "last": "Mei",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Wondra",
                        "suffix": ""
                    },
                    {
                        "first": "Hang",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "Chengxiang",
                        "middle": [],
                        "last": "Zhai",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "WWW '07: Proceedings of the 16 International Conference on World Wide Web",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and Chengxiang Zhai. 2007. Topic sentiment mix- ture: Modeling facets and opinions in weblogs. In WWW '07: Proceedings of the 16 International Conference on World Wide Web.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Improving opinion retrieval based on query-specific sentiment lexicon",
                "authors": [
                    {
                        "first": "Seung-Hoon",
                        "middle": [],
                        "last": "Na",
                        "suffix": ""
                    },
                    {
                        "first": "Yeha",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Sang-Hyob",
                        "middle": [],
                        "last": "Nam",
                        "suffix": ""
                    },
                    {
                        "first": "Jong-Hyeok",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "ECIR '09: Proceedings of the 31 st annual European Conference on Information Retrieval",
                "volume": "",
                "issue": "",
                "pages": "734--738",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Seung-Hoon Na, Yeha Lee, Sang-Hyob Nam, and Jong-Hyeok Lee. 2009. Improving opinion retrieval based on query-specific sentiment lexicon. In ECIR '09: Proceedings of the 31 st annual European Conference on Information Retrieval, pages 734-738.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "TREC-2006 at Maryland: Blog, Enterprise, Legal and QA Tracks",
                "authors": [
                    {
                        "first": "Douglas",
                        "middle": [],
                        "last": "Oard",
                        "suffix": ""
                    },
                    {
                        "first": "Tamer",
                        "middle": [],
                        "last": "Elsayed",
                        "suffix": ""
                    },
                    {
                        "first": "Jianqiang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yejun",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Pengyi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Eileen",
                        "middle": [],
                        "last": "Abels",
                        "suffix": ""
                    },
                    {
                        "first": "Jimmy",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Dagbert",
                        "middle": [],
                        "last": "Soergel",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Douglas Oard, Tamer Elsayed, Jianqiang Wang, Ye- jun Wu, Pengyi Zhang, Eileen Abels, Jimmy Lin, and Dagbert Soergel. 2006. TREC-2006 at Mary- land: Blog, Enterprise, Legal and QA Tracks. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Using random walks for question-focused sentence retrieval",
                "authors": [
                    {
                        "first": "Jahna",
                        "middle": [],
                        "last": "Otterbacher",
                        "suffix": ""
                    },
                    {
                        "first": "Gunes",
                        "middle": [],
                        "last": "Erkan",
                        "suffix": ""
                    },
                    {
                        "first": "Dragomir",
                        "middle": [
                            "R"
                        ],
                        "last": "Radev",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "EMNLP '05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jahna Otterbacher, Gunes Erkan, and Dragomir R. Radev. 2005. Using random walks for ques- tion-focused sentence retrieval. In EMNLP '05, Proceedings of 2005 Conference on Empirical Me- thods in Natural Language Processing.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "The pagerank citation ranking: Bringing order to the web",
                "authors": [
                    {
                        "first": "Larry",
                        "middle": [],
                        "last": "Page",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Brin",
                        "suffix": ""
                    },
                    {
                        "first": "Rajeev",
                        "middle": [],
                        "last": "Motwani",
                        "suffix": ""
                    },
                    {
                        "first": "Terry",
                        "middle": [],
                        "last": "Winograd",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Larry Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1998. The pagerank citation ranking: Bringing order to the web. Technical report, Stan- ford University.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Opinion mining and sentiment analysis",
                "authors": [
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Foundations and Trends in Information Retrieval",
                "volume": "2",
                "issue": "1-2",
                "pages": "1--135",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in In- formation Retrieval, 2(1-2): 1-135.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Extracting product features and opinion s from reviews",
                "authors": [
                    {
                        "first": "Ana-Maria",
                        "middle": [],
                        "last": "Popescu",
                        "suffix": ""
                    },
                    {
                        "first": "Oren",
                        "middle": [],
                        "last": "Etzioni",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "EMNLP '05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ana-Maria Popescu and Oren Etzioni. 2005. Extract- ing product features and opinion s from reviews. In EMNLP '05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Multi-document summarization using cluster-based link analysis",
                "authors": [
                    {
                        "first": "Xiaojun",
                        "middle": [],
                        "last": "Wan",
                        "suffix": ""
                    },
                    {
                        "first": "Jianwu",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "SIGIR '08: Proceedings of the 31th annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": "",
                "issue": "",
                "pages": "299--306",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiaojun Wan and Jianwu Yang. 2008. Mul- ti-document summarization using cluster-based link analysis. In SIGIR '08: Proceedings of the 31th an- nual international ACM SIGIR conference on Re- search and development in information retrieval, pages 299-306. ACM.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Recognizing contextual polarity in phrase-level sentiment analysis",
                "authors": [
                    {
                        "first": "Theresa",
                        "middle": [],
                        "last": "Wilson",
                        "suffix": ""
                    },
                    {
                        "first": "Janyce",
                        "middle": [],
                        "last": "Wiebe",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Hoffmann",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "EMNLP '05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In EMNLP '05, Proceedings of 2005 Conference on Empirical Me- thods in Natural Language Processing.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Opinmine -Opinion Analysis System by CUHK for NTCIR-6 Pilot Task",
                "authors": [
                    {
                        "first": "Ruifeng",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Kam-Fai",
                        "middle": [],
                        "last": "Wong",
                        "suffix": ""
                    },
                    {
                        "first": "Yunqing",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of NTCIR-6",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2007. Opinmine -Opinion Analysis System by CUHK for NTCIR-6 Pilot Task. In Proceedings of NTCIR-6.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A generation model to unify topic relevance and lexicon-based sentiment for opinion retrieval",
                "authors": [
                    {
                        "first": "Min",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xingyao",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "SIGIR '08: Proceedings of the 31 st Annual International ACM SI-GIR conference on Research and Development in Information Retrieval",
                "volume": "",
                "issue": "",
                "pages": "411--418",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Min Zhang and Xingyao Ye. 2008. A generation model to unify topic relevance and lexicon-based sentiment for opinion retrieval. In SIGIR '08: Pro- ceedings of the 31 st Annual International ACM SI- GIR conference on Research and Development in Information Retrieval, pages 411-418. ACM.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "UIC at TREC 2007 Blog Track",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Clement",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the 15 th Text Retrieval Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Zhang and Clement Yu. 2007. UIC at TREC 2007 Blog Track. In Proceedings of the 15 th Text Retrieval Conference.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Overview of Chinese Opinion Analysis Evaluation",
                "authors": [
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Hongbo",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xuanjing",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Songbo",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Kang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the First Chinese Opinion Analysis Evaluation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan, Kang Liu, and Qi Zhang. 2008. Overview of Chi- nese Opinion Analysis Evaluation 2008. In Pro- ceedings of the First Chinese Opinion Analysis Evaluation.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 2: Two kinds of information representation of opinion retrieval. (t 1 ='Avatar' o 1 = 'comfortable', o 2 ='favorite')(1) Current approaches cannot capture the relationship among opinions about the same topic. Suppose there is another document including sentence C which expresses the same opinion on Avatar. Existing information representation simply does not cater for the two identical opinions from different documents. In addition, if many documents contain opinions on Avatar, the relationship among them is not clearly represented by existing approaches.In this paper, we process opinion retrieval in the granularity of sentence as we observe that a complete opinion always exists within a sentence (refer to Figure2 (b)). To represent a relevant opinion, we define the notion of topic-sentiment word pair, which consists of a topic term and a sentiment word. A word pair maintains the associative information between the two words, and enables systems to draw up the relationship among all the sentences with the same opinion on an identical target. This relationship information can identify all documents with sentences including the sentiment words and to determine the contributions of such words to the target (topic term). Furthermore, based on word pairs, we designed a unified graph-based method for opinion retrieval (see later in Section 3).",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 3: Bipartite link graph.For our purpose, the word pairs layer is considered as hubs and the documents layer authorities. If a word pair occurs in one sentence of a document, there will be an edge between them.In Figure3, we can see that the word pair that has links to many documents can be assigned a high weight to denote a strong associative degree between the topic term and a sentiment word, and it likely expresses a relevant opinion. On the other hand, if a document has links to many word pairs, the document is with many relevant opinions, and it will result in high ranking.Formally, the representation for the bipartite graph is denoted as",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "lan et al., 2003;Otterbacher et al., 2005). It is found that the contribution of a sentiment word will not decrease even if it appears in all the sentences. Therefore in Equation4, we just use the length of a sentence instead of to normalize long sentences which would likely contain more sentiment words.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "text": "Figure 4: Performance of MAP with varying .Best MAP performance was achieved in COAE08 evaluation, when was set between 0.4 and 0.6. Therefore, in the following experiments, we set",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "FIGREF5": {
                "num": null,
                "text": "Figure 5: Difference of MAP from Median on COAE08 dataset. (MAP of Median is 0.3724)As shown in Figure5, the MAP performance was very low on topic 8 and topic 11. Topic 8, i.e. '\u6210\u9f99' (Jackie Chan), it was influenced by topic 7, i.e. '\u674e\u8fde\u6770' (Jet Lee) as there were a number of similar relevant targets for the two topics, and therefore many word pairs ended up the same. As a result, documents belonging to topic 7 and topic 8 could not be differentiated, and they both performed badly. In order to solve this problem, we extracted the topic term with highest relevant weight in the sentence to form word pairs so that it reduce the impact on the topic terms in common. 24% and 30% improvement were achieved, respectively.As to topic 11, i.e. '\u6307\u73af\u738b' (Lord of King), there were only 8 relevant documents without any opinion and 14 documents with relevant opinions. As a result, the graph constructed by insufficient documents worked ineffectively.Except for the above queries, GORM performed well in most of the others. To further investigate the effect of word pair, we summarized the top-5 word pairs with highest weight of 5 queries in Table2.",
                "uris": null,
                "fig_num": "5",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td/><td/><td>,</td><td>and</td><td>, ;</td></tr><tr><td>,</td><td/><td colspan=\"2\">is computed to judge the relevance</td></tr><tr><td>of</td><td>in</td><td colspan=\"2\">which belongs to ;</td></tr></table>",
                "type_str": "table",
                "text": "the number of sentences in ; is introduced as the trade-off parameter to balance the",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td/><td/><td colspan=\"2\">COAE08</td><td/></tr><tr><td/><td/><td colspan=\"2\">Evaluation metrics</td><td/></tr><tr><td>Run id</td><td>MAP</td><td>R-pre</td><td>bPref</td><td>P@10</td></tr><tr><td>IR</td><td>0.2797</td><td>0.3545</td><td>0.2474</td><td>0.4868</td></tr><tr><td>Doc</td><td>0.3316</td><td>0.3690</td><td>0.3030</td><td>0.6696</td></tr><tr><td>ROSC</td><td>0.3762</td><td>0.4321</td><td>0.4162</td><td>0.7089</td></tr><tr><td>Baseline</td><td>0.3774</td><td>0.4411</td><td>0.4198</td><td>0.6931</td></tr><tr><td>GORM</td><td>0.3978</td><td>0.4835</td><td>0.4265</td><td>0.7309</td></tr></table>",
                "type_str": "table",
                "text": "Comparison of different approaches on COAE08 dataset, and the best is highlighted.",
                "html": null,
                "num": null
            }
        }
    }
}