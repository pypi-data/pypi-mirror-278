{
    "paper_id": "D15-1311",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:55:44.157619Z"
    },
    "title": "Classifying Tweet Level Judgements of Rumours in Social Media",
    "authors": [
        {
            "first": "Michal",
            "middle": [],
            "last": "Lukasik",
            "suffix": "",
            "affiliation": {},
            "email": "m.lukasik@shef.ac.uk"
        },
        {
            "first": "Trevor",
            "middle": [],
            "last": "Cohn",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The University of Sheffield",
                "location": {}
            },
            "email": "t.cohn@unimelb.edu.au"
        },
        {
            "first": "Kalina",
            "middle": [],
            "last": "Bontcheva",
            "suffix": "",
            "affiliation": {},
            "email": "k.bontcheva@shef.ac.uk"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Social media is a rich source of rumours and corresponding community reactions. Rumours reflect different characteristics, some shared and some individual. We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task. Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.",
    "pdf_parse": {
        "paper_id": "D15-1311",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Social media is a rich source of rumours and corresponding community reactions. Rumours reflect different characteristics, some shared and some individual. We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task. Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "There is an increasing need to interpret and act upon rumours spreading quickly through social media, especially in circumstances where their veracity is hard to establish. For instance, during an earthquake in Chile rumours spread through Twitter that a volcano had become active and that there was a tsunami warning in Valparaiso (Mendoza et al., 2010) . Other examples, from the riots in England in 2011, were that rioters were going to attack Birmingham's children hospital and that animals had escaped from the zoo (Procter et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 332,
                        "end": 354,
                        "text": "(Mendoza et al., 2010)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 520,
                        "end": 542,
                        "text": "(Procter et al., 2013)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Social scientists (Procter et al., 2013) analysed manually a sample of tweets expressing different judgements towards rumours and categorised them manually in supporting, denying or questioning. The goal here is to carry out tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities (Procter et al., 2013) . In addition, information about tweet-level judgements has been used as a first step for early rumour detection by (Zhao et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 18,
                        "end": 40,
                        "text": "(Procter et al., 2013)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 365,
                        "end": 387,
                        "text": "(Procter et al., 2013)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 504,
                        "end": 523,
                        "text": "(Zhao et al., 2015)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The focus here is on tweet- (Qazvinian et al., 2011) or proposed regular expressions as a solution (Zhao et al., 2015) . We expect posts expressing similar opinions to exhibit many similar characteristics across different rumours. Based on the assumption of a common underlying linguistic signal, we build a transfer learning system that labels newly emerging rumours for which we have little or no annotated data. Results demonstrate that Gaussian Processbased multi task learning allows for significantly improved performance.",
                "cite_spans": [
                    {
                        "start": 28,
                        "end": 52,
                        "text": "(Qazvinian et al., 2011)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 99,
                        "end": 118,
                        "text": "(Zhao et al., 2015)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The novel contributions of this paper are: 1. Formulating the problem of classifying judgements of rumours in both supervised and unsupervised domain adaptation settings. 2. Showing how a multi-task learning approach outperforms singletask methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In the context of rumour spread in social media, researchers have studied differences in informa-tion flows between content of varying credibility. For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011) , then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the above attempted to automatically classify rumours.",
                "cite_spans": [
                    {
                        "start": 162,
                        "end": 183,
                        "text": "Procter et al. (2013)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 243,
                        "end": 263,
                        "text": "(Lotan et al., 2011)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 396,
                        "end": 417,
                        "text": "Mendoza et al. (2010)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 606,
                        "end": 628,
                        "text": "Friggeri et al. (2014)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "2"
            },
            {
                "text": "With respect to automatic methods for detecting misinformation and disinformation in social media, Ratkiewicz et al. (2011) detect political abuse (a kind of disinformation) spread through Twitter. The task is defined in purely information diffusion settings and is not necessarily related with the truthfulness of the piece of information. Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible. The main difference from our task is that credibility classification is carried out over the entire information cascade, classified objects are not necessarily rumours and no explicit judgement classification was performed in their approach.",
                "cite_spans": [
                    {
                        "start": 99,
                        "end": 123,
                        "text": "Ratkiewicz et al. (2011)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 341,
                        "end": 363,
                        "text": "Castillo et al. (2013)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "2"
            },
            {
                "text": "Early rumour identification is the focus of Zhao et al. (2015) , where regular expressions are used for finding questioning and denying tweets as a key pre-requisite step for rumour detection. Unfortunately, when we applied these regular expressions on our dataset, they yielded only 16% recall for questioning and 14% recall for denying tweets. Consequently, this motivated us to seek a better approach to tweet-level classification.",
                "cite_spans": [
                    {
                        "start": 44,
                        "end": 62,
                        "text": "Zhao et al. (2015)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "2"
            },
            {
                "text": "The work most relevant to ours is due to Qazvinian et al. (2011) . Their method first carries out rumour retrieval, whereby tweets are classified into rumour related and non-rumour related. Next, rumour-related tweets are classified into supporting and not-supporting. The classifier is trained by ignoring rumour identities, i.e., pooling together tweets from all rumours, and ignoring the temporal dependencies between tweets. In contrast, we formulate the rumour classifica- ",
                "cite_spans": [
                    {
                        "start": 41,
                        "end": 64,
                        "text": "Qazvinian et al. (2011)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "2"
            },
            {
                "text": "We evaluate our work on several rumours circulating on Twitter during the England riots in 2011 (see Table 2 ). The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots (Procter et al., 2013) . The original dataset also included commenting tweets, but these have been removed from our experiments due to their small number (they constituted only 5% of the corpus).",
                "cite_spans": [
                    {
                        "start": 291,
                        "end": 313,
                        "text": "(Procter et al., 2013)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 107,
                        "end": 108,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "As can be seen from the dataset overview in Table 2 , different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011) . These variations in majority classes across rumours underscores the modeling challenge in tweet-level classification of rumour attitudes.",
                "cite_spans": [
                    {
                        "start": 199,
                        "end": 221,
                        "text": "(Mendoza et al., 2010;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 222,
                        "end": 245,
                        "text": "Qazvinian et al., 2011)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 50,
                        "end": 51,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "With respect to veracity, one rumour has been confirmed as true (Miss Selfridge's being on fire), one is unsubstantiated (police beat girl), and the remaining five are known to be false. Note, however, that the focus here is not on classifying truthfulness, but instead on identifying the attitude expressed in each tweet towards the rumour.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "Let R be a set of rumours, each of which consists of tweets discussing it, \u2200 r\u2208R T r = {t r 1 , \u2022 \u2022 \u2022 , t r rn }. T = \u222a r\u2208R T r is the complete set of tweets from all rumours. Each tweet is classified as supporting, denying or questioning with respect to its rumour: y(t) \u2208 {0, 1, 2}, where 0 denotes supporting, 1 means denying and 2 denotes questioning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem formulation",
                "sec_num": "4"
            },
            {
                "text": "First, we consider the Leave One Out (LOO) setting, which means that for each rumour r \u2208 R, we construct the test set equal to T r and the training set equal to T \\ T r . Therefore this is a very challenging and realistic scenario, where the test set contains an entirely unseen rumour, from those in the training set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem formulation",
                "sec_num": "4"
            },
            {
                "text": "The second setting is Leave Part Out (LPO). In this formulation, a very small number of initial tweets from the target rumour is added to the training set {t r 1 , \u2022 \u2022 \u2022 , t r r k }. This scenario becomes applicable typically soon after a rumour breaks out and journalists have started monitoring and analysing the related tweet stream. The experiments section investigates how the number of initial training tweets influences classification performance on a fixed test set, namely:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem formulation",
                "sec_num": "4"
            },
            {
                "text": "{t r r l , \u2022 \u2022 \u2022 , t r rn }, l > k.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem formulation",
                "sec_num": "4"
            },
            {
                "text": "The tweet-level classification problem here assumes that tweets from the training set are already labelled with the rumour discussed and the attitude expressed towards that. This information can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015) . Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set.",
                "cite_spans": [
                    {
                        "start": 357,
                        "end": 376,
                        "text": "(Zhao et al., 2015)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem formulation",
                "sec_num": "4"
            },
            {
                "text": "Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015) . We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection. 1The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005) ) is a latent function f over inputs x: f (x) \u223c GP(m(x), k(x, x )), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which the outputs covary as a function of the inputs. We use a linear kernel, k(x, x ) = \u03c3 2 x x . The latent function is then mapped by the probit function \u03a6(f ) into the range [0, 1], such that the resulting value can be interpreted as p(y = 1|x).",
                "cite_spans": [
                    {
                        "start": 183,
                        "end": 206,
                        "text": "(Cohn and Specia, 2013;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 207,
                        "end": 227,
                        "text": "Lampos et al., 2014;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 228,
                        "end": 246,
                        "text": "Beck et al., 2014;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 247,
                        "end": 276,
                        "text": "Preotiuc-Pietro et al., 2015)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 486,
                        "end": 516,
                        "text": "(Rasmussen and Williams, 2005)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "The GPC posterior is calculated as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "p(f * |X, y, x * ) = p(f * |X, x * , f ) p(y|f )p(f ) p(y|X) df ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "where p(y|f",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": ") = n j=1 \u03a6(f j ) y j (1-\u03a6(f j )) 1-y j is the",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "Bernoulli likelihood of class y. After calculating the above posterior from the training data, this is used in prediction, i.e.,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "p(y * = 1|X, y, x * ) = \u03a6 (f * ) p (f * |X, y, x * ) df * .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "The above integrals are intractable and approximation techniques are required to solve them. There exist various methods to deal with calculating the posterior; here we use Expectation Propagation (EP; (Minka and Lafferty, 2002) ). In EP, the posterior is approximated by a fully factorised distribution, where each component is assumed to be an unnormalised Gaussian.",
                "cite_spans": [
                    {
                        "start": 202,
                        "end": 228,
                        "text": "(Minka and Lafferty, 2002)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "In order to conduct multi-class classification, we perform a one-vs-all classification for each label and then assign the one with the highest likelihood, amongst the three (supporting, denying, questioning). We choose this method due to interpretability of results, similar to recent work on occupational class classification (Preotiuc-Pietro et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 327,
                        "end": 357,
                        "text": "(Preotiuc-Pietro et al., 2015)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gaussian Processes for Classification",
                "sec_num": "5"
            },
            {
                "text": "In the LPO setting initial labelled tweets from the target rumour are observed as well. In this case, we propose to weight the importance of tweets from the reference rumours depending on how similar their characteristics are to the tweets from the target rumour available for training. To handle this with GPC, we use a multiple output model based on the Intrinsic Coregionalisation Model (ICM; ( \u00c1lvarez et al., 2012) ). It has already been applied successfully to NLP regression problems (Beck et al., 2014) and it can also be applied to classification ones. ICM parametrizes the kernel by a matrix which represents the extent of covariance between pairs of tasks. The complete kernel takes form of",
                "cite_spans": [
                    {
                        "start": 396,
                        "end": 419,
                        "text": "( \u00c1lvarez et al., 2012)",
                        "ref_id": null
                    },
                    {
                        "start": 491,
                        "end": 510,
                        "text": "(Beck et al., 2014)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intrinsic Coregionalization Model",
                "sec_num": null
            },
            {
                "text": "k((x, d), (x , d )) = k data (x, x )B d,d ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intrinsic Coregionalization Model",
                "sec_num": null
            },
            {
                "text": "where B is a square coregionalization matrix, d and d denote the tasks of the two inputs and k data is a kernel for comparing inputs x and x (here, linear). We parametrize the coregionalization matrix B = \u03baI + vv T , where v specifies the correlation between tasks and the vector \u03ba controls extent of task independence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intrinsic Coregionalization Model",
                "sec_num": null
            },
            {
                "text": "Hyperparameter selection We tune hyperparameters v, \u03ba and \u03c32 by maximizing evidence of the model p(y|X), thus having no need for a validation set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intrinsic Coregionalization Model",
                "sec_num": null
            },
            {
                "text": "Methods We consider GPs in three different settings, varying in what data the model is trained on and what kernel it uses. The first setting (denoted GP) considers only target rumour data for training. The second (GPPooled) additionally considers tweets from reference rumours (i.e. other than the target rumour). The third setting is GPICM, where an ICM kernel is used to weight influence from tweets from reference rumours.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intrinsic Coregionalization Model",
                "sec_num": null
            },
            {
                "text": "We conducted a series of preprocessing steps in order to address data sparsity. All words were lowercased; stopwords removed; all emoticons were replaced with words 2 ; and stemming was performed. In addition, multiple occurrences of a character were replaced with a double occurrence (Agarwal et al., 2011) , to correct for misspellings and lengthenings, e.g., looool. All punctuation was also removed, except for ., ! and ?, which we hypothesize to be important for expressing emotion. Lastly, usernames were removed as they tend to be rumour-specific, i.e., very few users comment on more than one rumour.",
                "cite_spans": [
                    {
                        "start": 285,
                        "end": 307,
                        "text": "(Agarwal et al., 2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Features",
                "sec_num": "6"
            },
            {
                "text": "After preprocessing the text data, we use either the resulting bag of words (BOW) feature representation or replace all words with their Brown cluster ids (Brown), using 1000 clusters acquired from a large scale Twitter corpus (Owoputi et al., 2013) . In all cases, simple re-tweets are removed from the training set to prevent bias (Llewellyn et al., 2014) . method acc Majority 0.68 GPPooled Brown 0.72 GPPooled BOW 0.69 Table 3 : Accuracy taken across all rumours in the LOO setting.",
                "cite_spans": [
                    {
                        "start": 227,
                        "end": 249,
                        "text": "(Owoputi et al., 2013)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 333,
                        "end": 357,
                        "text": "(Llewellyn et al., 2014)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 429,
                        "end": 430,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Features",
                "sec_num": "6"
            },
            {
                "text": "Table 3 shows the mean accuracy in the LOO scenario following the GPPooled method, which pools all reference rumours together ignoring their task identities. ICM can not use correlations to target rumour in this case and so can not be used. The majority baseline simply assigns the most frequent class from the training set.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experiments and Discussion",
                "sec_num": "7"
            },
            {
                "text": "We can observe that methods perform on a level similar to majority vote, outperforming it only slightly. This indicates how difficult the LOO task is, when no annotated target rumour tweets are available.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments and Discussion",
                "sec_num": "7"
            },
            {
                "text": "Figure 1 shows accuracy for a range of methods as the number of tweets about the target rumour used for training increases. Most notably, performance increases from 70% to around 80%, after only 10 annotated tweets from the target rumour become available, as compared to the results on unseen rumours from Table 3 . However, as the amount of target rumour increases, performance does not increase further, which suggests that even only 10 human-annotated tweets are enough to achieve significant performance benefits. Note also how the use of reference rumours is very important, as methods using only the target rumour obtain accuracy similar to the Majority vote classifier (GP Brown and GP BOW).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    },
                    {
                        "start": 312,
                        "end": 313,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experiments and Discussion",
                "sec_num": "7"
            },
            {
                "text": "The top performing methods are GPCIM and GPPooled, where use of Brown clusters consistently improves results for both methods over BOW, irrespective of the number of tweets about the target rumour annotated for training. Moreover, GPICM is better than GPPooled both with Brown and BOW features and GPCIM with Brown is ultimately the best performing of all.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments and Discussion",
                "sec_num": "7"
            },
            {
                "text": "In order to analyse the importance of Brown clusters, Automatic Relevance Determination (ARD) is used (Rasmussen and Williams, 2005) for the best performing GPICM Brown in the LPO scenario. Only the case where the first 10 tweets are used for training is considered, since it already performs very well. Using ARD, we learn a separate length-scale for each feature, thus establishing their importance. The weights learnt for different clusters are averaged over the 7 rumours and the top 5 Brown clusters for each label are shown in Table 4 . We can see that clusters around the words fake and bullshit turn out to be important for the denying class, and true for both supporting and questioning classes. This reinforces our hypothesis that common linguistic cues can be found across multiple rumours. Note how punctuation proves important as well, since clusters ? and ! are also very prominent.",
                "cite_spans": [
                    {
                        "start": 102,
                        "end": 132,
                        "text": "(Rasmussen and Williams, 2005)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 539,
                        "end": 540,
                        "text": "4",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Experiments and Discussion",
                "sec_num": "7"
            },
            {
                "text": "This paper investigated the problem of classifying judgements expressed in tweets about rumours.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "8"
            },
            {
                "text": "First, we considered a setting where no training data from target rumour is available (LOO). Without access to annotated examples of the target rumour the learning problem becomes very difficult. We showed that in the supervised domain adaptation setting (LPO) even annotating a small number of tweets helps to achieve better results. Moreover, we demonstrated the benefits of a multi task learning approach, as well as that Brown cluster features are more useful for the task than simple bag of words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "8"
            },
            {
                "text": "Judgement estimation is undoubtedly of great value e.g. for marketing, politics and journalism, helping to target widely believed topics. Although the focus here is on classifying community reactions, Castillo et al. (2013) showed that community reaction is correlated with actual rumour veracity. Consequently our classification methods may prove useful in the broader and more challenging task of annotating veracity.",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 223,
                        "text": "Castillo et al. (2013)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "8"
            },
            {
                "text": "An interesting direction for future work would be adding non-textual features. For example, the rumour diffusion pattern (Lukasik et al., 2015) may be a useful cue for judgement classification.",
                "cite_spans": [
                    {
                        "start": 121,
                        "end": 143,
                        "text": "(Lukasik et al., 2015)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "8"
            },
            {
                "text": "There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We used the dictionary from: http://bit.ly/ 1rX1Hdk and extended it with: :o, : |, =/, :s, :S, :p.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Work partially supported by the European Union under grant agreement No. 611233 PHEME. The work was implemented using the GPy toolkit (GPy authors, 2015).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data",
                "authors": [
                    {
                        "first": "Apoorv",
                        "middle": [],
                        "last": "Agarwal",
                        "suffix": ""
                    },
                    {
                        "first": "Boyi",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Ilia",
                        "middle": [],
                        "last": "Vovsha",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the Workshop on Languages in Social Media, LSM '11",
                "volume": "",
                "issue": "",
                "pages": "30--38",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram- bow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Work- shop on Languages in Social Media, LSM '11, pages 30-38.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Kernels for vector-valued functions: A review",
                "authors": [
                    {
                        "first": "Mauricio",
                        "middle": [
                            "A"
                        ],
                        "last": "\u00c1lvarez",
                        "suffix": ""
                    },
                    {
                        "first": "Lorenzo",
                        "middle": [],
                        "last": "Rosasco",
                        "suffix": ""
                    },
                    {
                        "first": "Neil",
                        "middle": [
                            "D"
                        ],
                        "last": "Lawrence",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Found. Trends Mach. Learn",
                "volume": "4",
                "issue": "3",
                "pages": "195--266",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mauricio A. \u00c1lvarez, Lorenzo Rosasco, and Neil D. Lawrence. 2012. Kernels for vector-valued func- tions: A review. Found. Trends Mach. Learn., 4(3):195-266.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Joint emotion analysis via multi-task Gaussian processes",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Beck",
                        "suffix": ""
                    },
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    },
                    {
                        "first": "Lucia",
                        "middle": [],
                        "last": "Specia",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP '14",
                "volume": "",
                "issue": "",
                "pages": "1798--1803",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Beck, Trevor Cohn, and Lucia Specia. 2014. Joint emotion analysis via multi-task Gaussian pro- cesses. In Proceedings of the Conference on Em- pirical Methods in Natural Language Processing, EMNLP '14, pages 1798-1803.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Predicting information credibility in time-sensitive social media",
                "authors": [
                    {
                        "first": "Carlos",
                        "middle": [],
                        "last": "Castillo",
                        "suffix": ""
                    },
                    {
                        "first": "Marcelo",
                        "middle": [],
                        "last": "Mendoza",
                        "suffix": ""
                    },
                    {
                        "first": "Barbara",
                        "middle": [],
                        "last": "Poblete",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Internet Research",
                "volume": "23",
                "issue": "5",
                "pages": "560--588",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2013. Predicting information credibility in time-sensitive social media. Internet Research, 23(5):560-588.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Modelling annotator bias with multi-task Gaussian processes: An application to machine translation quality estimation",
                "authors": [
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    },
                    {
                        "first": "Lucia",
                        "middle": [],
                        "last": "Specia",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "51st Annual Meeting of the Association for Computational Linguistics, ACL '13",
                "volume": "",
                "issue": "",
                "pages": "32--42",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Trevor Cohn and Lucia Specia. 2013. Modelling an- notator bias with multi-task Gaussian processes: An application to machine translation quality estima- tion. In 51st Annual Meeting of the Association for Computational Linguistics, ACL '13, pages 32-42.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Rumor cascades",
                "authors": [
                    {
                        "first": "Adrien",
                        "middle": [],
                        "last": "Friggeri",
                        "suffix": ""
                    },
                    {
                        "first": "Lada",
                        "middle": [],
                        "last": "Adamic",
                        "suffix": ""
                    },
                    {
                        "first": "Dean",
                        "middle": [],
                        "last": "Eckles",
                        "suffix": ""
                    },
                    {
                        "first": "Justin",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "International AAAI Conference on Weblogs and Social Media",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adrien Friggeri, Lada Adamic, Dean Eckles, and Justin Cheng. 2014. Rumor cascades. In International AAAI Conference on Weblogs and Social Media.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "GPy: A Gaussian process framework in Python",
                "authors": [],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "The GPy authors. 2015. GPy: A Gaussian process framework in Python. http://github.com/ SheffieldML/GPy.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Predicting and characterising user impact on twitter",
                "authors": [
                    {
                        "first": "Vasileios",
                        "middle": [],
                        "last": "Lampos",
                        "suffix": ""
                    },
                    {
                        "first": "Nikolaos",
                        "middle": [],
                        "last": "Aletras",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Preotiuc-Pietro",
                        "suffix": ""
                    },
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, EACL'14",
                "volume": "",
                "issue": "",
                "pages": "405--413",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vasileios Lampos, Nikolaos Aletras, Daniel Preotiuc- Pietro, and Trevor Cohn. 2014. Predicting and characterising user impact on twitter. In Proceed- ings of the 14th Conference of the European Chap- ter of the Association for Computational Linguistics, EACL'14, pages 405-413.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Re-using an argument corpus to aid in the curation of social media collections",
                "authors": [
                    {
                        "first": "Clare",
                        "middle": [],
                        "last": "Llewellyn",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Grover",
                        "suffix": ""
                    },
                    {
                        "first": "Jon",
                        "middle": [],
                        "last": "Oberlander",
                        "suffix": ""
                    },
                    {
                        "first": "Ewan",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation, LREC'14",
                "volume": "",
                "issue": "",
                "pages": "462--468",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Clare Llewellyn, Claire Grover, Jon Oberlander, and Ewan Klein. 2014. Re-using an argument corpus to aid in the curation of social media collections. In Proceedings of the Ninth International Conference on Language Resources and Evaluation, LREC'14, pages 462-468.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "The Arab spring-the revolutions were tweeted: Information flows during the 2011 Tunisian and Egyptian revolutions",
                "authors": [
                    {
                        "first": "Gilad",
                        "middle": [],
                        "last": "Lotan",
                        "suffix": ""
                    },
                    {
                        "first": "Erhardt",
                        "middle": [],
                        "last": "Graeff",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Ananny",
                        "suffix": ""
                    },
                    {
                        "first": "Devin",
                        "middle": [],
                        "last": "Gaffney",
                        "suffix": ""
                    },
                    {
                        "first": "Ian",
                        "middle": [],
                        "last": "Pearce",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Boyd",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "International Journal of Communication",
                "volume": "5",
                "issue": "0",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gilad Lotan, Erhardt Graeff, Mike Ananny, Devin Gaffney, Ian Pearce, and danah boyd. 2011. The Arab spring-the revolutions were tweeted: Infor- mation flows during the 2011 Tunisian and Egyptian revolutions. International Journal of Communica- tion, 5(0).",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Point process modelling of rumour dynamics in social media",
                "authors": [
                    {
                        "first": "Michal",
                        "middle": [],
                        "last": "Lukasik",
                        "suffix": ""
                    },
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    },
                    {
                        "first": "Kalina",
                        "middle": [],
                        "last": "Bontcheva",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "518--523",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michal Lukasik, Trevor Cohn, and Kalina Bontcheva. 2015. Point process modelling of rumour dynamics in social media. In Proceedings of the 53rd Annual Meeting of the Association for Computational Lin- guistics and the 7th International Joint Conference on Natural Language Processing of the Asian Fed- eration of Natural Language Processing, ACL 2015, pages 518-523.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Twitter under crisis: Can we trust what we RT? In 1st Workshop on Social Media Analytics, SOMA'10",
                "authors": [
                    {
                        "first": "Marcelo",
                        "middle": [],
                        "last": "Mendoza",
                        "suffix": ""
                    },
                    {
                        "first": "Barbara",
                        "middle": [],
                        "last": "Poblete",
                        "suffix": ""
                    },
                    {
                        "first": "Carlos",
                        "middle": [],
                        "last": "Castillo",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "71--79",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marcelo Mendoza, Barbara Poblete, and Carlos Castillo. 2010. Twitter under crisis: Can we trust what we RT? In 1st Workshop on Social Media An- alytics, SOMA'10, pages 71-79.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Expectationpropagation for the generative aspect model",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Minka",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Lafferty",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence, UAI'02",
                "volume": "",
                "issue": "",
                "pages": "352--359",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas Minka and John Lafferty. 2002. Expectation- propagation for the generative aspect model. In Pro- ceedings of the Eighteenth Conference on Uncer- tainty in Artificial Intelligence, UAI'02, pages 352- 359.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Improved part-of-speech tagging for online conversational text with word clusters",
                "authors": [
                    {
                        "first": "Olutobi",
                        "middle": [],
                        "last": "Owoputi",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Gimpel",
                        "suffix": ""
                    },
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Schneider",
                        "suffix": ""
                    },
                    {
                        "first": "Noah",
                        "middle": [
                            "A"
                        ],
                        "last": "Smith",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of NAACL",
                "volume": "",
                "issue": "",
                "pages": "380--390",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Olutobi Owoputi, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In Proceedings of NAACL, pages 380-390.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "An analysis of the user occupational class through twitter content",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Preotiuc-Pietro",
                        "suffix": ""
                    },
                    {
                        "first": "Vasileios",
                        "middle": [],
                        "last": "Lampos",
                        "suffix": ""
                    },
                    {
                        "first": "Nikolaos",
                        "middle": [],
                        "last": "Aletras",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015",
                "volume": "",
                "issue": "",
                "pages": "1754--1764",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Preotiuc-Pietro, Vasileios Lampos, and Niko- laos Aletras. 2015. An analysis of the user occupa- tional class through twitter content. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Pro- cessing, ACL 2015, pages 1754-1764.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Reading the riots: What were the police doing on twitter? Policing and society",
                "authors": [
                    {
                        "first": "Rob",
                        "middle": [],
                        "last": "Procter",
                        "suffix": ""
                    },
                    {
                        "first": "Jeremy",
                        "middle": [],
                        "last": "Crump",
                        "suffix": ""
                    },
                    {
                        "first": "Susanne",
                        "middle": [],
                        "last": "Karstedt",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Marta",
                        "middle": [],
                        "last": "Cantijoch",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "",
                "volume": "23",
                "issue": "",
                "pages": "413--436",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rob Procter, Jeremy Crump, Susanne Karstedt, Alex Voss, and Marta Cantijoch. 2013. Reading the riots: What were the police doing on twitter? Policing and society, 23(4):413-436.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Rumor has it: Identifying misinformation in microblogs",
                "authors": [
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Vahed Qazvinian",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Rosengren",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Dragomir",
                        "suffix": ""
                    },
                    {
                        "first": "Qiaozhu",
                        "middle": [],
                        "last": "Radev",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mei",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1589--1599",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vahed Qazvinian, Emily Rosengren, Dragomir R. Radev, and Qiaozhu Mei. 2011. Rumor has it: Identifying misinformation in microblogs. In Pro- ceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP '11, pages 1589-1599.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)",
                "authors": [
                    {
                        "first": "Carl",
                        "middle": [],
                        "last": "Edward Rasmussen",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "K I"
                        ],
                        "last": "Williams",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Carl Edward Rasmussen and Christopher K. I. Williams. 2005. Gaussian Processes for Ma- chine Learning (Adaptive Computation and Ma- chine Learning). The MIT Press.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Detecting and tracking political abuse in social media. In 5th International AAAI Conference on Weblogs and Social Media, ICWSM'11",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Ratkiewicz",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Conover",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Meiss",
                        "suffix": ""
                    },
                    {
                        "first": "Bruno",
                        "middle": [],
                        "last": "Gonalves",
                        "suffix": ""
                    },
                    {
                        "first": "Alessandro",
                        "middle": [],
                        "last": "Flammini",
                        "suffix": ""
                    },
                    {
                        "first": "Filippo",
                        "middle": [],
                        "last": "Menczer",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Ratkiewicz, Michael Conover, Mark Meiss, Bruno Gonalves, Alessandro Flammini, and Fil- ippo Menczer. 2011. Detecting and tracking po- litical abuse in social media. In 5th International AAAI Conference on Weblogs and Social Media, ICWSM'11.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Early detection of rumors in social media from enquiry posts",
                "authors": [
                    {
                        "first": "Zhe",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Resnick",
                        "suffix": ""
                    },
                    {
                        "first": "Qiaozhu",
                        "middle": [],
                        "last": "Mei",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "International World Wide Web Conference Committee",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. Early detection of rumors in social media from en- quiry posts. In International World Wide Web Con- ference Committee (IW3C2).",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Accuracy measures for different methods versus the size of the target rumour used for training in the LPO setting. The test set is fixed to all but the first 50 tweets of the target rumour.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>level judgement clas-</td></tr><tr><td>sification on unseen rumours, based on a training</td></tr></table>",
                "type_str": "table",
                "text": "Tweets on a rumour about hospital being attacked during 2011 England Riots.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>supporting</td><td>denying</td><td>questioning</td></tr><tr><td>?</td><td>fake</td><td>?</td></tr><tr><td>10001101</td><td>11111000001</td><td>10001101</td></tr><tr><td>!</td><td>not</td><td>!</td></tr><tr><td>10001100</td><td>001000</td><td>10001100</td></tr><tr><td>not</td><td>?</td><td>hope</td></tr><tr><td>001000</td><td>10001101</td><td>01000111110</td></tr><tr><td>fake</td><td>!</td><td>true</td></tr><tr><td>11111000001</td><td>10001100</td><td>111110010110</td></tr><tr><td>true</td><td>bullshit</td><td>searching</td></tr><tr><td>111110010110</td><td>11110101011111</td><td>01111000010</td></tr></table>",
                "type_str": "table",
                "text": "The test set is fixed to all but the first 50 tweets of the target rumour.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td/><td colspan=\"2\">: Top 5 Brown clusters, each shown</td></tr><tr><td colspan=\"2\">with a representative word.</td><td>For further</td></tr><tr><td colspan=\"3\">details please see the cluster definitions</td></tr><tr><td>at</td><td colspan=\"2\">http://www.ark.cs.cmu.edu/</td></tr><tr><td colspan=\"3\">TweetNLP/cluster_viewer.html.</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            }
        }
    }
}