{
    "paper_id": "N09-1072",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:00:56.422376Z"
    },
    "title": "Extracting Social Meaning: Identifying Interactional Style in Spoken Conversation",
    "authors": [
        {
            "first": "Dan",
            "middle": [],
            "last": "Jurafsky",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Stanford University",
                "location": {}
            },
            "email": "jurafsky@stanford.edu"
        },
        {
            "first": "Rajesh",
            "middle": [],
            "last": "Ranganath",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Stanford University",
                "location": {}
            },
            "email": "rajeshr@cs.stanford.edu"
        },
        {
            "first": "Dan",
            "middle": [],
            "last": "Mcfarland",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Stanford University",
                "location": {}
            },
            "email": "dmcfarla@stanford.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Automatically extracting social meaning and intention from spoken dialogue is an important task for dialogue systems and social computing. We describe a system for detecting elements of interactional style: whether a speaker is awkward, friendly, or flirtatious. We create and use a new spoken corpus of 991 4-minute speed-dates. Participants rated their interlocutors for these elements of style. Using rich dialogue, lexical, and prosodic features, we are able to detect flirtatious, awkward, and friendly styles in noisy natural conversational data with up to 75% accuracy, compared to a 50% baseline. We describe simple ways to extract relatively rich dialogue features, and analyze which features performed similarly for men and women and which were gender-specific.",
    "pdf_parse": {
        "paper_id": "N09-1072",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Automatically extracting social meaning and intention from spoken dialogue is an important task for dialogue systems and social computing. We describe a system for detecting elements of interactional style: whether a speaker is awkward, friendly, or flirtatious. We create and use a new spoken corpus of 991 4-minute speed-dates. Participants rated their interlocutors for these elements of style. Using rich dialogue, lexical, and prosodic features, we are able to detect flirtatious, awkward, and friendly styles in noisy natural conversational data with up to 75% accuracy, compared to a 50% baseline. We describe simple ways to extract relatively rich dialogue features, and analyze which features performed similarly for men and women and which were gender-specific.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "How can we extract social meaning from speech, deciding if a speaker is particularly engaged in the conversation, is uncomfortable or awkward, or is particularly friendly and flirtatious? Understanding these meanings and how they are signaled in language is an important sociolinguistic task in itself. Extracting them automatically from dialogue speech and text is crucial for developing socially aware computing systems for tasks such as detection of interactional problems or matching conversational style, and will play an important role in creating more natural dialogue agents (Pentland, 2005; Nass and Brave, 2005; Brave et al., 2005) .",
                "cite_spans": [
                    {
                        "start": 583,
                        "end": 599,
                        "text": "(Pentland, 2005;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 600,
                        "end": 621,
                        "text": "Nass and Brave, 2005;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 622,
                        "end": 641,
                        "text": "Brave et al., 2005)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Cues for social meaning permeate speech at every level of linguistic structure. Acoustic cues such as low and high F0 or energy and spectral tilt are important in detecting emotions such as annoyance, anger, sadness, or boredom (Ang et al., 2002; Lee and Narayanan, 2002; Liscombe et al., 2003) , speaker characteristics such as charisma (Rosenberg and Hirschberg, 2005) , or personality features like extroversion (Mairesse et al., 2007; Mairesse and Walker, 2008) . Lexical cues to social meaning abound. Speakers with links to depression or speakers who are under stress use more first person singular pronouns (Rude et al., 2004; Pennebaker and Lay, 2002; Cohn et al., 2004) , positive emotion words are cues to agreeableness (Mairesse et al., 2007) , and negative emotion words are useful cues to deceptive speech (Newman et al., 2003) . The number of words in a sentence can be a useful feature for extroverted personality (Mairesse et al., 2007) . Finally, dialog features such as the presence of disfluencies can inform listeners about speakers' problems in utterance planning or about confidence (Brennan and Williams, 1995; Brennan and Schober, 2001) .",
                "cite_spans": [
                    {
                        "start": 228,
                        "end": 246,
                        "text": "(Ang et al., 2002;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 247,
                        "end": 271,
                        "text": "Lee and Narayanan, 2002;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 272,
                        "end": 294,
                        "text": "Liscombe et al., 2003)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 338,
                        "end": 370,
                        "text": "(Rosenberg and Hirschberg, 2005)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 415,
                        "end": 438,
                        "text": "(Mairesse et al., 2007;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 439,
                        "end": 465,
                        "text": "Mairesse and Walker, 2008)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 614,
                        "end": 633,
                        "text": "(Rude et al., 2004;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 634,
                        "end": 659,
                        "text": "Pennebaker and Lay, 2002;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 660,
                        "end": 678,
                        "text": "Cohn et al., 2004)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 730,
                        "end": 753,
                        "text": "(Mairesse et al., 2007)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 819,
                        "end": 840,
                        "text": "(Newman et al., 2003)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 929,
                        "end": 952,
                        "text": "(Mairesse et al., 2007)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 1105,
                        "end": 1133,
                        "text": "(Brennan and Williams, 1995;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 1134,
                        "end": 1160,
                        "text": "Brennan and Schober, 2001)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our goal is to see whether cues of this sort are useful in detecting particular elements of conversational style and social intention; whether a speaker in a speed-dating conversation is judged by the interlocutor as friendly, awkward, or flirtatious.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our experiments make use of a new corpus we have collected, the SpeedDate Corpus. The corpus is based on three speed-dating sessions run at an elite private American university in 2005 and inspired by prior speed-dating research (Madan et al., 2005; Pentland, 2005) . The graduate student participants volunteered to be in the study and were promised emails of persons with whom they reported mutual liking. Each date was conducted in an open setting where there was substantial background noise. All participants wore audio recorders on a shoulder sash, thus resulting in two audio recordings of the approximately 1100 4-minute dates. In addition to the audio, we collected pre-test surveys, event scorecards, and post-test surveys. This is the largest sample we know of where audio data and detailed survey information were combined in a natural experiment.",
                "cite_spans": [
                    {
                        "start": 229,
                        "end": 249,
                        "text": "(Madan et al., 2005;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 250,
                        "end": 265,
                        "text": "Pentland, 2005)",
                        "ref_id": "BIBREF25"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Corpus",
                "sec_num": "2"
            },
            {
                "text": "The rich survey information included date perceptions and follow-up interest, as well as general attitudes, preferences, and demographic information. Participants were also asked about the conversational style and intention of the interlocutor. Each speaker was asked to report how often their date's speech reflected different conversational styles (awkward, friendly, flirtatious, funny, assertive) on a scale of 1-10 (1=never, 10=constantly): \"How often did the other person behave in the following ways on this 'date'?\". We chose three of these five to focus on in this paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Corpus",
                "sec_num": "2"
            },
            {
                "text": "We acquired acoustic information by taking the acoustic wave file from each recorder and manually segmenting it into a sequence of wavefiles, each corresponding to one 4-minute date. Since both speakers wore microphones, most dates had two recordings, one from the male recorder and one from the female recorder. Because of mechanical, operator, and experimenter errors, some recordings were lost, and thus some dates had only one recording. Transcribers at a professional transcription service used the two recordings to create a transcript for each date, and time-stamped the start and end time of each speaker turn. Transcribers were instructed to mark various disfluencies as well as some nonverbal elements of the conversation such as laughter.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Corpus",
                "sec_num": "2"
            },
            {
                "text": "Because of noise, participants who accidentally turned off their mikes, and some segmentation and transcription errors, a number of dates were not possible to analyze. 19 dates were lost completely, and for an additional 130 we lost one of the two audio tracks and had to use the remaining track to extract features for both interlocutors. The current study fo-cuses on the 991 remaining clean dates for which we had usable audio, transcripts, and survey information.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Corpus",
                "sec_num": "2"
            },
            {
                "text": "Our goal is to detect three of the style variables, in particular awkward, friendly, or flirtatious speakers, via a machine learning classifier. Recall that each speaker in a date (each conversation side) was labeled by his or her interlocutor with a rating from 1-10 for awkward, friendly, or flirtatious behavior. For the experiments, the 1-10 Likert scale ratings were first mean-centered within each respondent so that the average was 0. Then the top ten percent of the respondent-centered meaned Likert ratings were marked as positive for the trait, and the bottom ten percent were marked as negative for a trait. Thus each respondent labels the other speaker as either positive, negative, or NA for each of the three traits.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Experiments",
                "sec_num": "3"
            },
            {
                "text": "We run our binary classification experiments to predict this output variable.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Experiments",
                "sec_num": "3"
            },
            {
                "text": "For each speaker side of each 4-minute conversation, we extracted features from the wavefiles and the transcript, as described in the next section. We then trained six separate binary classifiers (for each gender for the 3 tasks), as described in Section 5.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Experiments",
                "sec_num": "3"
            },
            {
                "text": "In selecting features we drew on previous research on the use of relatively simple surface features that cue social meaning, described in the next sections.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Feature Extraction",
                "sec_num": "4"
            },
            {
                "text": "Each date was represented by the two 4-minute wavefiles, one from the recorder worn by each speaker, and a single transcription. Because of the very high level of noise, the speaker wearing the recorder was much clearer on his/her own recording, and so we extracted the acoustic features for each speaker from their own microphone (except for the 130 dates for which we only had one audio file). All lexical and discourse features were extracted from the transcripts.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Feature Extraction",
                "sec_num": "4"
            },
            {
                "text": "All features describe the speaker of the conversation side being labeled for style. The features for a conversation side thus indicate whether a speaker who talks a lot, laughs, is more disfluent, has higher F0, etc., is more or less likely to be considered flirtatious, friendly, or awkward by the interlocutor. We also computed the same features for the alter interlocutor. Alter features thus indicate the conversational behavior of the speaker talking with an interlocutor they considered to be flirtatious, friendly, or awkward.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Feature Extraction",
                "sec_num": "4"
            },
            {
                "text": "F0 and RMS amplitude features were extracted using Praat scripts (Boersma and Weenink, 2005) . Since the start and end of each turn were timemarked by hand, each feature was easily extracted over a turn, and then averages and standard deviations were taken over the turns in an entire conversation side. Thus the feature F0 MIN for a conversation side was computed by taking the F0 min of each turn in that conversation side (not counting zero values of F0), and then averaging these values over all turns in the side. F0 MIN SD is the standard deviation across turns of this same measure.",
                "cite_spans": [
                    {
                        "start": 65,
                        "end": 92,
                        "text": "(Boersma and Weenink, 2005)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Prosodic Features",
                "sec_num": "4.1"
            },
            {
                "text": "Note that we coded four measures of f0 variation, not knowing in advance which one was likely to be the most useful: F0 MEAN SD is the deviation across turns from the global F0 mean for the conversation side, measuring how variable the speakers mean f0 is across turns. F0 SD is the standard deviation within a turn for the f0 mean, and then averaged over turns, hence measures how variable the speakers f0 is within a turn. F0 SD SD measures how much the within-turn f0 variance varies from turn to turn, and hence is another measure of cross-turn f0 variation. PITCH RANGE SD measures how much the speakers pitch range varies from turn to turn, and hence is another measure of cross-turn f0 variation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Prosodic Features",
                "sec_num": "4.1"
            },
            {
                "text": "Lexical features have been widely explored in the psychological and computational literature. For these features we drew mainly on the LIWC lexicons of Pennebaker et al. (2007) , the standard for social psychological analysis of lexical features. From the large variety of lexical categories in LIWC we selected ten that the previous work of Mairesse et al. (2007) had found to be very significant in detecting personality-related features. The 10 LIWC features we used were Anger, Assent, Ingest, Insight, Negemotion, Sexual, Swear, I, We, and You. We also added two new lexical features, \"past tense auxiliary\", a heuristic for automatically detecting narra- tive or story-telling behavior, and Metadate, for discussion about the speed-date itself. The features are summarized in Table 2 .",
                "cite_spans": [
                    {
                        "start": 152,
                        "end": 176,
                        "text": "Pennebaker et al. (2007)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 342,
                        "end": 364,
                        "text": "Mairesse et al. (2007)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 788,
                        "end": 789,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Lexical Features",
                "sec_num": "4.2"
            },
            {
                "text": "A number of discourse features were extracted, drawing from the conversation analysis, disfluency and dialog act literature (Sacks et al., 1974; Jurafsky et al., 1998; Jurafsky, 2001) . While discourse features are clearly important for extracting social meaning, previous work on social meaning has met with less success in use of such features (with the exception of the 'critical segments' work of (Enos et al., 2007) ), presumably because discourse fea- tures are expensive to hand-label and hard to automatically extract. We chose a suggestive discourse features that we felt might still be automatically extracted.",
                "cite_spans": [
                    {
                        "start": 124,
                        "end": 144,
                        "text": "(Sacks et al., 1974;",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 145,
                        "end": 167,
                        "text": "Jurafsky et al., 1998;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 168,
                        "end": 183,
                        "text": "Jurafsky, 2001)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 401,
                        "end": 420,
                        "text": "(Enos et al., 2007)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "Four particular dialog acts were chosen as shown in Table 3 . Backchannels (or continuers) and appreciations (a continuer expressing positive affect) were coded by hand-built regular expressions. The regular expressions were based on analysis of the backchannels and appreciations in the hand-labeled Switchboard corpus of dialog acts (Jurafsky et al., 1997) . Questions were coded simply by the presence of question marks.",
                "cite_spans": [
                    {
                        "start": 335,
                        "end": 358,
                        "text": "(Jurafsky et al., 1997)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 58,
                        "end": 59,
                        "text": "3",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "Finally, repair questions (also called NTRIs; next turn repair indicators) are turns in which a speaker signals lack of hearing or understanding (Schegloff et al., 1977) . To detect these, we used a simple heuristic: the presence of 'Excuse me' or 'Wait', as in the following example: FEMALE: Okay. Are you excited about that? MALE:",
                "cite_spans": [
                    {
                        "start": 145,
                        "end": 169,
                        "text": "(Schegloff et al., 1977)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "Excuse me?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "A collaborative completion is a turn where a speaker completes the utterance begun by the alter (Lerner, 1991; Lerner, 1996) . Our heuristic for identifying collaborative completions was to select sentences for which the first word of the speaker was extremely predictable from the last two words of the previous speaker. We trained a word trigram model1 and used it to compute the probability p of the first word of a speaker's turn given the last two words of the interlocutor's turn. We arbitrarily chose the threshold .01, labeling all turns for which p > .01 as collaborative completions and used the total number of collaborative completions in a conversation side as our variable. This simple heuristic was errorful, but did tend to find completions beginning with and or or (1 below) and wh-questions followed by an NP or PP phrase that is grammatically coherent with the end of the question (2 and 3):",
                "cite_spans": [
                    {
                        "start": 96,
                        "end": 110,
                        "text": "(Lerner, 1991;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 111,
                        "end": 124,
                        "text": "Lerner, 1996)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "(1) FEMALE: The driving range.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "(1) MALE:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "And the tennis court, too.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "(2) MALE: What year did you graduate? (2) FEMALE: From high school?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "(3) FEMALE: What department are you in?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "(3) MALE:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "The business school.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "We also marked aspects of the preference structure of language. A dispreferred action is one in which a speaker avoids the face-threat to the interlocutor that would be caused by, e.g., refusing a request or not answering a question, by using specific strategies such as the use of well, hesitations, or restarts (Schegloff et al., 1977; Pomerantz, 1984) .",
                "cite_spans": [
                    {
                        "start": 313,
                        "end": 337,
                        "text": "(Schegloff et al., 1977;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 338,
                        "end": 354,
                        "text": "Pomerantz, 1984)",
                        "ref_id": "BIBREF26"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "Finally, we included the number of instances of laughter for the side, as well as the total number of turns a speaker took.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dialogue Act and Adjacency Pair Features",
                "sec_num": "4.3"
            },
            {
                "text": "A second group of discourse features relating to repair, disfluency, and speaker overlap are summarized BACKCHANNELS number of backchannel utterances in side (Uh-huh., Yeah., Right., Oh, okay.) regular expressions (the transcribers had been instructed to transcribe all filled pauses). Restarts are a type of repair in which speakers begin a phrase, break off, and then restart the syntactic phrase. The following example shows a restart; the speaker starts a sentence Uh, I and then restarts, There's a group...:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Disfluency Features",
                "sec_num": "4.4"
            },
            {
                "text": "Uh, I-there's a group of us that came in-Overlaps are cases in which both speakers were talking at the same time, and were marked by the transcribers in the transcripts:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Disfluency Features",
                "sec_num": "4.4"
            },
            {
                "text": "But-and also obviously-FEMALE: It sounds bigger.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MALE:",
                "sec_num": null
            },
            {
                "text": "-people in the CS school are not quite as social in general as other-",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MALE:",
                "sec_num": null
            },
            {
                "text": "Before performing the classification task, we preprocessed the data in two ways. First, we standardized all the variables to have zero mean and unit variance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "We did this to avoid imposing a prior on any of the features based on their numerical values. 2 Second, 2 Consider a feature A with mean 100 and a feature B with mean .1 where A and B are correlated with the output. Since regularization favors small weights there is a bias to put weight on feature A because intuitively the weight on feature B would we removed features correlated greater than .7. One goal of removing correlated features was to remove as much colinearity as possible from the regression so that the regression weights could be ranked for their importance in the classification. In addition, we hoped to improve classification because a large number of features require more training examples (Ng, 2004) . For example for male flirt we removed f0 range (highly correlated with f0 max), f0 min sd (highly correlated with f0 min), and Swear (highly correlated with Anger).",
                "cite_spans": [
                    {
                        "start": 711,
                        "end": 721,
                        "text": "(Ng, 2004)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "For each classification task due to the small amounts of data we performed k-fold cross validation to learn and evaluate our models. We used a variant of k-fold cross validation with five folds where three folds are used for training, one fold is used for validation, and one fold is used as a test set. This test fold is not used in any training step. This yields a datasplit of 60% for training, 20% for validation, and 20% for testing, or 120 training examples, 40 validation examples, and 40 test examples. To ensure that we were not learning something specific to our data split, we randomized our data ordering and repeated the k-fold cross validation variant 25 times.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "We used regularized logistic regression for classification. Recall that in logistic regression we train a vector of feature weights \u03b8 \u2208 R n so as to make the following classification of some output variable y for an input observation x:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "3 p(y|x; \u03b8) = 1 1 + exp(-\u03b8 T x)",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "In regularized logistic regression we find the need to be 1000 times larger to carry the same effect. This argument holds similarly for the reduction to unit variance. 3 Where n is the number of features plus 1 for the intercept.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "weights \u03b8 which maximize the following optimization problem:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "argmax \u03b8 i log p(y i |x i ; \u03b8) -\u03b1 * R(\u03b8) (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "R(\u03b8) is a regularization term used to penalize large weights. We chose R(\u03b8), the regularization function, to be the",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "L 1 norm of \u03b8. That is, R(\u03b8) = ||\u03b8|| 1 = n i=1 |\u03b8 i |.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "In our case, given the training set S train , test set S test , and validation set S val , we trained the weights \u03b8 as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "argmax \u03b1 accuracy(\u03b8 \u03b1 , S val ) (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "where for a given sparsity parameter \u03b1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "\u03b8 \u03b1 = argmax \u03b8 i log p(y i |x i ; \u03b8) -\u03b1 * R(\u03b8) (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "We chose L 1 -regularization because the number of training examples to learn well grows logarithmically with the number of input variables (Ng, 2004) , and to achieve a sparse activation of our features to find only the most salient explanatory variables. This choice of regularization was made to avoid the problems that often plague supervised learning in situations with large number of features but only a small number of examples. The search space over the sparsity parameter \u03b1 is bounded around an expected sparsity to prevent overfitting. Finally, to evaluate our model on the learned \u03b1 and \u03b8 \u03b1 we used the features X of the test set S test to compute the predicted outputs Y using the logistic regression model. Accuracy is simply computed as the percent of correct predictions.",
                "cite_spans": [
                    {
                        "start": 140,
                        "end": 150,
                        "text": "(Ng, 2004)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "To avoid any data ordering bias, we calculated a \u03b8 \u03b1 for each randomized run. The output of the runs was a vector of weights for each feature. We kept any feature if the median of its weight vector was nonzero. 4 A sample boxplot for the highest weighted ego features for predicting male flirt can be found in Figure 1 . ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 317,
                        "end": 318,
                        "text": "1",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Classifier Training",
                "sec_num": "5"
            },
            {
                "text": "Results for the 6 binary classifiers are presented in Table 5 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 60,
                        "end": 61,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "Awk Flirt Friendly M F M F M F Speaker 63% 51% 67% 60% 72% 68% +other 64% 64% 71% 60% 73% 75%",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "Table 5 : Accuracy of binary classification of each conversation side, where chance is 50%. The first row uses features only from the single speaker; the second adds all the features from the interlocutor as well. These accuracy results were aggregated from 25 randomized runs of 5-fold cross validation.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "The first row shows results using features extracted from the speaker being labeled. Here, all conversational styles are easiest to detect in men.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "The second row of table 5 shows the accuracy when using features from both speakers. Not surprisingly, adding information about the interlocutor tends to improve classification, and especially for women, suggesting that male speaking has greater sway over perceptions of conversational style. We discuss below the role of these features.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 24,
                        "end": 25,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "We first considered the features that helped classification when considering only the ego (i.e., the results in the first row of Table 5 ). Table 6 shows feature weights for the features (features were normed so weights are comparable), and is summarized in the following paragraphs:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 135,
                        "end": 136,
                        "text": "5",
                        "ref_id": null
                    },
                    {
                        "start": 146,
                        "end": 147,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "\u2022 Men who are labeled as friendly use you, col- 6 : Feature weights (median weights of the randomized runs) for the non-zero predictors for each classifier. Since our accuracy for detecting awkwardness in women based solely on ego features is so close to chance, we didn't analyze the awkwardness features for women here. laborative completions, laugh, overlap, but don't backchannel or use appreciations. Their utterances are shorter (in seconds and words) and they are quieter and their (minimum) pitch is lower and somewhat less variable.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 48,
                        "end": 49,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "\u2022 Women labeled as friendly have more collaborative completions, repair questions, laughter, and appreciations. They use more words overall, and use I more often. They are more disfluent (both restarts and uh) but less likely to swear. Prosodically their f0 is higher, and there seems to be some pattern involving quiet speech; more variation in intensity minimum than intensity max.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "\u2022 Men who are labeled as flirting ask more questions, including repair questions, and use you. They don't use backchannels or appreciations, or overlap as much. They laugh more, and use more sexual and negative emotional words. Prosodically they speak faster, with higher and more variable pitch, but quieter (lower intensity max).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "\u2022 The strongest features for women who are labeled as flirting are prosodic; they speak faster and louder with higher and more variable pitch. They also use more words in general, swear more, don't ask questions or use Assent, use more I, laugh more, and are somewhat more disfluent (restarts).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "\u2022 Men who are labeled as awkward are more disfluent, with increased restarts and filled pauses (uh and um). They are also not 'collaborative' conversationalists; they don't use appreciations, repair questions, collaborative completions, past-tense, or you, take fewer turns overall, and don't overlap. Prosodically the awkward labels are hard to characterize; there is both an increase in pitch variation (f0 sd sd) and a decrease (f0 mean sd). They don't seem to get quite as loud (intensity max).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "The previous analysis showed what features of the ego help in classification. We next asked about features of the alter, based on the results using both ego and alter features in the second row of Table 5 . Here we are asking about the linguistic behaviors of a speaker who describes the interlocutor as flirting, friendly, or awkward.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 203,
                        "end": 204,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "While we don't show these values in a table, we offer here an overview of their tendencies. For example for women who labeled their male interlocutors as friendly, the women got much quieter, used 'well' much more, laughed, asked more repair questions, used collaborative completions, and backchanneled more. When a man labeled a woman as friendly, he used an expanded intensity range (quieter intensity min, louder intensity max). laughed more, used more sexual terms, used less negative emotional terms, and overlapped more.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "When women labeled their male interlocutor as flirting, the women used many more repair questions, laughed more, and got quieter (lower intensity min). By contrast, when a man said his female interlocutor was flirting, he used more Insight and Anger words, and raised his pitch.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "When women labeled their male interlocutor as awkward, the women asked a lot of questions, used well, were disfluent (restarts), had a diminished pitch range, and didn't use I. In listening to some of these conversations, it was clear that the conversation lagged repeatedly, and the women used questions at these points to restart the conversations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "6"
            },
            {
                "text": "The results presented here should be regarded with some caution. The sample is not a random sample of English speakers or American adults, and speed dating is not a natural context for expressing every conversational style. Therefore, a wider array of studies across populations and genres would be required before a more general theory of conversational styles is established.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "On the other hand, the presented results may under-reflect the relations being captured. The quality of recordings and coarse granularity (1 second) of the time-stamps likely cloud the relations, and as the data is cleaned and improved, we expect the associations to only grow stronger.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "Caveats aside, we believe the evidence indicates that the perception of several types of conversational style have relatively clear signals across genders, but with some additional gender contextualization.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "Both genders convey flirtation by laughing more, speaking faster, and using higher and more variable pitch. Both genders convey friendliness by laughing more, and using collaborative completions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "However, we do find gender differences; men asl more questions when (labeled as) flirting, women ask fewer. Men labeled as flirting are softer, but women labeled as flirting are louder. Women flirt-ing swear more, while men are more likely to use sexual vocabulary. Gender differences exist as well for the other variables. Men labeled as friendly use you while women labeled as friendly use I. Friendly women are very disfluent; friendly men are not.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "While the features for friendly and flirtatious speech overlap, there are clear differences. Men speaker faster and with higher f0 (min) in flirtatious speech, but not faster and with lower f0 (min) in friendly speech. For men, flirtatious speech involves more questions and repair questions, while friendly speech does not. For women, friendly speech is more disfluent than flirtatious speech, and has more collaborative style (completions, repair questions, appreciations) .",
                "cite_spans": [
                    {
                        "start": 428,
                        "end": 474,
                        "text": "(completions, repair questions, appreciations)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "We also seem to see a model of collaborative conversational style (probably related to the collaborative floor of Edelsky (1981) and Coates (1996) ), cued by the use of more collaborative completions, repair questions and other questions, you, and laughter. These collaborative techniques were used by both women and men who were labeled as friendly, and occurred less with men labeled as awkward. Women themselves displayed more of this collaborative conversational style when they labeled the men as friendly. For women only, collaborative style included appreciations; while for men only, collaborative style included overlaps.",
                "cite_spans": [
                    {
                        "start": 114,
                        "end": 128,
                        "text": "Edelsky (1981)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 133,
                        "end": 146,
                        "text": "Coates (1996)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "In addition to these implications for social science, our work has implications for the extraction of meaning in general. A key focus of our work was on ways to extract useful dialog act and disfluency features (repair questions, backchannels, appreciations, restarts, dispreferreds) with very shallow methods. These features were indeed extractable and proved to be useful features in classification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "We are currently extending these results to predict date outcomes including 'liking', extending work such as Madan and Pentland (2006) .",
                "cite_spans": [
                    {
                        "start": 109,
                        "end": 134,
                        "text": "Madan and Pentland (2006)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "7"
            },
            {
                "text": "interpolated, with Good Turing smoothing, trained on the Treebank 3 Switchboard transcripts after stripping punctuation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We also performed a t-test to find salient feature values significantly different than zero; the non-zero median method turned out to be a more conservative measure in practice (intuitively, because L1 normed regression pushes weights to 0).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Thanks to three anonymous reviewers, Sonal Nalkur and Tanzeem Choudhury for assistance and advice on data collection, Sandy Pentland for a helpful discussion about feature extraction, and to Google for gift funding.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Prosody-Based Automatic Detection of Annoyance and Frustration in Human-Computer Dialog",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Ang",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Dhillon",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Krupski",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Shriberg",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Stolcke",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Ang, R. Dhillon, A. Krupski, E. Shriberg, and A. Stol- cke. 2002. Prosody-Based Automatic Detection of Annoyance and Frustration in Human-Computer Dia- log. In INTERSPEECH-02.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Praat: doing phonetics by computer",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Boersma",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Weenink",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "P. Boersma and D. Weenink. 2005. Praat: doing pho- netics by computer (version 4.3.14). [Computer pro- gram]. Retrieved May 26, 2005, from http://www. praat.org/.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Computers that care: Investigating the effects of orientation of emotion exhibited by an embodied conversational agent",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Brave",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Nass",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Hutchinson",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "International Journal of Human-Computer Studies",
                "volume": "62",
                "issue": "2",
                "pages": "161--178",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Brave, C. Nass, and K. Hutchinson. 2005. Comput- ers that care: Investigating the effects of orientation of emotion exhibited by an embodied conversational agent. International Journal of Human-Computer Studies, 62(2):161-178.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "How listeners compensate for disfluencies in spontaneous speech",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "E"
                        ],
                        "last": "Brennan",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [
                            "F"
                        ],
                        "last": "Schober",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Journal of Memory and Language",
                "volume": "44",
                "issue": "",
                "pages": "274--296",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. E. Brennan and M. F. Schober. 2001. How listen- ers compensate for disfluencies in spontaneous speech. Journal of Memory and Language, 44:274-296.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "The feeling of another's knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "E"
                        ],
                        "last": "Brennan",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Journal of Memory and Language",
                "volume": "34",
                "issue": "",
                "pages": "383--398",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. E. Brennan and M. Williams. 1995. The feeling of another's knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers. Journal of Memory and Language, 34:383-398.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Linguistic markers of psychological change surrounding September 11",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "A"
                        ],
                        "last": "Cohn",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [
                            "R"
                        ],
                        "last": "Mehl",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "W"
                        ],
                        "last": "Pennebaker",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Psychological Science",
                "volume": "15",
                "issue": "",
                "pages": "687--693",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. A. Cohn, M. R. Mehl, and J. W. Pennebaker. 2004. Linguistic markers of psychological change surround- ing September 11, 2001. Psychological Science, 15:687-693.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Who's got the floor?",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Edelsky",
                        "suffix": ""
                    }
                ],
                "year": 1981,
                "venue": "Language in Society",
                "volume": "10",
                "issue": "",
                "pages": "383--421",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Edelsky. 1981. Who's got the floor? Language in Society, 10:383-421.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Detecting Deception Using Critical Segments",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Enos",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Shriberg",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Graciarena",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Hirschberg",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Stolcke",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Enos, E. Shriberg, M. Graciarena, J. Hirschberg, and A. Stolcke. 2007. Detecting Deception Using Critical Segments. In INTERSPEECH-07.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Switchboard SWBD-DAMSL Labeling Project Coder's Manual, Draft 13",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Shriberg",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Biasca",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. Jurafsky, E. Shriberg, and D. Biasca. 1997. Switch- board SWBD-DAMSL Labeling Project Coder's Man- ual, Draft 13. Technical Report 97-02, University of Colorado Institute of Cognitive Science.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Lexical, prosodic, and syntactic cues for dialog acts",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Shriberg",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Fox",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Curl",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Proceedings, COLING-ACL Workshop on Discourse Relations and Discourse Markers",
                "volume": "",
                "issue": "",
                "pages": "114--120",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. Jurafsky, E. Shriberg, B. Fox, and T. Curl. 1998. Lex- ical, prosodic, and syntactic cues for dialog acts. In Proceedings, COLING-ACL Workshop on Discourse Relations and Discourse Markers, pages 114-120.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Pragmatics and computational linguistics",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. Jurafsky. 2001. Pragmatics and computational lin- guistics. In L. R. Horn and G. Ward, editors, Hand- book of Pragmatics. Blackwell.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Combining acoustic and language information for emotion recognition",
                "authors": [
                    {
                        "first": "C",
                        "middle": [
                            "M"
                        ],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [
                            "S"
                        ],
                        "last": "Narayanan",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "873--876",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. M. Lee and S. S. Narayanan. 2002. Combining acous- tic and language information for emotion recognition. In ICSLP-02, pages 873-876, Denver, CO.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "On the syntax of sentences-inprogress",
                "authors": [
                    {
                        "first": "G",
                        "middle": [
                            "H"
                        ],
                        "last": "Lerner",
                        "suffix": ""
                    }
                ],
                "year": 1991,
                "venue": "Language in Society",
                "volume": "20",
                "issue": "3",
                "pages": "441--458",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. H. Lerner. 1991. On the syntax of sentences-in- progress. Language in Society, 20(3):441-458.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "On the \"semi-permeable\" character of grammatical units in conversation: Conditional entry into the turn space of another speaker",
                "authors": [
                    {
                        "first": "G",
                        "middle": [
                            "H"
                        ],
                        "last": "Lerner",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Interaction and Grammar",
                "volume": "",
                "issue": "",
                "pages": "238--276",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. H. Lerner. 1996. On the \"semi-permeable\" character of grammatical units in conversation: Conditional en- try into the turn space of another speaker. In E. Ochs, E. A. Schegloff, and S. A. Thompson, editors, Interac- tion and Grammar, pages 238-276. Cambridge Uni- versity Press.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Classifying Subject Ratings of Emotional Speech Using Acoustic Features",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Liscombe",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Venditti",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Hirschberg",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Liscombe, J. Venditti, and J. Hirschberg. 2003. Clas- sifying Subject Ratings of Emotional Speech Using Acoustic Features. In INTERSPEECH-03.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Vibefones: Socially aware mobile phones",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Madan",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Pentland",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Tenth IEEE International Symposium on Wearable Computers",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Madan and A. Pentland. 2006. Vibefones: Socially aware mobile phones. In Tenth IEEE International Symposium on Wearable Computers.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Voices of attraction. Presented at Augmented Cognition, HCI",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Madan",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Caneel",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Pentland",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Madan, R. Caneel, and A. Pentland. 2005. Voices of attraction. Presented at Augmented Cognition, HCI 2005, Las Vegas.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Trainable generation of big-five personality styles through data-driven parameter estimation",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Mairesse",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Walker",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "ACL-08",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Mairesse and M. Walker. 2008. Trainable generation of big-five personality styles through data-driven pa- rameter estimation. In ACL-08, Columbus.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Using linguistic cues for the automatic recognition of personality in conversation and text",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Mairesse",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Walker",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Mehl",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Moore",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Journal of Artificial Intelligence Research (JAIR)",
                "volume": "30",
                "issue": "",
                "pages": "457--500",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Mairesse, M. Walker, M. Mehl, and R. Moore. 2007. Using linguistic cues for the automatic recognition of personality in conversation and text. Journal of Artifi- cial Intelligence Research (JAIR), 30:457-500.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Wired for speech: How voice activates and advances the human-computer relationship",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Nass",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Brave",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Nass and S. Brave. 2005. Wired for speech: How voice activates and advances the human-computer re- lationship. MIT Press, Cambridge, MA.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Lying words: Predicting deception from linguistic style",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "L"
                        ],
                        "last": "Newman",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "W"
                        ],
                        "last": "Pennebaker",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [
                            "S"
                        ],
                        "last": "Berry",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "M"
                        ],
                        "last": "Richards",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Personality and Social Psychology Bulletin",
                "volume": "29",
                "issue": "",
                "pages": "665--675",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. L. Newman, J. W. Pennebaker, D. S. Berry, and J. M. Richards. 2003. Lying words: Predicting deception from linguistic style. Personality and Social Psychol- ogy Bulletin, 29:665-675.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Feature selection, L1 vs. L2 regularization, and rotational invariance",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "Y"
                        ],
                        "last": "Ng",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Y. Ng. 2004. Feature selection, L1 vs. L2 regulariza- tion, and rotational invariance. In ICML 2004.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Language use and personality during crises: Analyses of Mayor Rudolph Giuliani's press conferences",
                "authors": [
                    {
                        "first": "J",
                        "middle": [
                            "W"
                        ],
                        "last": "Pennebaker",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [
                            "C"
                        ],
                        "last": "Lay",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Journal of Research in Personality",
                "volume": "36",
                "issue": "",
                "pages": "271--282",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. W. Pennebaker and T. C. Lay. 2002. Language use and personality during crises: Analyses of Mayor Rudolph Giuliani's press conferences. Journal of Research in Personality, 36:271-282.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Linguistic inquiry and word count: LIWC2007 operator's manual",
                "authors": [
                    {
                        "first": "J",
                        "middle": [
                            "W"
                        ],
                        "last": "Pennebaker",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Booth",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Francis",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. W. Pennebaker, R. Booth, and M. Francis. 2007. Lin- guistic inquiry and word count: LIWC2007 operator's manual. Technical report, University of Texas.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Socially aware computation and communication",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Pentland",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Computer",
                "volume": "",
                "issue": "",
                "pages": "63--70",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Pentland. 2005. Socially aware computation and communication. Computer, pages 63-70.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Agreeing and disagreeing with assessment: Some features of preferred/dispreferred turn shapes",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "M"
                        ],
                        "last": "Pomerantz",
                        "suffix": ""
                    }
                ],
                "year": 1984,
                "venue": "editors, Structure of Social Action: Studies in Conversation Analysis",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. M. Pomerantz. 1984. Agreeing and disagreeing with assessment: Some features of preferred/dispreferred turn shapes. In J. M. Atkinson and J. Heritage, edi- tors, Structure of Social Action: Studies in Conversa- tion Analysis. Cambridge University Press.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Acoustic/prosodic and lexical correlates of charismatic speech",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Rosenberg",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Hirschberg",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "EUROSPEECH-05",
                "volume": "",
                "issue": "",
                "pages": "513--516",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Rosenberg and J. Hirschberg. 2005. Acous- tic/prosodic and lexical correlates of charismatic speech. In EUROSPEECH-05, pages 513-516, Lis- bon, Portugal.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Language use of depressed and depression-vulnerable college students",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "S"
                        ],
                        "last": "Rude",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [
                            "M"
                        ],
                        "last": "Gortner",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "W"
                        ],
                        "last": "Pennebaker",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Cognition and Emotion",
                "volume": "18",
                "issue": "",
                "pages": "1121--1133",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. S. Rude, E. M. Gortner, and J. W. Pennebaker. 2004. Language use of depressed and depression-vulnerable college students. Cognition and Emotion, 18:1121- 1133.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "A simplest systematics for the organization of turntaking for conversation",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Sacks",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [
                            "A"
                        ],
                        "last": "Schegloff",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Jefferson",
                        "suffix": ""
                    }
                ],
                "year": 1974,
                "venue": "Language",
                "volume": "50",
                "issue": "4",
                "pages": "696--735",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Sacks, E. A. Schegloff, and G. Jefferson. 1974. A simplest systematics for the organization of turn- taking for conversation. Language, 50(4):696-735.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "The preference for self-correction in the organization of repair in conversation",
                "authors": [
                    {
                        "first": "E",
                        "middle": [
                            "A"
                        ],
                        "last": "Schegloff",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Jefferson",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Sacks",
                        "suffix": ""
                    }
                ],
                "year": 1977,
                "venue": "Language",
                "volume": "53",
                "issue": "",
                "pages": "361--382",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "E. A. Schegloff, G. Jefferson, and H. Sacks. 1977. The preference for self-correction in the organization of re- pair in conversation. Language, 53:361-382.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "APPRECIATIONS number of appreciations in side (Wow, That's true, Oh, great) QUESTIONS number of questions in side NTRI repair question (Next Turn Repair Indicator) (Wait, Excuse me) COMPLETION (an approximation to) utterances that were 'collaborative completions' DISPREFERRED (an approximation to) dispreferred responses, beginning with discourse marker well LAUGH number of instances of laughter in side TURNS total number of turns in side",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 1: An illustrative boxplot for flirtation in men showing the 10 most significant features and one not significant ('I'). Shown are median values (central red line), first quartile, third quartile, outliers (red X's) and interquartile range (filled box).",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>F0 MIN F0 MIN SD F0 MAX F0 MAX SD F0 MEAN F0 MEAN SD F0 SD F0 SD SD PITCH RANGE PITCH RANGE SD RMS MIN RMS MIN SD RMS MAX RMS MAX SD RMS MEAN RMS MEAN SD standard deviation from RMS mean minimum (non-zero) F0 per turn, av-eraged over turns standard deviation from F0 min maximum F0 per turn, averaged over turns standard deviation from F0 max mean F0 per turn, averaged over turns standard deviation (across turns) from F0 mean standard deviation (within a turn) from F0 mean, averaged over turns standard deviation from the f0 sd f0 max -f0 min per turn, averaged over turns standard deviation from mean pitch range minimum amplitude per turn, aver-aged over turns standard deviation from RMS min maximum amplitude per turn, aver-aged over turns standard deviation from RMS max mean amplitude per turn, averaged over turns TURN DUR duration of turn in seconds, averaged over turns TIME total time for a speaker for a conversa-tion side, in seconds RATE OF SPEECH number of words in turn divided by duration of turn in seconds, averaged over turns</td></tr></table>",
                "type_str": "table",
                "text": "Prosodic features for each conversation side, extracted using Praat from the hand-segmented turns of each side.",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>TOTAL WORDS</td><td>total number of words</td></tr><tr><td>PAST TENSE</td><td/></tr><tr><td colspan=\"2\">yeah, okay, cool, yes, awesome, absolutely, agree hell, sucks, damn, crap, shit, screw, heck, fuck* think*/thought, feel*/felt, find/found, understand*, figure*, idea*, imagine, wonder hate/hated, hell, ridiculous*, stupid, kill*, screwed, blame, sucks, mad, bother, shit NEGEMOTION bad, weird, hate, crazy, problem*, difficult, tough, awkward, boring, wrong, sad, worry, ASSENT SWEAR INSIGHT ANGER love*, passion*, loves, virgin, sex, screw SEXUAL INGEST food, eat*, water, bar/bars, drink*, cook*, dinner, coffee, wine, beer, restaurant, lunch, dish</td></tr></table>",
                "type_str": "table",
                "text": "of past tense auxiliaries was, were, had METADATE horn, date, bell, survey, speed, form, questionnaire, rushed, study, research YOU you, you'd, you'll, your, you're, yours, you've (not counting you know) WE lets, let's, our, ours, ourselves, us, we, we'd, we'll, we're, we've I I'd, I'll, I'm, I've, me, mine, my, myself (not counting I mean) Lexical features.Each feature value is a total count of the words in that class for each conversation side; asterisks indicate that suffixed forms were included (e.g., love, loves, loving). All except the first three are from LIWC(Pennebaker et al., 2007) (modified slightly, for example by removing you know and I mean). The last five classes include more words in addition to those shown.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>UH/UM</td><td>total number of filled pauses (uh or</td></tr><tr><td/><td>um) in conversation side</td></tr><tr><td>RESTART</td><td>total number of disfluent restarts in</td></tr><tr><td/><td>conversation side</td></tr><tr><td colspan=\"2\">OVERLAP number of turns in side which the two</td></tr><tr><td/><td>speakers overlapped</td></tr></table>",
                "type_str": "table",
                "text": "Dialog act/adjacency pair features.in Table4. Filled pauses (um, uh) were coded by",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Disfluency features",
                "html": null,
                "num": null
            }
        }
    }
}