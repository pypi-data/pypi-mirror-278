{
    "paper_id": "N18-1108",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:31:31.213288Z"
    },
    "title": "Colorless green recurrent networks dream hierarchically",
    "authors": [
        {
            "first": "Kristina",
            "middle": [],
            "last": "Gulordava",
            "suffix": "",
            "affiliation": {},
            "email": "kristina.gulordava@unige.ch"
        },
        {
            "first": "Piotr",
            "middle": [],
            "last": "Bojanowski",
            "suffix": "",
            "affiliation": {},
            "email": "bojanowski@fb.com"
        },
        {
            "first": "Edouard",
            "middle": [],
            "last": "Grave",
            "suffix": "",
            "affiliation": {},
            "email": "egrave@fb.com"
        },
        {
            "first": "Tal",
            "middle": [],
            "last": "Linzen",
            "suffix": "",
            "affiliation": {},
            "email": "tal.linzen@jhu.edu"
        },
        {
            "first": "Marco",
            "middle": [],
            "last": "Baroni",
            "suffix": "",
            "affiliation": {},
            "email": "mbaroni@fb.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Recurrent neural networks (RNNs) have achieved impressive results in a variety of linguistic processing tasks, suggesting that they can induce non-trivial properties of language. We investigate here to what extent RNNs learn to track abstract hierarchical syntactic structure. We test whether RNNs trained with a generic language modeling objective in four languages (Italian, English, Hebrew, Russian) can predict long-distance number agreement in various constructions. We include in our evaluation nonsensical sentences where RNNs cannot rely on semantic or lexical cues (\"The colorless green ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas I ate with the chair sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep furiously\"), and, for Italian, we compare model performance to human intuitions.\nOur language-model-trained RNNs make reliable predictions about long-distance agreement, and do not lag much behind human performance. We thus bring support to the hypothesis that RNNs are not just shallowpattern extractors, but they also acquire deeper grammatical competence.",
    "pdf_parse": {
        "paper_id": "N18-1108",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Recurrent neural networks (RNNs) have achieved impressive results in a variety of linguistic processing tasks, suggesting that they can induce non-trivial properties of language. We investigate here to what extent RNNs learn to track abstract hierarchical syntactic structure. We test whether RNNs trained with a generic language modeling objective in four languages (Italian, English, Hebrew, Russian) can predict long-distance number agreement in various constructions. We include in our evaluation nonsensical sentences where RNNs cannot rely on semantic or lexical cues (\"The colorless green ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas ideas I ate with the chair sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep sleep furiously\"), and, for Italian, we compare model performance to human intuitions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "Our language-model-trained RNNs make reliable predictions about long-distance agreement, and do not lag much behind human performance. We thus bring support to the hypothesis that RNNs are not just shallowpattern extractors, but they also acquire deeper grammatical competence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Recurrent neural networks (RNNs; Elman, 1990) are general sequence processing devices that do not explicitly encode the hierarchical structure that is thought to be essential to natural language (Everaert et al., 2015) . Early work using artificial languages showed that they may nevertheless be able to approximate context-free languages (Elman, 1991) . More recently, RNNs have achieved impressive results in large-scale tasks such as language modeling for speech recognition and machine translation, and are by now standard tools for sequential natural language tasks (e.g., Mikolov et al., 2010; Graves, 2012; Wu et al., 2016) . This suggests that RNNs may learn to track grammatical structure even when trained on noisier natural data. The conjecture is supported by the success of RNNs as feature extractors for syntactic parsing (e.g., Cross and Huang, 2016; Kiperwasser and Goldberg, 2016; Zhang et al., 2017) . Linzen et al. (2016) directly evaluated the extent to which RNNs can approximate hierarchical structure in corpus-extracted natural language data. They tested whether RNNs can learn to predict English subject-verb agreement, a task thought to require hierarchical structure in the general case (\"the girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl the boys like. Their experiments confirmed that RNNs can, in principle, handle such constructions. However, in their study RNNs could only succeed when provided with explicit supervision on the target task. Linzen and colleagues argued that the unsupervised language modeling objective is not sufficient for RNNs to induce the syntactic knowledge necessary to cope with long-distance agreement.",
                "cite_spans": [
                    {
                        "start": 33,
                        "end": 45,
                        "text": "Elman, 1990)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 195,
                        "end": 218,
                        "text": "(Everaert et al., 2015)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 339,
                        "end": 352,
                        "text": "(Elman, 1991)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 578,
                        "end": 599,
                        "text": "Mikolov et al., 2010;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 600,
                        "end": 613,
                        "text": "Graves, 2012;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 614,
                        "end": 630,
                        "text": "Wu et al., 2016)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 843,
                        "end": 865,
                        "text": "Cross and Huang, 2016;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 866,
                        "end": 897,
                        "text": "Kiperwasser and Goldberg, 2016;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 898,
                        "end": 917,
                        "text": "Zhang et al., 2017)",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 920,
                        "end": 940,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": ". . is is is is is is is is is is is is is is is is is",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The current paper reevaluates these conclusions. We strengthen the evaluation paradigm of Linzen and colleagues in several ways. Most importantly, their analysis did not rule out the possibility that RNNs might be relying on semantic or collocational/frequency-based information, rather than purely on syntactic structure. In \"dogs dogs dogs dogs dogs about what typically barks (dogs, not neighbourhoods), without relying on more abstract structural cues. In a follow-up study to Linzen and colleagues', Bernardy and Lappin (2017) observed that RNNs are better at long-distance agreement when they construct rich lexical representations of words, which suggests effects of this sort might indeed be at play.",
                "cite_spans": [
                    {
                        "start": 505,
                        "end": 531,
                        "text": "Bernardy and Lappin (2017)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We introduce a method to probe the syntactic abilities of RNNs that abstracts away from potential lexical, semantic and frequency-based confounds. Inspired by Chomsky's (1957) We extend the previous work in three additional ways. First, alongside English, which has few morphological cues to agreement, we examine Italian, Hebrew and Russian, which have richer morphological systems. Second, we go beyond subject-verb agreement and develop an automated method to harvest a variety of long-distance number agreement constructions from treebanks. Finally, for Italian, we collect human judgments for the tested sentences, providing an important comparison point for RNN performance. 1We focus on the more interesting unsupervised setup, where RNNs are trained to perform generic, large-scale language modeling (LM): they are not given explicit evidence, at training time, that they must focus on long-distance agreement, but they are rather required to track a multitude of cues that might help with word prediction in general.",
                "cite_spans": [
                    {
                        "start": 159,
                        "end": 175,
                        "text": "Chomsky's (1957)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our results are encouraging. RNNs trained with a LM objective solve the long-distance agreement problem well, even on nonce sentences. The pattern is consistent across languages, and, crucially, not far from human performance in Italian. Moreover, RNN performance on language modeling (measured in terms of perplexity) is a good predictor of long-distance agreement accuracy. This suggests that the ability to capture structural generalizations is an important aspect of what makes the best RNN architectures so good at language modeling. Since our positive results contradict, to some extent, those of Linzen et al. (2016) , we also replicate their relevant experiment using our best RNN (an LSTM). We outperform their models, suggesting that a careful architecture/hyperparameter search is crucial to obtain RNNs that are not only good at language modeling, but able to extract syntactic generalizations.",
                "cite_spans": [
                    {
                        "start": 603,
                        "end": 623,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2 Constructing a long-distance agreement benchmark",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Overview. We construct our number agreement test sets as follows. Original sentences are automatically extracted from a dependency treebank.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "They are then converted into nonce sentences by substituting all content words with random words with the same morphology, resulting in grammatical but nonsensical sequences. An LM is evaluated on its predictions for the target (second) word in the dependency, in both the original and nonce sentences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Long-distance agreement constructions. Agreement relations, such as subject-verb agreement in English, are an ideal test bed for the syntactic abilities of LMs, because the form of the second item (the target) is predictable from the first item (the cue). Crucially, the cue and the target are linked by a structural relation, where linear order in the word sequence does not matter (Everaert et al., 2015) In all these cases, the number of the main verb \"thinks\" is determined by its subject (\"girl\"), and this relation depends on the syntactic structure of the sentence, not on the linear sequence of words. As the last sentence shows, the word directly preceding the verb can even be a noun with the opposite number (\"friends\"), but this does not influence the structurally-determined form of the verb.",
                "cite_spans": [
                    {
                        "start": 383,
                        "end": 406,
                        "text": "(Everaert et al., 2015)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "When the cue and the target are adjacent (\"the girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl girl thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks thinks. . . \"), an LM can predict the target without access to syntactic structure: it can simply extract the relevant morphosyntactic features of words (e.g., number) and record the co-occurrence frequencies of patterns such as N P lur V P lur (Mikolov et al., 2013) . Thus, we focus here on long-distance agreement, where an arbitrary num- ber of words can occur between the elements of the agreement relation. We limit ourselves to number agreement (plural or singular), as it is the only overt agreement feature shared by all of the languages we study.",
                "cite_spans": [
                    {
                        "start": 489,
                        "end": 511,
                        "text": "(Mikolov et al., 2013)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Identifying candidate constructions. We started by collecting pairs of part-of-speech (POS) tags connected by a dependency arc. Independently of which element is the head of the relation, we refer to the first item as the cue and to the second as the target. We additionally refer to the POS sequence characterizing the entire pattern as a construction, and to the elements in the middle as context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "For each candidate construction, we collected all of the contexts in the corpus that intervene between the cue and the target (we define contexts as the sequence of POS tags of the top-level nodes in the dependency subtrees). For example, for the English subject-verb agreement construction shown in Fig. 1a , the context is defined by VERB (head of the relative clause) and ADV (adverbial modifier of the target verb), which together dominate the sequence \"the boys like often\". For the Russian adjective-noun agreement construction in Fig. 1b , the context is NOUN, because in the dependency grammar we use the noun \"moment\" is the head of the prepositional phrase \"at that moment\", which modifies the adjective \"deep\". The candidate agreement pair and the context form a construction, which is characterized by a sequence of POS tags, e.g., NOUN VERB ADV VERB or VERB NOUN CCONJ VERB (Fig. 1c ). ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 305,
                        "end": 307,
                        "text": "1a",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 542,
                        "end": 544,
                        "text": "1b",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 893,
                        "end": 895,
                        "text": "1c",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "is is is is is is is is is is is is is is is is is\"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "and \"girls girls girls girls girls girls girls girls girls girls girls girls girls girls girls girls girls who stayed at home were were were were were were were were were were were were were were were were were\". Conversely, standard syntactic structures might be split between different constructions, e.g., relative clause contexts occur in both NOUN VERB VERB and NOUN VERB ADV VERB constructions (the latter is illustrated by the English example in Fig. 1a ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 458,
                        "end": 460,
                        "text": "1a",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Construction contexts can contain a variable numbers of words. Since we are interested in challenging cases, we only considered cases in which at least three tokens intervened between the cue and the target.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Excluding non-agreement constructions. In the next step, we excluded constructions in which the candidate cue and target did not agree in number in all of the instances of the construction in the treebank (if both the cue and the target were morphologically annotated for number). This step retained English subject-verb constructions, for example, but excluded verb-object constructions, since any form of a verb can appear both with singular and plural objects. To focus on robust agreement patterns, we only kept constructions with at least 10 instances of both plural and singular agreement.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "When applied to the treebanks we used (see Section 3), this step resulted in between two (English) and 21 (Russian) constructions per lan-guage. English has the poorest morphology and consequently the lowest number of patterns with identifiable morphological agreement. Only the VP-conjunction construction (Fig. 1c ) was identified in all four languages. Subject-verb agreement constructions were extracted in all languages but Russian; Russian has relatively flexible word order and a noun dependent preceding a head verb is not necessarily its subject. The full list of extracted constructions in English and Italian is given in Tables 2 and 3, respectively. For the other languages, see the Supplementary Material (SM). 2",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 313,
                        "end": 315,
                        "text": "1c",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Original sentence test set. Our \"original\" sentence test set included all sentences from each construction where all words from the cue and up to and including the target occurred in the LM vocabulary (Section 3), and where the singular/plural counterpart of the target occurred in the treebank and in the language model vocabulary (this is required by the evaluation procedure outlined below). The total counts of constructions and original sentences in our test sets are provided in Table 1. The average number of context words separating the cue and the target ranged from 3.6 (Hebrew) to 4.5 (Italian).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Generating nonce sentences. We generated nine nonce variants of each original sentence as follows. Each content word (noun, verb, adjective, proper noun, numeral, adverb) in the sentence was substituted by another random content word from the treebank with matching POS and morphological features. To avoid forms that are ambiguous between several POS, which are particularly frequent in English (e.g., plural noun and singular verb forms), we excluded the forms that appeared with a different POS more than 10% of the time in the treebank. Function words (determiners, pronouns, adpositions, particles) and punctuation were left intact. For example, we generated the nonce (1b) from the original sentence (1a):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "( (e.g., \"it stays the shuttle\" in (1b)).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Evaluation procedure. For each sentence in our test set, we retrieved from our treebank the form that is identical to the agreement target in all morphological features except number (e.g., \"finds\" instead of \"find\" in (1b)). Given a sentence with prefix p up to and excluding the target, we then compute the probabilities P (t 1 |p) and P (t 2 |p) for the singular and plural variants of the target, t 1 and t 2 , based on the language model. Following Linzen et al. (2016) , we say that the model identified the correct target if it assigned a higher probability to the form with the correct number. In (1b), for example, the model should assign a higher probability to \"finds\" than \"find\".3 3 Experimental setup Treebanks. We extracted our test sets from the Italian, English, Hebrew and Russian Universal Dependency treebanks (UD, v2.0, Nivre et al., 2016) . The English and Hebrew treebanks were post-processed to obtain a richer morphological annotation at the word level (see SM for details).",
                "cite_spans": [
                    {
                        "start": 454,
                        "end": 474,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 841,
                        "end": 860,
                        "text": "Nivre et al., 2016)",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Training data for Italian, English and Russian were extracted from the respective Wikipedias. We downloaded recent dumps, extracted the raw text from them using WikiExtractor4 and tokenized it with TreeTagger (Schmid, 1995) . We also used the TreeTagger lemma annotation to filter out sentences with more than 5% unknown words. For Hebrew, we used the preprocessed Wikipedia corpus made available by Yoav Goldberg. 5 We extracted 90M token subsets for each language, shuffled them by sentence and split them into training and validation sets (8-to-1 proportion). For LM training, we included the 50K most frequent words in each corpus in the vocabulary, replacing the other tokens with the UNK symbol. The validation set perplexity values we report below exclude unknown tokens.",
                "cite_spans": [
                    {
                        "start": 209,
                        "end": 223,
                        "text": "(Schmid, 1995)",
                        "ref_id": "BIBREF36"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LM training data.",
                "sec_num": null
            },
            {
                "text": "RNN language models. We experimented with simple RNNs (sRNNs, Elman, 1990) , and their most successful variant, long-short term memory models (LSTMs, Hochreiter and Schmidhu-ber, 1997) . We use the PyTorch RNN implementation. 6 We trained the models with two hidden layer dimensionalities (650 and 200 units), and a range of batch sizes, learning rates and dropout rates. See SM for details on hyperparameter tuning. In general, a larger hidden layer size was the best predictor of lower perplexity. Given that our LSTMs outperformed our sRNNs, our discussion of the results will focus on the former; we will use the terms LSTM and RNN interchangeably.7 ",
                "cite_spans": [
                    {
                        "start": 62,
                        "end": 74,
                        "text": "Elman, 1990)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 150,
                        "end": 184,
                        "text": "Hochreiter and Schmidhu-ber, 1997)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LM training data.",
                "sec_num": null
            },
            {
                "text": "Baselines. We consider three baselines: first, a unigram baseline, which picks the most frequent form in the training corpus out of the two candidate target forms (singular or plural); second, a 5-gram model with Kneser-Ney smoothing (KN, Kneser and Ney, 1995) trained using the IRSTLM package (Federico et al., 2008) and queried using KenLM (Heafield, 2011) ; and third, a 5-gram LSTM, which only had access to windows of five tokens (Chelba et al., 2017) . Compared to KN, the 5-gram LSTM can generalize to unseen ngrams thanks to its embedding layer and recurrent connections. However, it cannot discover longdistance dependency patterns that span more than five words. See SM for details on the hyperparameters of this baseline.",
                "cite_spans": [
                    {
                        "start": 239,
                        "end": 260,
                        "text": "Kneser and Ney, 1995)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 294,
                        "end": 317,
                        "text": "(Federico et al., 2008)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 342,
                        "end": 358,
                        "text": "(Heafield, 2011)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 435,
                        "end": 456,
                        "text": "(Chelba et al., 2017)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LM training data.",
                "sec_num": null
            },
            {
                "text": "Human experiment in Italian. We presented the full Italian test set (119 original and 1071 nonce sentences) to human subjects through the Amazon Mechanical Turk interface. 8 We picked Italian because, being morphologically richer, it features more varied long-distance constructions than English. Subjects were requested to be native Italian speakers. They were presented with a sentence up to and excluding the target. The singular and plural forms of the target were presented below the sentence (in random order), and subjects were asked to select the more plausible form.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LM training data.",
                "sec_num": null
            },
            {
                "text": "To prevent long-distance agreement patterns from being too salient, we mixed the test set with the same number of filler sentences. We started from original fillers, which were random treebankextracted sentences up to a content word in singular or plural form. We then generated nonce fillers from the original ones using the procedure outlined in Section 2. A control subset of 688 fillers was manually selected by a linguistically-trained Italian native speaker as unambiguous cases. To make sure we were only using data from native (or at least highly proficient) Italian speakers, we filtered out the responses of subjects who chose the wrong target in more than 20% of the fillers. We collected on average 9.5 judgments for each item (minimum 5 judgments). To account for the variable number of judgments across sentences, accuracy rates were first calculated within each sentence and then averaged across sentences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LM training data.",
                "sec_num": null
            },
            {
                "text": "The overall results are reported in Table 1 . We report results averaged across the five models with the lowest validation perplexity, as well as standard deviations across these models. In summary, Table 2 : LSTM accuracy in the constructions N V V (subject-verb agreement with an intervening embedded clause) and V NP conj V (agreement between conjoined verbs separated by a complement of the first verb).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 42,
                        "end": 43,
                        "text": "1",
                        "ref_id": null
                    },
                    {
                        "start": 205,
                        "end": 206,
                        "text": "2",
                        "ref_id": "TABREF7"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "N V V V NP conj V",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "the LSTM clearly outperformed the other LMs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Rather surprisingly, its performance on nonce sentences was only moderately lower than on original ones; in Italian this gap was only 6.6%.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "The KN LM performed poorly; its accuracy on nonce sentences was comparable to that of the unigram baseline. This confirms that the number of the target in nonce sentences cannot be captured by shallow n-gram patterns. The 5-gram LSTM model greatly improved over the KN baseline; its accuracy dropped only modestly between the original and nonce sentences, demonstrating its syntactic generalization ability. Still, the results are substantially below those of the LSTM with unlimited history. This confirms that our test set contains hard long-distance agreement dependencies, and, more importantly, that the more general LSTM model can exploit broader contexts to learn about and track long-distance syntactic relations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "The increase in accuracy scores across the three LMs (KN, 5-gram LSTM and unbounded-context LSTM) correlates well with their validation perplexities in the language modeling task. We also found a strong correlation between agreement accuracy and validation perplexity across all the LSTM variants we explored in the hyperparameter search (68 models per language), with Pearson correlation coefficients ranging from r = -0.55 in Hebrew to r = -0.78 in English (p < 0.001 in all languages). This suggests that acquiring abstract syntactic competence is a natural component of the skills that improve the generic language modeling performance of RNNs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Differences across languages. English was by far the hardest language. We conjecture that this is due to its poorer morphology and higher POS ambiguity, which might not encourage a generic language model to track abstract syntactic configurations. There is an alternative hypothesis, however. We only extracted two constructions for English, both of which can be argued to be linguistically complex: subject-verb agreement with an intervening embedded clause, and agreement between two conjoined verbs with a nominal complement intervening between the verbs. Yet the results on these two constructions, comparable across languages (with the exception of the subject-verb construction in Russian, which was not extracted), confirm that English is particularly hard ( In languages such as Italian and Russian, which have richer morphology and less ambiguity at the part-of-speech level than English, the LSTMs show much better accuracy and a smaller gap between original and nonce sentences. These results are in line with human experimental studies that found that richer morphology correlates with fewer agreement attraction errors (Lorimor et al., 2008) . The pattern of accuracy rates in general, and the accuracy for the shared V NP conj V construction in particular, are consistent with the finding that Russian is less prone to human attraction errors than Italian, which, in turn, shows less errors than English.",
                "cite_spans": [
                    {
                        "start": 1132,
                        "end": 1154,
                        "text": "(Lorimor et al., 2008)",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "The largest drop in accuracy between original and nonce sentences occurred in Hebrew. A qualitative analysis of the data in this language suggests that this might be due to the numerical prevalence of a few constructions that can have multiple alternative readings, some of which can license the incorrect number. We leave a more systematic analysis of this finding for future research.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Human results. To put our results in context and provide a reasonable upper bound on the LM performance, in particular for nonce sentences, we next compare model performance to that of human Table 3 : Subject and LSTM accuracy on the Italian test set, by construction and averaged.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 197,
                        "end": 198,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "subjects in Italian. Table 3 reports the accuracy of the LSTMs and the human subjects, grouped by construction. 10 There was a consistent gap in human accuracy between original and nonce sentences (6.1% on average). The gap in accuracy between the human subjects and the model was quite small, and was similar for original and nonce sentences (2.4% and 2.9%, respectively).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 27,
                        "end": 28,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "In some of the harder constructions, particularly subject-verb agreement with an embedded clause, the accuracy of the LSTMs on nonce sentences was comparable to human accuracy (92.5 \u00b12.1 vs. 92.3%). To test whether the human subjects and the models struggle with the same sentences, we computed for each sentence (1) the number of times the human subjects selected the correct form of the target minus the number of times they selected the incorrect form, and (2) the difference in model log probability between the correct and incorrect form. The Spearman correlation between these quantities was significant, for both original (p < 0.05) and nonce sentences (p < 0.001). This indicates that humans were more likely to select the correct form in sentences in which the models were more confident in a correct prediction.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Moreover, some of the easiest and hardest constructions are the same for the human subjects and the models. In the easy constructions DET [AdjP] 10 The SM contains the results for the other languages broken down by construction. Note that Table 3 \"A useless but at least festive and youthful movie\" the adjective \"festivo\" is marked for singular number, offering a nearer reference for the target number than the cue \"inutile\". At the other end, NOUN [PP] VERB (participial) and NOUN [PP] ADVERB ADJ are difficult. Particularly in the nonce condition, where semantics is unhelpful or even misleading, the target could easily be interpreted as a modifier of the noun embedded in the preceding prepositional phrase. For example, for the nonce case:",
                "cite_spans": [
                    {
                        "start": 138,
                        "end": 144,
                        "text": "[AdjP]",
                        "ref_id": null
                    },
                    {
                        "start": 451,
                        "end": 455,
                        "text": "[PP]",
                        "ref_id": null
                    },
                    {
                        "start": 484,
                        "end": 488,
                        "text": "[PP]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 245,
                        "end": 246,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "(3) both the subjects and the model preferred to treat \"pedestrian\" as a modifier of \"rules\" (\"orchard of truly pedestrian rules\"), resulting in the wrong agreement given the intended syntactic structure.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Attractors. We define attractors as words with the same POS as the cue but the opposite number, which intervene in the linear order of the sen- tence between the cue and the target. Attractors constitute an obvious challenge for agreement processing (Bock and Miller, 1991) . We show how their presence affects human and model behavior in Fig. 2 . We limit our analysis to a maximum of two attractors, since there were only two original sentences in the test corpus with three attractors or more. Both model and human accuracies degraded with the number of attractors; the drop in accuracy was sharper in the nonce condition.",
                "cite_spans": [
                    {
                        "start": 250,
                        "end": 273,
                        "text": "(Bock and Miller, 1991)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 344,
                        "end": 345,
                        "text": "2",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "While the model performed somewhat worse than humans, the overall pattern was comparable.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Our results suggest that the LSTM is quite robust to the presence of attractors, in contrast to what was reported by Linzen et al. (2016) . We directly compared our English LSTM LM to theirs by predicting verb number on the Linzen et al. (2016) test set. We extracted sentences where all of the words between subject and verb were in our LM vocabulary. Out of those sentences, we sampled 2000 sentences with 0, 1 and 2 attractors and kept all the sentences with 3 and 4 attractors (1329 and 347 sentences, respectively). To ensure that our training set and Linzen's test set do not overlap (both are based on Wikipedia texts), we filtered out all of test sentences that appeared in our training data (187 sentences).",
                "cite_spans": [
                    {
                        "start": 117,
                        "end": 137,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 224,
                        "end": 244,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Fig. 3 compares our results to the results of the best LM-trained model in Linzen et al. (2016) (their \"Google LM\"). 12 Not only did our LM greatly outperform theirs, but it approached the performance of their supervised model. 13 This 12 These subject-verb agreement results are in general higher than for our own subject-verb agreement construction (NOUN VERB VERB) because the latter always includes an embedded clause, and it is therefore harder on average. 13 Similarly high performance of LM-trained RNNs on q q q q q q q q q q q q q q q 60 70 80 90 100 0 1 2 3 4",
                "cite_spans": [
                    {
                        "start": 75,
                        "end": 95,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 5,
                        "end": 6,
                        "text": "3",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4"
            },
            {
                "text": "Accuracy % Models q q q Linzen's Google LM Linzen's supervised Our LSTM LM difference in results points to the importance of careful tuning of LM-trained LSTMs, although we must leave to a further study a more detailed understanding of which differences crucially determine our better performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Number of attractors",
                "sec_num": null
            },
            {
                "text": "Early work showed that RNNs can, to a certain degree, handle data generated by context-free and even context-sensitive grammars (e.g., Elman, 1991 Elman, , 1993;; Rohde and Plaut, 1997; Christiansen and Chater, 1999; Gers and Schmidhuber, 2001; Cartling, 2008) . These experiments were based on small and controlled artificial languages, in which complex hierarchical phenomena were often overrepresented compared to natural languages. Our work, which is based on naturally occurring data, is most closely related to that of Linzen et al. (2016) and Bernardy and Lappin (2017) , which we discussed in the introduction. Other recent work has focused on the morphological and grammatical knowledge that RNN-based machine-translation systems and sentence embeddings encode, typically by training classifiers to decode various linguistic properties from hidden states of the network (e.g., Adi et al., 2017; Belinkov et al., 2017; Shi et al., 2016) , or looking at whether the end-to-end system correctly translates sentences with challenging constructions (Sennrich, 2017) .",
                "cite_spans": [
                    {
                        "start": 135,
                        "end": 146,
                        "text": "Elman, 1991",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 147,
                        "end": 162,
                        "text": "Elman, , 1993;;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 163,
                        "end": 185,
                        "text": "Rohde and Plaut, 1997;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 186,
                        "end": 216,
                        "text": "Christiansen and Chater, 1999;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 217,
                        "end": 244,
                        "text": "Gers and Schmidhuber, 2001;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 245,
                        "end": 260,
                        "text": "Cartling, 2008)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 525,
                        "end": 545,
                        "text": "Linzen et al. (2016)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 550,
                        "end": 576,
                        "text": "Bernardy and Lappin (2017)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 886,
                        "end": 903,
                        "text": "Adi et al., 2017;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 904,
                        "end": 926,
                        "text": "Belinkov et al., 2017;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 927,
                        "end": 944,
                        "text": "Shi et al., 2016)",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 1053,
                        "end": 1069,
                        "text": "(Sennrich, 2017)",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "5"
            },
            {
                "text": "Previous work in neurolinguistics and psycholinguistics used jabberwocky, or pseudo-word, sentences to probe how speakers process syntactic information (Friederici et al., 2000; Moro et al., 2001; Johnson and Goldberg, 2013) . Such sentences are obtained by substituting original words with morphologically and phonologically acceptable nonce forms. We are not aware of work that used nonce sentences made of real words to evaluate the syntactic abilities of models or human subjects. As a proof of concept, Pereira (2000) and, later, Mikolov (2012) computed the probability of Chomsky's famous \"colorless green ideas\" sentence using a class-based bigram LM and an RNN, respectively, and showed that it is much higher than the probability of its shuffled ungrammatical variants.",
                "cite_spans": [
                    {
                        "start": 152,
                        "end": 177,
                        "text": "(Friederici et al., 2000;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 178,
                        "end": 196,
                        "text": "Moro et al., 2001;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 197,
                        "end": 224,
                        "text": "Johnson and Goldberg, 2013)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 508,
                        "end": 522,
                        "text": "Pereira (2000)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 535,
                        "end": 549,
                        "text": "Mikolov (2012)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related work",
                "sec_num": "5"
            },
            {
                "text": "We ran an extensive analysis of the abilities of RNNs trained on a generic language-modeling task to predict long-distance number agreement. Results were consistent across four languages and a number of constructions. They were above strong baselines even in the challenging case of nonsense sentences, and not far from human performance. We are not aware of other collections of human long-distance agreement judgments on nonsensical sentences, and we thus consider our publicly available data set an important contribution of our work, of interest to students of human language processing in general.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "The constructions we considered are quite infrequent (according to a rough estimate based on the treebanks, the language in which they are most common is Hebrew, and even there they occur with average 0.8% sentence frequency). Moreover, they vary in the contexts that separate the cue and the target. So, RNNs are not simply memorizing frequent morphosyntactic sequences (which would already be impressive, for systems learning from raw text). We tentatively conclude that LMtrained RNNs can construct abstract grammatical representations of their input. This, in turn, suggests that the input itself contains enough information to trigger some form of syntactic learning in a system, such as an RNN, that does not contain an explicit prior bias in favour of syntactic structures.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "In future work, we would like to better understand what kind of syntactic information RNNs are encoding, and how. On the one hand, we plan to adapt methods to inspect information flow across RNN states (e.g., Hupkes et al., 2017) . On the other, we would like to expand our empirical investigation by focusing on other long-distance phenomena, such as overt case assignment (Blake, 2001) or parasitic gap licensing (Culicover and Postal, 2001) . While it is more challenging to extract reliable examples of such phenomena from corpora, their study would probe more sophisticated syntactic capabilities, possibly even shedding light on the theoretical analysis of the underlying linguistic structures. Finally, it may be useful to complement the corpus-driven approach used in the current paper with constructed evaluation sentences that isolate particular syntactic phenomena, independent of their frequency in a natural corpus, as is common in psycholinguistics (Enguehard et al., 2017) .",
                "cite_spans": [
                    {
                        "start": 209,
                        "end": 229,
                        "text": "Hupkes et al., 2017)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 374,
                        "end": 387,
                        "text": "(Blake, 2001)",
                        "ref_id": null
                    },
                    {
                        "start": 415,
                        "end": 443,
                        "text": "(Culicover and Postal, 2001)",
                        "ref_id": null
                    },
                    {
                        "start": 963,
                        "end": 987,
                        "text": "(Enguehard et al., 2017)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "The code to reproduce our experiments and the data used for training and evaluation, including the human judgments in Italian, can be found at https://github.com/ facebookresearch/colorlessgreenRNNs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Obviously, in the nonce cases, the LMs never assigned the highest overall probability to either of the two candidates. Qualitatively, in such cases LMs assigned the largest absolute probabilities to plausible frequent words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/attardi/ wikiextractor",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://u.cs.biu.ac.il/ \u02dcyogo/hebwiki/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/pytorch/examples/ tree/master/word_language_model",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Detailed results for sRNNs can be found in the SM.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://www.mturk.com/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The nonce condition has higher accuracy because our substitution procedure in English tends to reduce POS ambiguity.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The relatively low nonce LSTM performance on this construction is due to a few adjectives that could be reinterpreted as nouns.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Linzen's dataset was recently reported byYogatama et al. (2018).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We thank the reviewers, Germ\u00e1n Kruszewski, Gerhard J\u00e4ger, Adam Li\u0161ka, Tomas Mikolov, Gemma Boleda, Brian Dillon, Cristophe Pallier, Roberto Zamparelli and the Paris Syntax and Semantics Colloquium audience for feedback and advice.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": null
            },
            {
                "text": " * The work was conducted during the internship at Facebook AI Research, Paris.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "funding",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Fine-grained analysis of sentence embeddings using auxiliary prediction tasks",
                "authors": [
                    {
                        "first": "Yossi",
                        "middle": [],
                        "last": "Adi",
                        "suffix": ""
                    },
                    {
                        "first": "Einat",
                        "middle": [],
                        "last": "Kermany",
                        "suffix": ""
                    },
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Belinkov",
                        "suffix": ""
                    },
                    {
                        "first": "Ofer",
                        "middle": [],
                        "last": "Lavi",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of ICLR Conference Track",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav Goldberg. 2017. Fine-grained analysis of sentence embeddings using auxil- iary prediction tasks. In Proceedings of ICLR Conference Track. Toulon, France. Published online: https://openreview.net/group? id=ICLR.cc/2017/conference.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "What do neural machine translation models learn about morphology?",
                "authors": [
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Belinkov",
                        "suffix": ""
                    },
                    {
                        "first": "Nadir",
                        "middle": [],
                        "last": "Durrani",
                        "suffix": ""
                    },
                    {
                        "first": "Fahim",
                        "middle": [],
                        "last": "Dalvi",
                        "suffix": ""
                    },
                    {
                        "first": "Hassan",
                        "middle": [],
                        "last": "Sajjad",
                        "suffix": ""
                    },
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Glass",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "861--872",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. 2017. What do neural ma- chine translation models learn about morphology? In Proceedings of ACL. Vancouver, Canada, pages 861-872.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Using deep neural networks to learn syntactic agreement",
                "authors": [
                    {
                        "first": "Jean-Philippe",
                        "middle": [],
                        "last": "Bernardy",
                        "suffix": ""
                    },
                    {
                        "first": "Shalom",
                        "middle": [],
                        "last": "Lappin",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Linguistic Issues in Language Technology",
                "volume": "15",
                "issue": "2",
                "pages": "1--15",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jean-Philippe Bernardy and Shalom Lappin. 2017. Us- ing deep neural networks to learn syntactic agree- ment. Linguistic Issues in Language Technology 15(2):1-15.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Broken agreement",
                "authors": [
                    {
                        "first": "Kathryn",
                        "middle": [],
                        "last": "Bock",
                        "suffix": ""
                    },
                    {
                        "first": "Carol",
                        "middle": [],
                        "last": "Miller",
                        "suffix": ""
                    }
                ],
                "year": 1991,
                "venue": "Cognitive Psychology",
                "volume": "23",
                "issue": "1",
                "pages": "45--93",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kathryn Bock and Carol Miller. 1991. Broken agree- ment. Cognitive Psychology 23(1):45-93.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "On the implicit acquisition of a context-free grammar by a simple recurrent neural network",
                "authors": [
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Cartling",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Neurocomputing",
                "volume": "71",
                "issue": "",
                "pages": "1527--1537",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bo Cartling. 2008. On the implicit acquisition of a context-free grammar by a simple recurrent neural network. Neurocomputing 71:1527-1537.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "N-gram language modeling using recurrent neural network estimation",
                "authors": [
                    {
                        "first": "Ciprian",
                        "middle": [],
                        "last": "Chelba",
                        "suffix": ""
                    },
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Norouzi",
                        "suffix": ""
                    },
                    {
                        "first": "Samy",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1703.10724"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ciprian Chelba, Mohammad Norouzi, and Samy Ben- gio. 2017. N-gram language modeling using re- current neural network estimation. arXiv preprint arXiv:1703.10724 .",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Syntactic Structures. Mouton",
                "authors": [
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Chomsky",
                        "suffix": ""
                    }
                ],
                "year": 1957,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Noam Chomsky. 1957. Syntactic Structures. Mouton, Berlin, Germany.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Toward a connectionist model of recursion in human linguistic performance",
                "authors": [
                    {
                        "first": "Morten",
                        "middle": [],
                        "last": "Christiansen",
                        "suffix": ""
                    },
                    {
                        "first": "Nick",
                        "middle": [],
                        "last": "Chater",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Cognitive Science",
                "volume": "23",
                "issue": "2",
                "pages": "157--205",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Morten Christiansen and Nick Chater. 1999. Toward a connectionist model of recursion in human linguistic performance. Cognitive Science 23(2):157-205.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Incremental parsing with minimal features using bi-directional LSTM",
                "authors": [
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Cross",
                        "suffix": ""
                    },
                    {
                        "first": "Liang",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of ACL (Short Papers)",
                "volume": "",
                "issue": "",
                "pages": "32--37",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "James Cross and Liang Huang. 2016. Incremental parsing with minimal features using bi-directional LSTM. In Proceedings of ACL (Short Papers). Berlin, Germany, pages 32-37.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Parasitic gaps",
                "authors": [],
                "year": 2001,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Peter Culicover and Paul Postal, editors. 2001. Para- sitic gaps. MIT Press, Cambridge, MA.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Finding structure in time",
                "authors": [
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Elman",
                        "suffix": ""
                    }
                ],
                "year": 1990,
                "venue": "Cognitive Science",
                "volume": "14",
                "issue": "",
                "pages": "179--211",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jeffrey Elman. 1990. Finding structure in time. Cogni- tive Science 14:179-211.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Distributed representations, simple recurrent networks, and grammatical structure",
                "authors": [
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Elman",
                        "suffix": ""
                    }
                ],
                "year": 1991,
                "venue": "Machine Learning",
                "volume": "7",
                "issue": "",
                "pages": "195--225",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jeffrey Elman. 1991. Distributed representations, sim- ple recurrent networks, and grammatical structure. Machine Learning 7:195-225.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Learning and development in neural networks: The importance of starting small",
                "authors": [
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Elman",
                        "suffix": ""
                    }
                ],
                "year": 1993,
                "venue": "Cognition",
                "volume": "48",
                "issue": "",
                "pages": "71--99",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jeffrey Elman. 1993. Learning and development in neural networks: The importance of starting small. Cognition 48:71-99.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Exploring the syntactic abilities of RNNs with multi-task learning",
                "authors": [
                    {
                        "first": "\u00c9mile",
                        "middle": [],
                        "last": "Enguehard",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    },
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Linzen",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 21st Conference on Computational Natural Language Learning",
                "volume": "",
                "issue": "",
                "pages": "3--14",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "\u00c9mile Enguehard, Yoav Goldberg, and Tal Linzen. 2017. Exploring the syntactic abilities of RNNs with multi-task learning. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017). pages 3-14.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Structures, not strings: Linguistics as part of the cognitive sciences",
                "authors": [
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Everaert",
                        "suffix": ""
                    },
                    {
                        "first": "Marinus",
                        "middle": [],
                        "last": "Huybregts",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Chomsky",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Berwick",
                        "suffix": ""
                    },
                    {
                        "first": "Johan",
                        "middle": [],
                        "last": "Bolhuis",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Trends in Cognitive Sciences",
                "volume": "19",
                "issue": "12",
                "pages": "729--743",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Martin Everaert, Marinus Huybregts, Noam Chomsky, Robert Berwick, and Johan Bolhuis. 2015. Struc- tures, not strings: Linguistics as part of the cognitive sciences. Trends in Cognitive Sciences 19(12):729- 743.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Irstlm: An open source toolkit for handling large scale language models",
                "authors": [
                    {
                        "first": "Marcello",
                        "middle": [],
                        "last": "Federico",
                        "suffix": ""
                    },
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Bertoldi",
                        "suffix": ""
                    },
                    {
                        "first": "Mauro",
                        "middle": [],
                        "last": "Cettolo",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Ninth Annual Conference of the International Speech Communication Association",
                "volume": "",
                "issue": "",
                "pages": "1618--1621",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marcello Federico, Nicola Bertoldi, and Mauro Cet- tolo. 2008. Irstlm: An open source toolkit for han- dling large scale language models. In Ninth Annual Conference of the International Speech Communi- cation Association. pages 1618-1621.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Auditory language comprehension: An event-related fMRI study on the processing of syntactic and lexical information",
                "authors": [
                    {
                        "first": "Angela",
                        "middle": [
                            "D"
                        ],
                        "last": "Friederici",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Meyer",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Yves Von Cramon",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Brain and Language",
                "volume": "74",
                "issue": "2",
                "pages": "289--300",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Angela D. Friederici, Martin Meyer, and D. Yves Von Cramon. 2000. Auditory language comprehension: An event-related fMRI study on the processing of syntactic and lexical information. Brain and Lan- guage 74(2):289-300.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "LSTM recurrent networks learn simple context-free and context-sensitive languages",
                "authors": [
                    {
                        "first": "Felix",
                        "middle": [],
                        "last": "Gers",
                        "suffix": ""
                    },
                    {
                        "first": "J\u00fcrgen",
                        "middle": [],
                        "last": "Schmidhuber",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "IEEE Transactions on Neural Networks",
                "volume": "12",
                "issue": "6",
                "pages": "1333--1340",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Felix Gers and J\u00fcrgen Schmidhuber. 2001. LSTM recurrent networks learn simple context-free and context-sensitive languages. IEEE Transactions on Neural Networks 12(6):1333-1340.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Supervised Sequence Labelling with Recurrent Neural Networks",
                "authors": [
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Graves",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alex Graves. 2012. Supervised Sequence Labelling with Recurrent Neural Networks. Springer, Berlin.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Kenlm: Faster and smaller language model queries",
                "authors": [
                    {
                        "first": "Kenneth",
                        "middle": [],
                        "last": "Heafield",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Sixth Workshop on Statistical Machine Translation. Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "187--197",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kenneth Heafield. 2011. Kenlm: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation. Asso- ciation for Computational Linguistics, pages 187- 197.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Long short-term memory",
                "authors": [
                    {
                        "first": "Sepp",
                        "middle": [],
                        "last": "Hochreiter",
                        "suffix": ""
                    },
                    {
                        "first": "J\u00fcrgen",
                        "middle": [],
                        "last": "Schmidhuber",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Neural Computation",
                "volume": "9",
                "issue": "8",
                "pages": "1735--1178",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Computation 9(8):1735-178-.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Visualisation and diagnostic classifiers reveal how recurrent and recursive neural networks process hierarchical structure",
                "authors": [
                    {
                        "first": "Dieuwke",
                        "middle": [],
                        "last": "Hupkes",
                        "suffix": ""
                    },
                    {
                        "first": "Sara",
                        "middle": [],
                        "last": "Veldhoen",
                        "suffix": ""
                    },
                    {
                        "first": "Willem",
                        "middle": [],
                        "last": "Zuidema",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dieuwke Hupkes, Sara Veldhoen, and Willem Zuidema. 2017. Visualisation and diagnostic clas- sifiers reveal how recurrent and recursive neural net- works process hierarchical structure. http:// arxiv.org/abs/1711.10203.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Evidence for automatic accessing of constructional meaning: Jabberwocky sentences prime associated verbs",
                "authors": [
                    {
                        "first": "Matt",
                        "middle": [
                            "A"
                        ],
                        "last": "Johnson",
                        "suffix": ""
                    },
                    {
                        "first": "Adele",
                        "middle": [
                            "E"
                        ],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Language and Cognitive Processes",
                "volume": "28",
                "issue": "10",
                "pages": "1439--1452",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matt A. Johnson and Adele E. Goldberg. 2013. Ev- idence for automatic accessing of constructional meaning: Jabberwocky sentences prime associ- ated verbs. Language and Cognitive Processes 28(10):1439-1452.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Simple and accurate dependency parsing using bidirectional LSTM feature representations",
                "authors": [
                    {
                        "first": "Eliyahu",
                        "middle": [],
                        "last": "Kiperwasser",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "4",
                "issue": "",
                "pages": "313--327",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim- ple and accurate dependency parsing using bidi- rectional LSTM feature representations. Transac- tions of the Association for Computational Linguis- tics 4:313-327.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Improved backing-off for m-gram language modeling",
                "authors": [
                    {
                        "first": "Reinhard",
                        "middle": [],
                        "last": "Kneser",
                        "suffix": ""
                    },
                    {
                        "first": "Hermann",
                        "middle": [],
                        "last": "Ney",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Reinhard Kneser and Hermann Ney. 1995. Im- proved backing-off for m-gram language model- ing.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "ICASSP-95",
                "authors": [],
                "year": 1995,
                "venue": "Acoustics, Speech, and Signal Processing",
                "volume": "1",
                "issue": "",
                "pages": "181--184",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "In Acoustics, Speech, and Signal Processing, 1995. ICASSP-95., 1995 International Conference on. IEEE, volume 1, pages 181-184.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Assessing the ability of LSTMs to learn syntax-sensitive dependencies",
                "authors": [
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Linzen",
                        "suffix": ""
                    },
                    {
                        "first": "Emmanuel",
                        "middle": [],
                        "last": "Dupoux",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "4",
                "issue": "",
                "pages": "521--535",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. 2016. Assessing the ability of LSTMs to learn syntax-sensitive dependencies. Transactions of the Association for Computational Linguistics 4:521- 535.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Agreement and attraction in Russian",
                "authors": [
                    {
                        "first": "Heidi",
                        "middle": [],
                        "last": "Lorimor",
                        "suffix": ""
                    },
                    {
                        "first": "Kathryn",
                        "middle": [],
                        "last": "Bock",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Zalkind",
                        "suffix": ""
                    },
                    {
                        "first": "Alina",
                        "middle": [],
                        "last": "Sheyman",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Beard",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Language and Cognitive Processes",
                "volume": "23",
                "issue": "",
                "pages": "769--799",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Heidi Lorimor, Kathryn Bock, Ekaterina Zalkind, Alina Sheyman, and Robert Beard. 2008. Agree- ment and attraction in Russian. Language and Cog- nitive Processes 23(6):769-799.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Statistical language models based on neural networks",
                "authors": [
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomas Mikolov. 2012. Statistical language models based on neural networks. Dissertation, Brno Uni- versity of Technology.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Recurrent neural network based language model",
                "authors": [
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Karafi\u00e1t",
                        "suffix": ""
                    },
                    {
                        "first": "Luk\u00e1s",
                        "middle": [],
                        "last": "Burget",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Cernock\u00fd",
                        "suffix": ""
                    },
                    {
                        "first": "Sanjeev",
                        "middle": [],
                        "last": "Khudanpur",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of INTERSPEECH. Makuhari",
                "volume": "",
                "issue": "",
                "pages": "1045--1048",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomas Mikolov, Martin Karafi\u00e1t, Luk\u00e1s Burget, Jan Cernock\u00fd, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Proceed- ings of INTERSPEECH. Makuhari, Japan, pages 1045-1048.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Linguistic regularities in continuous space word representations",
                "authors": [
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    },
                    {
                        "first": "Wen-Tau",
                        "middle": [],
                        "last": "Yih",
                        "suffix": ""
                    },
                    {
                        "first": "Geoffrey",
                        "middle": [],
                        "last": "Zweig",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of NAACL",
                "volume": "",
                "issue": "",
                "pages": "746--751",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of NAACL. Atlanta, Georgia, pages 746-751.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Syntax and the brain: disentangling grammar by selective anomalies",
                "authors": [
                    {
                        "first": "Andrea",
                        "middle": [],
                        "last": "Moro",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Tettamanti",
                        "suffix": ""
                    },
                    {
                        "first": "Daniela",
                        "middle": [],
                        "last": "Perani",
                        "suffix": ""
                    },
                    {
                        "first": "Caterina",
                        "middle": [],
                        "last": "Donati",
                        "suffix": ""
                    },
                    {
                        "first": "Stefano",
                        "middle": [
                            "F"
                        ],
                        "last": "Cappa",
                        "suffix": ""
                    },
                    {
                        "first": "Ferruccio",
                        "middle": [],
                        "last": "Fazio",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Neuroimage",
                "volume": "13",
                "issue": "1",
                "pages": "110--118",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrea Moro, Marco Tettamanti, Daniela Perani, Cate- rina Donati, Stefano F Cappa, and Ferruccio Fazio. 2001. Syntax and the brain: disentangling grammar by selective anomalies. Neuroimage 13(1):110-118.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Universal dependencies v1: A multilingual treebank collection",
                "authors": [
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    },
                    {
                        "first": "Marie-Catherine",
                        "middle": [],
                        "last": "De Marneffe",
                        "suffix": ""
                    },
                    {
                        "first": "Filip",
                        "middle": [],
                        "last": "Ginter",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Hajic",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Slav",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    },
                    {
                        "first": "Sampo",
                        "middle": [],
                        "last": "Pyysalo",
                        "suffix": ""
                    },
                    {
                        "first": "Natalia",
                        "middle": [],
                        "last": "Silveira",
                        "suffix": ""
                    },
                    {
                        "first": "Reut",
                        "middle": [],
                        "last": "Tsarfaty",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Zeman",
                        "suffix": ""
                    },
                    {
                        "first": ";",
                        "middle": [],
                        "last": "Ference Chair",
                        "suffix": ""
                    },
                    {
                        "first": ")",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Khalid",
                        "middle": [],
                        "last": "Choukri",
                        "suffix": ""
                    },
                    {
                        "first": "Thierry",
                        "middle": [],
                        "last": "Declerck",
                        "suffix": ""
                    },
                    {
                        "first": "Sara",
                        "middle": [],
                        "last": "Goggi",
                        "suffix": ""
                    },
                    {
                        "first": "Marko",
                        "middle": [],
                        "last": "Grobelnik",
                        "suffix": ""
                    },
                    {
                        "first": "Bente",
                        "middle": [],
                        "last": "Maegaard",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [],
                        "last": "Mariani",
                        "suffix": ""
                    },
                    {
                        "first": "Helene",
                        "middle": [],
                        "last": "Mazo",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin- ter, Yoav Goldberg, Jan Hajic, Christopher D. Man- ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, and Daniel Zeman. 2016. Universal dependencies v1: A multilingual treebank collection. In Nicoletta Calzolari (Con- ference Chair), Khalid Choukri, Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente Maegaard, Joseph Mariani, Helene Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceed- ings of the Tenth International Conference on Lan- guage Resources and Evaluation (LREC 2016). Eu- ropean Language Resources Association (ELRA), Paris, France.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Formal grammar and information theory: together again? Philosophical",
                "authors": [
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "Pereira",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences",
                "volume": "358",
                "issue": "",
                "pages": "1239--1253",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fernando Pereira. 2000. Formal grammar and in- formation theory: together again? Philosophi- cal Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences 358(1769):1239-1253.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Simple recurrent networks and natural language: How important is starting small?",
                "authors": [
                    {
                        "first": "Douglas",
                        "middle": [],
                        "last": "Rohde",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Plaut",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Proceedings of CogSci. Stanford",
                "volume": "",
                "issue": "",
                "pages": "656--661",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Douglas Rohde and David Plaut. 1997. Simple recur- rent networks and natural language: How important is starting small? In Proceedings of CogSci. Stan- ford, CA, pages 656-661.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Improvements in part-ofspeech tagging with an application to German",
                "authors": [
                    {
                        "first": "Helmut",
                        "middle": [],
                        "last": "Schmid",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Proceedings of the EACL-SIGDAT Workshop",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Helmut Schmid. 1995. Improvements in part-of- speech tagging with an application to German. In Proceedings of the EACL-SIGDAT Workshop. Dublin, Ireland.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "How grammatical is characterlevel neural machine translation? assessing MT quality with contrastive translation pairs",
                "authors": [
                    {
                        "first": "Rico",
                        "middle": [],
                        "last": "Sennrich",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of EACL (Short Papers)",
                "volume": "",
                "issue": "",
                "pages": "376--382",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rico Sennrich. 2017. How grammatical is character- level neural machine translation? assessing MT quality with contrastive translation pairs. In Pro- ceedings of EACL (Short Papers). Valencia, Spain, pages 376-382.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Does string-based neural MT learn source syntax?",
                "authors": [
                    {
                        "first": "Xing",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Inkit",
                        "middle": [],
                        "last": "Padhi",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of EMNLP",
                "volume": "",
                "issue": "",
                "pages": "1526--1534",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xing Shi, Inkit Padhi, and Kevin Knight. 2016. Does string-based neural MT learn source syntax? In Proceedings of EMNLP. Austin, Texas, pages 1526- 1534.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Google's neural machine translation system: Bridging the gap between human and machine translation",
                "authors": [
                    {
                        "first": "Yonghui",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Schuster",
                        "suffix": ""
                    },
                    {
                        "first": "Zhifeng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Quoc",
                        "middle": [],
                        "last": "Le",
                        "suffix": ""
                    },
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Norouzi",
                        "suffix": ""
                    },
                    {
                        "first": "Wolfgang",
                        "middle": [],
                        "last": "Macherey",
                        "suffix": ""
                    },
                    {
                        "first": "Maxim",
                        "middle": [],
                        "last": "Krikun",
                        "suffix": ""
                    },
                    {
                        "first": "Yuan",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Qin",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Klaus",
                        "middle": [],
                        "last": "Macherey",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Klingner",
                        "suffix": ""
                    },
                    {
                        "first": "Apurva",
                        "middle": [],
                        "last": "Shah",
                        "suffix": ""
                    },
                    {
                        "first": "Melvin",
                        "middle": [],
                        "last": "Johnson",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaobing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Lukasz",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Stephan",
                        "middle": [],
                        "last": "Gouws",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshikiyo",
                        "middle": [],
                        "last": "Kato",
                        "suffix": ""
                    },
                    {
                        "first": "Taku",
                        "middle": [],
                        "last": "Kudo",
                        "suffix": ""
                    },
                    {
                        "first": "Hideto",
                        "middle": [],
                        "last": "Kazawa",
                        "suffix": ""
                    },
                    {
                        "first": "Keith",
                        "middle": [],
                        "last": "Stevens",
                        "suffix": ""
                    },
                    {
                        "first": "George",
                        "middle": [],
                        "last": "Kurian",
                        "suffix": ""
                    },
                    {
                        "first": "Nishant",
                        "middle": [],
                        "last": "Patil",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Cliff",
                        "middle": [],
                        "last": "Young",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Riesa",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Rudnick",
                        "suffix": ""
                    },
                    {
                        "first": "Oriol",
                        "middle": [],
                        "last": "Vinyals",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Corrado",
                        "suffix": ""
                    },
                    {
                        "first": "Macduff",
                        "middle": [],
                        "last": "Hughes",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Dean",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaob- ing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Google's neural machine trans- lation system: Bridging the gap between human and machine translation. http://arxiv.org/ abs/1609.08144.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Memory architectures in recurrent neural network language models",
                "authors": [
                    {
                        "first": "Dani",
                        "middle": [],
                        "last": "Yogatama",
                        "suffix": ""
                    },
                    {
                        "first": "Yishu",
                        "middle": [],
                        "last": "Miao",
                        "suffix": ""
                    },
                    {
                        "first": "Gabor",
                        "middle": [],
                        "last": "Melis",
                        "suffix": ""
                    },
                    {
                        "first": "Wang",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "Adhiguna",
                        "middle": [],
                        "last": "Kuncoro",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "Phil",
                        "middle": [],
                        "last": "Blunsom",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, and Phil Blunsom. 2018. Memory architectures in recurrent neural network language models. In International Con- ference on Learning Representations. https:// openreview.net/forum?id=SkFqf0lAZ.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Dependency parsing as head selection",
                "authors": [
                    {
                        "first": "Xingxing",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jianpeng",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of EACL",
                "volume": "",
                "issue": "",
                "pages": "665--676",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xingxing Zhang, Jianpeng Cheng, and Mirella Lapata. 2017. Dependency parsing as head selection. In Proceedings of EACL. Valencia, Spain, pages 665- 676.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "dogs dogs in the neighbourhood often bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark\", an RNN might get the right agreement by encoding information",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 1: Example agreement constructions defined by a dependency and the separating context, in (a) English, (b) Russian and (c) Italian.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 2: Accuracy by number of attractors in Italian. Human performance is shown in red and LSTM in blue (median model among top 5 ranked by perplexity). Error bars show standard error.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "text": "Figure 3: Linzen's attractor set. Our LM-trained LSTM (blue; \"median\" model) compared to their LSTM with explicit number supervision (green) and their best LM-trained LSTM (red).",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "TABREF3": {
                "content": "<table><tr><td>like</td><td>girl girl girl girl girl girl girl girl girl girl girl the boys girl</td></tr></table>",
                "type_str": "table",
                "text": "Our constructions do not necessarily correspond to standard syntactic structures. The English subject-verb agreement construction NOUN VERB VERB, for example, matches both object and subject relative clause contexts, e.g., \"girl girl girl girl girl",
                "html": null,
                "num": null
            },
            "TABREF7": {
                "content": "<table><tr><td>).</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF9": {
                "content": "<table><tr><td>(2)</td><td>un a giovanile giovanile giovanile giovanile giovanile film movie giovanile giovanile giovanile giovanile giovanile giovanile giovanile giovanile giovanile giovanile giovanile giovanile youthful</td><td>inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile inutile useless</td><td>ma but</td><td>almeno at.least</td><td>festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festivo festive</td><td>e and</td></tr></table>",
                "type_str": "table",
                "text": "reports linguistically intuitive construction labels. The corresponding POS patterns are (in same order as table rows): DET ADJ NOUN, NOUN VERB PRON VERB, NOUN VERB VERB, ADJ ADJ CCONJ ADJ, NOUN ADJ PUNCT PRON VERB, NOUN NOUN ADV ADJ, NOUN NOUN VERB, VERB NOUN CCONJ VERB.NOUN 11 and ADJ [conjoined ADJs] ADJ, one or more adjectives that intervene between the cue and the target agree in number with the target, providing shorter-distance evidence about its correct number. For example, in",
                "html": null,
                "num": null
            }
        }
    }
}