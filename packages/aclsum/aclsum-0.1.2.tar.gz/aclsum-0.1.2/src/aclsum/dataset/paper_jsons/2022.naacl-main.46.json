{
    "paper_id": "2022",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:56:23.306791Z"
    },
    "title": "User-Centric Gender Rewriting",
    "authors": [
        {
            "first": "Bashar",
            "middle": [],
            "last": "Alhafni",
            "suffix": "",
            "affiliation": {},
            "email": "alhafni@nyu.edu"
        },
        {
            "first": "Nizar",
            "middle": [],
            "last": "Habash",
            "suffix": "",
            "affiliation": {},
            "email": "nizar.habash@nyu.edu"
        },
        {
            "first": "Houda",
            "middle": [],
            "last": "Bouamor",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {
                    "country": "Qatar"
                }
            },
            "email": "hbouamor@qatar.cmu.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "In this paper, we define the task of gender rewriting in contexts involving two users (I and/or You) -first and second grammatical persons with independent grammatical gender preferences. We focus on Arabic, a gendermarking morphologically rich language. We develop a multi-step system that combines the positive aspects of both rule-based and neural rewriting models. Our results successfully demonstrate the viability of this approach on a recently created corpus for Arabic gender rewriting, achieving 88.42 M 2 F 0.5 on a blind test set. Our proposed system improves over previous work on the first-person-only version of this task, by 3.05 absolute increase in M 2 F 0.5 . We demonstrate a use case of our gender rewriting system by using it to post-edit the output of a commercial MT system to provide personalized outputs based on the users' grammatical gender preferences. We make our code, data, and pretrained models publicly available. 1 ",
    "pdf_parse": {
        "paper_id": "2022",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "In this paper, we define the task of gender rewriting in contexts involving two users (I and/or You) -first and second grammatical persons with independent grammatical gender preferences. We focus on Arabic, a gendermarking morphologically rich language. We develop a multi-step system that combines the positive aspects of both rule-based and neural rewriting models. Our results successfully demonstrate the viability of this approach on a recently created corpus for Arabic gender rewriting, achieving 88.42 M 2 F 0.5 on a blind test set. Our proposed system improves over previous work on the first-person-only version of this task, by 3.05 absolute increase in M 2 F 0.5 . We demonstrate a use case of our gender rewriting system by using it to post-edit the output of a commercial MT system to provide personalized outputs based on the users' grammatical gender preferences. We make our code, data, and pretrained models publicly available. 1 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Gender bias is a fundamental problem in natural language processing (NLP) and it has been receiving an increasing attention across a variety of core tasks such as machine translation (MT), co-reference resolution, and dialogue systems. Research has shown that NLP systems have the ability to embed and amplify gender bias (Sun et al., 2019) , which not only degrades users' experiences but also creates representational harm (Blodgett et al., 2020) . The embedded bias within NLP systems is usually attributed to training models on biased data that reflects the social inequalities of the world we live in. However, even the most balanced of models can still exhibit and amplify bias if they are designed to produce a single text output without taking their users' gender preferences into consideration. Therefore, to provide the correct user-aware output, NLP systems should be designed to produce outputs that are as gender-specific as the users information they have access to. Users information could be either embedded as part of the input or provided externally by the users themselves. In cases where this information is unavailable to the system, generating all gender-specific forms or a gender-neutral form is more appropriate.",
                "cite_spans": [
                    {
                        "start": 322,
                        "end": 340,
                        "text": "(Sun et al., 2019)",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 425,
                        "end": 448,
                        "text": "(Blodgett et al., 2020)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Producing user-aware outputs becomes more challenging for systems targeting multi-user contexts (first and second persons, with independent grammatical gender preferences), particularly when dealing with gender-marking morphologically rich languages. In this paper, we define the task of gender rewriting in contexts involving two users (I and/or You) -first and second grammatical persons with independent grammatical gender preferences and we focus on Arabic, a gender-marking morphologically rich language. The main contributions of our work are as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "1. We introduce a multi-step gender rewriting system that combines the positive aspects of rule-based and neural models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2. We demonstrate our approach's effectiveness by establishing a strong benchmark on a publicly available multi-user Arabic gender rewriting corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "3. We show that our best system yields state-ofthe-art results on the first-person-only version of this task, beating previous work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "4. We demonstrate a use case of our system by post-editing the output of an MT system to match users' grammatical gender preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "This paper is organized as follows. We first discuss related work ( \u00a72) as well as relevant Arabic linguistic facts ( \u00a73). We then define the gender rewriting task in \u00a74 and describe the data we use and the gender rewriting model we build in \u00a75 and \u00a76. Lastly, we present our experimental setup ( \u00a77) and results ( \u00a78) and conclude in \u00a79.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Substantial research has targeted the problem of gender bias in various NLP tasks such as MT (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Stafanovi\u010ds et al., 2020; Savoldi et al., 2021) , dialogue systems (Cercas Curry et al., 2020; Dinan et al., 2020; Liu et al., 2020a,b; Sheng et al., 2021) , language modeling (Lu et al., 2018; Bordia and Bowman, 2019; Sheng et al., 2019; Vig et al., 2020; Nadeem et al., 2021) , co-reference resolution (Rudinger et al., 2018; Zhao et al., 2018a) , and named entity recognition (Mehrabi et al., 2019) . While the majority of research has focused on tackling gender bias in English by debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019; Manzini et al., 2019; Zhao et al., 2020) or by training systems on gender-balanced corpora built using counterfactual data augmentation techniques (Lu et al., 2018; Hall Maudslay et al., 2019; Zmigrod et al., 2019) , our work falls under text rewriting through the controlled generation of gender alternatives for morphologically rich languages.",
                "cite_spans": [
                    {
                        "start": 93,
                        "end": 118,
                        "text": "(Rabinovich et al., 2017;",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 119,
                        "end": 146,
                        "text": "Vanmassenhove et al., 2018;",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 147,
                        "end": 172,
                        "text": "Stafanovi\u010ds et al., 2020;",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 173,
                        "end": 194,
                        "text": "Savoldi et al., 2021)",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 222,
                        "end": 241,
                        "text": "Curry et al., 2020;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 242,
                        "end": 261,
                        "text": "Dinan et al., 2020;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 262,
                        "end": 282,
                        "text": "Liu et al., 2020a,b;",
                        "ref_id": null
                    },
                    {
                        "start": 283,
                        "end": 302,
                        "text": "Sheng et al., 2021)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 323,
                        "end": 340,
                        "text": "(Lu et al., 2018;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 341,
                        "end": 365,
                        "text": "Bordia and Bowman, 2019;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 366,
                        "end": 385,
                        "text": "Sheng et al., 2019;",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 386,
                        "end": 403,
                        "text": "Vig et al., 2020;",
                        "ref_id": "BIBREF52"
                    },
                    {
                        "start": 404,
                        "end": 424,
                        "text": "Nadeem et al., 2021)",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 451,
                        "end": 474,
                        "text": "(Rudinger et al., 2018;",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 475,
                        "end": 494,
                        "text": "Zhao et al., 2018a)",
                        "ref_id": null
                    },
                    {
                        "start": 526,
                        "end": 548,
                        "text": "(Mehrabi et al., 2019)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 658,
                        "end": 682,
                        "text": "(Bolukbasi et al., 2016;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 683,
                        "end": 702,
                        "text": "Zhao et al., 2018b;",
                        "ref_id": null
                    },
                    {
                        "start": 703,
                        "end": 728,
                        "text": "Gonen and Goldberg, 2019;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 729,
                        "end": 750,
                        "text": "Manzini et al., 2019;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 751,
                        "end": 769,
                        "text": "Zhao et al., 2020)",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 876,
                        "end": 893,
                        "text": "(Lu et al., 2018;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 894,
                        "end": 921,
                        "text": "Hall Maudslay et al., 2019;",
                        "ref_id": null
                    },
                    {
                        "start": 922,
                        "end": 943,
                        "text": "Zmigrod et al., 2019)",
                        "ref_id": "BIBREF58"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background and Related Work",
                "sec_num": "2"
            },
            {
                "text": "Within text rewriting, Vanmassenhove et al. (2021) and Sun et al. (2021) recently presented rule-based and neural rewriting models to generate gender-neutral sentences in English. For morphologically rich languages and specifically Arabic, Habash et al. (2019) introduced the Arabic Parallel Gender Corpus v1.0 (APGC v1.0) of firstperson-singular constructions and designed a twostep gender identification and reinflection system to generate masculine and feminine grammatical gender alternatives. Alhafni et al. (2020) used APGC v1.0 to create a joint gender identification and reinflection model. They treated the problem as a user-aware grammatical error correction task and showed improvements over Habash et al. (2019) 's results. Both efforts modeled gender reinflection using character-level Seq2Seq models. More recently, Alhafni et al. (2022) extended APGC v1.0 to APGC v2.0 by including contexts involving first and second grammatical persons covering singular, dual, and plural constructions; and adding six times more sentences.",
                "cite_spans": [
                    {
                        "start": 23,
                        "end": 50,
                        "text": "Vanmassenhove et al. (2021)",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 55,
                        "end": 72,
                        "text": "Sun et al. (2021)",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 240,
                        "end": 260,
                        "text": "Habash et al. (2019)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 498,
                        "end": 519,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 703,
                        "end": 723,
                        "text": "Habash et al. (2019)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 830,
                        "end": 851,
                        "text": "Alhafni et al. (2022)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background and Related Work",
                "sec_num": "2"
            },
            {
                "text": "In our work, we use APGC v2.0 to build a multistep gender rewriting system to generate gender alternatives in multi-user contexts. We also show improvements over both Habash et al. (2019)'s and Alhafni et al. (2020) 's results on APGC v1.0.",
                "cite_spans": [
                    {
                        "start": 167,
                        "end": 193,
                        "text": "Habash et al. (2019)'s and",
                        "ref_id": null
                    },
                    {
                        "start": 194,
                        "end": 215,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background and Related Work",
                "sec_num": "2"
            },
            {
                "text": "We highlight two of the many challenges that face Modern Standard Arabic (MSA) NLP systems dealing with gender expressions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Arabic Linguistic Facts",
                "sec_num": "3"
            },
            {
                "text": "Arabic has a rich and complex morphological system that inflects for many morphological features (gender, number, person, case, state, aspect, mood, voice) , in addition to several attachable clitics (prepositions, particles, pronouns) (Habash, 2010) . Arabic nouns, adjectives, and verbs inflect for gender: masculine (M) and feminine (F), and for number: singular (S), dual (D) and plural (P).",
                "cite_spans": [
                    {
                        "start": 97,
                        "end": 155,
                        "text": "(gender, number, person, case, state, aspect, mood, voice)",
                        "ref_id": null
                    },
                    {
                        "start": 236,
                        "end": 250,
                        "text": "(Habash, 2010)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Morphological Richness and Complexity",
                "sec_num": null
            },
            {
                "text": "Changing the grammatical gender of Arabic words involves either changing the form of the base word, changing the pronominal enclitics that are attached to the base word, or a combination of both. A base word in Arabic refers to the stem along with its attachable affixes (prefixes, suffixes, circumfixes). Changing the base word gender requires either a suffix change, a pattern change, or a lexical change as shown in Table 1 (a-c). Arabic also has clitics that attach to the stem after affixes. A clitic is a morpheme that has the syntactic characteristics of a word but shows evidence of being phonologically bound to another word. In this respect, a clitic is distinctly different from an affix, which is phonologically and syntactically part of the word. Proclitics are clitics that precede the word (like a prefix), whereas enclitics are clitics that follow the word (like a suffix). Pronominal enclitics are pronouns that cliticize to previous words (Table 1(d)) . It is worth noting that multiple affixes and clitics can appear in a single word in Arabic and changing the grammatical gender of such words requires changing the genders of both the base word and its clitics (Table 1 (f-g)).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 425,
                        "end": 426,
                        "text": "1",
                        "ref_id": "TABREF0"
                    },
                    {
                        "start": 964,
                        "end": 969,
                        "text": "1(d))",
                        "ref_id": "TABREF0"
                    },
                    {
                        "start": 1188,
                        "end": 1189,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Morphological Richness and Complexity",
                "sec_num": null
            },
            {
                "text": "Orthographic Ambiguity Arabic uses diacritics to specify short vowels. However, these optional diacritics are usually omitted in Arabic orthography, leaving readers to infer the meaning of certain words based on the context (Habash, 2010) ",
                "cite_spans": [
                    {
                        "start": 224,
                        "end": 238,
                        "text": "(Habash, 2010)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Morphological Richness and Complexity",
                "sec_num": null
            },
            {
                "text": "We define the task of gender rewriting as generating alternatives of a given Arabic sentence to match different target user gender contexts (e.g., female speaker with a male listener, a male speaker with a male listener, etc.). This requires changing the grammatical gender (masculine or feminine) of certain words referring to the users (speaker/1 st person and listener/2 nd person). Previous work done by Habash et al. (2019) and Alhafni et al. (2020) refer to this task as gender reinflection, but we believe that gender rewriting is a more appropriate term given that it goes beyond reinflection. 3",
                "cite_spans": [
                    {
                        "start": 408,
                        "end": 428,
                        "text": "Habash et al. (2019)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 433,
                        "end": 454,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "Notation We will use four elementary symbols to facilitate the discussion of this task: 1M, 1F, 2M and 2F. The digit part of the symbol refers to the grammatical persons (1 st or 2 nd ) and the letter part refers to the grammatical genders (masculine or feminine). Additionally, we will use B to refer to invariant/ambiguous gender. We define the sentence-level gender using the following four labels: 1M/2F, 1F/2M, 1M/2F, and 1F/2F. These four labels indicate the grammatical persons and genders of the user contexts we are modeling.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "We define the word-level gender based on the genders of the word's base form and its attachable pronominal enclitics ( \u00a73) using the notation: base form gender + enclitic gender. This results in 3 Morphological reinflection usually refers to reinflecting either a lemma or an already inflected form to produce a desired form of a particular word (Cotterell et al., 2016 (Cotterell et al., , 2017)) .",
                "cite_spans": [
                    {
                        "start": 346,
                        "end": 369,
                        "text": "(Cotterell et al., 2016",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 370,
                        "end": 397,
                        "text": "(Cotterell et al., , 2017))",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "25 word-level gender labels (e.g., B+1F, 1F+2M). We use B to refer to gender invariant/ambiguous words. Examples of the word-level gender labels are shown in Table 2 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 164,
                        "end": 165,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "Task Definition Given an Arabic sentence and a sentence-level target gender, the goal is to rewrite the input sentence to match the target users' gender preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "Some of the models we explore only use sentence-level gender labels; while other models use word-level gender labels to identify which input words need to be rewritten to match the target users' gender preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Gender Rewriting Task",
                "sec_num": "4"
            },
            {
                "text": "For our experiments, we use the publicly available Arabic Parallel Gender Corpus (APGC) -a parallel corpus of Arabic sentences with gender annotations and gender rewritten alternatives of sentences selected from OpenSubtitles 2018 (Lison and Tiedemann, 2016) . The corpus comes in two versions: APGC v1.0 and APGC v2.0. APGC v1.0 was introduced by Habash et al. ( 2019) and it contains 12,238 first-person-singular Arabic parallel gender-annotated sentences. Alhafni et al. (2022) expanded APGC v1.0 by including contexts involving first and second grammatical persons covering singular, dual, and plural constructions to create v2.0, which contains 80,326 gender-annotated parallel sentences (596,799 words). Both versions of APGC include the original English parallels of the Arabic sentences. In all of our experiments, we use an extended version of APGC v2.0 to train and test our systems. We also report results on the test set of APGC v1.0 to compare with previous work.",
                "cite_spans": [
                    {
                        "start": 231,
                        "end": 258,
                        "text": "(Lison and Tiedemann, 2016)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 459,
                        "end": 480,
                        "text": "Alhafni et al. (2022)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "5"
            },
            {
                "text": "Annotations Each sentence in APGC v2.0 has word-level gender labels where each word is labeled as B, 1F, 2F, 1M, or 2M. All sentences containing gender-specific words referring to human participants have parallels representing their opposite gender forms. For the sentences without any gender-specific words, their parallels are trivial copies. Out of the 80,326 sentences in APGC v2.0, 46% (36,980) do not contain any gendered words, whereas sentences with gendered references constitute 54% (43, 346) . In terms of the word-level statistics, 9.7% (58,066) are gender-specific, whereas 90.3% (538,733) are marked as B.",
                "cite_spans": [
                    {
                        "start": 493,
                        "end": 497,
                        "text": "(43,",
                        "ref_id": null
                    },
                    {
                        "start": 498,
                        "end": 502,
                        "text": "346)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "5"
            },
            {
                "text": "Moreover, APGC v2.0 is organized into five parallel corpora that are fully aligned (1-to-1) at the word level: Input, Target 1M/2M, Target 1F/2M, Target 1M/2F, and Target 1F/2F. All five corpora are balanced in terms of gender, i.e., the number of words marked as 1F and 1M is the same; and the number of words marked as 2F and 2M is the same. The Input corpus contains sentences with all possible word types (B, 1F, 2F, 1M, 2M). The Target 1M/2M corpus contains sentences that consist of B, 1M, 2M words; the Target 1F/2M corpus contains sentences that consist of B, 1F, 2M words; the Target 1M/2F corpus contains sentences that consist of B, 1M, 2F words; and the Target 1F/2F corpus contains sentences that consist of B, 1F, 2F words. The four target corpora are intended to model the target users' gender preferences for a particular input. Preprocessing the Word-Level Annotations Since gender information could be expressed at different parts of Arabic words ( \u00a73), we automatically extend the APGC v2.0 word-level annotations to mark the genders of both the base words and their pronominal enclitics.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "5"
            },
            {
                "text": "Our preprocessing pipeline considers the labeled gendered words across the five parallel forms of each sentence in APGC v2.0. If the word ends with a gender marking pronominal enclitic, we label the gender of the enclitic based on predefined rules as 1F, 1M, 2F, or 2M. If the gendered word does not end with a gender-marking enclitic, then we label the enclitic as B. Once the enclitic is labeled, we compare the base form of the word across its parallel forms. If the base form is the same, we label it as B. Otherwise, we assign the base form the same label that is provided as part of APGC v2.0. All gender ambiguous words will be labeled as B. Table 2 presents some examples from APGC v2.0 with the extended word-level gender annotations.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 655,
                        "end": 656,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Splits",
                "sec_num": null
            },
            {
                "text": "The extended word-level statistics are presented in Appendix B. We make the extended word-level gender annotations publicly available as a new release of APGC (APGC v2.1).4 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Splits",
                "sec_num": null
            },
            {
                "text": "Most of the recent work on gender rewriting rely on using Seq2Seq models (Habash et al., 2019; Alhafni et al., 2020; Sun et al., 2021; Jain et al., 2021; Vanmassenhove et al., 2021) . However, the lack of large gender-annotated parallel datasets presents a challenge when training Seq2Seq models, and especially when dealing with morphologically rich languages. This issue is highlighted by Alhafni et al. (2020) , who report that most of the errors (68%) produced by their character-level Seq2Seq model are due to not making any changes to genderspecific words in the input sentences. Given the complexity of the gender rewriting task in Arabic and the relatively small training data size, we model the gender rewriting task using a multi-step system the combines the positive aspects of rule-based and neural models. Our system consists of three components: Gender identification, Out-of-context word gender rewriting, and In-context ranking and selection.",
                "cite_spans": [
                    {
                        "start": 73,
                        "end": 94,
                        "text": "(Habash et al., 2019;",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 95,
                        "end": 116,
                        "text": "Alhafni et al., 2020;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 117,
                        "end": 134,
                        "text": "Sun et al., 2021;",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 135,
                        "end": 153,
                        "text": "Jain et al., 2021;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 154,
                        "end": 181,
                        "text": "Vanmassenhove et al., 2021)",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 391,
                        "end": 412,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Multi-step Model Approach",
                "sec_num": "6"
            },
            {
                "text": "We first identify the word-level gender label (base word + pronominal enclitic) for each word in the input sentence. We build a word-level classifier by leveraging a Transformer-based pretrained language model. There are many Arabic monolingual BERT models available such as AraBERT (Antoun et al., 2020) , ARBERT (Abdul-Mageed et al., 2021) , and QARIB (Abdelali et al., 2021) . However, we chose to use CAMeLBERT MSA (Inoue et al., 2021) as it was pretrained on the largest MSA dataset to date. Following the work of Devlin et al. (2019) , we fine-tune CAMeLBERT MSA using Hugging Face's transformers (Wolf et al., 2020) by adding a fully-connected linear layer with a softmax on top of its architecture. During fine-tuning, we use the representation of the first sub-token as an input to the linear layer.",
                "cite_spans": [
                    {
                        "start": 283,
                        "end": 304,
                        "text": "(Antoun et al., 2020)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 314,
                        "end": 341,
                        "text": "(Abdul-Mageed et al., 2021)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 354,
                        "end": 377,
                        "text": "(Abdelali et al., 2021)",
                        "ref_id": null
                    },
                    {
                        "start": 419,
                        "end": 439,
                        "text": "(Inoue et al., 2021)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 519,
                        "end": 539,
                        "text": "Devlin et al. (2019)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 603,
                        "end": 622,
                        "text": "(Wolf et al., 2020)",
                        "ref_id": "BIBREF54"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Gender Identification (GID)",
                "sec_num": "6.1"
            },
            {
                "text": "Given the desired sentence-level target gender as an input and the identified gender label for each word in the input sentence, we decide if a word-level gender rewrite is needed based on the compatibility between the provided sentence-level target gender and the predicted word-level gender labels. We implement three word-level gender alternative generation models: Corpus-based Rewriter, Morphological Rewriter, and Neural Rewriter. Corpus-based Rewriter (CorpusR) We build a simple word-level lookup rewriting model by exploiting the fully aligned words in APGC v2.1. We implement this model as a bigram maximum likelihood estimator: given an input word with its bigram surrounding context (w i , w i-1 ), a gender alternative target word (y i ), and a desired word-level target gender (g), the CorpusR model is built by computing P (y i |w i , w i-1 , g) over the training examples. During inference, we generate all possible gender alternatives for the given input word (w i ). If the bigram context (w i , w i-1 ) was not observed in the training data, we backoff to a unigram context. If the input word was not observed during training, we pass it to the output as it is.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Out-of-context Word Gender Rewriting",
                "sec_num": "6.2"
            },
            {
                "text": "Morphological Rewriter (MorphR) For the morphological rewriter, we use the morphological analyzer and generator provided by CAMeL Tools (Obeid et al., 2020) . We extend the Standard Arabic Morphological Analyzer database (SAMA) (Graff et al., 2009) used by the morphological generator to produce controlled gender alternatives. We make our extensions to the database publicly available. 5Given an input word and a desired word-level target gender, the morphological generator has the ability to produce gender alternatives by either rewriting the base word, its pronominal enclitics, or both. If an input word does not get recognized by the morphological analyzer and generator, we pass it to the output as it is. It is worth noting that this rewriting model does not require any training data.",
                "cite_spans": [
                    {
                        "start": 136,
                        "end": 156,
                        "text": "(Obeid et al., 2020)",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 228,
                        "end": 248,
                        "text": "(Graff et al., 2009)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Out-of-context Word Gender Rewriting",
                "sec_num": "6.2"
            },
            {
                "text": "Neural Rewriter (NeuralR) Inspired by work done on out-of-context morphological reinfection (Kann and Sch\u00fctze, 2016; Cotterell et al., 2018) , we design a character-level encoder-decoder model with attention. Given an input word and word-level target gender, the encoder-decoder model would generate gender alternatives of the input word. For the encoder, we use a two-layer bidrectional GRU (Cho et al., 2014) and for the decoder we use a two-layer GRU with additive attention (Bahdanau et al., 2015) . Furthermore, we employ side constraints (Sennrich et al., 2016) to control for the generation of gender alternatives. That is, we add the word-level target gender as a special token (e.g., <1F+B>) to the beginning of the input word and we feed that entire sequence to the model (i.e., <1F+B>",
                "cite_spans": [
                    {
                        "start": 92,
                        "end": 116,
                        "text": "(Kann and Sch\u00fctze, 2016;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 117,
                        "end": 140,
                        "text": "Cotterell et al., 2018)",
                        "ref_id": null
                    },
                    {
                        "start": 392,
                        "end": 410,
                        "text": "(Cho et al., 2014)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 478,
                        "end": 501,
                        "text": "(Bahdanau et al., 2015)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 544,
                        "end": 567,
                        "text": "(Sennrich et al., 2016)",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Out-of-context Word Gender Rewriting",
                "sec_num": "6.2"
            },
            {
                "text": "). The intuition here is that the attentional encoder-decoder model would be able to learn to pay attention to the side constraints to generate the desired gender alternative of the input word. During inference, we use beam search to generate the top 3-best hypotheses.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Out-of-context Word Gender Rewriting",
                "sec_num": "6.2"
            },
            {
                "text": "Since the three word-level gender alternative generation models we implement are out-of-context and given Arabic's morphological richness, we expect to get multiple output words when generating a single gender alternative for a particular input word. This leads to producing multiple candidate gender alternative output sentences. To select the best candidate output sentence, we rank all candidates in full sentential context based on their pseudo-loglikelihood (PLL) scores (Salazar et al., 2020) . We first use Hugging Face's transformers to fine-tune the CAMeLBERT MSA model on the Input corpus of APGC v2.1 by using a masked language modeling (Devlin et al., 2019) objective. This helps in mitigating the domain shift (Gretton et al., 2006) issue between CAMeLBERT's pretraining data and APGC v2.1. We then compute the PLL score for each sentence using the fine-tuned CAMeLBERT MSA model by masking the sentence tokens one by one. 6 We will refer to the in-context ranking and selection as simply selection throughout the paper.",
                "cite_spans": [
                    {
                        "start": 476,
                        "end": 498,
                        "text": "(Salazar et al., 2020)",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 648,
                        "end": 669,
                        "text": "(Devlin et al., 2019)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 723,
                        "end": 745,
                        "text": "(Gretton et al., 2006)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "In-Context Ranking and Selection",
                "sec_num": "6.3"
            },
            {
                "text": "Figure 1 presents an overview of our gender rewriting model. We describe the training settings and the model's hyperparameters in Appendix A.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "1",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "In-Context Ranking and Selection",
                "sec_num": "6.3"
            },
            {
                "text": "7 Experimental Setup",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "In-Context Ranking and Selection",
                "sec_num": "6.3"
            },
            {
                "text": "We follow Alhafni et al. (2020) by treating the gender rewriting problem as a user-aware grammatical error correction task and use the MaxMatch (M 2 ) scorer (Dahlmeier and Ng, 2012) as our evaluation metric. The M 2 scorer computes the precision (P), recall (R), and F 0.5 by maximally matching phraselevel edits made by a system to gold-standard edits. The gold edits are computed by the M 2 scorer based on provided gold references. Moreover and to be consistent with previous work, we also report BLEU (Papineni et al., 2002) scores which are obtained using SacreBLEU (Post, 2018) . We report the gender rewriting results in a normalized space for Alif, Ya, and Ta-Marbuta (Habash, 2010) .",
                "cite_spans": [
                    {
                        "start": 10,
                        "end": 31,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 158,
                        "end": 182,
                        "text": "(Dahlmeier and Ng, 2012)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 506,
                        "end": 529,
                        "text": "(Papineni et al., 2002)",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 572,
                        "end": 584,
                        "text": "(Post, 2018)",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 677,
                        "end": 691,
                        "text": "(Habash, 2010)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Metrics",
                "sec_num": "7.1"
            },
            {
                "text": "Do Nothing Our first baseline trivially passes the input sentences to the output as they are. This baseline highlights the level of similarity between the inputs and the outputs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "7.2"
            },
            {
                "text": "Joint Baseline Model Our second baseline uses a variant of the sentence-level linguistically enhanced joint gender identification and rewriting model introduced by Alhafni et al. (2020) . The main difference between this model and the one introduced by Alhafni et al. ( 2020) is that we model four multi-user target genders, whereas they only modeled two single-user target genders (1M, 1F). We implement this joint baseline model using a character-level GRU encoder-decoder with additive attention, where the learned input characterlevel representations are enriched with word-level morphological features obtained from the extended morphological analyzer that is part of CAMeL Tools. The representation of the input sentencelevel target gender (1M/2M, 1F/2M, 1M/2F, 1F/2F) is learned as part of the model and used during decoding when generating gender alternatives. We refer to this baseline as Joint+Morph.",
                "cite_spans": [
                    {
                        "start": 164,
                        "end": 185,
                        "text": "Alhafni et al. (2020)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 253,
                        "end": 269,
                        "text": "Alhafni et al. (",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "7.2"
            },
            {
                "text": "Extended Joint Baseline Models Our third and fourth baseline models reduce the complexity of the Joint+Morph model by not learning a representation for the input sentence-level target gender as part of the model. Instead, we provide the sentence-level target gender information as side constraints. We add the target gender as a special token to the beginning of the input sentence (e.g., <1M/2F>Input Sentence) when we feed it to the model. Moreover, we explore the effectiveness of enriching the input character representations with word-level morphological features. To do so, we omit the morphological features from the first joint variant, and we use them in the second. We refer to these models as Joint+Side Constraints and Joint+Morph+Side Constraints, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "7.2"
            },
            {
                "text": "We explore five variants of the gender rewriting multi-step model described in \u00a76. All five variants use the same gender identification (GID) and incontext selection models, but they differ in their outof-context word-level gender rewriting generation setup. The first three variants use one word-level gender rewriting model each -CorpusR, Mor-phR, or NeuralR. The fourth multi-step model uses MorphR as a backoff if the input words that need to be rewritten are not observed by the Cor-pusR model during training (CorpusR\u00bbMorphR). The fifth system uses all three word-level gender alternative generation models in a backoff cascade: CorpusR\u00bbMorphR\u00bbNeuralR.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Multi-step Models",
                "sec_num": "7.3"
            },
            {
                "text": "Given the relatively small size of APGC v2.1 and motivated by recent work on using data augmentation to improve grammatical error correction (Wan et al., 2020; Stahlberg and Kumar, 2021) , we investigate adding additional training examples through data augmentation. We randomly selected 800K sentences from the English-Arabic portion of the OpenSubtitles 2018 dataset, which was used to build APGC. We ensured that all extracted pairs include either first or second (or both) person pronouns on the English side: I, me, my, mine, myself, and you, your, yours, yourself. To generate gender alternatives of the selected Arabic sentences, we pass each sentence four times through our best gender rewriting system to generate all four user gender contexts (1M/2M, 1F/2M, 1M/2F, 1F/2F). We add the 800K selected Arabic sentences and their 1M/2M, 1F/2M, 1M/2F, 1F/2F generated gen-der alternatives to the Input, Target 1M/2M, Target 1F/2M, Target 1M/2F, and Target 1F/2F corpora of the training split of APGC v2.1, respectively. At the end, we end up with 857,603 Arabic parallel sentences (6,209,958 words). We make the synthetically generated data publicly available.",
                "cite_spans": [
                    {
                        "start": 141,
                        "end": 159,
                        "text": "(Wan et al., 2020;",
                        "ref_id": "BIBREF53"
                    },
                    {
                        "start": 160,
                        "end": 186,
                        "text": "Stahlberg and Kumar, 2021)",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Augmentation",
                "sec_num": "7.4"
            },
            {
                "text": "Table 3 presents the DEV set results. Joint+Side Constraints and Joint+Morph+Side Constraints significantly improve over the Joint+Morph baseline with up to 13.87 increase in F 0.5 . The best performing system overall is our multi-step model using all rewrite components -Table 3 (i), henceforth, Our Best Model. It improves over all the joint models in every compared metric, including a 22.84 increase in F 0.5 when compared to the Joint+Morph baseline. Our Best Model's biggest advantages seem to come from combining the three word-level out-of-context gender alternative generation models in a cascaded setup to deal with OOV words during the generation. Comparing (i) with (e,f,g) in Table 3 , we observe improvements ranging from 3.91 to 6.02 F 0.5 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 278,
                        "end": 279,
                        "text": "3",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 695,
                        "end": 696,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "We used Our Best Model to conduct the data augmentation experiments as discussed in \u00a77.4. The full set of augmentation experiment results are presented in Appendix C. The best augmented model's results, which benefits from augmentation in the GID and NeuralR components, are also presented in Table 3 (j). However, its increase of 0.19 points in F 0.5 is not statistically significant with McNemar's (McNemar, 1947) test at p > 0.05.",
                "cite_spans": [
                    {
                        "start": 390,
                        "end": 415,
                        "text": "McNemar's (McNemar, 1947)",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 299,
                        "end": 300,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "The results of our best models on the TEST sets of APGC v2.1 and APGC v1.0 are presented in Table 4 . The results on APGC v2.1 TEST show consistent conclusions with the DEV results. Our best augmented model improves over its nonaugmented variant in every compared metric, including a 0.25 absolute increase in F 0.5 that is statistically significant with McNemar's test at p < 0.05. For APGC v1.0, we do not report results with augmentation for fair comparison to previous results. In both TEST sets, we establish new SOTAs.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 98,
                        "end": 99,
                        "text": "4",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "Error Analysis We conducted an error analysis over the output of our best augmented system on APGC v2.1 DEV. In total, there were 1,475 (5.5% out of 26,588) sentences with errors across the four target corpora. The majority of errors (67.3%) were caused by GID which achieves a word-level accuracy of 98.9% on DEV. The gender-rewriting errors constituted 18.1% and selection errors 14.6%. Considering different target corpora, we observe that every time an F target is added, the number of errors increases. The 1M/2M target outputs has the lowest number of errors (268 or 18%), while the 1M/2F targets outputs has the highest number of errors (480 or 33%).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "Use Case: Post-Editing MT Output We demonstrate next how our proposed gender rewriting model could be used to personalize the output of user-unaware MT systems through post-editing. We use the English to Arabic Google Translate output sentences that are part of APGC v2.1. We evaluate Google Translate's output against all four target corpora (1M/2M, 1F/2M, 1M/2F, 1F/2F) separately. To re-target Google Translate's Arabic output for the four user gender contexts we model, we pass each Arabic sentence four times through our best augmented system (Table 3(j) ). We present the evaluation in terms of BLEU in Table 6 over APGC v2.1 TEST. All the results are reported in an orthographically normalized space for Alif, Ya, and Ta-Marbuta.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 555,
                        "end": 559,
                        "text": "3(j)",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 615,
                        "end": 616,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "Again, we observe that every time an M participant is switched to F, the BLEU scores drop for Google Translate's output. This is consistent to what have been reported by Alhafni et al. (2022) and highlights the bias the machine translation output has towards masculine grammatical gender preferences. The post-edited outputs generated by our best augmented system improves over Google Translate's across the four target user contexts, achieving the highest increase in 2.27 BLEU points for 1F/2F.",
                "cite_spans": [
                    {
                        "start": 170,
                        "end": 191,
                        "text": "Alhafni et al. (2022)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "8"
            },
            {
                "text": "We defined the task of gender rewriting in contexts involving two users (I and/or You), and developed a multi-step system that combines the positive aspects of both rule-based and neural rewriting models. Our best models establish the benchmark for this newly defined task and the SOTA for a previously defined first person version of it. We further demonstrated a use case of our gender rewriting system by post-editing the output of a commercial MT system to provide personalized outputs based on the users' grammatical gender preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "9"
            },
            {
                "text": "In future work, we plan to explore the use of other pretrained models, and to work on the problem of gender rewriting in other languages and dialectal varieties.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "9"
            },
            {
                "text": "Gender Rewriting Our underlying intention of developing a gender rewriting model for Arabic is to increase the inclusiveness of NLP applications that deal with gender-marking morphologically rich languages. Our work aims at empowering and allowing users to interact with NLP technology in a way that is consistent with their social identities. We acknowledge that by limiting the choice of gender expressions to the grammatical gender choices in Arabic, we exclude other alternatives such as non-binary gender or no-gender expressions. However, we are not aware of any sociolinguistics published research that discusses such alternatives for Arabic. We stress on the importance of adapting Arabic NLP models to new gender alternative forms as they emerge as part of the language usage. We further recognize the limitations of the gender identification component we use as part of our multi-step gender rewriting model as it relies on a language model that was pretrained on a large monolingual Arabic corpus, which could possibly contain biased text. We realize the potential risks of our proposed gender rewriting model if it is intentionally maliciously misused to produce gender alternatives that do not match the target users' gender preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ethical Considerations",
                "sec_num": null
            },
            {
                "text": "Data We use the publicly available Arabic Parallel Gender Corpus (APGC). 7 It is subject to its creators' own Copy Rights and User Agreement and we strictly adhere to its intended usage. It is worth 7 http://resources.camel-lab.com/ noting that APGC does not contain any heterocentric assumptions as part of its annotations (e.g., the word 'my husband' is labeled as genderambiguous (B)). Moreover, all proper names are labeled as B, even when they have strong genderspecific association (Alhafni et al., 2022) . The Arabic data we use for our data augmentation experiments was randomly sampled from OpenSubtitles 2018 (Lison and Tiedemann, 2016) , which is publicly available. 8 OpenSubtitles is distributed under a Creative Commons license.9 ",
                "cite_spans": [
                    {
                        "start": 488,
                        "end": 510,
                        "text": "(Alhafni et al., 2022)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 619,
                        "end": 646,
                        "text": "(Lison and Tiedemann, 2016)",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ethical Considerations",
                "sec_num": null
            },
            {
                "text": "Gender Identification We fine-tune CAMeL-BERT MSA on a single GPU for 10 epochs with a learning rate of 5e-5, batch size of 32, a seed of 12345, and a maximum sequence length of 128.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Detailed Experimental Setup",
                "sec_num": null
            },
            {
                "text": "For the augmentation experiments, we use the same hyperparamters but we run the fine-tuning for 3 epochs. At the end of the fine-tuning, we pick the best checkpoint based on the performance on the DEV set. Our gender identification model has 108,506,901 parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Detailed Experimental Setup",
                "sec_num": null
            },
            {
                "text": "In-Context Ranking and Selection We finetune CAMeLBERT MSA on a single GPU for 3 epochs with a learning of 5e-5, batch size of 32, and a seed of 88. The fine-tuned CAMeLBERT MSA model has 109,112,880 parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Detailed Experimental Setup",
                "sec_num": null
            },
            {
                "text": "Neural Rewriter (NeuralR) For the characterlevel encoder-decoder neural rewriter model we use a character embedding size of 128, a hidden size of 256, a dropout probability of 0.2 on the outputs of each GRU layer, and gradient clipping with a maximum norm of 1. We train for 50 epochs on a single GPU with early stopping after 6 epochs if the loss does not decrease on the DEV set. We use the Adam (Kingma and Ba, 2014) optimizer with an initial learning rate of 5e-4, decaying by a factor of 0.5 if the loss on the DEV set does not decrease after 2 epochs. We train with greedy decoding and a batch size of 32. We also apply scheduled sampling (teacher forcing) (Bengio et al., 2015) with a constant sampling probability (0. It is worth noting that all the results presented in this work are reported over a single run and the hyperparameters of our neural models were manually tuned based on the performance on the DEV set. ",
                "cite_spans": [
                    {
                        "start": 663,
                        "end": 684,
                        "text": "(Bengio et al., 2015)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Detailed Experimental Setup",
                "sec_num": null
            },
            {
                "text": "https://github.com/CAMeL-Lab/ gender-rewriting/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Arabic transliteration is in the HSB scheme(Habash et al., 2007).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://resources.camel-lab.com/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We provide code to reconstruct our extended database from the original SAMA 3.1 database (LDC2010L01) which can be obtained from the LDC.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We useSalazar et al. (2020)'s implementation to compute the PLL scores: https://github.com/awslabs/ mlm-scoring",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://opus.nlpl.eu/ OpenSubtitles-v2018.php",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Attribution-Non Commercial 4.0 International.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Rowan Hall Maudslay, Hila Gonen, Ryan Cotterell, and Simone Teufel. 2019. It's all in the name: Mitigating gender bias with name-based counterfactual data substitution. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We thank Alberto Chierici, Christian Khairallah, Go Inoue, and Ossama Obeid for the helpful discussions. We acknowledge the support of the High Performance Computing Center at New York University Abu Dhabi. Finally, we wish to thank the anonymous reviewers at NAACL 2022 for their feedback.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": null
            },
            {
                "text": "When it comes to the data augmentation experiments, we took the best performing system ( 3(i) ). This is attributed to the noisy coverage increase in the CorpusR model and can be observed by the decrease in precision (88.19) and recall (86.66). When we train the GID and the Neu-ralR models on the augmented data (Table 8 (b-c)), we get an increase in F 0.5 reaching 88.28 and 88.12, respectively. However, using both the augmented GID and CorpusR models (Table 8(d) ) decreases the performance slightly as it achieves 88.10 in F 0.5 . The best performing system was the one that uses both the augmented GID and NeuralR models (Table 8 (e)) as it improves over its non-augmented variant reaching 88.30 (0.19 increase) in F 0.5 . Combining the three augmented GID, CorpusR, and NeuralR models (Table 8 (f)) achieves 88.08 in F 0.5 .",
                "cite_spans": [
                    {
                        "start": 455,
                        "end": 466,
                        "text": "(Table 8(d)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 89,
                        "end": 93,
                        "text": "3(i)",
                        "ref_id": null
                    },
                    {
                        "start": 320,
                        "end": 321,
                        "text": "8",
                        "ref_id": null
                    },
                    {
                        "start": 634,
                        "end": 635,
                        "text": "8",
                        "ref_id": null
                    },
                    {
                        "start": 799,
                        "end": 800,
                        "text": "8",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "C Augmentation Experiments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Kareem Darwish, and Younes Samih. 2021. Pre-training bert on arabic tweets: Practical considerations",
                "authors": [
                    {
                        "first": "Ahmed",
                        "middle": [],
                        "last": "Abdelali",
                        "suffix": ""
                    },
                    {
                        "first": "Sabit",
                        "middle": [],
                        "last": "Hassan",
                        "suffix": ""
                    },
                    {
                        "first": "Hamdy",
                        "middle": [],
                        "last": "Mubarak",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ahmed Abdelali, Sabit Hassan, Hamdy Mubarak, Ka- reem Darwish, and Younes Samih. 2021. Pre-training bert on arabic tweets: Practical considerations.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "ARBERT & MARBERT: Deep bidirectional transformers for Arabic",
                "authors": [
                    {
                        "first": "Muhammad",
                        "middle": [],
                        "last": "Abdul-Mageed",
                        "suffix": ""
                    },
                    {
                        "first": "Abdelrahim",
                        "middle": [],
                        "last": "Elmadany",
                        "suffix": ""
                    },
                    {
                        "first": "El",
                        "middle": [],
                        "last": "Moatez",
                        "suffix": ""
                    },
                    {
                        "first": "Billah",
                        "middle": [],
                        "last": "Nagoudi",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "7088--7105",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.acl-long.551"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Muhammad Abdul-Mageed, AbdelRahim Elmadany, and El Moatez Billah Nagoudi. 2021. ARBERT & MARBERT: Deep bidirectional transformers for Ara- bic. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan- guage Processing (Volume 1: Long Papers), pages 7088-7105, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Gender-aware reinflection using linguistically enhanced neural models",
                "authors": [
                    {
                        "first": "Bashar",
                        "middle": [],
                        "last": "Alhafni",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Houda",
                        "middle": [],
                        "last": "Bouamor",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the Second Workshop on Gender Bias in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "139--150",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bashar Alhafni, Nizar Habash, and Houda Bouamor. 2020. Gender-aware reinflection using linguistically enhanced neural models. In Proceedings of the Sec- ond Workshop on Gender Bias in Natural Language Processing, pages 139-150, Barcelona, Spain (On- line). Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "The Arabic Parallel Gender Corpus 2.0: Extensions and analyses",
                "authors": [
                    {
                        "first": "Bashar",
                        "middle": [],
                        "last": "Alhafni",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Houda",
                        "middle": [],
                        "last": "Bouamor",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Proceedings of the 13th Language Resources and Evaluation Conference (LREC)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bashar Alhafni, Nizar Habash, and Houda Bouamor. 2022. The Arabic Parallel Gender Corpus 2.0: Exten- sions and analyses. In Proceedings of the 13th Lan- guage Resources and Evaluation Conference (LREC), Marseille, France.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "AraBERT: Transformer-based model for Arabic language understanding",
                "authors": [
                    {
                        "first": "Fady",
                        "middle": [],
                        "last": "Wissam Antoun",
                        "suffix": ""
                    },
                    {
                        "first": "Hazem",
                        "middle": [],
                        "last": "Baly",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Hajj",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection",
                "volume": "",
                "issue": "",
                "pages": "9--15",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wissam Antoun, Fady Baly, and Hazem Hajj. 2020. AraBERT: Transformer-based model for Arabic lan- guage understanding. In Proceedings of the 4th Work- shop on Open-Source Arabic Corpora and Process- ing Tools, with a Shared Task on Offensive Language Detection, pages 9-15, Marseille, France. European Language Resource Association.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Neural machine translation by jointly learning to align and translate",
                "authors": [
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the International Conference on Learning Representations (ICLR)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings of the International Conference on Learning Representa- tions (ICLR).",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Scheduled sampling for sequence prediction with recurrent neural networks",
                "authors": [
                    {
                        "first": "Samy",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "Oriol",
                        "middle": [],
                        "last": "Vinyals",
                        "suffix": ""
                    },
                    {
                        "first": "Navdeep",
                        "middle": [],
                        "last": "Jaitly",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled sampling for sequence prediction with recurrent neural networks. CoRR, abs/1506.03099.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Language (technology) is power: A critical survey of \"bias\" in NLP",
                "authors": [
                    {
                        "first": "Lin",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "Solon",
                        "middle": [],
                        "last": "Blodgett",
                        "suffix": ""
                    },
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Barocas",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Hanna",
                        "middle": [],
                        "last": "Wallach",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "5454--5476",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.485"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Su Lin Blodgett, Solon Barocas, Hal Daum\u00e9 III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of \"bias\" in NLP. In Pro- ceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 5454- 5476, Online. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
                "authors": [
                    {
                        "first": "Tolga",
                        "middle": [],
                        "last": "Bolukbasi",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "James",
                        "middle": [
                            "Y"
                        ],
                        "last": "Zou",
                        "suffix": ""
                    },
                    {
                        "first": "Venkatesh",
                        "middle": [],
                        "last": "Saligrama",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [
                            "T"
                        ],
                        "last": "Kalai",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "29",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to computer programmer as woman is to home- maker? debiasing word embeddings. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Identifying and reducing gender bias in word-level language models",
                "authors": [
                    {
                        "first": "Shikha",
                        "middle": [],
                        "last": "Bordia",
                        "suffix": ""
                    },
                    {
                        "first": "Samuel",
                        "middle": [
                            "R"
                        ],
                        "last": "Bowman",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter",
                "volume": "",
                "issue": "",
                "pages": "7--15",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-3002"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Shikha Bordia and Samuel R. Bowman. 2019. Identify- ing and reducing gender bias in word-level language models. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Work- shop, pages 7-15, Minneapolis, Minnesota.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Conversational assistants and gender stereotypes: Public perceptions and desiderata for voice personas",
                "authors": [
                    {
                        "first": "Amanda Cercas",
                        "middle": [],
                        "last": "Curry",
                        "suffix": ""
                    },
                    {
                        "first": "Judy",
                        "middle": [],
                        "last": "Robertson",
                        "suffix": ""
                    },
                    {
                        "first": "Verena",
                        "middle": [],
                        "last": "Rieser",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the Second Workshop on Gender Bias in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "72--78",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Amanda Cercas Curry, Judy Robertson, and Verena Rieser. 2020. Conversational assistants and gender stereotypes: Public perceptions and desiderata for voice personas. In Proceedings of the Second Work- shop on Gender Bias in Natural Language Process- ing, pages 72-78, Barcelona, Spain (Online). Associ- ation for Computational Linguistics.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
                "authors": [
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Bart",
                        "middle": [],
                        "last": "Van Merri\u00ebnboer",
                        "suffix": ""
                    },
                    {
                        "first": "Caglar",
                        "middle": [],
                        "last": "Gulcehre",
                        "suffix": ""
                    },
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Fethi",
                        "middle": [],
                        "last": "Bougares",
                        "suffix": ""
                    },
                    {
                        "first": "Holger",
                        "middle": [],
                        "last": "Schwenk",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "1724--1734",
                "other_ids": {
                    "DOI": [
                        "10.3115/v1/D14-1179"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Kyunghyun Cho, Bart van Merri\u00ebnboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724- 1734, Doha, Qatar.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Jason Eisner, and Mans Hulden. 2018. The CoNLL-SIGMORPHON 2018 shared task: Universal morphological reinflection",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Cotterell",
                        "suffix": ""
                    },
                    {
                        "first": "Christo",
                        "middle": [],
                        "last": "Kirov",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Sylak-Glassman",
                        "suffix": ""
                    },
                    {
                        "first": "G\u00e9raldine",
                        "middle": [],
                        "last": "Walther",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Vylomova",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Arya",
                        "suffix": ""
                    },
                    {
                        "first": "Katharina",
                        "middle": [],
                        "last": "Mc-Carthy",
                        "suffix": ""
                    },
                    {
                        "first": "Sabrina",
                        "middle": [
                            "J"
                        ],
                        "last": "Kann",
                        "suffix": ""
                    },
                    {
                        "first": "Garrett",
                        "middle": [],
                        "last": "Mielke",
                        "suffix": ""
                    },
                    {
                        "first": "Miikka",
                        "middle": [],
                        "last": "Nicolai",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Silfverberg",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Yarowsky",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the CoNLL-SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection",
                "volume": "",
                "issue": "",
                "pages": "1--27",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/K18-3001"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\u00e9raldine Walther, Ekaterina Vylomova, Arya D. Mc- Carthy, Katharina Kann, Sabrina J. Mielke, Garrett Nicolai, Miikka Silfverberg, David Yarowsky, Ja- son Eisner, and Mans Hulden. 2018. The CoNLL- SIGMORPHON 2018 shared task: Universal mor- phological reinflection. In Proceedings of the CoNLL-SIGMORPHON 2018 Shared Task: Univer- sal Morphological Reinflection, pages 1-27, Brussels. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "CoNLL-SIGMORPHON 2017 shared task: Universal morphological reinflection in 52 languages",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Cotterell",
                        "suffix": ""
                    },
                    {
                        "first": "Christo",
                        "middle": [],
                        "last": "Kirov",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Sylak-Glassman",
                        "suffix": ""
                    },
                    {
                        "first": "G\u00e9raldine",
                        "middle": [],
                        "last": "Walther",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Vylomova",
                        "suffix": ""
                    },
                    {
                        "first": "Patrick",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Manaal",
                        "middle": [],
                        "last": "Faruqui",
                        "suffix": ""
                    },
                    {
                        "first": "Sandra",
                        "middle": [],
                        "last": "K\u00fcbler",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Yarowsky",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Mans",
                        "middle": [],
                        "last": "Hulden",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\u00e9raldine Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Sandra K\u00fcbler, David Yarowsky, Jason Eisner, and Mans Hulden. 2017. CoNLL- SIGMORPHON 2017 shared task: Universal mor- phological reinflection in 52 languages. CoRR, abs/1706.09031.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "The SIGMORPHON 2016 shared taskmorphological reinflection",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Cotterell",
                        "suffix": ""
                    },
                    {
                        "first": "Christo",
                        "middle": [],
                        "last": "Kirov",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Sylak-Glassman",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Yarowsky",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Mans",
                        "middle": [],
                        "last": "Hulden",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Workshop of the Special Interest Group on Computational Morphology and Phonology (SIGMORPHON)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, David Yarowsky, Jason Eisner, and Mans Hulden. 2016. The SIGMORPHON 2016 shared task- morphological reinflection. In Proceedings of the Workshop of the Special Interest Group on Computa- tional Morphology and Phonology (SIGMORPHON), Berlin, Germany.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Better evaluation for grammatical error correction",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Dahlmeier",
                        "suffix": ""
                    },
                    {
                        "first": "Hwee Tou",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "",
                "issue": "",
                "pages": "568--572",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Dahlmeier and Hwee Tou Ng. 2012. Better evaluation for grammatical error correction. In Pro- ceedings of the 2012 Conference of the North Amer- ican Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 568-572, Montr\u00e9al, Canada.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Devlin",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "4171--4186",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1423"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Queens are powerful too: Mitigating gender bias in dialogue generation",
                "authors": [
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Dinan",
                        "suffix": ""
                    },
                    {
                        "first": "Angela",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Adina",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    },
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Urbanek",
                        "suffix": ""
                    },
                    {
                        "first": "Douwe",
                        "middle": [],
                        "last": "Kiela",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "8173--8188",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.emnlp-main.656"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Emily Dinan, Angela Fan, Adina Williams, Jack Ur- banek, Douwe Kiela, and Jason Weston. 2020. Queens are powerful too: Mitigating gender bias in dialogue generation. In Proceedings of the 2020 Con- ference on Empirical Methods in Natural Language Processing (EMNLP), pages 8173-8188, Online. As- sociation for Computational Linguistics.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them",
                "authors": [
                    {
                        "first": "Hila",
                        "middle": [],
                        "last": "Gonen",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hila Gonen and Yoav Goldberg. 2019. Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Standard Arabic Morphological Analyzer (SAMA) Version 3.1. Linguistic Data Consortium LDC",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Graff",
                        "suffix": ""
                    },
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Maamouri",
                        "suffix": ""
                    },
                    {
                        "first": "Basma",
                        "middle": [],
                        "last": "Bouziri",
                        "suffix": ""
                    },
                    {
                        "first": "Sondos",
                        "middle": [],
                        "last": "Krouna",
                        "suffix": ""
                    },
                    {
                        "first": "Seth",
                        "middle": [],
                        "last": "Kulick",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "73",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Graff, Mohamed Maamouri, Basma Bouziri, Sondos Krouna, Seth Kulick, and Tim Buckwal- ter. 2009. Standard Arabic Morphological Analyzer (SAMA) Version 3.1. Linguistic Data Consortium LDC2009E73.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "A kernel method for the two-sample-problem",
                "authors": [
                    {
                        "first": "Arthur",
                        "middle": [],
                        "last": "Gretton",
                        "suffix": ""
                    },
                    {
                        "first": "Karsten",
                        "middle": [],
                        "last": "Borgwardt",
                        "suffix": ""
                    },
                    {
                        "first": "Malte",
                        "middle": [],
                        "last": "Rasch",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "19",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bern- hard Sch\u00f6lkopf, and Alex Smola. 2006. A kernel method for the two-sample-problem. In Advances in Neural Information Processing Systems, volume 19. MIT Press.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Automatic gender identification and reinflection in Arabic",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Houda",
                        "middle": [],
                        "last": "Bouamor",
                        "suffix": ""
                    },
                    {
                        "first": "Christine",
                        "middle": [],
                        "last": "Chung",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "155--165",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W19-3822"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Houda Bouamor, and Christine Chung. 2019. Automatic gender identification and reinflec- tion in Arabic. In Proceedings of the First Workshop on Gender Bias in Natural Language Processing, pages 155-165, Florence, Italy.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "On Arabic Transliteration",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Abdelhadi",
                        "middle": [],
                        "last": "Soudi",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Buckwalter",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Arabic Computational Morphology: Knowledge-based and Empirical Methods",
                "volume": "",
                "issue": "",
                "pages": "15--22",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Meth- ods, pages 15-22. Springer, Netherlands.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Introduction to Arabic natural language processing",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Nizar",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "volume": "3",
                "issue": "",
                "pages": "5267--5275",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Y Habash. 2010. Introduction to Arabic natural language processing, volume 3. Morgan & Claypool Publishers. and the 9th International Joint Conference on Natu- ral Language Processing (EMNLP-IJCNLP), pages 5267-5275, Hong Kong, China.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "The interplay of variant, size, and task type in Arabic pre-trained language models",
                "authors": [
                    {
                        "first": "Go",
                        "middle": [],
                        "last": "Inoue",
                        "suffix": ""
                    },
                    {
                        "first": "Bashar",
                        "middle": [],
                        "last": "Alhafni",
                        "suffix": ""
                    },
                    {
                        "first": "Nurpeiis",
                        "middle": [],
                        "last": "Baimukan",
                        "suffix": ""
                    },
                    {
                        "first": "Houda",
                        "middle": [],
                        "last": "Bouamor",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the Sixth Arabic Natural Language Processing Workshop",
                "volume": "",
                "issue": "",
                "pages": "92--104",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Go Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda Bouamor, and Nizar Habash. 2021. The interplay of variant, size, and task type in Arabic pre-trained language models. In Proceedings of the Sixth Arabic Natural Language Processing Workshop, pages 92- 104, Kyiv, Ukraine (Virtual). Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Generating gender augmented data for NLP",
                "authors": [
                    {
                        "first": "Nishtha",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Maja",
                        "middle": [],
                        "last": "Popovi\u0107",
                        "suffix": ""
                    },
                    {
                        "first": "Declan",
                        "middle": [],
                        "last": "Groves",
                        "suffix": ""
                    },
                    {
                        "first": "Eva",
                        "middle": [],
                        "last": "Vanmassenhove",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "93--102",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.gebnlp-1.11"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nishtha Jain, Maja Popovi\u0107, Declan Groves, and Eva Vanmassenhove. 2021. Generating gender aug- mented data for NLP. In Proceedings of the 3rd Workshop on Gender Bias in Natural Language Pro- cessing, pages 93-102, Online. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Singlemodel encoder-decoder with explicit morphological representation for reinflection",
                "authors": [
                    {
                        "first": "Katharina",
                        "middle": [],
                        "last": "Kann",
                        "suffix": ""
                    },
                    {
                        "first": "Hinrich",
                        "middle": [],
                        "last": "Sch\u00fctze",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "volume": "2",
                "issue": "",
                "pages": "555--560",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P16-2090"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Katharina Kann and Hinrich Sch\u00fctze. 2016. Single- model encoder-decoder with explicit morphological representation for reinflection. In Proceedings of the 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 2: Short Papers), pages 555-560, Berlin, Germany.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Adam: A method for stochastic optimization",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Diederik",
                        "suffix": ""
                    },
                    {
                        "first": "Jimmy",
                        "middle": [],
                        "last": "Kingma",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ba",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1412.6980"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles",
                "authors": [
                    {
                        "first": "Pierre",
                        "middle": [],
                        "last": "Lison",
                        "suffix": ""
                    },
                    {
                        "first": "J\u00f6rg",
                        "middle": [],
                        "last": "Tiedemann",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Language Resources and Evaluation Conference (LREC)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pierre Lison and J\u00f6rg Tiedemann. 2016. OpenSubti- tles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the Lan- guage Resources and Evaluation Conference (LREC), Portoro\u017e, Slovenia.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Does gender matter? towards fairness in dialogue systems",
                "authors": [
                    {
                        "first": "Haochen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jamell",
                        "middle": [],
                        "last": "Dacon",
                        "suffix": ""
                    },
                    {
                        "first": "Wenqi",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Hui",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zitao",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jiliang",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "4403--4416",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.coling-main.390"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Haochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu, and Jiliang Tang. 2020a. Does gender matter? towards fairness in dialogue systems. In Proceed- ings of the 28th International Conference on Com- putational Linguistics, pages 4403-4416, Barcelona, Spain (Online). International Committee on Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Mitigating gender bias for neural dialogue generation with adversarial learning",
                "authors": [
                    {
                        "first": "Haochen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Wentao",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yiqi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Hui",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zitao",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jiliang",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "893--903",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.emnlp-main.64"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Haochen Liu, Wentao Wang, Yiqi Wang, Hui Liu, Zitao Liu, and Jiliang Tang. 2020b. Mitigating gender bias for neural dialogue generation with adversarial learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 893-903, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Preetam Amancharla, and Anupam Datta",
                "authors": [
                    {
                        "first": "Kaiji",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Piotr",
                        "middle": [],
                        "last": "Mardziel",
                        "suffix": ""
                    },
                    {
                        "first": "Fangjing",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Gender bias in neural natural language processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kaiji Lu, Piotr Mardziel, Fangjing Wu, Preetam Aman- charla, and Anupam Datta. 2018. Gender bias in neural natural language processing.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Manzini",
                        "suffix": ""
                    },
                    {
                        "first": "Lim",
                        "middle": [],
                        "last": "Yao Chong",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [
                            "W"
                        ],
                        "last": "Black",
                        "suffix": ""
                    },
                    {
                        "first": "Yulia",
                        "middle": [],
                        "last": "Tsvetkov",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "615--621",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1062"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Thomas Manzini, Lim Yao Chong, Alan W Black, and Yulia Tsvetkov. 2019. Black is to criminal as cau- casian is to police: Detecting and removing multi- class bias in word embeddings. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 615-621, Minneapolis, Min- nesota. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Note on the sampling error of the difference between correlated proportions or percentages",
                "authors": [
                    {
                        "first": "Quinn",
                        "middle": [],
                        "last": "Mcnemar",
                        "suffix": ""
                    }
                ],
                "year": 1947,
                "venue": "Psychometrika",
                "volume": "12",
                "issue": "2",
                "pages": "153--157",
                "other_ids": {
                    "DOI": [
                        "10.1007/BF02295996"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Quinn McNemar. 1947. Note on the sampling error of the difference between correlated proportions or percentages. Psychometrika, 12(2):153-157.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Man is to person as woman is to location: Measuring gender bias in named entity recognition",
                "authors": [
                    {
                        "first": "Ninareh",
                        "middle": [],
                        "last": "Mehrabi",
                        "suffix": ""
                    },
                    {
                        "first": "Thamme",
                        "middle": [],
                        "last": "Gowda",
                        "suffix": ""
                    },
                    {
                        "first": "Fred",
                        "middle": [],
                        "last": "Morstatter",
                        "suffix": ""
                    },
                    {
                        "first": "Nanyun",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Aram",
                        "middle": [],
                        "last": "Galstyan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ninareh Mehrabi, Thamme Gowda, Fred Morstatter, Nanyun Peng, and Aram Galstyan. 2019. Man is to person as woman is to location: Measuring gender bias in named entity recognition.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "StereoSet: Measuring stereotypical bias in pretrained language models",
                "authors": [
                    {
                        "first": "Moin",
                        "middle": [],
                        "last": "Nadeem",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Bethke",
                        "suffix": ""
                    },
                    {
                        "first": "Siva",
                        "middle": [],
                        "last": "Reddy",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "5356--5371",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.acl-long.416"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Moin Nadeem, Anna Bethke, and Siva Reddy. 2021. StereoSet: Measuring stereotypical bias in pretrained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Lin- guistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5356-5371, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "CAMeL tools: An open source python toolkit for Arabic natural language processing",
                "authors": [
                    {
                        "first": "Ossama",
                        "middle": [],
                        "last": "Obeid",
                        "suffix": ""
                    },
                    {
                        "first": "Nasser",
                        "middle": [],
                        "last": "Zalmout",
                        "suffix": ""
                    },
                    {
                        "first": "Salam",
                        "middle": [],
                        "last": "Khalifa",
                        "suffix": ""
                    },
                    {
                        "first": "Dima",
                        "middle": [],
                        "last": "Taji",
                        "suffix": ""
                    },
                    {
                        "first": "Mai",
                        "middle": [],
                        "last": "Oudah",
                        "suffix": ""
                    },
                    {
                        "first": "Bashar",
                        "middle": [],
                        "last": "Alhafni",
                        "suffix": ""
                    },
                    {
                        "first": "Go",
                        "middle": [],
                        "last": "Inoue",
                        "suffix": ""
                    },
                    {
                        "first": "Fadhl",
                        "middle": [],
                        "last": "Eryani",
                        "suffix": ""
                    },
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Erdmann",
                        "suffix": ""
                    },
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of The 12th Language Resources and Evaluation Conference",
                "volume": "",
                "issue": "",
                "pages": "7022--7032",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ossama Obeid, Nasser Zalmout, Salam Khalifa, Dima Taji, Mai Oudah, Bashar Alhafni, Go Inoue, Fadhl Eryani, Alexander Erdmann, and Nizar Habash. 2020. CAMeL tools: An open source python toolkit for Ara- bic natural language processing. In Proceedings of The 12th Language Resources and Evaluation Con- ference, pages 7022-7032, Marseille, France. Euro- pean Language Resources Association.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "BLEU: a Method for Automatic Evaluation of Machine Translation",
                "authors": [
                    {
                        "first": "Kishore",
                        "middle": [],
                        "last": "Papineni",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    },
                    {
                        "first": "Todd",
                        "middle": [],
                        "last": "Ward",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Jing",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "311--318",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the Conference of the Association for Computa- tional Linguistics (ACL), pages 311-318, Philadel- phia, Pennsylvania, USA.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "A call for clarity in reporting BLEU scores",
                "authors": [
                    {
                        "first": "Matt",
                        "middle": [],
                        "last": "Post",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "volume": "",
                "issue": "",
                "pages": "186--191",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-6319"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Matt Post. 2018. A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186- 191, Brussels, Belgium.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Personalized machine translation: Preserving original author traits",
                "authors": [
                    {
                        "first": "Ella",
                        "middle": [],
                        "last": "Rabinovich",
                        "suffix": ""
                    },
                    {
                        "first": "Raj",
                        "middle": [
                            "Nath"
                        ],
                        "last": "Patel",
                        "suffix": ""
                    },
                    {
                        "first": "Shachar",
                        "middle": [],
                        "last": "Mirkin",
                        "suffix": ""
                    },
                    {
                        "first": "Lucia",
                        "middle": [],
                        "last": "Specia",
                        "suffix": ""
                    },
                    {
                        "first": "Shuly",
                        "middle": [],
                        "last": "Wintner",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 15th Conference of the European Chapter",
                "volume": "1",
                "issue": "",
                "pages": "1074--1084",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ella Rabinovich, Raj Nath Patel, Shachar Mirkin, Lucia Specia, and Shuly Wintner. 2017. Personalized ma- chine translation: Preserving original author traits. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Lin- guistics: Volume 1, Long Papers, pages 1074-1084, Valencia, Spain.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Gender bias in coreference resolution",
                "authors": [
                    {
                        "first": "Rachel",
                        "middle": [],
                        "last": "Rudinger",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Naradowsky",
                        "suffix": ""
                    },
                    {
                        "first": "Brian",
                        "middle": [],
                        "last": "Leonard",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter",
                "volume": "2",
                "issue": "",
                "pages": "8--14",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-2002"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme. 2018. Gender bias in coreference resolution. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 8-14, New Orleans, Louisiana.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Masked language model scoring",
                "authors": [
                    {
                        "first": "Julian",
                        "middle": [],
                        "last": "Salazar",
                        "suffix": ""
                    },
                    {
                        "first": "Davis",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Toan",
                        "middle": [
                            "Q"
                        ],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "Katrin",
                        "middle": [],
                        "last": "Kirchhoff",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2699--2712",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.240"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Julian Salazar, Davis Liang, Toan Q. Nguyen, and Ka- trin Kirchhoff. 2020. Masked language model scor- ing. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2699-2712, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Gender Bias in Machine Translation",
                "authors": [
                    {
                        "first": "Beatrice",
                        "middle": [],
                        "last": "Savoldi",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Gaido",
                        "suffix": ""
                    },
                    {
                        "first": "Luisa",
                        "middle": [],
                        "last": "Bentivogli",
                        "suffix": ""
                    },
                    {
                        "first": "Matteo",
                        "middle": [],
                        "last": "Negri",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Turchi",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "9",
                "issue": "",
                "pages": "845--874",
                "other_ids": {
                    "DOI": [
                        "10.1162/tacl_a_00401"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Beatrice Savoldi, Marco Gaido, Luisa Bentivogli, Mat- teo Negri, and Marco Turchi. 2021. Gender Bias in Machine Translation. Transactions of the Associa- tion for Computational Linguistics, 9:845-874.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Controlling politeness in neural machine translation via side constraints",
                "authors": [
                    {
                        "first": "Rico",
                        "middle": [],
                        "last": "Sennrich",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Haddow",
                        "suffix": ""
                    },
                    {
                        "first": "Alexandra",
                        "middle": [],
                        "last": "Birch",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "",
                "issue": "",
                "pages": "35--40",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N16-1005"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Controlling politeness in neural machine trans- lation via side constraints. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 35-40, San Diego, California. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Revealing persona biases in dialogue systems",
                "authors": [
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Sheng",
                        "suffix": ""
                    },
                    {
                        "first": "Josh",
                        "middle": [],
                        "last": "Arnold",
                        "suffix": ""
                    },
                    {
                        "first": "Zhou",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Nanyun",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Emily Sheng, Josh Arnold, Zhou Yu, Kai-Wei Chang, and Nanyun Peng. 2021. Revealing persona biases in dialogue systems.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "The woman worked as a babysitter: On biases in language generation",
                "authors": [
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Sheng",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Premkumar",
                        "middle": [],
                        "last": "Natarajan",
                        "suffix": ""
                    },
                    {
                        "first": "Nanyun",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "volume": "",
                "issue": "",
                "pages": "3407--3412",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D19-1339"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, and Nanyun Peng. 2019. The woman worked as a babysitter: On biases in language generation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan- guage Processing (EMNLP-IJCNLP), pages 3407- 3412, Hong Kong, China.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Mitigating gender bias in machine translation with target gender annotations",
                "authors": [
                    {
                        "first": "Art\u016brs",
                        "middle": [],
                        "last": "Stafanovi\u010ds",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Art\u016brs Stafanovi\u010ds, Toms Bergmanis, and M\u0101rcis Pinnis. 2020. Mitigating gender bias in machine translation with target gender annotations.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Synthetic data generation for grammatical error correction with tagged corruption models",
                "authors": [
                    {
                        "first": "Felix",
                        "middle": [],
                        "last": "Stahlberg",
                        "suffix": ""
                    },
                    {
                        "first": "Shankar",
                        "middle": [],
                        "last": "Kumar",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications",
                "volume": "",
                "issue": "",
                "pages": "37--47",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Felix Stahlberg and Shankar Kumar. 2021. Synthetic data generation for grammatical error correction with tagged corruption models. In Proceedings of the 16th Workshop on Innovative Use of NLP for Build- ing Educational Applications, pages 37-47, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Mitigating gender bias in natural language processing: Literature review",
                "authors": [
                    {
                        "first": "Tony",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Gaut",
                        "suffix": ""
                    },
                    {
                        "first": "Shirlyn",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxin",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Mai",
                        "middle": [],
                        "last": "Elsherief",
                        "suffix": ""
                    },
                    {
                        "first": "Jieyu",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Diba",
                        "middle": [],
                        "last": "Mirza",
                        "suffix": ""
                    },
                    {
                        "first": "Elizabeth",
                        "middle": [],
                        "last": "Belding",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Wang",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1630--1640",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P19-1159"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. 2019. Mitigating gender bias in natural language processing: Literature review. In Proceedings of the 57th Annual Meeting of the Association for Computa- tional Linguistics, pages 1630-1640, Florence, Italy. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "They, them, theirs: Rewriting with gender-neutral english",
                "authors": [
                    {
                        "first": "Tony",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Kellie",
                        "middle": [],
                        "last": "Webster",
                        "suffix": ""
                    },
                    {
                        "first": "Apu",
                        "middle": [],
                        "last": "Shah",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Wang",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Melvin",
                        "middle": [],
                        "last": "Johnson",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tony Sun, Kellie Webster, Apu Shah, William Yang Wang, and Melvin Johnson. 2021. They, them, theirs: Rewriting with gender-neutral english.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "NeuTral Rewriter: A rule-based and neural approach to automatic rewriting into gender neutral alternatives",
                "authors": [
                    {
                        "first": "Eva",
                        "middle": [],
                        "last": "Vanmassenhove",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Emmery",
                        "suffix": ""
                    },
                    {
                        "first": "Dimitar",
                        "middle": [],
                        "last": "Shterionov",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "8940--8948",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.emnlp-main.704"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Eva Vanmassenhove, Chris Emmery, and Dimitar Shteri- onov. 2021. NeuTral Rewriter: A rule-based and neu- ral approach to automatic rewriting into gender neu- tral alternatives. In Proceedings of the 2021 Confer- ence on Empirical Methods in Natural Language Pro- cessing, pages 8940-8948, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Getting gender right in neural machine translation",
                "authors": [
                    {
                        "first": "Eva",
                        "middle": [],
                        "last": "Vanmassenhove",
                        "suffix": ""
                    },
                    {
                        "first": "Christian",
                        "middle": [],
                        "last": "Hardmeier",
                        "suffix": ""
                    },
                    {
                        "first": "Andy",
                        "middle": [],
                        "last": "Way",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "3003--3008",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1334"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018. Getting gender right in neural machine translation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Process- ing, pages 3003-3008, Brussels, Belgium.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Investigating gender bias in language models using causal mediation analysis",
                "authors": [
                    {
                        "first": "Jesse",
                        "middle": [],
                        "last": "Vig",
                        "suffix": ""
                    },
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Gehrmann",
                        "suffix": ""
                    },
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Belinkov",
                        "suffix": ""
                    },
                    {
                        "first": "Sharon",
                        "middle": [],
                        "last": "Qian",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Nevo",
                        "suffix": ""
                    },
                    {
                        "first": "Yaron",
                        "middle": [],
                        "last": "Singer",
                        "suffix": ""
                    },
                    {
                        "first": "Stuart",
                        "middle": [],
                        "last": "Shieber",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "33",
                "issue": "",
                "pages": "12388--12401",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer, and Stu- art Shieber. 2020. Investigating gender bias in lan- guage models using causal mediation analysis. In Advances in Neural Information Processing Systems, volume 33, pages 12388-12401. Curran Associates, Inc.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Improving grammatical error correction with data augmentation by editing latent representation",
                "authors": [
                    {
                        "first": "Zhaohong",
                        "middle": [],
                        "last": "Wan",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaojun",
                        "middle": [],
                        "last": "Wan",
                        "suffix": ""
                    },
                    {
                        "first": "Wenguang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2202--2212",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.coling-main.200"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Zhaohong Wan, Xiaojun Wan, and Wenguang Wang. 2020. Improving grammatical error correction with data augmentation by editing latent representation. In Proceedings of the 28th International Conference on Computational Linguistics, pages 2202-2212, Barcelona, Spain (Online). International Committee on Computational Linguistics.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Transformers: State-of-the-art natural language processing",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Wolf",
                        "suffix": ""
                    },
                    {
                        "first": "Lysandre",
                        "middle": [],
                        "last": "Debut",
                        "suffix": ""
                    },
                    {
                        "first": "Victor",
                        "middle": [],
                        "last": "Sanh",
                        "suffix": ""
                    },
                    {
                        "first": "Julien",
                        "middle": [],
                        "last": "Chaumond",
                        "suffix": ""
                    },
                    {
                        "first": "Clement",
                        "middle": [],
                        "last": "Delangue",
                        "suffix": ""
                    },
                    {
                        "first": "Anthony",
                        "middle": [],
                        "last": "Moi",
                        "suffix": ""
                    },
                    {
                        "first": "Pierric",
                        "middle": [],
                        "last": "Cistac",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Rault",
                        "suffix": ""
                    },
                    {
                        "first": "Remi",
                        "middle": [],
                        "last": "Louf",
                        "suffix": ""
                    },
                    {
                        "first": "Morgan",
                        "middle": [],
                        "last": "Funtowicz",
                        "suffix": ""
                    },
                    {
                        "first": "Joe",
                        "middle": [],
                        "last": "Davison",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Shleifer",
                        "suffix": ""
                    },
                    {
                        "first": "Clara",
                        "middle": [],
                        "last": "Patrick Von Platen",
                        "suffix": ""
                    },
                    {
                        "first": "Yacine",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Julien",
                        "middle": [],
                        "last": "Jernite",
                        "suffix": ""
                    },
                    {
                        "first": "Canwen",
                        "middle": [],
                        "last": "Plu",
                        "suffix": ""
                    },
                    {
                        "first": "Teven",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Sylvain",
                        "middle": [],
                        "last": "Le Scao",
                        "suffix": ""
                    },
                    {
                        "first": "Mariama",
                        "middle": [],
                        "last": "Gugger",
                        "suffix": ""
                    },
                    {
                        "first": "Quentin",
                        "middle": [],
                        "last": "Drame",
                        "suffix": ""
                    },
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Lhoest",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Rush",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "38--45",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.emnlp-demos.6"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, Remi Louf, Morgan Funtow- icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Trans- formers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "Gender bias in multilingual embeddings and crosslingual transfer",
                "authors": [
                    {
                        "first": "Jieyu",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Subhabrata",
                        "middle": [],
                        "last": "Mukherjee",
                        "suffix": ""
                    },
                    {
                        "first": "Saghar",
                        "middle": [],
                        "last": "Hosseini",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmed",
                        "middle": [],
                        "last": "Hassan",
                        "suffix": ""
                    },
                    {
                        "first": "Awadallah",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2896--2907",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.260"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jieyu Zhao, Subhabrata Mukherjee, Saghar Hosseini, Kai-Wei Chang, and Ahmed Hassan Awadallah. 2020. Gender bias in multilingual embeddings and cross- lingual transfer. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, pages 2896-2907, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Gender bias in coreference resolution: Evaluation and debiasing methods",
                "authors": [
                    {
                        "first": "Jieyu",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Tianlu",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Yatskar",
                        "suffix": ""
                    },
                    {
                        "first": "Vicente",
                        "middle": [],
                        "last": "Ordonez",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter",
                "volume": "2",
                "issue": "",
                "pages": "15--20",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-2003"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Or- donez, and Kai-Wei Chang. 2018a. Gender bias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 15-20, New Orleans, Louisiana.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "Learning gender-neutral word embeddings",
                "authors": [
                    {
                        "first": "Jieyu",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Yichao",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Zeyu",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "4847--4853",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1521"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang, and Kai- Wei Chang. 2018b. Learning gender-neutral word embeddings. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Process- ing, pages 4847-4853, Brussels, Belgium.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "b58",
                "title": "Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology",
                "authors": [
                    {
                        "first": "Ran",
                        "middle": [],
                        "last": "Zmigrod",
                        "suffix": ""
                    },
                    {
                        "first": "Sabrina",
                        "middle": [
                            "J"
                        ],
                        "last": "Mielke",
                        "suffix": ""
                    },
                    {
                        "first": "Hanna",
                        "middle": [],
                        "last": "Wallach",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Cotterell",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1651--1661",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P19-1161"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ran Zmigrod, Sabrina J. Mielke, Hanna Wallach, and Ryan Cotterell. 2019. Counterfactual data augmenta- tion for mitigating gender stereotypes in languages with rich morphology. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1651-1661, Florence, Italy.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF1": {
                "num": null,
                "text": "We useAlhafni et al. (2022)'s splits: 57,603 sentences (427,523 words) for training (TRAIN), 6,647 sentences (49,257 words) for development (DEV), and 16,076 sentences (120,019 words) for testing (TEST).",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 1: The multi-step gender rewriting system. First person gendered words are in purple and second person gendered words are in red. The sentence-level target gender is 1M/2M. The input words glad (1F+B), know you (B+2F), and ladies (2F+B) are rewritten to their masculine forms.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "3) during training. During inference, we use beam search with a beam width of 10 to produce the top 3-best hypotheses. Our NeuralR model has 3,287,110 parameters. Joint Models The training settings and the hyperparameters of the joint models are identical to the ones we use in our NeuralR model. The crucial difference between the Joint+Morph model and its extended variants (Joint+Side Constraints and Joint+Morph+Side Constraints) is that the rewriting in the Joint+Morph model is conditioned on the sentence-level target gender. The representation of the sentence-level target gender in the baseline model is learned as an embedding of size 10 during training and only used in the decoder. Our Joint+Morph model has 3,481,178 parameters; the Joint+Side Constraints model has 3,293,258 parameters; and the Joint+Morph+Side Constraints model has 3,480,926 parameters. Training Time The CorpusR model was trained on a single CPU and it took \u22482 minutes to be trained. All our neural models were trained on a single GPU. Fine-tuning CAMeLBERT MSA on the gender identification task took \u22481 hour; finetuning CAMeLBERT MSA on the MLM objective took \u22481 hour. Training the NeuralR model with different settings took \u224812 hours in total. All the baseline joint models took \u224829 hours to be trained.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>. This</td></tr></table>",
                "type_str": "table",
                "text": "Examples of the changes needed to generate gender alternative forms of gender-specific words in Arabic.",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Examples from the Arabic Parallel Gender Corpus v2.0 including the extended word-level annotations for each sentence and its rewrite to the opposite grammatical gender forms where appropriate. First person gendered words are in purple and second person gendered words are in red. M is Masculine; F is Feminine; and B is invariant.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td colspan=\"2\">(a) Do Nothing (b) Joint + Morph</td><td>P 100.0 0.0 0.0 89.36 R F 0.5 BLEU 64.76 67.40 65.27 93.31</td></tr><tr><td>(c) Joint (d) Joint</td><td>+ Side Constraints + Morph + Side Constraints</td><td>77.10 77.71 77.22 95.60 78.97 79.84 79.14 96.17</td></tr><tr><td>(e) GID (f) GID (g) GID</td><td>+ CorpusR + Selection + MorphR + Selection + NeuralR + Selection</td><td>88.22 71.22 84.20 96.54 84.48 75.29 82.47 96.96 84.62 73.32 82.09 96.75</td></tr><tr><td>(h) GID (i) GID</td><td>+ CorpusR \u00bb MorphR + Selection + CorpusR \u00bb MorphR \u00bb NeuralR</td><td>88.59 85.84 88.02 97.96 + Selection 88.46 86.74 88.11 98.04</td></tr><tr><td>(j)</td><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Table 5 presents a summary of the error types our best augmented gender rewriting model makes. GID Aug + CorpusR \u00bb MorphR \u00bb NeuralR Aug + Selection 88.67 86.84 88.30 98.05",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td>P</td><td>R</td><td>F 0.5 BLEU</td></tr></table>",
                "type_str": "table",
                "text": "Results of a number of systems on the DEV set of APGC v2.1. Aug indicates using augmented data.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td/><td colspan=\"4\">1M/2M 1F/2M 1M/2F 1F/2F</td></tr><tr><td colspan=\"5\">150 56% 194 70% 325 68% 324 72% Rewrite 69 26% 50 18% 82 17% 66 15% GID Select 49 18% 35 13% 73 15% 58 13%</td></tr><tr><td>Total</td><td>268</td><td>279</td><td>480</td><td>448</td></tr></table>",
                "type_str": "table",
                "text": "Gender rewriting results on the TEST sets of APGC v2.1 and APGC v1.0.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td>Target</td><td>1M/2M 1F/2M 1M/2F 1F/2F</td></tr><tr><td colspan=\"2\">Google Translate 13.59 13.15 11.38 10.96</td></tr><tr><td>Best System Aug</td><td>13.71 13.64 13.30 13.23</td></tr><tr><td colspan=\"2\">Table 6: BLEU results on the post-edited Google Trans-late output of APGC v2.1 TEST using our best aug-mented system.</td></tr></table>",
                "type_str": "table",
                "text": "Error type statistics of our best augmented system's performance on APGC v2.1 DEV.",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table><tr><td>Word Gender Label</td><td colspan=\"2\">Train Dev</td><td>Test</td><td/></tr><tr><td>B</td><td colspan=\"4\">385,693 44,629 108,411 538,733</td></tr><tr><td>B+1M</td><td>28</td><td>5</td><td>10</td><td>43</td></tr><tr><td>B+1F</td><td>28</td><td>5</td><td>10</td><td>43</td></tr><tr><td>B+2M</td><td>1,042</td><td>98</td><td colspan=\"2\">279 1,419</td></tr><tr><td>B+2F</td><td>1,042</td><td>98</td><td colspan=\"2\">279 1,419</td></tr><tr><td>1M+B</td><td>3,490</td><td>422</td><td colspan=\"2\">958 4,870</td></tr><tr><td>1F+B</td><td>3,490</td><td>422</td><td colspan=\"2\">958 4,870</td></tr><tr><td>2M+B</td><td colspan=\"4\">16,320 1,787 4,548 22,655</td></tr><tr><td>2F+B</td><td colspan=\"4\">16,320 1,787 4,548 22,655</td></tr><tr><td>1M+1F</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1F+1M</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1M+2F</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>1F+2M</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>1M+1M</td><td>9</td><td>0</td><td>1</td><td>10</td></tr><tr><td>1F+1F</td><td>9</td><td>0</td><td>1</td><td>10</td></tr><tr><td>1M+2M</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>1F+2F</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2M+1M</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2F+1M</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2M+1F</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2F+1F</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2M+2M</td><td>22</td><td>2</td><td>8</td><td>32</td></tr><tr><td>2F+2F</td><td>22</td><td>2</td><td>8</td><td>32</td></tr><tr><td>2M+2F</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2F+2M</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td/><td colspan=\"4\">427,523 49,257 120,019 596,799</td></tr></table>",
                "type_str": "table",
                "text": "Parallel Gender Corpus v2.1: Extended Word-Level Annotations The statistics of the extended word-level gender annotations of APGC v2.1 across the TRAIN, DEV, and TEST splits.",
                "html": null,
                "num": null
            }
        }
    }
}