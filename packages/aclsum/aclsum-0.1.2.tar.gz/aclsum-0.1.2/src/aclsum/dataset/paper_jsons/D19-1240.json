{
    "paper_id": "D19-1240",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:13:55.066322Z"
    },
    "title": "Deep Reinforcement Learning-based Text Anonymization against Private-Attribute Inference",
    "authors": [
        {
            "first": "Ahmadreza",
            "middle": [],
            "last": "Mosallanezhad",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Arizona State University",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Ghazaleh",
            "middle": [],
            "last": "Beigi",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Arizona State University",
                "location": {}
            },
            "email": "gbeigi@asu.edu"
        },
        {
            "first": "Huan",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Arizona State University",
                "location": {}
            },
            "email": "huanliu@asu.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "User-generated textual data is rich in content and has been used in many user behavioral modeling tasks. However, it could also leak user private-attribute information that they may not want to disclose such as age and location. User's privacy concerns mandate data publishers to protect privacy. One effective way is to anonymize the textual data. In this paper, we study the problem of textual data anonymization and propose a novel Reinforcement Learning-based Text Anonymizor, RLTA, which addresses the problem of private-attribute leakage while preserving the utility of textual data. Our approach first extracts a latent representation of the original text w.r.t. a given task, then leverages deep reinforcement learning to automatically learn an optimal strategy for manipulating text representations w.r.t. the received privacy and utility feedback. Experiments show the effectiveness of this approach in terms of preserving both privacy and utility.",
    "pdf_parse": {
        "paper_id": "D19-1240",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "User-generated textual data is rich in content and has been used in many user behavioral modeling tasks. However, it could also leak user private-attribute information that they may not want to disclose such as age and location. User's privacy concerns mandate data publishers to protect privacy. One effective way is to anonymize the textual data. In this paper, we study the problem of textual data anonymization and propose a novel Reinforcement Learning-based Text Anonymizor, RLTA, which addresses the problem of private-attribute leakage while preserving the utility of textual data. Our approach first extracts a latent representation of the original text w.r.t. a given task, then leverages deep reinforcement learning to automatically learn an optimal strategy for manipulating text representations w.r.t. the received privacy and utility feedback. Experiments show the effectiveness of this approach in terms of preserving both privacy and utility.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Social media users generate a tremendous amount of data such as profile information, network connections and online reviews and posts. Online vendors use this data to understand users preferences and further predict their future needs. However, user-generated data is rich in content and malicious attackers can infer users' sensitive information. AOL search data leak in 2006 is an example of privacy breaches which results in users re-identification according to the published AOL search logs and queries (Pass et al., 2006) . Therefore, these privacy concerns mandate that data be anonymized before publishing. Recent research has shown that textual data alone may contain sufficient information about users' private-attributes that they do not want to disclose such as age, gender, location, political views and sexual orienta-tion (Mukherjee and Liu, 2010; Volkova et al., 2015) . Little attention has been paid to protect users textual information (Li et al., 2018; Zhang et al., 2018; Anandan et al., 2012; Saygin et al., 2006) .",
                "cite_spans": [
                    {
                        "start": 507,
                        "end": 526,
                        "text": "(Pass et al., 2006)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 836,
                        "end": 861,
                        "text": "(Mukherjee and Liu, 2010;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 862,
                        "end": 883,
                        "text": "Volkova et al., 2015)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 954,
                        "end": 971,
                        "text": "(Li et al., 2018;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 972,
                        "end": 991,
                        "text": "Zhang et al., 2018;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 992,
                        "end": 1013,
                        "text": "Anandan et al., 2012;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 1014,
                        "end": 1034,
                        "text": "Saygin et al., 2006)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Anonymizing textual information comes at the cost of losing utility of data for future applications. Some existing work shows the degraded quality of textual information (Anandan et al., 2012; Zhang et al., 2018; Saygin et al., 2006) . Another related problem setting is when the latent representation of the user generated texts is shared for different tasks. It is very common to use recurrent neural networks to create a representation of user generated text to use for different machine learning tasks. Hitaj el al. show text representations can leak users' private information such as location (Hitaj et al., 2017) . This work aims to anonymize users' textual information against private-attribute inference attacks.",
                "cite_spans": [
                    {
                        "start": 170,
                        "end": 192,
                        "text": "(Anandan et al., 2012;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 193,
                        "end": 212,
                        "text": "Zhang et al., 2018;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 213,
                        "end": 233,
                        "text": "Saygin et al., 2006)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 507,
                        "end": 519,
                        "text": "Hitaj el al.",
                        "ref_id": null
                    },
                    {
                        "start": 599,
                        "end": 619,
                        "text": "(Hitaj et al., 2017)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Adversarial learning is the state-of-the-art approach for creating a privacy preserving text embedding (Li et al., 2018; Coavoux et al., 2018) . In these methods, a model is trained to create a text embedding, but we cannot control the privacyutility balance. Recent success of reinforcement learning (RL) (Paulus et al., 2017; Sun and Zhang, 2018) shows a feasible alternative: by leveraging reinforcement learning, we can include feedback of attackers and utility in a reward function that allows for the control of the privacy-utility balance. Furthermore, an RL agent can perturb parts of an embedded text for preserving both utility and privacy, instead of retraining an embedding as in adversarial learning. Therefore, we propose a novel Reinforcement Learning-based Text Anonymizer, namely, RLTA, composed of two main components: 1) an attention based task-aware text representation learner to extract latent embedding representation of the original text's content w.r.t. a given task, and 2) a deep reinforcement learning based privacy and utility preserver to convert the problem of text anonymization to a one-player game in which the agent's goal is to learn the optimal strategy for text embedding manipulation to satisfy both privacy and utility. The Deep Q-Learning algorithm is then used to train the agent capable of changing the text embedding w.r.t. the received feedback from the privacy and utility subcomponents.",
                "cite_spans": [
                    {
                        "start": 103,
                        "end": 120,
                        "text": "(Li et al., 2018;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 121,
                        "end": 142,
                        "text": "Coavoux et al., 2018)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 306,
                        "end": 327,
                        "text": "(Paulus et al., 2017;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 328,
                        "end": 348,
                        "text": "Sun and Zhang, 2018)",
                        "ref_id": "BIBREF25"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We investigate the following challenges: 1) How could we extract the textual embedding w.r.t. a given task? 2) How could we perturb the extracted text embedding to ensure that user privateattribute information is obscured? and 3) How could we preserve the utility of text embedding during anonymization? Our main contributions are: (1) we study the problem of text anonymization by learning a reinforced task-aware text anonymizer, (2) we corporate a data-utility taskaware checker to ensure that the utility of textual embeddings is preserved w.r.t. a given task, and",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(3) we conduct experiments on real-world data to demonstrate the effectiveness of RLTA in an important natural language processing task.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Reinforcement Learning (RL) has applications in natural language processing and recommendation systems. For example, a recent paper (Paulus et al., 2017) combines RL with a supervised method to get a readable and informative article summary. Another work uses RL to solve the problem of adversarial generative models for text generation (Shi et al., 2018) . Sun et al. also uses RL in a recommendation system which recommends items according to the users' feedbacks and preferences (Sun and Zhang, 2018) Textual data is rich in content and recent research has shown that users' private-attributes can be easily inferred from the text (Beretta et al., 2015; Mukherjee and Liu, 2010; Volkova et al., 2015) , however, few papers consider user privacy w.r.t. such data. Anandan et al. (2012) introduce t-Plausibility which uses an information theoretic based approach to sanitize documents heuristically. This method does not preserves the utility of data during anonymization process. Another work focuses on leveraging differential privacy (Dwork et al., 2017) to make the extracted Term Frequency Inverse Document (TF-IDF) textual vectors pri-vate (Zhang et al., 2018) . It has been shown that TF-IDF cannot accurately capture semantic meaning of the text which can hurt its usefulness for different tasks (Lan et al., 2005) .",
                "cite_spans": [
                    {
                        "start": 132,
                        "end": 153,
                        "text": "(Paulus et al., 2017)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 337,
                        "end": 355,
                        "text": "(Shi et al., 2018)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 482,
                        "end": 503,
                        "text": "(Sun and Zhang, 2018)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 634,
                        "end": 656,
                        "text": "(Beretta et al., 2015;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 657,
                        "end": 681,
                        "text": "Mukherjee and Liu, 2010;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 682,
                        "end": 703,
                        "text": "Volkova et al., 2015)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 766,
                        "end": 787,
                        "text": "Anandan et al. (2012)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 1038,
                        "end": 1058,
                        "text": "(Dwork et al., 2017)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 1147,
                        "end": 1167,
                        "text": "(Zhang et al., 2018)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 1305,
                        "end": 1323,
                        "text": "(Lan et al., 2005)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Two recent similar works Li et al. (2018) ; Coavoux et al. (2018) convert textual data anonymization into a minimax problem. These works use the idea of adversarial learning to create a text embedding which satisfies utility and protects users against private-attribute leakage. Our scenario is similar to the work of (Li et al., 2018) as they have considered several attribute-inference attackers as adversaries to create a privacy-preserving text embedding. (Beigi et al., 2019b,a) propose a method for privacy preserving text representation. In this method, they try to add noise to an existing text representation in a way that it does not change the meaning of the text and it preserves the user's private attributes.",
                "cite_spans": [
                    {
                        "start": 25,
                        "end": 41,
                        "text": "Li et al. (2018)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 44,
                        "end": 65,
                        "text": "Coavoux et al. (2018)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 318,
                        "end": 335,
                        "text": "(Li et al., 2018)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 460,
                        "end": 483,
                        "text": "(Beigi et al., 2019b,a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Our work is different from the existing works. First, we consider the task that the textual information will be used for and protect users against leakage of private-attributes. Second, we incorporate deep RL to anonymize the extracted text embedding by receiving privacy and utility feedbacks and automatically learning the optimal strategy for proper manipulation of text embeddings.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Let X = {x 1 , x 2 , ..., x N } denotes a set of N documents and each document x i is composed of a sequence of words. We denote v i \u2208 R d\u00d71 as the embedded representation of the original document x i . Let P = {p 1 , p 2 , ..., p m } denotes a set of m private-attributes that users do not want to disclose such as age, gender, location, etc. The goal of reinforced task-aware text anonymizer is to learn an embedding representation of each document and then anonymize it such that 1) users privacy is preserved by preventing any potential attacker to infer users' private-attribute information from the textual embedding data, and 2) utility of the text embedding is maintained for a given task T which incorporates such data, e.g., classification. In this paper, we study the following problem: Problem 3.1. Given a set of documents X , set of private-attributes P, and given task T , learn an anonymizer f that can learn a private embedded representation v i from the original document x i so that, 1) the adversary cannot infer the targeted user's private-attributes P from the private text representation v i , and 2) the generated private representation v i is good for the given task T . The problem can be formally defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "v i = f (x i , P, T )",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Problem Statement",
                "sec_num": "3"
            },
            {
                "text": "Due to the success of Reinforcement Learning (Shi et al., 2018; Paulus et al., 2017) , we use RL to address the aforementioned problem. RL (Sutton and Barto, 2018) formulates the problem within the framework of Markov Decision Process (MDP), and learns an action-selection policy based on past observations of transition data. An MDP is defined by state space S = {s}, action space A = {a}, transition probability function P : S \u00d7 A \u00d7 S \u2192 [0, 1] and reward function r : S \u00d7 A \u00d7 S \u2192 R.",
                "cite_spans": [
                    {
                        "start": 45,
                        "end": 63,
                        "text": "(Shi et al., 2018;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 64,
                        "end": 84,
                        "text": "Paulus et al., 2017)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 139,
                        "end": 163,
                        "text": "(Sutton and Barto, 2018)",
                        "ref_id": "BIBREF26"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "3"
            },
            {
                "text": "We discuss the reinforced task-aware text anonymizer framework. The input of this private system is the user generated text, and the output is a privacy-preserving text representation. As in Figure . 1, this framework consists of two major components: 1) an attention based task-aware text representation learner, and 2) a deep RL based privacy and utility preserver. The text representation learner aims to extract the embedded representation of a document w.r.t. a given task by minimizing the task's loss function. Then, the deep RL preserver manipulates the embedded text representation by learning the optimal strategy so that both privacy and utility of the embedded representation are preserved. It includes two sub-components: 1) private-attribute inference attacker D P , and 2) data-utility task-aware checker D U . The former seeks to infer user privateattribute information based on their embedded text representation. The latter incorporates the given manipulated embedded text representation for a given task T and investigates the usefulness of the latent representation for T .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "4"
            },
            {
                "text": "The RL component then utilizes the feedback of the two sub-components to guide the data manipulation process by ensuring that the new text embedding does not leak user private-attributes by confusing the adversary in D P and the changes made to the representation does not destroy the semantic meaning for T .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "4"
            },
            {
                "text": "Let x = {w 1 , ..., w m } be a document with m words. Attention mechanism has shown to be effective in capturing embedding of textual information w.r.t. a given task (Pennington et al.; Vaswani et al., 2017) . We use a bi-directional recurrent neural network (RNN) to encode the given document into an initial embedding representation. RNN has been shown to be effective for summarizing and learning semantic of unstructured noisy short texts (Cho et al., 2014; Shang et al., 2015) . We use GloVe 100d (Pennington et al.) to exchange each word w i with its corresponding word vector, note that different dimensionality can be used. This process produces a matrix of text x \u2208 R m * 100 .",
                "cite_spans": [
                    {
                        "start": 166,
                        "end": 185,
                        "text": "(Pennington et al.;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 186,
                        "end": 207,
                        "text": "Vaswani et al., 2017)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 443,
                        "end": 461,
                        "text": "(Cho et al., 2014;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 462,
                        "end": 481,
                        "text": "Shang et al., 2015)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 502,
                        "end": 521,
                        "text": "(Pennington et al.)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "We employ the gated recurrent unit (GRU) as the cell type to build the RNN, which is designed in a manner to have a more persisted memory (Cho et al., 2014) . The bi-directional GRU will read the text forward and backwards, then outputs two hidden states h fw t , h bw t and an output o t . We then concatenate two hidden states as the initial encoded embedding of the given original document:",
                "cite_spans": [
                    {
                        "start": 138,
                        "end": 156,
                        "text": "(Cho et al., 2014)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "H t = Concat(h fw t , h bw t )",
                        "eq_num": "(2)"
                    }
                ],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "After calculating the initial context vector H t , we seek to pinpoint specific information within the H t , which helps the classifier to predict the labels with higher confidence (Luong et al., 2015) We use the location-based attention layer based on the work of Luong et al. (2015) . The attention layer calculates a vector a t including a weight for each element in the H t , showing the importance of that element. The context vector v t is calculated:",
                "cite_spans": [
                    {
                        "start": 181,
                        "end": 201,
                        "text": "(Luong et al., 2015)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 265,
                        "end": 284,
                        "text": "Luong et al. (2015)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "v t = m i=1 a t,i H i (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "The vector v t is then fed to a neural network classifier for the given utility task. Classification is one of the common tasks for textual data. Based on the output of the classifier and loss function, we update the three networks so that the output of the attention layer is an useful context that can be used for a utility task (Ranzato et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 331,
                        "end": 353,
                        "text": "(Ranzato et al., 2015)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Extracting Textual Embedding",
                "sec_num": "4.1"
            },
            {
                "text": "Here, we discuss the details of the second component which seeks to preserve privacy and utility.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Reinforced Task-Aware Text Anonymizer",
                "sec_num": "4.2"
            },
            {
                "text": "Textual information is rich in content and publishing textual embedding representation without proper anonymization leads to privacy breach and revealing the private-attributes of an individual such age, gender and location. It is thus essential to protect the textual information before publishing it. The goal of our model is to manipulated learned embedded representation such that any potential adversary cannot infer users' privateattribute information. However, a challenge is that the text anonymizer does not know the adversary's attack model. To address this challenge, we add a private-attribute inference attacker D P sub-component to our text anonymizer. This subcomponent learns a classifier that can accurately identify the private information of users from their embedded text representations v u . We incorporate this sub-component to understand how the textual embedded representation should be anonymized to obfuscate the private information.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Inspired by the success of RL (Kaelbling et al., 1996; Mnih et al., 2013; Van Hasselt et al., 2016) , we model this problem using RL to automatically learn how to anonymize the text representations w.r.t. the private-attribute inference attacker. In our RL model, one agent is trained to change a randomly selected text embedding representation. Then, the agent keeps interacting with the environment and changes the text embedding accordingly based on its current state and received rewards so that the private-attribute inference attacker cannot correctly identify user's private-attribute information given his embedding. In this part, we define the main four parts of RL environment in our problem, i.e., environment, state, action and reward.",
                "cite_spans": [
                    {
                        "start": 30,
                        "end": 54,
                        "text": "(Kaelbling et al., 1996;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 55,
                        "end": 73,
                        "text": "Mnih et al., 2013;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 74,
                        "end": 99,
                        "text": "Van Hasselt et al., 2016)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 Environment: Environment in our problem includes the private-attribute inference attackers D P and the text embedding v u . Note that D P is trained beforehand.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 State: State describes the current situation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Here, state is the current text embedding vector v u,t which reflects the results of the agents' actions on v u up to time t.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 Actions: Action is define as selecting one element such as v u,k in text embedding vector v u = {v u,1 , ..., v u,m } and changing it to a value near -1, 0 or 1. This results in 3.m actions where m is the size of the embedding vector.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Changing value to near 1: In this action, the agent changes the value of v u,k to a value between 0.9 to 1.0. As v u,k will be multiplied by a classifier's weight, the output will be the weight as is. In another word, the value v u,k will become important to the classifier.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Changing value to near 0: In this action the v u,k will be changed to a value between -0.01 to 0.01. This action makes v u,k seem neutral and unimportant to a classifier as it will result in a 0 when multiplied by a weight.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Changing value to near -1: In this action, the agent changes v u,k to a value between -1.0 to -0.9. This action will make v u,k important to a classifier, but, in a negative way.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "\u2022 Reward: Reward in our problem is defined based on how successfully the agent obfuscated the private-attribute information against the attacker so far. In particular, we defined the reward function at state s t+1 according to the confidence of private-attribute inference attacker C p k for private-attribute p k given the resultant text embedding at state s t+1 , i.e., v t+1 . Considering the classifier's input data as v u and its correct label as i, we define the confidence for a multi-class classifier as the difference between the probability of actual value of the privateattribute and the minimum probability of other values of the private-attribute:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "C p k = P r(l = i|v u ) -max j =i P r(l = j|v u ) (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Where l indicates label. For each privateattribute attacker p k , the confidence score C p k is within the range [-1, 1]. Positive value demonstrates that the attacker has predicted privateattribute accurately, and negative value indicates that the attacker was not able to infer user's private-attribute. According to this definition, the reward will be positive if action a t has caused information hiding, and will be negative if the action a t was not able to hide sensitive information. Having confidence of privateattribute inference attackers, reward function at state s t+1 is defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "r t+1 (s t+1 ) = - p k \u2208D P C p k (s t+1 )",
                        "eq_num": "(5)"
                    }
                ],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "The reward r t is calculated according to the state s t+1 which associated with the transition of agent from state s t after applying action a t . Note that the goal of agent is to maximize the amount of received rewards so that the mean of rewards r over time t \u2208 [0, T ] (T is the terminal time) will be positive and above 0.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Protecting Private-Attributes",
                "sec_num": "4.2.1"
            },
            {
                "text": "Thus far, we have discussed how to 1) learn textual embeddings from the given original document w.r.t. the given task, and 2) prevent leakage of private-attribute information by developing a reinforcement learning environment which incorporates a private-attribute inference attacker and manipulates the initial given text embedding accordingly to fool the attacker. However, data obfuscation comes at the cost of data utility loss. Utility is defined as the quality of the given data for a given task. Neglecting the utility of the text embedding while manipulating it, may destroy the semantic meaning of the text data for the given task. Classification is one of the common tasks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "In order to preserve the utility of data, we need to ensure that preserving privacy of data does not destroy the semantic meaning of the text embedding representation w.r.t. the given task. We approach this challenge by changing the agent's reward function w.r.t. the data utility. We add a utility sub-component, i.e., classifier D U , to the reinforcement learning environment which its goal is to assess the quality of resultant embedding representation. We use the confidence of the classifier for the given task to measure the utility of embedding representation using the text embedding vector v u the its correct label i.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "C = P r(l = i|v u ) -min j P r(l = j|v u ) (6)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "The agent can then use the feedback from the utility classifier to make decision when taking actions. We thus modify the reward function in order to incorporate the confidence of utility sub-component. Reward function at state s t+1 can be defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "r t+1 (s t+1 ) =\u03b1C D U (s t+1 )-",
                        "eq_num": "(7)"
                    }
                ],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "-(1 -\u03b1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "p k \u2208D P C p k (s t+1 ) -B",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "where C D U and C p k represent the confidence of utility sub-component and private-attribute inference attacker, respectively. Moreover, B demonstrates a baseline reward which forces the agent to reach a minimum reward value. The coefficient \u03b1 also control the amount of contribution from both private-attribute inference and utility sub-components in the Eq. 7.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preserving Utility of Text Embedding",
                "sec_num": "4.2.2"
            },
            {
                "text": "Given the formulation of states and actions, we aim to learn the optimal strategy via manipulating text representations w.r.t. the private-attribute attackers and utility sub-component feedbacks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "We manipulate the text embeddings by repeatedly choosing an action a t given current state s t , and then applying actions on current state to transit to the new one s t+1 . The agent then receives reward r t+1 as a consequence of interacting with the environment. The goal of agent is to manipulate text embedding v u,k in a way that maximizes its reward according to Eq. 7. Moreover, the agent updates its action selection policy \u03c0(s) so that it can achieve the maximum reward over time.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "In RLTA we use Deep Q-Learning which is a variant of Q-Learning. In this algorithm the goal is to find the following function:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Q * (s t , a t ) = E st+1 [r t+1 + \u03b3 max a Q * (s t+1 , a )] (8)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "where Q(s, a) corresponds to the Q-function for extracting actions and it is defined as the expected return based on state s and action a. Moreover, Q * (s, a) denotes the optimal action-value Qfunction which has the maximum expected return using the optimal policy \u03c0(s). Rewards are also discounted by a factor of \u03b3 per time step. The agent keeps interacting with the environment till it reaches the terminal time T .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Since it is not feasible to estimate Q * (s, a) in Eq.8, we use a function approximator to estimate the state-action value function Q * (s, a) \u2248 Algorithm 1 The Learning Process of RLTA Require: v, D P , D U , \u03b1, \u03b3, B, T .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "1: Initialize replay memory M with size N 2: while training is not terminal do 3:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "s t \u2190 v 4:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "for t \u2208 {0, 1, ..., T } do 5:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Choose action a t using -greedy 6:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Perform a t on s t and get (s t+1 , r t+1 )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "7:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "M \u2190 M + (s t , a t , r t+1 , s t+1 )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "8:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "s t \u2190 s t+1 9:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Sample mini-batch b from memroy M 10:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "for (s, a, s , r) \u2208 b do 11:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Update DQN weights using Eq. 11",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "12:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "end for 13:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "end for 14: end while Q(s, a; \u03b8). Given neural networks as excellent function approximators (Cybenko, 1989) , we lverage a deep neural network function approximator with parameters \u03b8, or a Deep Q-Network (DQN) (Mnih et al., 2013) by minimizing the following:",
                "cite_spans": [
                    {
                        "start": 92,
                        "end": 107,
                        "text": "(Cybenko, 1989)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 210,
                        "end": 229,
                        "text": "(Mnih et al., 2013)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "L(\u03b8) = E st,at,r t+1 ,s t+1 [(y -Q(s, a; \u03b8)) 2 ] (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "in which y is the target for the current iteration:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "y = E s t+1 [r t+1 + \u03b3 max a Q(s t+1 , a ; \u03b8 p )] (10)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "\u03b8 p is the parameters from the previous iteration.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "We update the DQN according to the derivation of Eq. 9 with respect to the parameter \u03b8:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "\u2207 \u03b8 L(\u03b8) = E st,at,r t+1 ,s t+1 [(r (11) +\u03b3 max a Q(s t+1 , a ; \u03b8 p ) -Q(s t , a t ; \u03b8))\u2207 \u03b8 Q(s t , a t ; \u03b8)]",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Algorithm 1 shows the optimization process.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Optimization Algorithm",
                "sec_num": "4.3"
            },
            {
                "text": "Experiments are designed to answer the following questions: Q1(Privacy): How well RLTA can obscure users' private-attribute information? Q2(Utility): How well RLTA can preserve utility of the textual data w.r.t. the given task? Q3(Privacy-Utility Relation): How does improving user privacy affects loss of utility?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "To answer the first question (Q1), we use investigate the robustness of resultant text embedding against private-attribute inference attacks. We consider two private-attribute information, i.e., location and gender. To answer the second question (Q2), we report experimental results w.r.t. a wellknown task, sentiment analysis. Sentiment analysis has many applications in user-behavioral modeling and Web (Zafarani et al., 2014) . In particular, we predict sentiment of the given textual embedding. To answer the final question (Q3), we examine the privacy improvement against utility loss.",
                "cite_spans": [
                    {
                        "start": 405,
                        "end": 428,
                        "text": "(Zafarani et al., 2014)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "We use a real-world dataset from Trustpilot (Hovy et al., 2015) . This dataset includes user reviews along with users private-attribute information such as location and gender. We remove non-English reviews based on LANGID.py1 (Lui and Baldwin, 2012) and only keep reviews classified as English. Then, we consider English reviews associated with location of US and UK and create a subset of data with 10k users. Each review is associated with a rating score. We consider the review's sentiment as positive if its rating score is {4, 5} and consider it as negative if rating is {1, 2, 3}",
                "cite_spans": [
                    {
                        "start": 44,
                        "end": 63,
                        "text": "(Hovy et al., 2015)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 227,
                        "end": 250,
                        "text": "(Lui and Baldwin, 2012)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "5.1"
            },
            {
                "text": "For extracting the initial textual embedding, we use a bi-directional RNNs which their hidden sizes are set to 25. This makes the size of the final hidden vector H t as 50. We also use a logistic regression with a linear network as the classifier in the attention mechanism. We use a 3-layer network for the Deep Q-network, i.e., input, hidden and output layers. Dimensions of the input and hidden layers are set to 50 and 700, respectively. Dimension of the last layer, i.e., output, is also set as 150. This layer outputs the state-action values which we execute the action with the best value.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Implementation Details",
                "sec_num": "5.2"
            },
            {
                "text": "For each of the private-attribute attackers and utility sub-components, we use feed-forward network with a single hidden layer with dimension of 100 which gets the textual embedding as input and uses a Sof tmax function as output.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Implementation Details",
                "sec_num": "5.2"
            },
            {
                "text": "We first train both private-attribute inference attacker D P and utility sub-component D U on the training set. These sub-components do not change after that. Then, we train an agent on each selected data for 5000 episodes. The reward discount for agents is \u03b3 = 0.99 and batch size b = 32. We also set the terminal time T = 25. We run RLTA for 5 times and select the best agent based on the cumulative reward. We also vary \u03b1 as \u03b1 = {0, 0.25, 0.5, 0.75, 1}. The higher values of Lower AUC for private-attribute inference attacks shows higher privacy, while higher AUC for the sentiment prediction task indicates higher utility.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Implementation Details",
                "sec_num": "5.2"
            },
            {
                "text": "\u03b1 indicate more utility contribution in RLTA.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Implementation Details",
                "sec_num": "5.2"
            },
            {
                "text": "We use 10-fold cross validation of RLTA for evaluating both private-attribute inference attacker and an utility task with the following baselines:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "\u2022 ORIGINAL: This baseline is a variant of proposed RLTA which does not change the original user text embeddings v u and publishes it as is.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "\u2022 ADV-ALL: This adversarial method has two main components, i.e., generator and discriminator, and creates a text representation that has high quality for a given task, but has poor quality for inferring private-attributes (Li et al., 2018) .",
                "cite_spans": [
                    {
                        "start": 223,
                        "end": 240,
                        "text": "(Li et al., 2018)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "\u2022 ENC-DEC: Using an auto-encoder is one of the effective methods to create a text embedding (Nallapati et al., 2016) . We modify this simple method to create a privacy-preserving text embedding. This method gets the original text x and outputs a re-constructed text x.",
                "cite_spans": [
                    {
                        "start": 92,
                        "end": 116,
                        "text": "(Nallapati et al., 2016)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "The following loss function is used to train the model. After training, we use the encoder's output as the text representation v u (Cho et al., 2014) .",
                "cite_spans": [
                    {
                        "start": 131,
                        "end": 149,
                        "text": "(Cho et al., 2014)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "loss = - x\u2208X log P r(x|x)+",
                        "eq_num": "(12)"
                    }
                ],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "+ \u03b1((",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "p k C p k ) -C D U )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "In which \u03b1 is the privacy budget.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "To examine the privacy of final text embedding, we apply the trained private-attribute attacker sub-component D P to the output of each method to evaluate the users' privacy. We consider two private attributes, i.e., location and gender. We then compute the attacker's AUC. Lower attacker's AUC indicates that textual embeddings have higher privacy after anonymization against the private-attribute inference attacker. We also report experimental results w.r.t. the utility. In particular, we predict sentiment (positive and negative) of the given textual embedding by applying trained utility sub-component D U to the resultant text embedding from test set for each method. We then compute AUC score for sentiment prediction task. Higher values of AUC demonstrate that the utility of textual embedding has been preserved.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Design",
                "sec_num": "5.3"
            },
            {
                "text": "We answer the three question Q1, Q2 and Q3 to evaluate our proposed method RLTA.We use a natural language processing task, sentiment prediction, using a three layer neural network. Privacy (Q1). demonstrates the results of private-attribute inference attack w.r.t. gender and location attributes. The lower the value of AUC is, the more privacy user has in terms of obscuring private attributes. We also report the performance of RLTA for different values of \u03b1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "5.4"
            },
            {
                "text": "We observe that ORIGINAL is not robust against private-attribute inference attack for both gender and location attributes. This confirms leakage of users private information from their textual data. Moreover, RLTA has significantly lower AUC score for both gender and location attributes in comparison to other methods. This demonstrates the effectiveness of RL for obfuscating private attributes. In RLTA, the AUC score for privateattribute inference attack increases for both attributes with the increase of \u03b1 which shows the degradation in user privacy. The reason is because of the fact that agent pays less attention to privacy by increasing the value of \u03b1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "5.4"
            },
            {
                "text": "In the ENC-DEC method, as the value of \u03b1 increases, the encoder tries to generate a text representation that is prune to inference attacks but it does not lose its utility w.r.t. the given task D U . The results show that as \u03b1 increases, the AUC of inference attackers will decrease.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "5.4"
            },
            {
                "text": "). To answer the second question, we investigate the utility of embeddings w.r.t. sentiment prediction. Results for different values of \u03b1 are demonstrated in Figure . 2(c). The higher the value of the AUC is, the higher utility is preserved.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Utility (Q2",
                "sec_num": null
            },
            {
                "text": "The ORIGINAL approach has the highest AUC score which shows the utility of the text embeddings before any anonymization. We observe that the results for RLTA is comparable to the ORIGI-NAL approach which shows that RLTA preserves the utility of text embedding. Moreover, RLTA outperforms ADV-ALL which confirms the effectiveness of reinforced task-aware text anonymization approach in preserving utility of the textual embeddings. We also observe that the AUC of RLTA w.r.t. sentiment prediction task increases with the increase of value of \u03b1. This is because with the increase of \u03b1, the agent pays more attention to the feedbacks of utility sub-component.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Utility (Q2",
                "sec_num": null
            },
            {
                "text": "We also observe a small utility loss after applying RLTA when \u03b1 = 1. This is because the agent keeps changing the text embedding until it reaches the terminal time. These changes result in loss of utility even when the \u03b1 = 1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Utility (Q2",
                "sec_num": null
            },
            {
                "text": "Finally, in the ENC-DEC method, as both utility and attackers have the same importance, trying to preserving privacy would result in huge utility loss as we increase the value of \u03b1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Utility (Q2",
                "sec_num": null
            },
            {
                "text": "Privacy-Utility Relation (Q3). Results show that the ORIGINAL achieves the highest AUC score for both utility task and private-attribute inference attack. This shows that ORIGINAL has the highest utility which comes at the cost of significant user privacy loss. However, comparing results of privacy and utility for \u03b1 = 0.5, we observe RLTA has achieved the lowest AUC score for attribute inference attacks in comparison to other baselines, thus has the highest privacy. It also reaches the higher utility level in comparison to the ADV-ALL. RLTA also has comparable utility results to the ORIGINAL approach. We also observe that increasing the \u03b1 reduces the performance of RLTA in terms of privacy but increases its performance for utility. However, with \u03b1 = 1, RLTA preserves both user privacy and utility in comparison to ORIGINAL, ENC-DEC, and ADV-ALL. Table 1 : Impact of different private-attribute inference attackers on RLTA when \u03b1 = 0.5. With \u03b1 = 0.5, privacy and utility will contribute equally.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 863,
                        "end": 864,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Utility (Q2",
                "sec_num": null
            },
            {
                "text": "Here, we investigate the impact of different private-attribute inference attackers. We define two variants of our proposed model, RLTA-GEN and RLTA-LOC. In each of these variants, we train the agent in RLTA w.r.t. the one of privateattribute attackers, e.g., RLTA-GEN is trained to solely hide gender attribute. For this experiment we set \u03b1 = 0.5 as in this case privacy and utility sub-components contribute equally during training phase (Eq. 7). Results are shown in Table 1 . RLTA-LOC and RLTA-GEN have the best performance amongst all methods in obfuscating location and gender private-attributes, respectively. Results show that using RLTA-LOC could also help improve privacy on gender and likewise for (RLTA-GEN) in comparison to other approaches.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 475,
                        "end": 476,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Impact of Different Components",
                "sec_num": "5.4.1"
            },
            {
                "text": "RLTA-GEN performs better in terms of utility, in comparison to RLTA which incorporates both gender and location attackers. Moreover, results show that both RLTA-GEN and RLTA-LOC have better utility than other baselines.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of Different Components",
                "sec_num": "5.4.1"
            },
            {
                "text": "To sum-up, these results indicate that although using one private-attribute attacker in the training process can help in preserving more utility, it can compromise obscuring other private-attributes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of Different Components",
                "sec_num": "5.4.1"
            },
            {
                "text": "Parameter Analysis: Our proposed method RLTA has an important parameter \u03b1 to change the level of privacy and utility. We illustrate the effect of this parameter by changing it as \u03b1 \u2208 {0.0, 0.1, 0.25, 0.5, 0.75, 1.0}. According to the Figure 2 , when the \u03b1 parameter increases, the privacy loss will decrease, but, the utility loss will increase. This shows the utility and the privacy have an association with each other. Hence, the more privacy loss decreases, the utility loss increases. Choosing the right value for \u03b1 depends on the application and usage of this method. According to the results, choosing \u03b1 = 0.5 would result in a balanced privacy-utility. In some applications where the privacy of users are important and critical, we can set the \u03b1 parameter above 0.5. On the other hand, if the users privacy is not top priority, this parameter can be set to a lower value than 0.5 which although it does not protect users' private attribute as good as when \u03b1 >= 0.5, but it does protect users' private attribute at a reasonable level.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 241,
                        "end": 242,
                        "text": "2",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Impact of Different Components",
                "sec_num": "5.4.1"
            },
            {
                "text": "To evaluate the convergence of rewards, we consider agent's reward during training phase for each episode, shown in Figure . 3. The result indicates that agent's average reward is low at the beginning and then it increases afterward. This is because agent performs many random actions at the beginning to explore the action state space. We also observe that after several episodes, the reward converges to the baseline reward B. This confirms that the agent has learned a proper action selection policy \u03c0(s) to preserve both utility and privacy by satisfying the objectives of Eq. 7.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Rewards Convergence",
                "sec_num": "5.4.2"
            },
            {
                "text": "In this paper, we propose a deep reinforcement learning based text anonymization, RLTA, which creates a text embedding such that does not leak user's private-attribute information while preserving its utility w.r.t. a given task. RLTA has two main components: (1) an attention based taskaware text representation learner, and (2) a deep RL based privacy and utility preserver. Our results illustrate the effectiveness of RLTA in preserving privacy and utility. One future direction is to generate privacy preserving text rather than embeddings. We also adopt deep Q-learning to train the agent. A future direction is to apply different RL algorithms and investigate how it impacts results. It would be also interesting to adopt RLTA for other types of data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "https://github.com/saffsd/langid.py",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "The authors would like to thank Jundong Li for his help throughout the paper. This material is based upon the work supported, in part, by NSF 1614576, ARO W911NF-15-1-0328 and ONR N00014-17-1-2605.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": "7"
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Generalizing words to desensitize text",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Balamurugan Anandan",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Clifton",
                        "suffix": ""
                    },
                    {
                        "first": "Mummoorthy",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Pedro",
                        "middle": [],
                        "last": "Murugesan",
                        "suffix": ""
                    },
                    {
                        "first": "Luo",
                        "middle": [],
                        "last": "Pastrana-Camacho",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Si",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "5",
                "issue": "",
                "pages": "505--534",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Balamurugan Anandan, Chris Clifton, Wei Jiang, Mummoorthy Murugesan, Pedro Pastrana- Camacho, and Luo Si. 2012. t-plausibility: Generalizing words to desensitize text. Trans. Data Privacy, 5(3):505-534.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "2019a. I am not what i write: Privacy preserving text representation learning",
                "authors": [
                    {
                        "first": "Ghazaleh",
                        "middle": [],
                        "last": "Beigi",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Shu",
                        "suffix": ""
                    },
                    {
                        "first": "Ruocheng",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Suhang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Huan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1907.03189"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ghazaleh Beigi, Kai Shu, Ruocheng Guo, Suhang Wang, and Huan Liu. 2019a. I am not what i write: Privacy preserving text representation learn- ing. arXiv preprint arXiv:1907.03189.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Privacy preserving text representation learning",
                "authors": [
                    {
                        "first": "Ghazaleh",
                        "middle": [],
                        "last": "Beigi",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Shu",
                        "suffix": ""
                    },
                    {
                        "first": "Ruocheng",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Suhang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Huan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 30th on Hypertext and Social Media (HT19)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ghazaleh Beigi, Kai Shu, Ruocheng Guo, Suhang Wang, and Huan Liu. 2019b. Privacy preserving text representation learning. Proceedings of the 30th on Hypertext and Social Media (HT19). ACM.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "An interactive method for inferring demographic attributes in twitter",
                "authors": [
                    {
                        "first": "Valentina",
                        "middle": [],
                        "last": "Beretta",
                        "suffix": ""
                    },
                    {
                        "first": "Daniele",
                        "middle": [],
                        "last": "Maccagnola",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "ACM Conference on Hypertext & Social Media",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Valentina Beretta, Daniele Maccagnola, Timothy Crib- bin, and Enza Messina. 2015. An interactive method for inferring demographic attributes in twitter. In ACM Conference on Hypertext & Social Media.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
                "authors": [
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Bart",
                        "middle": [],
                        "last": "Van Merri\u00ebnboer",
                        "suffix": ""
                    },
                    {
                        "first": "Caglar",
                        "middle": [],
                        "last": "Gulcehre",
                        "suffix": ""
                    },
                    {
                        "first": "Dzmitry",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "Fethi",
                        "middle": [],
                        "last": "Bougares",
                        "suffix": ""
                    },
                    {
                        "first": "Holger",
                        "middle": [],
                        "last": "Schwenk",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1406.1078"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Kyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Privacy-preserving neural representations of text",
                "authors": [
                    {
                        "first": "Maximin",
                        "middle": [],
                        "last": "Coavoux",
                        "suffix": ""
                    },
                    {
                        "first": "Shashi",
                        "middle": [],
                        "last": "Narayan",
                        "suffix": ""
                    },
                    {
                        "first": "Shay",
                        "middle": [
                            "B"
                        ],
                        "last": "Cohen",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1808.09408"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Maximin Coavoux, Shashi Narayan, and Shay B Co- hen. 2018. Privacy-preserving neural representa- tions of text. arXiv preprint arXiv:1808.09408.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Approximation by superpositions of a sigmoidal function",
                "authors": [
                    {
                        "first": "George",
                        "middle": [],
                        "last": "Cybenko",
                        "suffix": ""
                    }
                ],
                "year": 1989,
                "venue": "Mathematics of control, signals and systems",
                "volume": "2",
                "issue": "",
                "pages": "303--314",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "George Cybenko. 1989. Approximation by superposi- tions of a sigmoidal function. Mathematics of con- trol, signals and systems, 2(4):303-314.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Calibrating noise to sensitivity in private data analysis",
                "authors": [
                    {
                        "first": "Cynthia",
                        "middle": [],
                        "last": "Dwork",
                        "suffix": ""
                    },
                    {
                        "first": "Frank",
                        "middle": [],
                        "last": "Mcsherry",
                        "suffix": ""
                    },
                    {
                        "first": "Kobbi",
                        "middle": [],
                        "last": "Nissim",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Journal of Privacy and Confidentiality",
                "volume": "7",
                "issue": "3",
                "pages": "17--51",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2017. Calibrating noise to sensitiv- ity in private data analysis. Journal of Privacy and Confidentiality, 7(3):17-51.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Deep models under the gan: information leakage from collaborative deep learning",
                "authors": [
                    {
                        "first": "Briland",
                        "middle": [],
                        "last": "Hitaj",
                        "suffix": ""
                    },
                    {
                        "first": "Giuseppe",
                        "middle": [],
                        "last": "Ateniese",
                        "suffix": ""
                    },
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "P\u00e9rez-Cruz",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": "",
                "issue": "",
                "pages": "603--618",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Briland Hitaj, Giuseppe Ateniese, and Fernando P\u00e9rez- Cruz. 2017. Deep models under the gan: informa- tion leakage from collaborative deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages 603-618. ACM.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "User review sites as a resource for large-scale sociolinguistic studies",
                "authors": [
                    {
                        "first": "Dirk",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    },
                    {
                        "first": "Anders",
                        "middle": [],
                        "last": "Johannsen",
                        "suffix": ""
                    },
                    {
                        "first": "Anders",
                        "middle": [],
                        "last": "S\u00f8gaard",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 24th International Conference on World Wide Web",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dirk Hovy, Anders Johannsen, and Anders S\u00f8gaard. 2015. User review sites as a resource for large-scale sociolinguistic studies. In Proceedings of the 24th International Conference on World Wide Web.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Reinforcement learning: A survey",
                "authors": [
                    {
                        "first": "Leslie",
                        "middle": [],
                        "last": "Pack",
                        "suffix": ""
                    },
                    {
                        "first": "Kaelbling",
                        "middle": [],
                        "last": "Michael L Littman",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "W"
                        ],
                        "last": "Moore",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Journal of artificial intelligence research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Leslie Pack Kaelbling, Michael L Littman, and An- drew W Moore. 1996. Reinforcement learning: A survey. Journal of artificial intelligence research.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "A comparative study on term weighting schemes for text categorization",
                "authors": [
                    {
                        "first": "Man",
                        "middle": [],
                        "last": "Lan",
                        "suffix": ""
                    },
                    {
                        "first": "Sam-Yuan",
                        "middle": [],
                        "last": "Sung",
                        "suffix": ""
                    },
                    {
                        "first": "Hwee-Boon",
                        "middle": [],
                        "last": "Low",
                        "suffix": ""
                    },
                    {
                        "first": "Chew-Lim",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "IEEE International Joint Conference on Neural Networks",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Man Lan, Sam-Yuan Sung, Hwee-Boon Low, and Chew-Lim Tan. 2005. A comparative study on term weighting schemes for text categorization. In IEEE International Joint Conference on Neural Networks.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Towards robust and privacy-preserving text representations",
                "authors": [
                    {
                        "first": "Yitong",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Timothy",
                        "middle": [],
                        "last": "Baldwin",
                        "suffix": ""
                    },
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "The 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yitong Li, Timothy Baldwin, and Trevor Cohn. 2018. Towards robust and privacy-preserving text repre- sentations. In The 56th Annual Meeting of the As- sociation for Computational Linguistics.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "langid. py: An off-the-shelf language identification tool",
                "authors": [
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Lui",
                        "suffix": ""
                    },
                    {
                        "first": "Timothy",
                        "middle": [],
                        "last": "Baldwin",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the ACL 2012 system demonstrations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marco Lui and Timothy Baldwin. 2012. langid. py: An off-the-shelf language identification tool. In Pro- ceedings of the ACL 2012 system demonstrations.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Effective approaches to attention-based neural machine translation",
                "authors": [
                    {
                        "first": "Thang",
                        "middle": [],
                        "last": "Luong",
                        "suffix": ""
                    },
                    {
                        "first": "Hieu",
                        "middle": [],
                        "last": "Pham",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1412--1421",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thang Luong, Hieu Pham, and Christopher D Man- ning. 2015. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412-1421.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller",
                "authors": [
                    {
                        "first": "Volodymyr",
                        "middle": [],
                        "last": "Mnih",
                        "suffix": ""
                    },
                    {
                        "first": "Koray",
                        "middle": [],
                        "last": "Kavukcuoglu",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1312.5602"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Volodymyr Mnih, Koray Kavukcuoglu, David Sil- ver, Alex Graves, Ioannis Antonoglou, Daan Wier- stra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Improving gender classification of blog authors",
                "authors": [
                    {
                        "first": "Arjun",
                        "middle": [],
                        "last": "Mukherjee",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Empirical Methods in natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Arjun Mukherjee and Bing Liu. 2010. Improving gen- der classification of blog authors. In Empirical Methods in natural Language Processing (EMNLP).",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Abstractive text summarization using sequence-to-sequence rnns and beyond",
                "authors": [
                    {
                        "first": "Ramesh",
                        "middle": [],
                        "last": "Nallapati",
                        "suffix": ""
                    },
                    {
                        "first": "Bowen",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Caglar",
                        "middle": [],
                        "last": "Gulcehre",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Xiang",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1602.06023"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ramesh Nallapati, Bowen Zhou, Caglar Gulcehre, Bing Xiang, et al. 2016. Abstractive text summa- rization using sequence-to-sequence rnns and be- yond. arXiv preprint arXiv:1602.06023.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "A picture of search",
                "authors": [
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Pass",
                        "suffix": ""
                    },
                    {
                        "first": "Abdur",
                        "middle": [],
                        "last": "Chowdhury",
                        "suffix": ""
                    },
                    {
                        "first": "Cayley",
                        "middle": [],
                        "last": "Torgeson",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "1st international conference on Scalable information systems (InfoScale)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Greg Pass, Abdur Chowdhury, and Cayley Torgeson. 2006. A picture of search. In 1st international con- ference on Scalable information systems (InfoScale).",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "A deep reinforced model for abstractive summarization",
                "authors": [
                    {
                        "first": "Romain",
                        "middle": [],
                        "last": "Paulus",
                        "suffix": ""
                    },
                    {
                        "first": "Caiming",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1705.04304"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Romain Paulus, Caiming Xiong, and Richard Socher. 2017. A deep reinforced model for abstractive sum- marization. arXiv preprint arXiv:1705.04304.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Glove: Global vectors for word representation",
                "authors": [
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Pennington",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of conference on Empirical Methods in natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word represen- tation. In Proceedings of conference on Empirical Methods in natural Language Processing (EMNLP).",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Sequence level training with recurrent neural networks",
                "authors": [
                    {
                        "first": "Aurelio",
                        "middle": [],
                        "last": "Marc",
                        "suffix": ""
                    },
                    {
                        "first": "Sumit",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Chopra",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zaremba",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1511.06732"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2015. Sequence level train- ing with recurrent neural networks. arXiv preprint arXiv:1511.06732.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Sanitization and anonymization of document repositories",
                "authors": [
                    {
                        "first": "Dilek",
                        "middle": [],
                        "last": "Y\u00fccel Saygin",
                        "suffix": ""
                    },
                    {
                        "first": "G\u00f6khan",
                        "middle": [],
                        "last": "Hakkini-Tur",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Tur",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Web and information security",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y\u00fccel Saygin, Dilek Hakkini-Tur, and G\u00f6khan Tur. 2006. Sanitization and anonymization of document repositories. In Web and information security.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Neural responding machine for short-text conversation",
                "authors": [
                    {
                        "first": "Lifeng",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhengdong",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Hang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neural responding machine for short-text conversa- tion. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Toward diverse text generation with inverse reinforcement learning",
                "authors": [
                    {
                        "first": "Zhan",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Xinchi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "27th International Joint Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhan Shi, Xinchi Chen, Xipeng Qiu, and Xuanjing Huang. 2018. Toward diverse text generation with inverse reinforcement learning. In 27th Interna- tional Joint Conference on Artificial Intelligence.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Conversational recommender system",
                "authors": [
                    {
                        "first": "Yueming",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "ACM SIGIR Conference on Research & Development in Information Retrieval",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yueming Sun and Yi Zhang. 2018. Conversational rec- ommender system. In ACM SIGIR Conference on Research & Development in Information Retrieval.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Reinforcement learning: An introduction",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Richard",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "G"
                        ],
                        "last": "Sutton",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Barto",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Richard S Sutton and Andrew G Barto. 2018. Rein- forcement learning: An introduction. MIT press.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Deep reinforcement learning with double qlearning",
                "authors": [
                    {
                        "first": "Hado",
                        "middle": [],
                        "last": "Van Hasselt",
                        "suffix": ""
                    },
                    {
                        "first": "Arthur",
                        "middle": [],
                        "last": "Guez",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Silver",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "30th AAAI Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hado Van Hasselt, Arthur Guez, and David Silver. 2016. Deep reinforcement learning with double q- learning. In 30th AAAI Conference.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Attention is all you need",
                "authors": [
                    {
                        "first": "Ashish",
                        "middle": [],
                        "last": "Vaswani",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    },
                    {
                        "first": "Niki",
                        "middle": [],
                        "last": "Parmar",
                        "suffix": ""
                    },
                    {
                        "first": "Jakob",
                        "middle": [],
                        "last": "Uszkoreit",
                        "suffix": ""
                    },
                    {
                        "first": "Llion",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Aidan",
                        "middle": [
                            "N"
                        ],
                        "last": "Gomez",
                        "suffix": ""
                    },
                    {
                        "first": "\u0141ukasz",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Illia",
                        "middle": [],
                        "last": "Polosukhin",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "5998--6008",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems, pages 5998-6008.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Inferring latent user properties from texts published in social media",
                "authors": [
                    {
                        "first": "Svitlana",
                        "middle": [],
                        "last": "Volkova",
                        "suffix": ""
                    },
                    {
                        "first": "Yoram",
                        "middle": [],
                        "last": "Bachrach",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "29th AAAI Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Svitlana Volkova, Yoram Bachrach, Michael Arm- strong, and Vijay Sharma. 2015. Inferring latent user properties from texts published in social media. In 29th AAAI Conference on Artificial Intelligence.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Social media mining: an introduction",
                "authors": [
                    {
                        "first": "Reza",
                        "middle": [],
                        "last": "Zafarani",
                        "suffix": ""
                    },
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Ali Abbasi",
                        "suffix": ""
                    },
                    {
                        "first": "Huan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Reza Zafarani, Mohammad Ali Abbasi, and Huan Liu. 2014. Social media mining: an introduction. Cam- bridge University Press.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Privacy-preserving social media data outsourcing",
                "authors": [
                    {
                        "first": "Jinxue",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jingchao",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yanchao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xia",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "IEEE INFOCOM Conference on Computer Communications",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jinxue Zhang, Jingchao Sun, Rui Zhang, Yanchao Zhang, and Xia Hu. 2018. Privacy-preserving so- cial media data outsourcing. In IEEE INFOCOM Conference on Computer Communications.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: The architecture of RLTA method",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "It allows the model to attend to different parts of the given original document at each step and then learns what to attend based on the input document and what it has produced as embedding representation so far, as shown in Figure. 1.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure2: AUC scores for private-attribute and sentiment prediction tasks for different values of \u03b1. Lower AUC for private-attribute inference attacks shows higher privacy, while higher AUC for the sentiment prediction task indicates higher utility.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 3: The average of agent's rewards",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            }
        }
    }
}