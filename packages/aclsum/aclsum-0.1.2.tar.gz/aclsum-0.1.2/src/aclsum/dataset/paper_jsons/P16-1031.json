{
    "paper_id": "P16-1031",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:00:44.918505Z"
    },
    "title": "Bi-Transferring Deep Neural Networks for Domain Adaptation",
    "authors": [
        {
            "first": "Guangyou",
            "middle": [],
            "last": "Zhou",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Central China Normal University",
                "location": {
                    "postCode": "430079",
                    "settlement": "Wuhan",
                    "country": "China"
                }
            },
            "email": "gyzhou@mail.ccnu.edu"
        },
        {
            "first": "Zhiwen",
            "middle": [],
            "last": "Xie",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Central China Normal University",
                "location": {
                    "postCode": "430079",
                    "settlement": "Wuhan",
                    "country": "China"
                }
            },
            "email": "xiezhiwen@mail.ccnu.edu"
        },
        {
            "first": "Jimmy",
            "middle": [
                "Xiangji"
            ],
            "last": "Huang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "York University",
                "location": {
                    "settlement": "Toronto",
                    "country": "Canada"
                }
            },
            "email": "jhuang@yorku.ca"
        },
        {
            "first": "Tingting",
            "middle": [],
            "last": "He",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Central China Normal University",
                "location": {
                    "postCode": "430079",
                    "settlement": "Wuhan",
                    "country": "China"
                }
            },
            "email": "tthe@mail.ccnu.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). Due to the mismatch among different domains, a sentiment classifier trained in one domain may not work well when directly applied to other domains. Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs. To address the above challenge, we propose a novel domain adaptation method, called Bi-Transferring Deep Neural Networks (BTDNNs). The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain. The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner. As a result, the transferred source domain is supervised and follows similar distribution as the target domain. Therefore, any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in a target domain. We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products. Experimental results show that our proposed approach significantly outperforms the several baseline methods, and achieves an accuracy which is competitive with the state-of-the-art method for domain adaptation.",
    "pdf_parse": {
        "paper_id": "P16-1031",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). Due to the mismatch among different domains, a sentiment classifier trained in one domain may not work well when directly applied to other domains. Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs. To address the above challenge, we propose a novel domain adaptation method, called Bi-Transferring Deep Neural Networks (BTDNNs). The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain. The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner. As a result, the transferred source domain is supervised and follows similar distribution as the target domain. Therefore, any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in a target domain. We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products. Experimental results show that our proposed approach significantly outperforms the several baseline methods, and achieves an accuracy which is competitive with the state-of-the-art method for domain adaptation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "With the rise of social media (e.g., blogs and social networks etc.), more and more user generated sentiment data have been shared on the Web (Pang et al., 2002; Pang and Lee, 2008; Liu, 2012; Zhou et al., 2011) . They exist in the form of user reviews on shopping or opinion sites, in posts of blogs/questions or customer feedbacks. This has created a surge of research in sentiment classification (or sentiment analysis), which aims to automatically determine the sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs, questions).",
                "cite_spans": [
                    {
                        "start": 142,
                        "end": 161,
                        "text": "(Pang et al., 2002;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 162,
                        "end": 181,
                        "text": "Pang and Lee, 2008;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 182,
                        "end": 192,
                        "text": "Liu, 2012;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 193,
                        "end": 211,
                        "text": "Zhou et al., 2011)",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Machine learning algorithms have been proved promising and widely used for sentiment classification (Pang et al., 2002; Pang and Lee, 2008; Liu, 2012) . However, the performance of these models relies on manually labeled training data. In many practical cases, we may have plentiful labeled data in the source domain, but very few or no labeled data in the target domain with a different data distribution. For example, we may have many labeled books reviews, but we are interested in detecting the polarity of electronics reviews. Reviews for different products might have different vocabularies, thus classifiers trained on one domain often fail to produce satisfactory results when transferring to another domain. This has motivated much research on cross-domain (domain adaptation) sentiment classification which transfers the knowledge from the source domain to the target domain (Thomas et al., 2006; Snyder and Barzilay, 2007; Blitzer et al., 2006; Blitzer et al., 2007; Daume III, 2007; Li and Zong, 2008; Li et al., 2009; Pan et al., 2010; Kumar et al., 2010; Glorot et al., 2011; Chen et al., 2011a; Chen et al., 2012; Li et al., 2012; Xia et al., 2013a; Li et al., 2013; Zhou et al., 2015a; Zhuang et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 119,
                        "text": "(Pang et al., 2002;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 120,
                        "end": 139,
                        "text": "Pang and Lee, 2008;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 140,
                        "end": 150,
                        "text": "Liu, 2012)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 885,
                        "end": 906,
                        "text": "(Thomas et al., 2006;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 907,
                        "end": 933,
                        "text": "Snyder and Barzilay, 2007;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 934,
                        "end": 955,
                        "text": "Blitzer et al., 2006;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 956,
                        "end": 977,
                        "text": "Blitzer et al., 2007;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 978,
                        "end": 994,
                        "text": "Daume III, 2007;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 995,
                        "end": 1013,
                        "text": "Li and Zong, 2008;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 1014,
                        "end": 1030,
                        "text": "Li et al., 2009;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 1031,
                        "end": 1048,
                        "text": "Pan et al., 2010;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 1049,
                        "end": 1068,
                        "text": "Kumar et al., 2010;",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 1069,
                        "end": 1089,
                        "text": "Glorot et al., 2011;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 1090,
                        "end": 1109,
                        "text": "Chen et al., 2011a;",
                        "ref_id": null
                    },
                    {
                        "start": 1110,
                        "end": 1128,
                        "text": "Chen et al., 2012;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 1129,
                        "end": 1145,
                        "text": "Li et al., 2012;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 1146,
                        "end": 1164,
                        "text": "Xia et al., 2013a;",
                        "ref_id": null
                    },
                    {
                        "start": 1165,
                        "end": 1181,
                        "text": "Li et al., 2013;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 1182,
                        "end": 1201,
                        "text": "Zhou et al., 2015a;",
                        "ref_id": null
                    },
                    {
                        "start": 1202,
                        "end": 1222,
                        "text": "Zhuang et al., 2015)",
                        "ref_id": "BIBREF54"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Depending on whether the labeled data are available for the target domain, cross-domain sen-timent classification can be divided into two categories: supervised domain adaptation and unsupervised domain adaptation. In scenario of supervised domain adaptation, labeled data is available in the target domain but the number is usually too small to train a good sentiment classifier, while in unsupervised domain adaptation only unlabeled data is available in the target domain, which is more challenging. This work focuses on the unsupervised domain adaptation problem of which the essence is how to employ the unlabeled data of target domain to guide the model learning from the labeled source domain.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The fundamental challenge of cross-domain sentiment classification lies in that the source domain and the target domain have different data distribution. Recent work has investigated several techniques for alleviating the domain discrepancy: instance-weight adaptation (Huang et al., 2007; Jiang and Zhai, 2007; Li and Zong, 2008; Mansour et al., 2009; Dredze et al., 2010; Chen et al., 2011b; Chen et al., 2011a; Chen et al., 2012; Li et al., 2013; Xia et al., 2013a) and feature representation adaptation (Thomas et al., 2006; Snyder and Barzilay, 2007; Blitzer et al., 2006; Blitzer et al., 2007; Li et al., 2009; Pan et al., 2010; Zhou et al., 2015a; Zhuang et al., 2015) . The first kind of methods assume that some training data in the source domain are very useful for the target domain and these data can be used to train models for the target domain after re-weighting. In contrast, feature representation approaches attempt to develop an adaptive feature representation that is effective in reducing the difference between domains.",
                "cite_spans": [
                    {
                        "start": 269,
                        "end": 289,
                        "text": "(Huang et al., 2007;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 290,
                        "end": 311,
                        "text": "Jiang and Zhai, 2007;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 312,
                        "end": 330,
                        "text": "Li and Zong, 2008;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 331,
                        "end": 352,
                        "text": "Mansour et al., 2009;",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 353,
                        "end": 373,
                        "text": "Dredze et al., 2010;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 374,
                        "end": 393,
                        "text": "Chen et al., 2011b;",
                        "ref_id": null
                    },
                    {
                        "start": 394,
                        "end": 413,
                        "text": "Chen et al., 2011a;",
                        "ref_id": null
                    },
                    {
                        "start": 414,
                        "end": 432,
                        "text": "Chen et al., 2012;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 433,
                        "end": 449,
                        "text": "Li et al., 2013;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 450,
                        "end": 468,
                        "text": "Xia et al., 2013a)",
                        "ref_id": null
                    },
                    {
                        "start": 507,
                        "end": 528,
                        "text": "(Thomas et al., 2006;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 529,
                        "end": 555,
                        "text": "Snyder and Barzilay, 2007;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 556,
                        "end": 577,
                        "text": "Blitzer et al., 2006;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 578,
                        "end": 599,
                        "text": "Blitzer et al., 2007;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 600,
                        "end": 616,
                        "text": "Li et al., 2009;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 617,
                        "end": 634,
                        "text": "Pan et al., 2010;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 635,
                        "end": 654,
                        "text": "Zhou et al., 2015a;",
                        "ref_id": null
                    },
                    {
                        "start": 655,
                        "end": 675,
                        "text": "Zhuang et al., 2015)",
                        "ref_id": "BIBREF54"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Recently, some efforts have been initiated on learning robust feature representations with deep neural networks (DNNs) in the context of crossdomain sentiment classification (Glorot et al., 2011; Chen et al., 2012) . Glorot et al. (2011) proposed to learn robust feature representations with stacked denoising auto-encoders (SDAs) (Vincent et al., 2008) . Denoising auto-encoders are onelayer neural networks that are optimized to reconstruct input data from partial and random corruption. These denoisers can be stacked into deep learning architectures. The outputs of their intermediate layers are then used as input features for SVMs (Fan et al., 2008) . Chen et al. (2012) proposed a marginalized SDA (mSDA) that addressed the two crucial limitations of SDAs: high computational cost and lack of scalability to highdimensional features. However, these methods learn the unified domain-invariable feature representations by combining the source domain data and that of the target domain data together, which cannot well characterize the domain-specific features as well as the commonality of domains.",
                "cite_spans": [
                    {
                        "start": 174,
                        "end": 195,
                        "text": "(Glorot et al., 2011;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 196,
                        "end": 214,
                        "text": "Chen et al., 2012)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 217,
                        "end": 237,
                        "text": "Glorot et al. (2011)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 331,
                        "end": 353,
                        "text": "(Vincent et al., 2008)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 637,
                        "end": 655,
                        "text": "(Fan et al., 2008)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 658,
                        "end": 676,
                        "text": "Chen et al. (2012)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "To this end, we propose a Bi-Transferring Deep Neural Networks (BTDNNs) which can transfer the source domain examples to the target domain and also transfer the target domain examples to the source domain, as shown in Figure 1 . In BTDNNs, the linear transformation makes the feasibility of transferring between domains, and the linear data reconstruction manner ensures the distribution consistency between the transferred domain and the desirable domain. Specifically, our BTDNNs has one common encoder f c , two decoders g s and g t which can map an example to the source domain and the target domain respectively. As a result, the source domain can be transferred to the target domain along with its sentiment label, and any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in the target domain, as the transferred source domain data share the similar distribution as the target domain. Experimental results show that the proposed approach significantly outperforms several baselines, and achieves an accuracy which is competitive with the state-of-the-art method for cross-domain sentiment classification.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 225,
                        "end": 226,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 describes our proposed bi-transferring deep neural networks (BTDNNs). Section 4 presents the experimental results. In Section 5, we conclude with ideas for future research.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Domain adaptation aims to generalize a classifier that is trained on a source domain, for which typically plenty of training data is available, to a target domain, for which data is scarce. Cross-domain generalization is important in many real applications, the key challenge is that data in the source and the target domain are often distributed differently.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Recent work has investigated several techniques for alleviating the difference in the context of cross-domain sentiment classification task. Blitzer et al. (2007) proposed a structural correspondence learning (SCL) algorithm to train a crossdomain sentiment classifier. SCL is motivated by a multi-task learning algorithm, alternating structural optimization (ASO), proposed by Ando and Zhang (2005) . Given labeled data from a source domain and unlabeled data from both source and target domains, SCL attempts to model the relationship between \"pivot features\" and \"non-pivot features\". Pan et al. (2010) proposed a spectral feature alignment (SFA) algorithm to align the domain-specific words from the source and target domains into meaningful clusters, with the help of domain-independent words as a bridge. In the way, the cluster can be used to reduce the gap between domain-specific words of two domains. Dredze et al. (2010) combined classifier weights using confidence-weighted learning, which represented the covariance of the weight vectors. Xia et al. (2013a) proposed an instance selection and instance weighting method for cross-domain sentiment classification. After that, Xia et al. (2013b) proposed a feature ensemble plus sample selection method to further improve the sentiment classification adaptation. Zhou et al. (Zhou et al., 2015b) proposed to bridge the domain gap with the help of topical correspondence. Li et al. (2009) proposed to transfer common lexical knowledge across domains via matrix factorization techniques. Zhou et al. (2015a) further improved the matrix factorization techniques via a regularization term on the pivots and domain-specific words, ensuring that the pivots capture only correspondence aspects and the domain-specific words capture only individual aspects. Li and Zong (2008) proposed the multi-label consensus training approach which combined several base classifiers trained with SCL. Chen et al. (2012) proposed a domain adaptation algorithm based on sample and feature selection. Li et al. (2013) proposed an active learning algorithm for cross-domain sentiment classification. Xiao and Guo (2013) investigated the online active domain adaptation problem in a novel but practical setting where the labels can be acquired with a lower cost in the source domain than in the target domain.",
                "cite_spans": [
                    {
                        "start": 141,
                        "end": 162,
                        "text": "Blitzer et al. (2007)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 378,
                        "end": 399,
                        "text": "Ando and Zhang (2005)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 588,
                        "end": 605,
                        "text": "Pan et al. (2010)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 911,
                        "end": 931,
                        "text": "Dredze et al. (2010)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 1052,
                        "end": 1070,
                        "text": "Xia et al. (2013a)",
                        "ref_id": null
                    },
                    {
                        "start": 1187,
                        "end": 1205,
                        "text": "Xia et al. (2013b)",
                        "ref_id": null
                    },
                    {
                        "start": 1323,
                        "end": 1355,
                        "text": "Zhou et al. (Zhou et al., 2015b)",
                        "ref_id": null
                    },
                    {
                        "start": 1431,
                        "end": 1447,
                        "text": "Li et al. (2009)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 1546,
                        "end": 1565,
                        "text": "Zhou et al. (2015a)",
                        "ref_id": null
                    },
                    {
                        "start": 1810,
                        "end": 1828,
                        "text": "Li and Zong (2008)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 1940,
                        "end": 1958,
                        "text": "Chen et al. (2012)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 2037,
                        "end": 2053,
                        "text": "Li et al. (2013)",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 2135,
                        "end": 2154,
                        "text": "Xiao and Guo (2013)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "There has also been research in exploring careful structuring of features or prior knowledge for domain adaptation. Daum\u00e9 III ( 2007) proposed a kernel-mapping function which maps both source and target domains data to a high-dimensional feature space so that data points from the same domain are twice as similar as those form different domains. Dai et al. (2008) proposed translated learning which used a language model to link the class labels to the features in the source domain, which in turn is translated to the features in the target domain. Xia et al. (2010) proposed a POSbased ensemble model for cross-domain sentiment classification. Xiao et al. (2013) proposed a supervised representation learning method to tackle domain adaptation by inducing predictive latent features based on supervised word clustering. He et al. (2011) employed a joint sentiment-topic model for cross-domain sentiment classification; Bollegala et al. ( 2011) used a sentiment sensitive thesaurus to perform cross-domain sentiment classification. Xiao and Guo (2015) proposed to learn distributed state representations for cross-domain sequence predictions.",
                "cite_spans": [
                    {
                        "start": 347,
                        "end": 364,
                        "text": "Dai et al. (2008)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 551,
                        "end": 568,
                        "text": "Xia et al. (2010)",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 647,
                        "end": 665,
                        "text": "Xiao et al. (2013)",
                        "ref_id": null
                    },
                    {
                        "start": 823,
                        "end": 839,
                        "text": "He et al. (2011)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 1034,
                        "end": 1053,
                        "text": "Xiao and Guo (2015)",
                        "ref_id": "BIBREF44"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Recently, some efforts have been initiated on learning robust feature representations with deep neural networks (DNNs) for cross-domain natural language processing. Glorot et al. (2011) and Chen et al. (2012) proposed to use deep learning for cross-domain sentiment classification. Most recently, Yang and Eisenstein (2014) proposed an unsupervised domain adaptation method with marginalized structured dropout. Furthermore, Yang and Eisenstein (2015) proposed to use feature embeddings with metadata domain attributes for multi-domain adaptation. In this paper, our proposed approach BTDNNs tackles the domain discrepancy with a linear data construction manner, which can effectively model the domainspecific features as well as the commonality of domains. Deep learning techniques have also been proposed to heterogeneous transfer learning (Socher et al., 2013; Zhou et al., 2014; Kan et al., 2015; Long et al., 2015) , where knowledge is transferred from one modality to another based on the correspondences at hand. Our proposed framework can be considered as a more general case, where the bias of the correspondences between the source and target domains is constrained with a linear data reconstruction manner.",
                "cite_spans": [
                    {
                        "start": 165,
                        "end": 185,
                        "text": "Glorot et al. (2011)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 190,
                        "end": 208,
                        "text": "Chen et al. (2012)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 297,
                        "end": 323,
                        "text": "Yang and Eisenstein (2014)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 425,
                        "end": 451,
                        "text": "Yang and Eisenstein (2015)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 842,
                        "end": 863,
                        "text": "(Socher et al., 2013;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 864,
                        "end": 882,
                        "text": "Zhou et al., 2014;",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 883,
                        "end": 900,
                        "text": "Kan et al., 2015;",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 901,
                        "end": 919,
                        "text": "Long et al., 2015)",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Besides, other researchers also explore the DNNs for sentiment analysis (Socher et al., 2011; Tang et al., 2014; Tang et al., 2015; Zhai and Zhang, 2016; Chandar et al., 2014) . However, all these methods focus on the sentiment analysis without considering the domain discrepancy. In this paper, we focus on domain adaptation for sentiment classification with a different model formulation and task definition.",
                "cite_spans": [
                    {
                        "start": 72,
                        "end": 93,
                        "text": "(Socher et al., 2011;",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 94,
                        "end": 112,
                        "text": "Tang et al., 2014;",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 113,
                        "end": 131,
                        "text": "Tang et al., 2015;",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 132,
                        "end": 153,
                        "text": "Zhai and Zhang, 2016;",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 154,
                        "end": 175,
                        "text": "Chandar et al., 2014)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "3 Bi-Transferring Deep Neural Networks",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Given two domains X s and X t , where X s and X t are referred to a source domain and a target domain, respectively. Suppose we have a set of labeled sentiment examples as well as some unlabeled examples in the source domain X s with size n s , containing terms from a vocabulary V with size m. The examples in the source domain X s can be represented as a term-document matrix",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Definition",
                "sec_num": "3.1"
            },
            {
                "text": "X s = {x s 1 , \u2022 \u2022 \u2022 , x s ns } \u2208 R m\u00d7ns , with their senti- ment labels y s = {y s 1 , \u2022 \u2022 \u2022 , y s ns }, where x s i \u2208 R m",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Definition",
                "sec_num": "3.1"
            },
            {
                "text": "is the feature representation of the i-th source domain example with a tf-idf weight of the corresponding term and y s i \u2208 {+1, -1} is its sentiment label. 1Similarly, suppose we have a set of unlabeled examples in the target domain X t with size n t , containing terms from a vocabulary V with size m. The examples in target domain X t can also be represented as a term-document matrix X t = {x",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Definition",
                "sec_num": "3.1"
            },
            {
                "text": "(t) 1 , \u2022 \u2022 \u2022 , x (t)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Definition",
                "sec_num": "3.1"
            },
            {
                "text": "nt } \u2208 R m\u00d7nt , where each example denotes a tf-idf weight of the corresponding term. The task of cross-domain sentiment classification is to learn a robust classifier to predict the polarity of unseen examples from X t . Note that we only consider one source domain and one target domain in this paper. However, our proposed algorithm is a general framework and can be easily adapted to multi-domain problems.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Definition",
                "sec_num": "3.1"
            },
            {
                "text": "An auto-encoder is an unsupervised neural network which is trained to reconstruct a given input vector from its latent representation (Bengio et al., 2007) . It can be seen as a special neural network with three layers: the input layer, the latent layer, and the reconstruction layer. An autoencoder contains two parts: encoder and decoder. The encoder, denoted as f , attempts to map an input vector x \u2208 R m\u00d71 to the latent representation z \u2208 R k\u00d71 , in which k is the number of neurons in the latent layer. Usually, f is a nonlinear function as follows:",
                "cite_spans": [
                    {
                        "start": 134,
                        "end": 155,
                        "text": "(Bengio et al., 2007)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "z = f (x) = se(Wx + b) (1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "where s e is the activation function of the encoder, whose input is called the activation function, which is usually non-linear, such as sigmoid function or tanh function is a linear transform parameter, and b \u2208 R k\u00d71 is the basis. The decoder, denoted as g, tries to map the latent representation z back to a reconstruction:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "g(z) = s d (W z + b ) (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "Similarly, s d is the activation function of the decoder with parameters {W , b }.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "The training objective is the determination of parameters {W, b} and {W , b } that minimize the average reconstruction errors:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "L = min W,b,W ,b N i=1 xi -g(f (xi)) 2 2 (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "where x i represents the i-th one of N training examples. Parameters {W, b} and {W , b } can be optimized by stochastic or mini-batch gradient descent. By minimizing the reconstruction error, we require the latent features should be able to reconstruct the original input as much as possible.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Basic Auto-Encoder",
                "sec_num": "3.2"
            },
            {
                "text": "The traditional auto-encoder in subsection 3.2 attempts to reconstruct the input itself, which is usually used for feature representation learning. Nevertheless, our proposed bi-transferring deep neural networks (BTDNNs) attempts to transfer examples between domains to deal with the domain discrepancy, with the inspiration of DNNs in computer vision (Kan et al., 2015) . Motivated by the successful application in computer vision (Kan et al., 2015) , we construct the architecture of BTDNNs with one encoder f e , and two decoders, g s and g t shown in Figure 1 , which can transform an input example to the source domain and the target domain respectively. 2 Specifically, the encoder f c tries to map an input example x into the latent feature representation z, which is common to both the source and target domains as follows:",
                "cite_spans": [
                    {
                        "start": 352,
                        "end": 370,
                        "text": "(Kan et al., 2015)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 432,
                        "end": 450,
                        "text": "(Kan et al., 2015)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 562,
                        "end": 563,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "z = fc(x) = se(Wcx + bc)",
                        "eq_num": "(4)"
                    }
                ],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "The decoder g s attempts to map the latent representation to the source domain, and the decoder g t attempts to map the latent representation to the target domain as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "gs(x) = s d (Wsz + bs) (5) gt(x) = s d (Wtz + bt)",
                        "eq_num": "(6)"
                    }
                ],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "where s e (\u2022) and s d (\u2022) are the element-wise nonlinear activation function, e.g., sigmoid or tanh function, W c and b c are the parameters for encoder f c , W s and b s are the parameters for decoder g s , W t and b t are the parameters for decoder g t . Following the literature (Kan et al., 2015) , we attempt to map the source domain examples X s to the source domain (e.g., X s itself) with an encoder f c and a decoder g s . Similarly, given an encoder f c and a decoder g t , we aim to map the source domain examples X s to the target domain. Although it is unknown what the mapped examples look like, they are expected to follow the similar distribution as the target domain. This kind of distribution consistency between two domains can be characterized from the perspective of a linear data reconstruction manner.",
                "cite_spans": [
                    {
                        "start": 282,
                        "end": 300,
                        "text": "(Kan et al., 2015)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "The two domains X s and X t can be generally reconstructed from each other, and their distances can be used to measure the domain discrepancy. Following the literature (He et al., 2012) , BTDNNs attempt to represent a transferred source domain g t (f c (x s i )) with a linear reconstruction function from the target domain:",
                "cite_spans": [
                    {
                        "start": 168,
                        "end": 185,
                        "text": "(He et al., 2012)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "gt(fc(x s i )) -Xt\u03b2 t i ) 2 2 (7)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "2 In the implementation, we use the stacked denoising auto-encoders (SDA) (Vincent et al., 2008) to model the source and the target domain data.",
                "cite_spans": [
                    {
                        "start": 74,
                        "end": 96,
                        "text": "(Vincent et al., 2008)",
                        "ref_id": "BIBREF39"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "where \u03b2 t i is the coefficients for the reconstruction of transferred source domain examples. Equation (7) enforces that each example of transferred domain is consistent with that of target domain, which ensures that the transferred source domain follows the similar distribution as the target domain. The overall objective for the examples of source domain X s can be formulated as below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "min fc,gs,g t ,\u03b2 s i Xs -gs(fc(Xs)) 2 2 + gt(fc(Xs)) -XtBt) 2 2 s.t. \u03b2 t i 2 2 < \u03c4, Bt = [\u03b2 t 1 , \u03b2 t 2 , \u2022 \u2022 \u2022 , \u03b2 t ns ] T \u2208 R ns\u00d7n t where g s (f c (X s ) = [g s (f c (x s 1 )), \u2022 \u2022 \u2022 , g s (f c (x s nt ))] and g t (f c (X s ) = [g t (f c (x t 1 )), g t (f c (x t ns ))].",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "The same simplifications are used hereinafter if without misunderstanding.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "Similarly, for the examples of target domain X t , with encoder f c and decoder g t they should be mapped on the target domain. Also, with encoder f c and decoder g s they should be mapped to the source domain, where they can be reconstructed by the source domain examples from the point of view of a linear data reconstruction manner (He et al., 2012) , so as to ensure a similar distribution between the source domain and the transferred target domain. The overall objective for the examples of target domain X t can be written as:",
                "cite_spans": [
                    {
                        "start": 335,
                        "end": 352,
                        "text": "(He et al., 2012)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "min fc,gs,g t ,\u03b2 t i Xt -gt(fc(Xt)) 2 2 + gs(fc(Xt)) -XsBs) 2 2 s.t. \u03b2 s j 2 2 < \u03c4, Bs = [\u03b2 s 1 , \u03b2 s 2 , \u2022 \u2022 \u2022 , \u03b2 s n t ] T \u2208 R n t \u00d7ns",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "Combining the above equations, the overall objective of BTDNNs can be formulated as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "min fc,gs,g t ,Bs,B t Xs -gs(fc(Xs)) 2 2 + gt(fc(Xs)) -XtBt) 2 2 + Xt -gt(fc(Xt)) 2 2 + gs(fc(Xt)) -XsBs) 2 2 (8) + \u03b3 ns i=1 \u03b2 t i 2 2 + n t j=1 \u03b2 s j 2 2",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "where \u03b3 is a regularization parameter controlling the amount of shrinkage. With the optimization of equation ( 8), our proposed approach BTDNNs can map any input examples to the source and target domains respectively. Especially, the source domain examples X s can transferred to the target domain along with their sentiment labels. The transferred source domain data g t (f s (X s )) share the similar distribution as the target domain, so any supervised method can be used to learn a classifier for sentiment classification in the target domain. In this paper, a linear support vector machine (SVM) (Fan et al., 2008) is employed for building sentiment classification models.",
                "cite_spans": [
                    {
                        "start": 601,
                        "end": 619,
                        "text": "(Fan et al., 2008)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Bi-Transferring Deep Neural Networks",
                "sec_num": "3.3"
            },
            {
                "text": "Note that the optimization problem in equation ( 8 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "+ Xt -gt(fc(Xt)) 2 2 + gs(fc(Xt)) -Xs) 2 2 (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "where Xs = X s B s and Xt = X t B t . Equation ( 9) can easily optimized by gradient descent as the basic auto-encoder (Bengio et al., 2007) .",
                "cite_spans": [
                    {
                        "start": 119,
                        "end": 140,
                        "text": "(Bengio et al., 2007)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "3.4.2 Optimize {B s , B t } given {f c , g s , g t }",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "When {f c , g s , g t } are fixed, the objective function in equation ( 8) can be written as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "min Bs,B t Gt -XtBt) 2 2 + Gs -XsBs) 2 2 + \u03b3 ns i=1 \u03b2 t i 2 2 + n t j=1 \u03b2 s j 2 2",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "where",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "g s (f c (X t )) = G s = [g s 1 , \u2022 \u2022 \u2022 , g s nt ] and g t (f c (X s )) = G t = [g t 1 , \u2022 \u2022 \u2022 , g t ns ].",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "Since G s and G t are independent with each other, so they can be optimized independently. The optimization of G s with other variables fixed is a least squares problem with 2 -regularization. It can also be decomposed into n t optimization problems, with each corresponding to one \u03b2 s j and can be solved in parallel:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "min \u03b2 s j g s j -Xs\u03b2 s j 2 2 + \u03b3 \u03b2 s j 2 2 (10) for j = 1, 2, \u2022 \u2022 \u2022 , n t .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "It is a standard 2 -regularized least squares problem and the solution is:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "\u03b2 s j = X T s Xs + \u03b3I -1 X T s g s j (",
                        "eq_num": "11"
                    }
                ],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "where I is an identity matrix with all entries equal to 1. Similarly, The optimization of G t can also be decomposed into n s 2 -regularized least squares problems and the solution of each one is:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "\u03b2 t i = X T t Xt + \u03b3I -1 X T t g t i",
                        "eq_num": "(12)"
                    }
                ],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "for i = 1, 2, \u2022 \u2022 \u2022 , n s . We repeat the above equations until f c , g s , g t , B s and B t converge or a maximum number of iterations is exceeded.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Learning Algorithm",
                "sec_num": "3.4"
            },
            {
                "text": "In this section, we analyze the computational complexity of the learning algorithm described in equations ( 9), ( 11) and ( 12). Besides expressing the complexity of the algorithm using big O notation, we also count the number of arithmetic operations to provide more details about the run time. Computational complexity of learning matrix G s is O(m \u00d7 n s \u00d7 k) per iteration. Similarly, for each iteration, learning matrices G t takes O(m \u00d7 n t \u00d7 k). Learning matrices B s and B t takes O(m 2 \u00d7 n s ) and O(m 2 \u00d7 n t ) operations per iteration. In real applications, we have k m. Therefore, the overall complexity of the algorithm, dominated by computation of matrices B s and B t , is O(m 2 \u00d7 n) where n = max(n s , n t ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Algorithm Complexity",
                "sec_num": "3.5"
            },
            {
                "text": "Domain adaptation for sentiment classification has been widely studied in the NLP community. A large majority experiments are performed on the benchmark made of reviews of Amazon products gathered by Blitzer et al. (2006) . This data set contains 4 different domains: Book (B), DVDs (D), Electronics (E) and Kitchen (K). For simplicity and comparability, we follow the convention of (Blitzer et al., 2006; Pan et al., 2010; Glorot et al., 2011; Xiao and Guo, 2013 ) and only consider the binary classification problem whether a review is positive (higher than 3 stars) or negative (3 stars or lower). There are 1000 positive and 1000 negative reviews for each domain, as well as approximately 4,000 unlabeled reviews (varying slightly between domains). The positive and negative reviews are also exactly balanced. ",
                "cite_spans": [
                    {
                        "start": 200,
                        "end": 221,
                        "text": "Blitzer et al. (2006)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 383,
                        "end": 405,
                        "text": "(Blitzer et al., 2006;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 406,
                        "end": 423,
                        "text": "Pan et al., 2010;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 424,
                        "end": 444,
                        "text": "Glorot et al., 2011;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 445,
                        "end": 463,
                        "text": "Xiao and Guo, 2013",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Set",
                "sec_num": "4.1"
            },
            {
                "text": "\u2192 B, E \u2192 B, K \u2192 B, K \u2192 E, D \u2192 E, B \u2192 E, B \u2192 D, K \u2192 D, E \u2192 D, B \u2192 K, D \u2192 K, E \u2192 K,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Set",
                "sec_num": "4.1"
            },
            {
                "text": "where the word before an arrow corresponds with the source domain and the word after an arrow corresponds with the target domain. To be fair to other algorithms that we compare to, we use the raw bag-of-words unigram/bigram features as their input and pre-process with tf-idf (Blitzer et al., 2006) . ",
                "cite_spans": [
                    {
                        "start": 276,
                        "end": 298,
                        "text": "(Blitzer et al., 2006)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Set",
                "sec_num": "4.1"
            },
            {
                "text": "As a baseline method, we train a linear SVM (Fan et al., 2008) on the raw bag-of-words representation of the labeled source domain and test it on the target domain. In the original paper regarding the benchmark data set, Blitzer et al. (2006) Recently, some efforts have been initiated on learning robust feature representations with DNNs for cross-domain sentiment classification. Glorot et al. (2011) first employed stacked Denoising Auto-encoders (SDA) to extract meaningful representation for domain adaptation. Chen et al. (2012) proposed marginalized SDA (mSDA) that addressed the high computational cost and lack of scalability to high-dimensional features. Zhuang et al. (2015) proposed a state-of-the-art method called transfer learning with deep autoencoders (TLDA).",
                "cite_spans": [
                    {
                        "start": 44,
                        "end": 62,
                        "text": "(Fan et al., 2008)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 221,
                        "end": 242,
                        "text": "Blitzer et al. (2006)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 382,
                        "end": 402,
                        "text": "Glorot et al. (2011)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 516,
                        "end": 534,
                        "text": "Chen et al. (2012)",
                        "ref_id": null
                    },
                    {
                        "start": 665,
                        "end": 685,
                        "text": "Zhuang et al. (2015)",
                        "ref_id": "BIBREF54"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "For SCL, PJNMF, SDA, mSDA and TLDA, we use the source codes provided by the authors. For SFA and MCT, we re-implement them based on the original papers. The above methods serve as comparisons in our empirical evaluation. For fair comparison, all hyper-parameters are set by 5-fold cross validation on the training set from the source domain. 3 For our proposed BTDNNs, the number of hidden neurons is set as 1000, the regularization parameter \u03b3 is tuned via 5-fold cross-validation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "For SDA, mSDA, TLDA and BTDNNs, we can construct the classifiers for the target domain in two ways. The first way is directly to use the stacking SVM on top of the output of the hidden layer. The second way is to apply the standard SVM to train a classifier for source domain in the embedding space. Then the classifiers is applied to predict sentiment labels for target domain data. For fair comparison with the shallow models, we choose the second way in this paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "Figure 2 shows the accuracy of classification results for all methods and for all source-target domain pairs. We can check that all compared methods achieve the similar performance with the results reported in the original papers. From Figure 2 , we can see that our proposed approach BTDNNs outperforms all other eight comparison methods in general. The baseline performs poorly on all the 12 tasks, while the other seven domain adaptation methods, SCL, MCT, SFA, PJNMF, SDA, mSDA and TLDA, consistently outperform the baseline method across all the 12 tasks, which demonstrates that the transferred knowledge from the source domain to the target domain is useful for sentiment classification. Nevertheless, the improvements achieved by these seven methods over the baseline are much smaller than the proposed approach BTDNNs.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "2",
                        "ref_id": null
                    },
                    {
                        "start": 243,
                        "end": 244,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "Surprisingly, we note that the deep learning based methods (SDA, mSDA and TLDA) perform worse than our approach, the reason may be that SDA, mSDA and TLDA learn the unified domaininvariable feature representations by combining the source domain data and that of the target domain data together, which cannot well characterize the domain-specific features as well as the commonality of domains. On the contrary, our proposed BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "We also conduct significance tests for our proposed approach BTDNNs and the state-of-the-art method (TLDA) using a McNemar paired test for labeling disagreements (Gillick and Cox, 1989) . In general, the average result on the 12 sourcetarget domain pairs indicates that the difference benchmark set by the authors. between BTDNNs and TLDA is mildly significant with p < 0.08. Furthermore, we also conduct the experiments on a much larger industrial-strength data set of 22 domains (Glorot et al., 2011) . The preliminary results show that BTDNNs significantly outperforms TLDA (p < 0.05). Therefore, we will report our detailed results and discussions in our future work.",
                "cite_spans": [
                    {
                        "start": 162,
                        "end": 185,
                        "text": "(Gillick and Cox, 1989)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 481,
                        "end": 502,
                        "text": "(Glorot et al., 2011)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compared Methods",
                "sec_num": "4.2"
            },
            {
                "text": "In this subsection, we look into how similar two domains are to each other. Ben-David et al. (2006) showed that the A-distance as a measure of how different between the two domains. They hypothesized that it should be difficult to discriminate between the source and target domains in order to have a good transfer between them. In practice, computing the exact A-distance is impossible and one has to compute a proxy. Similar to (Glorot et al., 2011) , the proxy for the A-distance is then defined as 2(1 -2 ), where is the generalization error of a linear SVM classifier trained on the binary classification problem to distinguish inputs between the two domains.",
                "cite_spans": [
                    {
                        "start": 76,
                        "end": 99,
                        "text": "Ben-David et al. (2006)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 430,
                        "end": 451,
                        "text": "(Glorot et al., 2011)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Domain Divergence",
                "sec_num": "4.3"
            },
            {
                "text": "Figure 3 presents the results for each pair of domains. Surprisingly, the distance is increased with the help of new feature representations, e.g., distinguishing between domains becomes easier with the BTDNNs features. We explain this effect through the fact that BTDNNs can ensure the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner, which can learn a generally better representations for the input data. This helps both tasks, distinguishing between domains and sentiment classification (e.g., in the book domain BTDNNs might interpolate the feature \"exciting\" from \"boring\", both are not particularly relevant for sentiment classification but might help distinguish the review from the Electronic domain.).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Domain Divergence",
                "sec_num": "4.3"
            },
            {
                "text": "In this paper, we propose a novel Bi-Transferring Deep Neural Networks (BTDNNs) for crossdomain sentiment classification. The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain. The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner. Experimental results show that BTDNNs significantly outperforms the several baselines, and achieves an accuracy which is competitive with the state-of-the-art method for sentiment classification adaptation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "5"
            },
            {
                "text": "There are some ways in which this research could be continued. First, since deep learning may obtain better generalization on large-scale data sets (Bengio, 2009) , a straightforward path of the future research is to apply the proposed BTDNNs for domain adaptation on a much larger industrial-strength data set of 22 domains (Glorot et al., 2011) . Second, we will try to investigate the use of the proposed approach for other kinds of data set, such as 20 newsgroups and Reuters-21578 (Li et al., 2012; Zhuang et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 148,
                        "end": 162,
                        "text": "(Bengio, 2009)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 325,
                        "end": 346,
                        "text": "(Glorot et al., 2011)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 486,
                        "end": 503,
                        "text": "(Li et al., 2012;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 504,
                        "end": 524,
                        "text": "Zhuang et al., 2013)",
                        "ref_id": "BIBREF53"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "5"
            },
            {
                "text": "We use upper case and lower case characters represent the matrices and vectors respectively throughout the paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We keep the default value of some of the parameters in SCL and SFA, e.g., the number of stop-words removed and stemming parameters -as they were already tuned for this",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "This work was supported by the National Natural Science Foundation of China (No. 61303180 and No. 61573163), the Fundamental Research Funds for the Central Universities (No. CCNU15ZD003 and No. CCNU16A02024), and also supported by a Discovery grant from the Natural Sciences and Engineering Research Council (NSERC) of Canada and an NSERC CREATE award. We thank the anonymous reviewers for their insightful comments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "A framework for learning predictive structures from multiple tasks and unlabeled data",
                "authors": [
                    {
                        "first": "Rie",
                        "middle": [],
                        "last": "Kubota",
                        "suffix": ""
                    },
                    {
                        "first": "Ando",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Tong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "J. Mach. Learn. Res",
                "volume": "6",
                "issue": "",
                "pages": "1817--1853",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rie Kubota Ando and Tong Zhang. 2005. A frame- work for learning predictive structures from multi- ple tasks and unlabeled data. J. Mach. Learn. Res., 6:1817-1853.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Analysis of representations for domain adaptation",
                "authors": [
                    {
                        "first": "Shai",
                        "middle": [],
                        "last": "Ben-David",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Blitzer",
                        "suffix": ""
                    },
                    {
                        "first": "Koby",
                        "middle": [],
                        "last": "Crammer",
                        "suffix": ""
                    },
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "Pereira",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "137--144",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shai Ben-David, John Blitzer, Koby Crammer, and Fer- nando Pereira. 2006. Analysis of representations for domain adaptation. In NIPS, pages 137-144.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Greedy layer-wise training of deep networks",
                "authors": [
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "Pascal",
                        "middle": [],
                        "last": "Lamblin",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Popovici",
                        "suffix": ""
                    },
                    {
                        "first": "Hugo",
                        "middle": [],
                        "last": "Larochelle",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "153--160",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universite De Montreal, and Montreal Quebec. 2007. Greedy layer-wise training of deep networks. In NIPS, pages 153-160.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Learning deep architectures for AI. Foundations and Trends in Machine Learning",
                "authors": [
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "2",
                "issue": "",
                "pages": "1--127",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yoshua Bengio. 2009. Learning deep architectures for AI. Foundations and Trends in Machine Learning, 2(1):1-127.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Domain adaptation with structural correspondence learning",
                "authors": [
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Blitzer",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "Pereira",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "120--128",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspon- dence learning. In EMNLP, pages 120-128.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification",
                "authors": [
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Blitzer",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Dredze",
                        "suffix": ""
                    },
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "Pereira",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "120--128",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John Blitzer, M. Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification. In EMNLP, pages 120-128.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Using multiple sources to construct a sentiment sensitive thesaurus for cross-domain sentiment classification",
                "authors": [
                    {
                        "first": "Danushka",
                        "middle": [],
                        "last": "Bollegala",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Weir",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Carroll",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "132--141",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Danushka Bollegala, David Weir, and John Carroll. 2011. Using multiple sources to construct a senti- ment sensitive thesaurus for cross-domain sentiment classification. In ACL, pages 132-141.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "An autoencoder approach to learning bilingual word representations",
                "authors": [
                    {
                        "first": "Sarath",
                        "middle": [],
                        "last": "Chandar",
                        "suffix": ""
                    },
                    {
                        "first": "Stanislas",
                        "middle": [],
                        "last": "Lauly",
                        "suffix": ""
                    },
                    {
                        "first": "Hugo",
                        "middle": [],
                        "last": "Larochelle",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Mitesh",
                        "suffix": ""
                    },
                    {
                        "first": "Balaraman",
                        "middle": [],
                        "last": "Khapra",
                        "suffix": ""
                    },
                    {
                        "first": "Vikas",
                        "middle": [],
                        "last": "Ravindran",
                        "suffix": ""
                    },
                    {
                        "first": "Amrita",
                        "middle": [],
                        "last": "Raykar",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Saha",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "1--9",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sarath Chandar, Stanislas Lauly, Hugo Larochelle, Mitesh M Khapra, Balaraman Ravindran, Vikas Raykar, and Amrita Saha. 2014. An autoencoder approach to learning bilingual word representations. In NIPS, pages 1-9.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "2011a. Co-training for domain adaptation",
                "authors": [
                    {
                        "first": "Minmin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Blitzer",
                        "suffix": ""
                    },
                    {
                        "first": "Kilian",
                        "middle": [],
                        "last": "Weinberger",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "1--9",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minmin Chen, John Blitzer, and Kilian Weinberger. 2011a. Co-training for domain adaptation. In NIPS, pages 1-9.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Automatic feature decomposition for single view co-training",
                "authors": [
                    {
                        "first": "Minmin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Kilian",
                        "middle": [],
                        "last": "Weinberger",
                        "suffix": ""
                    },
                    {
                        "first": "Yixin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "953--960",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minmin Chen, Kilian Weinberger, and Yixin Chen. 2011b. Automatic feature decomposition for single view co-training. In ICML, pages 953-960.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Marginalized denoising autoencoders for domain adaptation",
                "authors": [
                    {
                        "first": "Minmin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Zhixiang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Kilian",
                        "middle": [],
                        "last": "Weinberger",
                        "suffix": ""
                    },
                    {
                        "first": "Fei",
                        "middle": [],
                        "last": "Sha",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "767--774",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minmin Chen, Zhixiang Xu, Kilian Weinberger, and Fei Sha. 2012. Marginalized denoising autoen- coders for domain adaptation. In ICML, pages 767- 774.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Translated learning: transfer learning across different feature spaces",
                "authors": [
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Dai",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Q",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "353--360",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "W. Dai, Y. Chen, G. Xue, Q. Yang, and Y. Yu. 2008. Translated learning: transfer learning across differ- ent feature spaces. In NIPS, pages 353-360.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Frustratingly easy domain adaptation",
                "authors": [
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daume",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "256--263",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hal Daume III. 2007. Frustratingly easy domain adap- tation. In ACL, pages 256-263.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Multi-domain learning by confidenceweighted parameter combination",
                "authors": [
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Dredze",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Kulesza",
                        "suffix": ""
                    },
                    {
                        "first": "Koby",
                        "middle": [],
                        "last": "Crammer",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Machine Learning",
                "volume": "79",
                "issue": "12",
                "pages": "123--149",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark Dredze, Alex Kulesza, and Koby Crammer. 2010. Multi-domain learning by confidence- weighted parameter combination. Machine Learn- ing, 79(12):123-149.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Liblinear: A library for large linear classification",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Chang",
                        "middle": [
                            "K"
                        ],
                        "last": "Hsieh",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Lin",
                        "middle": [
                            "C"
                        ],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "J. Mach. Learn. Res",
                "volume": "9",
                "issue": "",
                "pages": "1871--1874",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Fan, Chang K., Hsieh C., Wang X., and Lin C. 2008. Liblinear: A library for large linear classification. J. Mach. Learn. Res., 9:1871-1874.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Some statistical issues in the comparison of speech recoginition algorithms",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Gillick",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Cox",
                        "suffix": ""
                    }
                ],
                "year": 1989,
                "venue": "ICASSP",
                "volume": "",
                "issue": "",
                "pages": "532--535",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "L. Gillick and S. Cox. 1989. Some statistical issues in the comparison of speech recoginition algorithms. In ICASSP, pages 532-535.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Domain adaptation for large-scale sentiment classification: A deep learning approach",
                "authors": [
                    {
                        "first": "Xavier",
                        "middle": [],
                        "last": "Glorot",
                        "suffix": ""
                    },
                    {
                        "first": "Antoine",
                        "middle": [],
                        "last": "Bordes",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "513--520",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML, pages 513-520.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Automatically extracting polarity-bearing topics for cross-domain sentiment classification",
                "authors": [
                    {
                        "first": "Yulan",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Chenghua",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Harith",
                        "middle": [],
                        "last": "Alani",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "123--131",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yulan He, Chenghua Lin, and Harith Alani. 2011. Automatically extracting polarity-bearing topics for cross-domain sentiment classification. In ACL, pages 123-131.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Document summarization based on data reconstruction",
                "authors": [
                    {
                        "first": "Zhanying",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Chun",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bu",
                        "suffix": ""
                    },
                    {
                        "first": "Can",
                        "middle": [],
                        "last": "Jiajun",
                        "suffix": ""
                    },
                    {
                        "first": "Lijun",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Deng",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaofei",
                        "middle": [],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "620--626",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhanying He, Chun Chen, Bu, Jiajun, Can Wang, Li- jun Zhang, Deng Cai, and Xiaofei He. 2012. Doc- ument summarization based on data reconstruction. In AAAI, pages 620-626.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Correcting samples selection bias by unlabeled data",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Smola",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Gretton",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Bordwardt",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Scholkopf",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "601--608",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Huang, A. Smola, A. Gretton, K. Bordwardt, and B. Scholkopf. 2007. Correcting samples selection bias by unlabeled data. In NIPS, pages 601-608.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Instance weighting for domain adaptation in nlp",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Zhai",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "264--271",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Jiang and C. Zhai. 2007. Instance weighting for domain adaptation in nlp. In ACL, pages 264-271.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Bi-shifting auto-encoder for unsupervised domain adaptation",
                "authors": [
                    {
                        "first": "Meina",
                        "middle": [],
                        "last": "Kan",
                        "suffix": ""
                    },
                    {
                        "first": "Shiguang",
                        "middle": [],
                        "last": "Shan",
                        "suffix": ""
                    },
                    {
                        "first": "Xilin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "ICCV",
                "volume": "",
                "issue": "",
                "pages": "3846--3854",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Meina Kan, Shiguang Shan, and Xilin Chen. 2015. Bi-shifting auto-encoder for unsupervised domain adaptation. In ICCV, pages 3846-3854.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A co-regularization based semi-supervised domain adaptation",
                "authors": [
                    {
                        "first": "Abhishek",
                        "middle": [],
                        "last": "Kumar",
                        "suffix": ""
                    },
                    {
                        "first": "Avishek",
                        "middle": [],
                        "last": "Saha",
                        "suffix": ""
                    },
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "478--486",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Abhishek Kumar, Avishek Saha, and Hal Daum\u00e9 III. 2010. A co-regularization based semi-supervised domain adaptation. In NIPS, pages 478-486.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Multidomain adaption for sentiment classification: Using multiple classifier combining classification",
                "authors": [
                    {
                        "first": "Shoushan",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Chengqing",
                        "middle": [],
                        "last": "Zong",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shoushan Li and Chengqing Zong. 2008. Multi- domain adaption for sentiment classification: Us- ing multiple classifier combining classification. In NLPKE.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Knowledge transformation for cross-domain sentiment classification",
                "authors": [
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Vikas",
                        "middle": [],
                        "last": "Sindhwani",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [
                            "Q"
                        ],
                        "last": "Chris",
                        "suffix": ""
                    },
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "SIGIR",
                "volume": "",
                "issue": "",
                "pages": "716--717",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tao Li, Vikas Sindhwani, Chris H. Q. Ding, and Yi Zhang 0005. 2009. Knowledge transformation for cross-domain sentiment classification. In SIGIR, pages 716-717.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Topic correlation analysis for cross-domain text classification",
                "authors": [
                    {
                        "first": "Lianghao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoming",
                        "middle": [],
                        "last": "Jin",
                        "suffix": ""
                    },
                    {
                        "first": "Mingsheng",
                        "middle": [],
                        "last": "Long",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "998--1004",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lianghao Li, Xiaoming Jin, and Mingsheng Long. 2012. Topic correlation analysis for cross-domain text classification. In AAAI, pages 998-1004.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Active learning for crossdomain sentiment classification",
                "authors": [
                    {
                        "first": "Shoushan",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yunxia",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Zhongqing",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Guodong",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "2127--2133",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shoushan Li, Yunxia Xue, Zhongqing Wang, and Guodong Zhou. 2013. Active learning for cross- domain sentiment classification. In IJCAI, pages 2127-2133.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Sentiment analysis and opinion mining",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Liu. 2012. Sentiment analysis and opinion mining. Morgan & Claypool Publishers.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Learning transferable features with deep adaptation networks",
                "authors": [
                    {
                        "first": "Mingsheng",
                        "middle": [],
                        "last": "Long",
                        "suffix": ""
                    },
                    {
                        "first": "Yue",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Jianmin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "I"
                        ],
                        "last": "Jordan",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "97--105",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. 2015. Learning transferable features with deep adaptation networks. In ICML, pages 97-105.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Domain adatation with multiple sources",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Mansour",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Mohri",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Rostamizadeh",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "264--271",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. Mansour, M. Mohri, and A. Rostamizadeh. 2009. Domain adatation with multiple sources. In NIPS, pages 264-271.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Cross-domain sentiment classification via spectral feature alignment",
                "authors": [
                    {
                        "first": "Xiaochuan",
                        "middle": [],
                        "last": "Sinno Jialin Pan",
                        "suffix": ""
                    },
                    {
                        "first": "Jian-Tao",
                        "middle": [],
                        "last": "Ni",
                        "suffix": ""
                    },
                    {
                        "first": "Qiang",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Zheng",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "751--760",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen. 2010. Cross-domain sen- timent classification via spectral feature alignment. In WWW, pages 751-760.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Opinion mining and sentiment analysis",
                "authors": [
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Found. Trends Inf. Retr",
                "volume": "2",
                "issue": "12",
                "pages": "1--135",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(12):1-135.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Thumbs up? sentiment classification using machine learning techniques",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Vaithyanathan",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "79--86",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In EMNLP, pages 79-86.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Multiple aspect ranking using the good grief algorithm",
                "authors": [
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Snyder",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "NAACL",
                "volume": "",
                "issue": "",
                "pages": "300--307",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Benjamin Snyder and Regina Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. In NAACL, pages 300-307.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Semi-supervised recursive autoencoders for predicting sentiment distributions",
                "authors": [
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Pennington",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [
                            "H"
                        ],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "Y"
                        ],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "In EMNLP",
                "volume": "",
                "issue": "",
                "pages": "151--161",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning. 2011. Semi-supervised recursive autoencoders for predict- ing sentiment distributions. In EMNLP, pages 151- 161.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Zero-shot learning through cross-modal transfer",
                "authors": [
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    },
                    {
                        "first": "Milind",
                        "middle": [],
                        "last": "Ganjoo",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "Y"
                        ],
                        "last": "Ng",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "935--943",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Richard Socher, Milind Ganjoo, Christopher D. Man- ning, and Andrew Y. Ng. 2013. Zero-shot learning through cross-modal transfer. In NIPS, pages 935- 943.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Learning sentimentspecific word embedding for twitter sentiment classification",
                "authors": [
                    {
                        "first": "Duyu",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Furu",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Ting",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "1555--1565",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014. Learning sentiment- specific word embedding for twitter sentiment clas- sification. In ACL, pages 1555-1565.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Document modeling with gated recurrent neural network for sentiment classification",
                "authors": [
                    {
                        "first": "Duyu",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Ting",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "1422--1432",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Duyu Tang, Bing Qin, and Ting Liu. 2015. Document modeling with gated recurrent neural network for sentiment classification. In EMNLP, pages 1422- 1432.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts",
                "authors": [
                    {
                        "first": "Matt",
                        "middle": [],
                        "last": "Thomas",
                        "suffix": ""
                    },
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "327--335",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from congressional floor-debate transcripts. In EMNLP, pages 327-335.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Extracting and composing robust features with denoising autoencoders",
                "authors": [
                    {
                        "first": "Pascal",
                        "middle": [],
                        "last": "Vincent",
                        "suffix": ""
                    },
                    {
                        "first": "Hugo",
                        "middle": [],
                        "last": "Larochelle",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "Pierre-Antoine",
                        "middle": [],
                        "last": "Manzagol",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "1096--1103",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoen- coders. In ICML, pages 1096-1103.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "A pos-based ensemble model for cross-domain sentiment classification",
                "authors": [
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Chengqing",
                        "middle": [],
                        "last": "Zong",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "IJCNLP",
                "volume": "",
                "issue": "",
                "pages": "614--622",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rui Xia, , and Chengqing Zong. 2010. A pos-based ensemble model for cross-domain sentiment classi- fication. In IJCNLP, pages 614-622.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Instance selection and instance weighting for cross-domain sentiment classification via pu learning",
                "authors": [
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Xuelei",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Chengqing",
                        "middle": [],
                        "last": "Zong",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "2276--2182",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rui Xia, Xuelei Hu, Jianfeng Lu, and Chengqing Zong. 2013a. Instance selection and instance weighting for cross-domain sentiment classification via pu learn- ing. In IJCAI, pages 2276-2182.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Feature ensemble plus sample selection: Domain adaptation for sentiment classification",
                "authors": [
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Chengqing",
                        "middle": [],
                        "last": "Zong",
                        "suffix": ""
                    },
                    {
                        "first": "Xuelei",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Cambria",
                        "middle": [],
                        "last": "Erik",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "IEEE Intelligent Systems",
                "volume": "28",
                "issue": "3",
                "pages": "10--18",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rui Xia, Chengqing Zong, Xuelei Hu, and Cambria Erik. 2013b. Feature ensemble plus sample selec- tion: Domain adaptation for sentiment classification. IEEE Intelligent Systems, 28(3):10-18.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Online active learning for cost-sensitive domain adaptation",
                "authors": [
                    {
                        "first": "Min",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Yuhong",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "CoNLL",
                "volume": "",
                "issue": "",
                "pages": "1--9",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Min Xiao and Yuhong Guo. 2013. Online active learn- ing for cost-sensitive domain adaptation. In CoNLL, pages 1-9.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Learning hidden markov models with distributed state representations for domain adaptation",
                "authors": [
                    {
                        "first": "Min",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Yuhong",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "524--529",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Min Xiao and Yuhong Guo. 2015. Learning hidden markov models with distributed state representations for domain adaptation. In ACL, pages 524-529.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Learning latent word representations for domain adaptation using supervised word clustering",
                "authors": [
                    {
                        "first": "Min",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Feipeng",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Yuhong",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "152--162",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Min Xiao, Feipeng Zhao, and Yuhong Guo. 2013. Learning latent word representations for domain adaptation using supervised word clustering. In EMNLP, pages 152-162.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Fast easy unsupervised domain adaptation with marginalized structured dropout",
                "authors": [
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Eisenstein",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "538--544",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yi Yang and Jacob Eisenstein. 2014. Fast easy unsu- pervised domain adaptation with marginalized struc- tured dropout. In ACL, pages 538-544.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Unsupervised multi-domain adaptation with feature embeddings",
                "authors": [
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Eisenstein",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "NAACL",
                "volume": "",
                "issue": "",
                "pages": "672--682",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yi Yang and Jacob Eisenstein. 2015. Unsupervised multi-domain adaptation with feature embeddings. In NAACL, pages 672-682.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Semi-supervised autoencoder for sentiment analysis",
                "authors": [
                    {
                        "first": "Shuangfei",
                        "middle": [],
                        "last": "Zhai",
                        "suffix": ""
                    },
                    {
                        "first": "(",
                        "middle": [],
                        "last": "Zhongfei",
                        "suffix": ""
                    },
                    {
                        "first": ")",
                        "middle": [],
                        "last": "Mark",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "1394--1400",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shuangfei Zhai and Zhongfei (Mark) Zhang. 2016. Semi-supervised autoencoder for sentiment analy- sis. In AAAI, pages 1394-1400.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Phrase-based translation model for question retrieval in community question answer archives",
                "authors": [
                    {
                        "first": "Guangyou",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Kang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "653--662",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu. 2011. Phrase-based translation model for question retrieval in community question answer archives. In ACL, pages 653-662.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "Hybrid heterogeneous transfer learning through deep learning",
                "authors": [
                    {
                        "first": "Joey Tianyi",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Sinno",
                        "middle": [],
                        "last": "Jialin Pan",
                        "suffix": ""
                    },
                    {
                        "first": "Ivorw",
                        "middle": [],
                        "last": "Tsang",
                        "suffix": ""
                    },
                    {
                        "first": "Yan",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "2213--2219",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joey Tianyi Zhou, Sinno Jialin Pan, IvorW. Tsang, and Yan Yan. 2014. Hybrid heterogeneous trans- fer learning through deep learning. In AAAI, pages 2213-2219.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Linking heterogeneous input features with pivots for domain adaptation",
                "authors": [
                    {
                        "first": "Guangyou",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Tingting",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Wensheng",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaohua",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "1419--1425",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guangyou Zhou, Tingting He, Wensheng Wu, and Xi- aohua Hu. 2015a. Linking heterogeneous input fea- tures with pivots for domain adaptation. In IJCAI, pages 1419-1425.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Xiyue Guo, Xinhui Tu, and Tingting He. 2015b. Cross-domain sentiment classification via topical correspondence transfer",
                "authors": [
                    {
                        "first": "Guangyou",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Yin",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Neurocomputing",
                "volume": "159",
                "issue": "",
                "pages": "298--305",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guangyou Zhou, Yin Zhou, Xiyue Guo, Xinhui Tu, and Tingting He. 2015b. Cross-domain sentiment clas- sification via topical correspondence transfer. Neu- rocomputing, 159:298-305.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Concept learning for crossdomain text classification: A general probabilistic framework",
                "authors": [
                    {
                        "first": "Fuzhen",
                        "middle": [],
                        "last": "Zhuang",
                        "suffix": ""
                    },
                    {
                        "first": "Ping",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "Peifeng",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    },
                    {
                        "first": "Qing",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Zhongzhi",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "1960--1966",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fuzhen Zhuang, Ping Luo, Peifeng Yin, Qing He, and Zhongzhi Shi. 2013. Concept learning for cross- domain text classification: A general probabilistic framework. In IJCAI, pages 1960-1966.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Supervised representation learning: Transfer learning with deep autoencoders",
                "authors": [
                    {
                        "first": "Fuzhen",
                        "middle": [],
                        "last": "Zhuang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaohu",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "4119--4125",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fuzhen Zhuang, Xiaohu Cheng, Ping Luo, Sinno Jialin Pan, and Qing He. 2015. Supervised representation learning: Transfer learning with deep autoencoders. In IJCAI, pages 4119-4125.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: The framework of Bi-transferring Deep Neural Networks (BTDNNs). Through BTDNNs, a source domain example can be transferred to the target domain where it can be reconstructed by the target domain examples, and vice versa.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "the literature (Pan et al., 2010), we can construct 12 cross-domain sentiment classification tasks: D",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 3: Proxy A-distance between domains of the Amazon benchmark for the 6 different pairs.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td/><td colspan=\"2\">Therefore,</td></tr><tr><td colspan=\"3\">although we cannot expect to get a global min-</td></tr><tr><td colspan=\"3\">imum of the above problem, we shall develop a</td></tr><tr><td colspan=\"3\">simple and efficient optimization algorithm via al-</td></tr><tr><td colspan=\"2\">ternative iterations.</td><td/></tr><tr><td>3.4.1 min fc,gs,g t</td><td>Xs -gs(fc(Xs)) 2 2 + gt(fc(Xs)) -Xt)</td><td>2 2</td></tr></table>",
                "type_str": "table",
                "text": ") is not convex in variables {f c , g s , g t , B s , B t } together. However, when considering one variable at a time, the cost function turns out to be convex. For example, given {g s , g t , B s , B t }, the cost function is a convex function w.r.t. f c . Optimize {f c , g s , g t } given {B s , B t } When B s and B t are fixed, the objective function in equation (8) can be formulated as:",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td/><td>82</td><td/><td/><td/><td/><td/><td/><td>81</td></tr><tr><td/><td>81</td><td/><td/><td/><td/><td/><td/><td>80</td></tr><tr><td/><td>80</td><td/><td/><td/><td/><td/><td/><td>79</td></tr><tr><td/><td>79</td><td/><td/><td/><td/><td>baseline</td><td/><td>78</td><td>baseline</td></tr><tr><td>Accuracy (%)</td><td>75 76 77 78</td><td/><td/><td/><td/><td>SCL MCT SFA PJNMF SDA mSDA TLDA</td><td>Accuracy (%)</td><td>75 76 77</td><td>SCL MCT SFA PJNMF SDA mSDA TLDA</td></tr><tr><td/><td>74</td><td/><td/><td/><td/><td>BTDNNs</td><td/><td>74</td><td>BTDNNs</td></tr><tr><td/><td>73</td><td/><td/><td/><td/><td/><td/><td>73</td></tr><tr><td/><td>72</td><td/><td/><td/><td/><td/><td/><td>72</td></tr><tr><td/><td>71</td><td>B-&gt;D</td><td>E-&gt;D</td><td/><td>K-&gt;D</td><td/><td/><td>71</td><td>D-&gt;B</td><td>E-&gt;B</td><td>K-&gt;B</td></tr><tr><td/><td>86</td><td/><td/><td/><td/><td/><td/><td>88</td></tr><tr><td/><td>84</td><td/><td/><td/><td/><td/><td/><td>86</td></tr><tr><td>Accuracy (%)</td><td>78 80 82 76</td><td/><td/><td/><td/><td>baseline SCL MCT SFA PJNMF SDA mSDA TLDA BTDNNs</td><td>Accuracy (%)</td><td>80 82 84 78</td><td>baseline SCL MCT SFA PJNMF SDA mSDA TLDA BTDNNs</td></tr><tr><td/><td>74</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td>76</td></tr><tr><td/><td>72</td><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td>B-&gt;E</td><td>D-&gt;E</td><td/><td>K-&gt;E</td><td/><td/><td>74</td><td>B-&gt;K</td><td>D-&gt;K</td><td>E-&gt;K</td></tr><tr><td colspan=\"2\">Figure 2: Domain</td><td/><td colspan=\"4\">#Train #Test #Unlab. % Neg.</td><td/></tr><tr><td colspan=\"2\">Books</td><td/><td>1600</td><td>400</td><td>4465</td><td>50%</td><td/></tr><tr><td colspan=\"2\">DVDs</td><td/><td>1600</td><td>400</td><td>5945</td><td>50%</td><td/></tr><tr><td colspan=\"3\">Electronics</td><td>1600</td><td>400</td><td>5681</td><td>50%</td><td/></tr><tr><td colspan=\"2\">Kitchen</td><td/><td>1600</td><td>400</td><td>3586</td><td>50%</td><td/></tr></table>",
                "type_str": "table",
                "text": "Table1presents the statistics of the data set. Average results for cross-domain sentiment classification on the Amazon product benchmark of 4 domains. Amazon review statistics. This table depicts the number of training, testing and unlabeled reviews for each domain, as well as the portion of negative training reviews of the data set.",
                "html": null,
                "num": null
            }
        }
    }
}