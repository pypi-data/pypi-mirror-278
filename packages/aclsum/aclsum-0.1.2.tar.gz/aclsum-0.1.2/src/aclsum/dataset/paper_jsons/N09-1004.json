{
    "paper_id": "N09-1004",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:53:42.514348Z"
    },
    "title": "A Fully Unsupervised Word Sense Disambiguation Method Using Dependency Knowledge",
    "authors": [
        {
            "first": "Ping",
            "middle": [],
            "last": "Chen",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Houston-Downtown",
                "location": {}
            },
            "email": "chenp@uhd.edu"
        },
        {
            "first": "Chris",
            "middle": [],
            "last": "Bowes",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Houston-Downtown",
                "location": {}
            },
            "email": "bowesc@uhd.edu"
        },
        {
            "first": "Wei",
            "middle": [],
            "last": "Ding",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Massachusetts-Boston",
                "location": {}
            },
            "email": "ding@cs.umb.edu"
        },
        {
            "first": "David",
            "middle": [],
            "last": "Brown",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Houston-Downtown",
                "location": {}
            },
            "email": "brownd@uhd.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Word sense disambiguation is the process of determining which sense of a word is used in a given context. Due to its importance in understanding semantics of natural languages, word sense disambiguation has been extensively studied in Computational Linguistics. However, existing methods either are brittle and narrowly focus on specific topics or words, or provide only mediocre performance in real-world settings. Broad coverage and disambiguation quality are critical for a word sense disambiguation system. In this paper we present a fully unsupervised word sense disambiguation method that requires only a dictionary and unannotated text as input. Such an automatic approach overcomes the problem of brittleness suffered in many existing methods and makes broad-coverage word sense disambiguation feasible in practice. We evaluated our approach using SemEval 2007 Task 7 (Coarse-grained English All-words Task), and our system significantly outperformed the best unsupervised system participating in Se-mEval 2007 and achieved the performance approaching top-performing supervised systems. Although our method was only tested with coarse-grained sense disambiguation, it can be directly applied to fine-grained sense disambiguation.",
    "pdf_parse": {
        "paper_id": "N09-1004",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Word sense disambiguation is the process of determining which sense of a word is used in a given context. Due to its importance in understanding semantics of natural languages, word sense disambiguation has been extensively studied in Computational Linguistics. However, existing methods either are brittle and narrowly focus on specific topics or words, or provide only mediocre performance in real-world settings. Broad coverage and disambiguation quality are critical for a word sense disambiguation system. In this paper we present a fully unsupervised word sense disambiguation method that requires only a dictionary and unannotated text as input. Such an automatic approach overcomes the problem of brittleness suffered in many existing methods and makes broad-coverage word sense disambiguation feasible in practice. We evaluated our approach using SemEval 2007 Task 7 (Coarse-grained English All-words Task), and our system significantly outperformed the best unsupervised system participating in Se-mEval 2007 and achieved the performance approaching top-performing supervised systems. Although our method was only tested with coarse-grained sense disambiguation, it can be directly applied to fine-grained sense disambiguation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "In many natural languages, a word can represent multiple meanings/senses, and such a word is called a homograph. Word sense disambiguation(WSD) is the process of determining which sense of a homograph is used in a given context. WSD is a long-standing problem in Computational Linguistics, and has significant impact in many real-world applications including machine translation, information extraction, and information retrieval. Generally, WSD methods use the context of a word for its sense disambiguation, and the context information can come from either annotated/unannotated text or other knowledge resources, such as Word-Net (Fellbaum, 1998) , SemCor (SemCor, 2008) , Open Mind Word Expert (Chklovski and Mihalcea, 2002) , eXtended WordNet (Moldovan and Rus, 2001) , Wikipedia (Mihalcea, 2007) , parallel corpora (Ng, Wang, and Chan, 2003) . In (Ide and V\u00e9ronis, 1998) many different WSD approaches were described. Usually, WSD techniques can be divided into four categories (Agirre and Edmonds, 2006) ,",
                "cite_spans": [
                    {
                        "start": 633,
                        "end": 649,
                        "text": "(Fellbaum, 1998)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 652,
                        "end": 673,
                        "text": "SemCor (SemCor, 2008)",
                        "ref_id": null
                    },
                    {
                        "start": 698,
                        "end": 728,
                        "text": "(Chklovski and Mihalcea, 2002)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 748,
                        "end": 772,
                        "text": "(Moldovan and Rus, 2001)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 785,
                        "end": 801,
                        "text": "(Mihalcea, 2007)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 821,
                        "end": 847,
                        "text": "(Ng, Wang, and Chan, 2003)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 853,
                        "end": 876,
                        "text": "(Ide and V\u00e9ronis, 1998)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 983,
                        "end": 1009,
                        "text": "(Agirre and Edmonds, 2006)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Dictionary and knowledge based methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "These methods use lexical knowledge bases such as dictionaries and thesauri, and hypothesize that context knowledge can be extracted from definitions of words. For example, Lesk disambiguated two words by finding the pair of senses with the greatest word overlap in their dictionary definitions (Lesk, 1986) .",
                "cite_spans": [
                    {
                        "start": 295,
                        "end": 307,
                        "text": "(Lesk, 1986)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Supervised methods. Supervised methods mainly adopt context to disambiguate words. A supervised method includes a training phase and a testing phase. In the training phase, a sense-annotated training corpus is required, from which syntactic and semantic features are extracted to create a classifier using machine learning techniques, such as Support Vector Machine (Novischi et al., 2007) . In the following testing phase, a word is classified into senses (Mihalcea, 2002) (Ng and Lee, 1996) . Currently supervised methods achieve the best disambiguation quality (about 80% precision and recall for coarse-grained WSD in the most recent WSD evaluation conference SemEval 2007 (Navigli et al., 2007) ). Nevertheless, since training corpora are manually annotated and expensive, supervised methods are often brittle due to data scarcity, and it is hard to annotate and acquire sufficient contextual information for every sense of a large number of words existing in natural languages.",
                "cite_spans": [
                    {
                        "start": 368,
                        "end": 391,
                        "text": "(Novischi et al., 2007)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 459,
                        "end": 475,
                        "text": "(Mihalcea, 2002)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 476,
                        "end": 494,
                        "text": "(Ng and Lee, 1996)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 679,
                        "end": 701,
                        "text": "(Navigli et al., 2007)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Semi-supervised methods. To overcome the knowledge acquisition bottleneck problem suffered by supervised methods, these methods make use of a small annotated corpus as seed data in a bootstrapping process (Hearst, 1991 ) (Yarowsky, 1995) . A word-aligned bilingual corpus can also serve as seed data (Ng, Wang, and Chan, 2003) .",
                "cite_spans": [
                    {
                        "start": 207,
                        "end": 220,
                        "text": "(Hearst, 1991",
                        "ref_id": null
                    },
                    {
                        "start": 221,
                        "end": 239,
                        "text": ") (Yarowsky, 1995)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 302,
                        "end": 328,
                        "text": "(Ng, Wang, and Chan, 2003)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Unsupervised methods. These methods acquire contextual information directly from unannotated raw text, and senses can be induced from text using some similarity measure (Lin, 1997) . However, automatically acquired information is often noisy or even erroneous. In the most recent SemEval 2007 (Navigli et al., 2007) , the best unsupervised systems only achieved about 70% precision and 50% recall.",
                "cite_spans": [
                    {
                        "start": 171,
                        "end": 182,
                        "text": "(Lin, 1997)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 295,
                        "end": 317,
                        "text": "(Navigli et al., 2007)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Disambiguation of a limited number of words is not hard, and necessary context information can be carefully collected and hand-crafted to achieve high disambiguation accuracy as shown in (Yarowsky, 1995) . However, such approaches suffer a significant performance drop in practice when domain or vocabulary is not limited. Such a \"cliff-style\" performance collapse is called brittleness, which is due to insufficient knowledge and shared by many techniques in Artificial Intelligence. The main challenge of a WSD system is how to overcome the knowledge acquisition bottleneck and efficiently collect the huge amount of context knowledge. More precisely, a practical WSD need figure out how to create and maintain a comprehensive, dynamic, and up-todate context knowledge base in a highly automatic manner. The context knowledge required in WSD has the following properties:",
                "cite_spans": [
                    {
                        "start": 187,
                        "end": 203,
                        "text": "(Yarowsky, 1995)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "1. The context knowledge need cover a large number of words and their usage. Such a requirement of broad coverage is not trivial because a natural language usually contains thousands of words, and some popular words can have dozens of senses. For example, the Oxford English Dictionary has approximately 301,100 main entries (Oxford, 2003) , and the average polysemy of the WordNet inventory is 6.18 (Fellbaum, 1998) . Clearly acquisition of such a huge amount of knowledge can only be achieved with automatic techniques.",
                "cite_spans": [
                    {
                        "start": 325,
                        "end": 339,
                        "text": "(Oxford, 2003)",
                        "ref_id": null
                    },
                    {
                        "start": 400,
                        "end": 416,
                        "text": "(Fellbaum, 1998)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2. Natural language is not a static phenomenon. New usage of existing words emerges, which creates new senses. New words are created, and some words may \"die\" over time. It is estimated that every year around 2,500 new words appear in English (Kister, 1992) . Such dynamics requires a timely maintenance and updating of context knowledge base, which makes manual collection even more impractical.",
                "cite_spans": [
                    {
                        "start": 243,
                        "end": 257,
                        "text": "(Kister, 1992)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Taking into consideration the large amount and dynamic nature of context knowledge, we only have limited options when choosing knowledge sources for WSD. WSD is often an unconscious process to human beings. With a dictionary and sample sentences/phrases an average educated person can correctly disambiguate most polysemous words. Inspired by human WSD process, we choose an electronic dictionary and unannotated text samples of word instances as context knowledge sources for our WSD system. Both sources can be automatically accessed, provide an excellent coverage of word meanings and usage, and are actively updated to reflect the current state of languages. In this paper we present a fully unsupervised WSD system, which only requires WordNet sense inventory and unannotated text. In the rest of this paper, section 2 describes how to acquire and represent the context knowledge for WSD. We present our WSD algorithm in section 3. Our WSD system is evaluated with SemEval-2007 Task 7 (Coarse-grained English All-words Task) data set, and the experiment results are discussed in section 4. We conclude in section 5.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Figure 1 shows an overview of our context knowledge acquisition process, and collected knowledge is saved in a local knowledge base. Here are some details about each step.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Context Knowledge Acquisition and Representation",
                "sec_num": "2"
            },
            {
                "text": "The goal of this step is to collect as many as possible valid sample sentences containing the instances of to-be-disambiguated words. Preferably these instances are also diverse and cover many senses of a word. We have considered two possible text sources, 1. Electronic text collection, e.g., Gutenberg project (Gutenberg, 1971) . Such collections often include thousands of books, which are often written by professionals and can provide many valid and accurate usage of a large number of words. Nevertheless, books in these collections are usually copyright-free and old, hence are lack of new words or new senses of words used in modern English.",
                "cite_spans": [
                    {
                        "start": 312,
                        "end": 329,
                        "text": "(Gutenberg, 1971)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Corpus building through Web search",
                "sec_num": "2.1"
            },
            {
                "text": "2. Web documents. Billions of documents exist in the World Wide Web, and millions of Web pages are created and updated everyday. Such a huge dynamic text collection is an ideal source to provide broad and up-to-date context knowledge for WSD. The major concern about Web documents is inconsistency of their quality, and many Web pages are spam or contain erroneous information. However, factual errors in Web pages will not hurt the performance of WSD.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Corpus building through Web search",
                "sec_num": "2.1"
            },
            {
                "text": "Nevertheless, the quality of context knowledge is affected by broken sentences of poor linguistic quality and invalid word usage, e.g., sentences like \"Colorless green ideas sleep furiously\" that violate commonsense knowledge.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Corpus building through Web search",
                "sec_num": "2.1"
            },
            {
                "text": "Based on our experience these kind of errors are negligible when using popular Web search engines to retrieve relevant Web pages.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Corpus building through Web search",
                "sec_num": "2.1"
            },
            {
                "text": "To start the acquisition process, words that need to be disambiguated are compiled and saved in a text file. Each single word is submitted to a Web search engine as a query. Several search engines provide API's for research communities to automatically retrieve large number of Web pages. In our experiments we used both Google and Yahoo! API's to retrieve up to 1,000 Web pages for each tobe-disambiguated word. Collected Web pages are cleaned first, e.g., control characters and HTML tags are removed. Then sentences are segmented simply based on punctuation (e.g., ?, !, .). Sentences that contain the instances of a specific word are extracted and saved into a local repository.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Corpus building through Web search",
                "sec_num": "2.1"
            },
            {
                "text": "Sentences organized according to each word are sent to a dependency parser, Minipar. Dependency parsers have been widely used in Computational Linguistics and natural language processing. An evaluation with the SUSANNE corpus shows that Minipar achieves 89% precision with respect to dependency relations (Lin, 1998) . After parsing sentences are converted to parsing trees and saved in files. Neither our simple sentence segmentation approach nor Minipar parsing is 100% accurate, so a small number of invalid dependency relations may exist in parsing trees. The impact of these erroneous relations will be minimized in our WSD algorithm. Comparing with tagging or chunking, parsing is relatively expensive and time-consuming. However, in our method parsing is not performed in real time when we disambiguate words. Instead, sentences are parsed only once to extract dependency relations, then these relations are merged and saved in a local knowledge base for the following disambiguation. Hence, parsing will not affect the speed of disambiguation at all.",
                "cite_spans": [
                    {
                        "start": 305,
                        "end": 316,
                        "text": "(Lin, 1998)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parsing",
                "sec_num": "2.2"
            },
            {
                "text": "After parsing, dependency relations from different sentences are merged and saved in a context knowledge base. The merging process is straightforward. A dependency relation includes one head word/node and one dependent word/node. Nodes from different dependency relations are merged into one as long as they represent the same word. An example is shown in Figure 2 , which merges the following two sentences:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 363,
                        "end": 364,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Merging dependency relations",
                "sec_num": "2.3"
            },
            {
                "text": "\"Computer programmers write software.\" \"Many companies hire computer programmers.\"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Merging dependency relations",
                "sec_num": "2.3"
            },
            {
                "text": "In a dependency relation \"word 1 \u2192 word 2 \", word 1 is the head word, and word 2 is the dependent word. After merging dependency relations, we will obtain a weighted directed graph with a word as a node, a dependency relation as an edge, and the number of occurrences of dependency relation as weight of an edge. This weight indicates the strength of semantic relevancy of head word and dependent word. This graph will be used in the following WSD Figure 3 : WSD Procedure process as our context knowledge base. As a fully automatic knowledge acquisition process, it is inevitable to include erroneous dependency relations in the knowledge base. However, since in a large text collection valid dependency relations tend to repeat far more times than invalid ones, these erroneous edges only have minimal impact on the disambiguation quality as shown in our evaluation results.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 455,
                        "end": 456,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Merging dependency relations",
                "sec_num": "2.3"
            },
            {
                "text": "Our WSD approach is based on the following insight:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "If a word is semantically coherent with its context, then at least one sense of this word is semantically coherent with its context.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "Assume that the text to be disambiguated is semantically valid, if we replace a word with its glosses one by one, the correct sense should be the one that will maximize the semantic coherence within this word's context. Based on this idea we set up our WSD procedure as shown in Figure 3 . First both the original sentence that contains the to-be-disambiguated word and the glosses of to-bedisambiguated word are parsed. Then the parsing tree generated from each gloss is matched with the parsing tree of original sentence one by one. The gloss most semantically coherent with the original sentence will be chosen as the correct sense. How to measure the semantic coherence is critical. Our idea is based on the following hypotheses (assume word 1 is the to-be-disambiguated word):",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 286,
                        "end": 287,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "\u2022 In a sentence if word 1 is dependent on word 2 , and we denote the gloss of the correct sense of word 1 as g 1i , then g 1i contains the most semantically coherent words that are dependent on word 2 ;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "\u2022 In a sentence if a set of words DEP 1 are dependent on word 1 , and we denote the gloss of the correct sense of word 1 as g 1i , then g 1i contains the most semantically coherent words that DEP 1 are dependent on.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "For example, we try to disambiguate \"company\" in \"A large company hires many computer programmers\", after parsing we obtain the dependency relations \"hire \u2192 company\" and \"company \u2192 large\". The correct sense for the word \"company\" should be \"an institution created to conduct business\". If in the context knowledge base there exist the dependency relations \"hire \u2192 institution\" or \"institution \u2192 large\", then we believe that the gloss \"an institution created to conduct business\" is semantically coherent with its context -the original sentence. The gloss with the highest semantic coherence will be chosen as the correct sense. Obviously, the size of context knowledge base has a positive impact on the disambiguation quality, which is also verified in our experiments (see Section 4.2). Figure 4 shows our detailed WSD algorithm. Semantic coherence score is generated by the function T reeM atching, and we adopt a sentence as the context of a word.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 795,
                        "end": 796,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "We illustrate our WSD algorithm through an example. Assume we try to disambiguate \"company\" in the sentence \"A large software company hires many computer programmers\". \"company\" has 9 senses as a noun in WordNet 2.1. Let's pick the following two glosses to go through our WSD process.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WSD Algorithm",
                "sec_num": "3"
            },
            {
                "text": "\u2022 small military unit First we parse the original sentence and two glosses, and get three weighted parsing trees as shown in Figure 5 . All weights are assigned to nodes/words in these parsing trees. In the parsing tree of the original sentence the weight of a node is reciprocal of the distance between this node and tobe-disambiguated node \"company\" (line 12 in Figure 4 ). In the parsing tree of a gloss the weight of a node is reciprocal of the level of this node in the parsing tree (line 16 in Figure 4 ). Assume that our context knowledge base contains relevant dependency relations shown in Figure 6 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 132,
                        "end": 133,
                        "text": "5",
                        "ref_id": "FIGREF3"
                    },
                    {
                        "start": 371,
                        "end": 372,
                        "text": "4",
                        "ref_id": null
                    },
                    {
                        "start": 507,
                        "end": 508,
                        "text": "4",
                        "ref_id": null
                    },
                    {
                        "start": 606,
                        "end": 607,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Input: Glosses from WordNet; S: the sentence to be disambiguated; G: the knowledge base generated in Section 2; 1. Input a sentence S, W = {w| w's part of speech is noun, verb, adjective, or adverb, w \u2208 S}; 2. Parse S with a dependency parser, generate parsing tree T S ; 3. For each w \u2208 W { 4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Input all w's glosses from WordNet; 5.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "For each gloss w i { 6.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Parse w i , get a parsing tree T wi ; 7. score = TreeMatching(T S , T wi ); } 8.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "If the highest score is larger than a preset threshold, choose the sense with the highest score as the correct sense; 9.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Otherwise, choose the first sense. 10. } TreeMatching(T S , T wi ) 11. For each node n Si \u2208 T S { 12.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Assign weight w Si = 1 l Si , l Si is the length between n Si and w i in T S ; 13. } 14. For each node n wi \u2208 T wi { 15.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Load its dependent words D wi from G; 16.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "Assign weight w wi = 1 l wi , l wi is the level number of n wi in T wi ; 17.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "For each n Sj { 18.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "If The weights in the context knowledge base are assigned to dependency relation edges. These weights are normalized to [0, 1] based on the number of dependency relation instances obtained in the acquisition and merging process. A large number of occurrences will be normalized to a high value (close to 1), and a small number of occurrences will be nor- Now we load the dependent words of each word in gloss 1 from the knowledge base (line 14, 15 in Figure 4 ), and we get {small, large} for \"institution\" and {large, software} for \"business\". In the dependent words of \"company\", \"large\" belongs to the dependent word sets of \"institution\" and \"business\", and \"software\" belongs to the dependent word set of \"business\", so the coherence score of gloss 1 is calculated as (line 19, 20 in Figure 4 ):",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 458,
                        "end": 459,
                        "text": "4",
                        "ref_id": null
                    },
                    {
                        "start": 796,
                        "end": 797,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "1.0\u00d71.0\u00d70.7 + 1.0\u00d70.25\u00d70.8 + 1.0\u00d70.25\u00d70.9 = 1.125",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "We go through the same process with the second gloss \"small military unit\". \"Large\" is the only dependent word of \"company\" appearing in the dependent word set of \"unit\" in gloss 2, so the coherence score of gloss 2 in the current context is:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "1.0 \u00d7 1.0 \u00d7 0.8 = 0.8",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "After comparing the coherence scores of two glosses, we choose sense 1 of \"company\" as the correct sense (line 9 in Figure 4 ). This example illustrates that a strong dependency relation between a head word and a dependent word has a powerful disambiguation capability, and disambiguation quality is also significantly affected by the quality of dictionary definitions.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 123,
                        "end": 124,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "In Figure 4 the T reeM atching function matches the dependent words of to-be-disambiguated word (line 15 in Figure 4 ), and we call this matching strategy as dependency matching. This strategy will not work if a to-be-disambiguated word has no dependent words at all, for example, when the word \"company\" in \"Companies hire computer programmers\" has no dependent words. In this case, we developed the second matching strategy, which is to match the head words that the to-be-disambiguated word is dependent on, such as matching \"hire\" (the head word of \"company\") in Figure 5 (a). Using the dependency relation \"hire \u2192 company\", we can correctly choose sense 1 since there is no such relation as \"hire \u2192 unit\" in the knowledge base. This strategy is also helpful when disambiguating adjectives and adverbs since they usually only depend on other words, and rarely any other words are dependent on them. The third matching strategy is to consider synonyms as a match besides the exact matching words. Synonyms can be obtained through the synsets in WordNet. For example, when we disambiguate \"company\" in \"Big companies hire many computer programmers\", \"big\" can be considered as a match for \"large\". We call this matching strategy as synonym matching. The three matching strategies can be combined and applied together, and in Section 4.1 we show the experiment results of 5 different matching strategy combinations.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 10,
                        "end": 11,
                        "text": "4",
                        "ref_id": null
                    },
                    {
                        "start": 115,
                        "end": 116,
                        "text": "4",
                        "ref_id": null
                    },
                    {
                        "start": 574,
                        "end": 575,
                        "text": "5",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "\u2022 an institution created to conduct business",
                "sec_num": null
            },
            {
                "text": "We have evaluated our method using SemEval-2007 Task 07 (Coarse-grained English All-words Task) test set (Navigli et al., 2007) . The task organizers provide a coarse-grained sense inventory created with SSI algorithm (Navigli and Velardi, 2005) , training data, and test data. Since our method does not need any training or special tuning, neither coarse-grained sense inventory nor training data was used. The test data includes: a news article about \"homeless\" (including totally 951 words, 368 words are annotated and need to be disambiguated), a review of the book \"Feeding Frenzy\" (including totally 987 words, 379 words are annotated and need to be disambiguated), an article about some traveling experience in France (including totally 1311 words, 500 words are annotated and need to be disambiguated), computer programming(including totally 1326 words, 677 words are annotated and need to be disambiguated), and a biography of the painter Masaccio (including totally 802 words, 345 words are annotated and need to be disambiguated). Two authors of (Navigli et al., 2007) independently and manually annotated part of the test set (710 word instances), and the pairwise agreement was 93.80%. This inter-annotator agreement is usually considered an upper-bound for WSD systems.",
                "cite_spans": [
                    {
                        "start": 105,
                        "end": 127,
                        "text": "(Navigli et al., 2007)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 218,
                        "end": 245,
                        "text": "(Navigli and Velardi, 2005)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 1057,
                        "end": 1079,
                        "text": "(Navigli et al., 2007)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4"
            },
            {
                "text": "We followed the WSD process described in Section 2 and 3 using the WordNet 2.1 sense repository that is adopted by SemEval-2007 Task 07. All experiments were performed on a Pentium 2.33GHz dual core PC with 3GB memory. Among the 2269 tobe-disambiguated words in the five test documents, 1112 words are unique and submitted to Google API as queries. The retrieved Web pages were cleaned, and 1945189 relevant sentences were extracted. On average 1749 sentences were obtained for each word. The Web page retrieval step took 3 days, and the cleaning step took 2 days. Parsing was very time-consuming and took 11 days. The merging step took 3 days. Disambiguation of 2269 words in the 5 test articles took 4 hours. All these steps can be parallelized and run on multiple computers, and the whole process will be shortened accordingly.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4"
            },
            {
                "text": "The overall disambiguation results are shown in Table 1 . For comparison we also listed the results of the top three systems and three unsuper-vised systems participating in SemEval-2007 Task 07. All of the top three systems (UoR-SSI, NUS-PT, NUS-ML) are supervised systems, which used annotated resources (e.g., SemCor, Defense Science Organization Corpus) during the training phase. Our fully unsupervised WSD system significantly outperforms the three unsupervised systems (SUSSZ-FR, SUSSX-C-WD, SUSSX-CR) and achieves performance approaching the top-performing supervised WSD systems.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 54,
                        "end": 55,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4"
            },
            {
                "text": "To test the effectiveness of different matching strategies discussed in Section 3, we performed some additional experiments. Table 2 shows the disambiguation results by each individual document with the following 5 matching strategies:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 131,
                        "end": 132,
                        "text": "2",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "1. Dependency matching only.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "2. Dependency and backward matching.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "3. Dependency and synonym backward matching.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "4. Dependency and synonym dependency matching.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "5. Dependency, backward, synonym backward, and synonym dependency matching.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "As expected combination of more matching strategies results in higher disambiguation quality. By analyzing the scoring details, we verified that backward matching is especially useful to disambiguate adjectives and adverbs. Adjectives and adverbs are often dependent words, so dependency matching itself rarely finds any matched words. Since synonyms are semantically equivalent, it is reasonable that synonym matching can also improve disambiguation performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of different matching strategies to disambiguation quality",
                "sec_num": "4.1"
            },
            {
                "text": "To test the impact of knowledge base size to disambiguation quality we randomly selected 1339264 sentences (about two thirds of all sentences) from our text collection and built a smaller knowledge base. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact of knowledge base size to disambiguation quality",
                "sec_num": "4.2"
            },
            {
                "text": "Broad coverage and disambiguation quality are critical for WSD techniques to be adopted in practice. This paper proposed a fully unsupervised WSD method. We have evaluated our approach with SemEval-2007 Task 7 (Coarse-grained English Allwords Task) data set, and we achieved F-scores approaching the top performing supervised WSD systems. By using widely available unannotated text and a fully unsupervised disambiguation approach, our method may provide a viable solution to the problem of WSD. The future work includes:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "5"
            },
            {
                "text": "1. Continue to build the knowledge base, enlarge the coverage and improve the system performance. The experiment results in Section 4.2 clearly show that more word instances can improve the disambiguation accuracy and recall scores;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "5"
            },
            {
                "text": "2. WSD is often an unconscious process for human beings. It is unlikely that a reader examines all surrounding words when determining the sense of a word, which calls for a smarter and more selective matching strategy than what we have tried in Section 4.1;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "5"
            },
            {
                "text": "3. Test our WSD system on fine-grained SemEval 2007 WSD task 17. Although we only evaluated our approach with coarse-grained senses, our method can be directly applied to finegrained WSD without any modifications.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion and Future Work",
                "sec_num": "5"
            }
        ],
        "back_matter": [
            {
                "text": "This work is partially funded by NSF grant 0737408 and Scholar Academy at the University of Houston Downtown. This paper contains proprietary information protected under a pending U.S. patent.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Word Sense Disambiguation: Algorithms and Applications",
                "authors": [],
                "year": 2006,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Agirre, Eneko, Philip Edmonds (eds.). 2006. Word Sense Disambiguation: Algorithms and Applications, Springer.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Building a sense tagged corpus with open mind word expert",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Chklovski",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the Acl-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions",
                "volume": "",
                "issue": "",
                "pages": "116--122",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chklovski, T. and Mihalcea, R. 2002. Building a sense tagged corpus with open mind word expert. In Pro- ceedings of the Acl-02 Workshop on Word Sense Dis- ambiguation: Recent Successes and Future Directions, Morristown, NJ, 116-122.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "WordNet: An Electronic Lexical Database",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Fellbaum",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Fellbaum, WordNet: An Electronic Lexical Database, MIT press, 1998",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Noun Homograph Disambiguation Using Local Context in Large Text Corpora",
                "authors": [],
                "year": 1991,
                "venue": "Proc. 7th Annual Conference of the University of Waterloo Center for the New OED and Text Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Project Gutenberg, available at www.gutenberg.org Hearst, M. (1991) Noun Homograph Disambiguation Us- ing Local Context in Large Text Corpora, Proc. 7th Annual Conference of the University of Waterloo Cen- ter for the New OED and Text Research, Oxford.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Introduction to the special issue on word sense disambiguation: the state of the art",
                "authors": [
                    {
                        "first": "Nancy",
                        "middle": [],
                        "last": "Ide",
                        "suffix": ""
                    },
                    {
                        "first": "Jean",
                        "middle": [],
                        "last": "V\u00e9ronis",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Comput. Linguist",
                "volume": "24",
                "issue": "1",
                "pages": "2--40",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nancy Ide and Jean V\u00e9ronis. 1998. Introduction to the special issue on word sense disambiguation: the state of the art. Comput. Linguist., 24(1):2-40.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Dictionaries defined",
                "authors": [
                    {
                        "first": "Ken",
                        "middle": [],
                        "last": "Kister",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Library Journal",
                "volume": "117",
                "issue": "11",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kister, Ken. \"Dictionaries defined\", Library Journal, Vol. 117 Issue 11, p43, 4p, 2bw",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Lesk",
                        "suffix": ""
                    }
                ],
                "year": 1986,
                "venue": "Proceedings of the 5th Annual international Conference on Systems Documentation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lesk, M. 1986. Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proceedings of the 5th An- nual international Conference on Systems Documenta- tion (Toronto, Ontario, Canada). V. DeBuys, Ed. SIG- DOC '86.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Dependency-based evaluation of minipar",
                "authors": [
                    {
                        "first": "Dekang",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Proceedings of the LREC Workshop on the Evaluation of Parsing Systems",
                "volume": "",
                "issue": "",
                "pages": "234--241",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dekang Lin. 1998. Dependency-based evaluation of minipar. In Proceedings of the LREC Workshop on the Evaluation of Parsing Systems, pages 234-241, Granada, Spain.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Using syntactic dependency as local context to resolve word sense ambiguity",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Proceedings of the 35th Annual Meeting of the Association For Computational Linguistics and Eighth Conference of the European Chapter of the Association For Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lin, D. 1997. Using syntactic dependency as local con- text to resolve word sense ambiguity. In Proceedings of the 35th Annual Meeting of the Association For Com- putational Linguistics and Eighth Conference of the European Chapter of the Association For Computa- tional Linguistics (Madrid, Spain, July 07 -12, 1997).",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Using Wikipedia for Automatic Word Sense Disambiguation",
                "authors": [
                    {
                        "first": "Rada",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL 2007)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rada Mihalcea, Using Wikipedia for Automatic Word Sense Disambiguation, in Proceedings of the North American Chapter of the Association for Computa- tional Linguistics (NAACL 2007), Rochester, April 2007.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Instance based learning with automatic feature selection applied to word sense disambiguation",
                "authors": [
                    {
                        "first": "Rada",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the 19th international conference on Computational linguistics",
                "volume": "",
                "issue": "",
                "pages": "1--7",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rada Mihalcea. 2002. Instance based learning with au- tomatic feature selection applied to word sense disam- biguation. In Proceedings of the 19th international conference on Computational linguistics, pages 1-7, Morristown, NJ.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Explaining Answers with Extended WordNet",
                "authors": [
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Moldovan",
                        "suffix": ""
                    },
                    {
                        "first": "Vasile",
                        "middle": [],
                        "last": "Rus",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dan Moldovan and Vasile Rus, Explaining Answers with Extended WordNet, ACL 2001.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Semeval-2007 task 07: Coarsegrained english all-words task",
                "authors": [
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Navigli",
                        "suffix": ""
                    },
                    {
                        "first": "Kenneth",
                        "middle": [
                            "C"
                        ],
                        "last": "Litkowski",
                        "suffix": ""
                    },
                    {
                        "first": "Orin",
                        "middle": [],
                        "last": "Hargraves",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
                "volume": "",
                "issue": "",
                "pages": "30--35",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Roberto Navigli, Kenneth C. Litkowski, and Orin Har- graves. 2007. Semeval-2007 task 07: Coarse- grained english all-words task. In Proceedings of the Fourth International Workshop on Semantic Evalua- tions (SemEval-2007), pages 30-35, Prague, Czech Republic.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Structural semantic interconnections: a knowledge-based approach to word sense disambiguation",
                "authors": [
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Navigli",
                        "suffix": ""
                    },
                    {
                        "first": "Paola",
                        "middle": [],
                        "last": "Velardi",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)",
                "volume": "27",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Roberto Navigli and Paola Velardi. 2005. Structural se- mantic interconnections: a knowledge-based approach to word sense disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 27(7):10631074.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Exploiting Parallel Texts for Word Sense Disambiguation: An Empirical Study",
                "authors": [
                    {
                        "first": "Tou",
                        "middle": [],
                        "last": "Hwee",
                        "suffix": ""
                    },
                    {
                        "first": "Bin",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Yee",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Chan",
                        "middle": [],
                        "last": "Seng",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hwee Tou Ng, Bin Wang, and Yee Seng Chan. Exploit- ing Parallel Texts for Word Sense Disambiguation: An Empirical Study. ACL, 2003.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Integrating multiple knowledge sources to disambiguate word sense: an exemplar-based approach",
                "authors": [
                    {
                        "first": "Tou",
                        "middle": [],
                        "last": "Hwee",
                        "suffix": ""
                    },
                    {
                        "first": "Hian",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Lee",
                        "middle": [],
                        "last": "Beng",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Proceedings of the 34th annual meeting on Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "40--47",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hwee Tou Ng and Hian Beng Lee. 1996. Integrat- ing multiple knowledge sources to disambiguate word sense: an exemplar-based approach. In Proceedings of the 34th annual meeting on Association for Computa- tional Linguistics, pages 40-47, Morristown, NJ.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Lcc-wsd: System description for English coarse grained all words task at semeval 2007",
                "authors": [
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Novischi",
                        "suffix": ""
                    },
                    {
                        "first": "Muirathnam",
                        "middle": [],
                        "last": "Srikanth",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Bennett",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
                "volume": "",
                "issue": "",
                "pages": "223--226",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adrian Novischi, Muirathnam Srikanth, and Andrew Bennett. 2007. Lcc-wsd: System description for En- glish coarse grained all words task at semeval 2007. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 223- 226, Prague, Czech Republic.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Oxford Dictionary of English",
                "authors": [],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Catherine Soanes and Angus Stevenson, editors. 2003. Oxford Dictionary of English. Oxford University Press.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Unsupervised word sense disambiguation rivaling supervised methods",
                "authors": [
                    {
                        "first": "Rada",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    },
                    {
                        "first": ";",
                        "middle": [],
                        "last": "Html Yarowsky",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Proceedings of the 33rd Annual Meeting on Association For Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rada Mihalcea, available at http://www.cs.unt.edu/ rada/downloads.html Yarowsky, D. 1995. Unsupervised word sense disam- biguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting on Association For Com- putational Linguistics (Cambridge, Massachusetts, June 26 -30, 1995).",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Context Knowledge Acquisition and Representation Process",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Merging two parsing trees. The number beside each edge is the number of occurrences of this dependency relation existing in the context knowledge base.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 4: WSD Algorithm",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 5: Weighted parsing trees of the original sentence and two glosses of \"company\"",
                "uris": null,
                "fig_num": "5",
                "type_str": "figure"
            },
            "TABREF1": {
                "content": "<table><tr><td>shows the experiment results. Overall</td></tr><tr><td>disambiguation quality has dropped slightly, which</td></tr></table>",
                "type_str": "table",
                "text": ".28 66.23 66.23 63.20 63.20 66.47 66.47 56.52 56.52 65.14 65.14 2 70.65 70.65 70.98 70.98 65.20 65.20 72.23 72.23 58.84 58.84 68.18 68.18 3 79.89 79.89 75.20 75.20 69.00 69.00 71.94 71.94 64.64 64.64 72.01 72.01 4 80.71 80.71 78.10 78.10 72.80 72.80 71.05 71.05 67.54 67.54 73.65 73.65 5 80.16 80.16 78.10 78.10 69.40 69.40 72.82 72.82 66.09 66.09 73.12 73.12",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>Matching</td><td colspan=\"2\">Overall</td></tr><tr><td>strategy</td><td>P</td><td>R</td></tr><tr><td>1</td><td colspan=\"2\">65.36 65.36</td></tr><tr><td>2</td><td colspan=\"2\">67.78 67.78</td></tr><tr><td>3</td><td colspan=\"2\">68.09 68.09</td></tr><tr><td>4</td><td colspan=\"2\">70.69 70.69</td></tr><tr><td>5</td><td colspan=\"2\">67.78 67.78</td></tr></table>",
                "type_str": "table",
                "text": "Disambiguation scores by article with 5 matching strategies shows a positive correlation between the amount of context knowledge and disambiguation quality. It is reasonable to assume that our disambiguation performance can be improved further by collecting and incorporating more context knowledge.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Disambiguation scores by article with a smaller knowledge base",
                "html": null,
                "num": null
            }
        }
    }
}