{
    "paper_id": "2021",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:59:25.231241Z"
    },
    "title": "CHEMNER: Fine-Grained Chemistry Named Entity Recognition with Ontology-Guided Distant Supervision",
    "authors": [
        {
            "first": "Xuan",
            "middle": [],
            "last": "Wang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Illinois at Urbana-Champaign",
                "location": {
                    "region": "IL",
                    "country": "USA"
                }
            },
            "email": ""
        },
        {
            "first": "Vivian",
            "middle": [],
            "last": "Hu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Illinois at Urbana-Champaign",
                "location": {
                    "region": "IL",
                    "country": "USA"
                }
            },
            "email": "vivianh2@illinois.edu"
        },
        {
            "first": "Xiangchen",
            "middle": [],
            "last": "Song",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {
                    "region": "PA",
                    "country": "USA"
                }
            },
            "email": "xiangchensong@cmu.edu"
        },
        {
            "first": "Shweta",
            "middle": [],
            "last": "Garg",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Illinois at Urbana-Champaign",
                "location": {
                    "region": "IL",
                    "country": "USA"
                }
            },
            "email": "shwetag2@illinois.edu"
        },
        {
            "first": "Jinfeng",
            "middle": [],
            "last": "Xiao",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Illinois at Urbana-Champaign",
                "location": {
                    "region": "IL",
                    "country": "USA"
                }
            },
            "email": ""
        },
        {
            "first": "Jiawei",
            "middle": [],
            "last": "Han",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Illinois at Urbana-Champaign",
                "location": {
                    "region": "IL",
                    "country": "USA"
                }
            },
            "email": "hanj@illinois.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Scientific literature analysis needs fine-grained named entity recognition (NER) to provide a wide range of information for scientific discovery. For example, chemistry research needs to study dozens to hundreds of distinct, fine-grained entity types, making consistent and accurate annotation difficult even for crowds of domain experts. On the other hand, domain-specific ontologies and knowledge bases (KBs) can be easily accessed, constructed, or integrated, which makes distant supervision realistic for fine-grained chemistry NER. In distant supervision, training labels are generated by matching mentions in a document with the concepts in the knowledge bases (KBs). However, this kind of KB-matching suffers from two major challenges: incomplete annotation and noisy annotation. We propose CHEMNER, an ontologyguided, distantly-supervised method for finegrained chemistry NER to tackle these challenges. It leverages the chemistry type ontology structure to generate distant labels with novel methods of flexible KB-matching and ontology-guided multi-type disambiguation. It significantly improves the distant label generation for the subsequent sequence labeling model training. We also provide an expertlabeled, chemistry NER dataset with 62 finegrained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that CHEMNER is highly effective, outperforming substantially the stateof-the-art NER methods (with .25 absolute F1 score improvement).",
    "pdf_parse": {
        "paper_id": "2021",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Scientific literature analysis needs fine-grained named entity recognition (NER) to provide a wide range of information for scientific discovery. For example, chemistry research needs to study dozens to hundreds of distinct, fine-grained entity types, making consistent and accurate annotation difficult even for crowds of domain experts. On the other hand, domain-specific ontologies and knowledge bases (KBs) can be easily accessed, constructed, or integrated, which makes distant supervision realistic for fine-grained chemistry NER. In distant supervision, training labels are generated by matching mentions in a document with the concepts in the knowledge bases (KBs). However, this kind of KB-matching suffers from two major challenges: incomplete annotation and noisy annotation. We propose CHEMNER, an ontologyguided, distantly-supervised method for finegrained chemistry NER to tackle these challenges. It leverages the chemistry type ontology structure to generate distant labels with novel methods of flexible KB-matching and ontology-guided multi-type disambiguation. It significantly improves the distant label generation for the subsequent sequence labeling model training. We also provide an expertlabeled, chemistry NER dataset with 62 finegrained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that CHEMNER is highly effective, outperforming substantially the stateof-the-art NER methods (with .25 absolute F1 score improvement).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Named entity recognition (NER) is a fundamental step in scientific literature analysis to build AI-driven systems for molecular discovery, synthetic strategy designing, and manufacturing (Xie et al., 2013; Szklarczyk et al., 2015; Huang et al., 2015; Szklarczyk et al., 2017; de Almeida et al., 2019) . It aims to locate and classify entity mentions (e.g., \"Suzuki-Miyaura cross-coupling reactions\") from unstructured text into pre-defined categories (e.g., \"coupling reactions\"). In the chemistry domain, previous NER studies are mostly focused on one coarse-grained entity type (i.e., chemicals) (Krallinger et al., 2015; He et al., 2020; Watanabe et al., 2019) and rely on large amounts of manuallyannotated data for training deep learning models (Chiu and Nichols, 2016; Ma and Hovy, 2016; Lample et al., 2016; Wang et al., 2019b; Devlin et al., 2019; Liu et al., 2019) .",
                "cite_spans": [
                    {
                        "start": 187,
                        "end": 205,
                        "text": "(Xie et al., 2013;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 206,
                        "end": 230,
                        "text": "Szklarczyk et al., 2015;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 231,
                        "end": 250,
                        "text": "Huang et al., 2015;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 251,
                        "end": 275,
                        "text": "Szklarczyk et al., 2017;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 276,
                        "end": 300,
                        "text": "de Almeida et al., 2019)",
                        "ref_id": null
                    },
                    {
                        "start": 598,
                        "end": 623,
                        "text": "(Krallinger et al., 2015;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 624,
                        "end": 640,
                        "text": "He et al., 2020;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 641,
                        "end": 663,
                        "text": "Watanabe et al., 2019)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 750,
                        "end": 774,
                        "text": "(Chiu and Nichols, 2016;",
                        "ref_id": null
                    },
                    {
                        "start": 775,
                        "end": 793,
                        "text": "Ma and Hovy, 2016;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 794,
                        "end": 814,
                        "text": "Lample et al., 2016;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 815,
                        "end": 834,
                        "text": "Wang et al., 2019b;",
                        "ref_id": null
                    },
                    {
                        "start": 835,
                        "end": 855,
                        "text": "Devlin et al., 2019;",
                        "ref_id": null
                    },
                    {
                        "start": 856,
                        "end": 873,
                        "text": "Liu et al., 2019)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In real-world applications, it is important to recognize chemistry entities on diverse and finegrained types (e.g., \"inorganic phophorus compounds\", \"coupling reactions\" and \"catalysts\") to provide a wide range of information for scientific discovery. It will need dozens to hundreds of distinct types, making consistent and accurate annotation difficult even for domain experts. On the other hand, the domain-specific ontologies and knowledge bases (KBs) can be easily accessed, constructed, or integrated, which makes distant supervision realistic for fine-grained chemistry NER.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Still, challenges exist for correctly recognizing the entity boundaries and accurately typing entities with distant supervision. In distant supervision, training labels are generated by matching the mentions in a document with the concepts in the knowledge bases (KBs). However, this kind of KB-matching suffers from two major challenges:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(1) incomplete annotation where a mention in a document can be matched only partially or missed completely due to an incomplete coverage of the KBs (Figure 1a ), and (2) noisy annotation where a mention can be erroneously matched due to the potential matching of multiple entity types in the KBs (Figure 1b ). Due to the complex name structures (e.g., nested naming structures and long chemical formulas) of chemical entities, these challenges lead to severe low-precision and low-recall for finegrained chemistry NER with distant supervision.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 156,
                        "end": 158,
                        "text": "1a",
                        "ref_id": "FIGREF0"
                    },
                    {
                        "start": 304,
                        "end": 306,
                        "text": "1b",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Several studies have attempted to address the incomplete annotation problem in distantlysupervised NER. For example, AutoNER (Shang et al., 2018b) introduces an \"unknown\" type that can be skipped during training to reduce the effect of false negative labeling with distant supervision. BOND (Liang et al., 2020) leverages the power of pre-trained language models and a self-training approach to iteratively incorporate more training labels and improve the NER performance. However, previous methods assume a high precision and reasonable coverage of KB-matching for distant label generation. For example, the KB-matching on the CoNLL03 dataset (Liang et al., 2020) reported over 80% on precision and over 60% on recall. These methods do not work well with fine-grained chemistry NER that has severe low precision and low recall with KB-matching. Previous studies also largely ignore the noisy annotation problem by simply discarding those multi-labels during the KBmatching process (Liang et al., 2020) . However, the noisy labels cannot be simply ignored for the chemistry entities because they consist of a large portion of distant training labels. We observe that more than 60% of the entities have multiple labels during KB-matching in the chemistry domain.",
                "cite_spans": [
                    {
                        "start": 125,
                        "end": 146,
                        "text": "(Shang et al., 2018b)",
                        "ref_id": null
                    },
                    {
                        "start": 291,
                        "end": 311,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 644,
                        "end": 664,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 982,
                        "end": 1002,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We propose CHEMNER, an ontology-guided, distantly-supervised NER method for fine-grained chemistry NER. Taking an input corpus, a chemistry type ontology and associated entity dictionaries collected from the KBs, we develop a novel flexible KB-matching method with TF-IDF-based majority voting to resolve the incomplete annota-tion problem. Then we develop a novel ontologyguided multi-type disambiguation method to resolve the noisy annotation problem. Taking the output from the above two steps as distant supervision, we further train a sequence labeling model to cover additional entities. CHEMNER significantly improves the distant label generation for the subsequent NER model training. We also provide an expert-labeled, chemistry NER dataset with 62 finegrained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that CHEMNER is highly effective, achieving substantially better performance (with .25 absolute F1 score improvement) compared with the state-ofthe-art NER methods. We have released our data and code to benefit future studies1 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Distantly-Supervised NER. Aiming to reduce expensive manual annotation, distant supervision has been used to generate training labels automatically by utilizing the entity information from existing KBs. The major research efforts lie in dealing with the incomplete annotation problem caused by an incomplete coverage of the KBs (Fries et al., 2017; Shang et al., 2018b; Peng et al., 2019; Wang et al., 2019a Wang et al., , 2020a,b;,b; Liang et al., 2020) .",
                "cite_spans": [
                    {
                        "start": 328,
                        "end": 348,
                        "text": "(Fries et al., 2017;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 349,
                        "end": 369,
                        "text": "Shang et al., 2018b;",
                        "ref_id": null
                    },
                    {
                        "start": 370,
                        "end": 388,
                        "text": "Peng et al., 2019;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 389,
                        "end": 407,
                        "text": "Wang et al., 2019a",
                        "ref_id": null
                    },
                    {
                        "start": 408,
                        "end": 434,
                        "text": "Wang et al., , 2020a,b;,b;",
                        "ref_id": null
                    },
                    {
                        "start": 435,
                        "end": 454,
                        "text": "Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "AutoNER (Shang et al., 2018b) proposes a \"tieor-break\" tagging scheme to leverage distant supervision from entity dictionaries. Compared with the traditional \"BIOES\" tagging scheme, the \"tie-orbreak\" tagging scheme introduces an \"unknown\" type that can be skipped during training to reduce the effect of false negative labeling brought by the incomplete KB-matching. However, AutoPhrase often misses low-frequency phrases for the \"unknown\" entity generation using a phrase mining method AutoPhrase (Shang et al., 2018a) . Positive and unlabeled learning (PU-learning) is used in distantly-supervised NER to provide an unbiased and consistent estimator of the objective function (Peng et al., 2019) . However, there are two limitations in using PU-learning for distantly-supervised NER. First, PU-learning uses the prior distribution for each entity type, a parameter that is estimated from an existing human-annotated test set that is not always available for new entity types. Second, the performance of PU-learning is highly sensitive to the class-imbalance rate for each entity type, a parameter that is heuristically determined. It is difficult to apply PU-learning to distantly-supervised NER tasks on new entity types in new domains due to the above two limitations. BOND (Liang et al., 2020) leverages the power of pre-trained language models (e.g., BERT and RoBERTa) and a selftraining approach to iteratively incorporate more training labels and improve the NER performance. However, they do not work well with fine-grained chemistry entities that have a severe low-precision and low-recall problem with KB-matching. They also largely ignore the noisy annotation problem by simply discarding those multi-labels during the KB-matching process.",
                "cite_spans": [
                    {
                        "start": 8,
                        "end": 29,
                        "text": "(Shang et al., 2018b)",
                        "ref_id": null
                    },
                    {
                        "start": 498,
                        "end": 519,
                        "text": "(Shang et al., 2018a)",
                        "ref_id": null
                    },
                    {
                        "start": 678,
                        "end": 697,
                        "text": "(Peng et al., 2019)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 1278,
                        "end": 1298,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Other Related Tasks. One similar task to finegrained NER is entity linking (Francis-Landau et al., 2016; Gupta et al., 2017; Raiman and Raiman, 2018; Le and Titov, 2018 ) that maps a candidate entity in the text to a concept identifier in the knowledge bases. However, entity linking cannot deal with new entities that do not exist in the background knowledge bases. Another similar task is fine-grained entity typing (FET) (Hoffart et al., 2011; Yosef et al., 2012; Ling and Weld, 2012; Del Corro et al., 2015; Ren et al., 2015; Choi et al., 2018) that has been extensively studied in the general domain. FET aims at classifying an entity mention into a wide range of entity types by disambiguating the pre-identified entity mentions into a set of candidate entity types. It is formulated as a multi-class, multi-label classification problem and does not assume type exclusiveness. The fine-grained NER task targets both entity boundary detection and entity type recognition and assumes each entity to be tagged with only one type in a given context. In this study, we focus on the finegrained NER task in the chemistry domain.",
                "cite_spans": [
                    {
                        "start": 75,
                        "end": 104,
                        "text": "(Francis-Landau et al., 2016;",
                        "ref_id": null
                    },
                    {
                        "start": 105,
                        "end": 124,
                        "text": "Gupta et al., 2017;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 125,
                        "end": 149,
                        "text": "Raiman and Raiman, 2018;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 150,
                        "end": 168,
                        "text": "Le and Titov, 2018",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 424,
                        "end": 446,
                        "text": "(Hoffart et al., 2011;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 447,
                        "end": 466,
                        "text": "Yosef et al., 2012;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 467,
                        "end": 487,
                        "text": "Ling and Weld, 2012;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 488,
                        "end": 511,
                        "text": "Del Corro et al., 2015;",
                        "ref_id": null
                    },
                    {
                        "start": 512,
                        "end": 529,
                        "text": "Ren et al., 2015;",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 530,
                        "end": 548,
                        "text": "Choi et al., 2018)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "We propose CHEMNER, an ontology-guided distantly-supervised NER method for fine-grained chemistry NER (Figure 2 ). It includes distant label generation (entity span detection, flexible KBmatching, and ontology-guided multi-type disambiguation) and sequence labeling model training.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 110,
                        "end": 111,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "The CHEMNER Framework",
                "sec_num": "3"
            },
            {
                "text": "The input to CHEMNER includes two parts: (1) a chemistry literature corpus, and (2) a fine-grained chemistry type ontology and associated entity dictionaries for each type.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "Corpus Collection. For this study, we collected a chemistry literature corpus from PubChem2 . This corpus contains 4,608 papers, among which 319 papers have the full-text and all have the title and abstract. There are 71,406 sentences in this corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "Type Ontology and Dictionary Collection. We collected a fine-grained chemistry type ontology from Wikipedia categories rooted under the Chemistry category3 . We treat the Wikipedia category pages as types and the titles of the pages associated with each category as the entity dictionary for each type. We further remove irrelevant types and merge some fine-grained types to their coarse-grained parent types based on their term frequencies in the corpus. We also expand the entity dictionaries with synonyms collected from the PubChem knowledge base. Finally, we obtained a fine-grained chemistry entity type ontology with 62 types and its associated dictionaries with 10,551 entities. Figure 3 shows a subset of our chemistry type ontology.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 694,
                        "end": 695,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "The complete fine-grained chemistry type ontology with 62 types can be found in Appendix A.1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Preparation",
                "sec_num": "3.1"
            },
            {
                "text": "Taking the input corpus, chemistry type ontology and associated entity dictionaries collected from the KBs, we first develop a flexible KB-matching method to resolve the incomplete annotation problem. Chemistry entities usually have complex name structures, such as nested naming structures (e.g., \"aryl chloride\" where \"aryl\" is a FUCNTIONAL GROUP, \"chloride\" is a HALIDE but altogether is an ORGANOHALIDE) and long chemical formulas (e.g., \"Methyl 3'-(((Trifluoromethyl)sulfonyl)oxy)-[1,1'-biphenyl]-4-carboxylate\"), that are quite flexible and cannot be fully covered by the KBs. Simple KB-matching used in previous distantly-supervised NER methods (Shang et al., 2018b; Liang et al., 2020) cannot match those complex chemistry entities that do not exist in the KBs, which leads to a severe low precision and low recall for labeling the fine-grained chemistry entities.",
                "cite_spans": [
                    {
                        "start": 652,
                        "end": 673,
                        "text": "(Shang et al., 2018b;",
                        "ref_id": null
                    },
                    {
                        "start": 674,
                        "end": 693,
                        "text": "Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "We propose to first conduct entity span detection with chemistry phrase chunking tools followed by a flexible KB-matching to resolve the incomplete KB-matching problem. We use two phrase chunking tools, ChemDataExtractor (Swain and Cole, 2016) and Genia Tagger (Tsuruoka and Tsujii, 2005) , to generate candidate entity spans in the input corpus (e.g., in Figure 2 sentence S2, the phrase chunking tools find \"Suzuki-Miyaura crosscoupling reactions\" as a candidate entity span.) Based on the detected candidate entity spans, we develop a flexible KB-matching method with TF-IDF-based majority voting to resolve the incomplete annotation problem.",
                "cite_spans": [
                    {
                        "start": 261,
                        "end": 288,
                        "text": "(Tsuruoka and Tsujii, 2005)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 363,
                        "end": 364,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "The flexible KB-matching method can match long and complex chemistry entities (e.g., chemical compounds) that do not exist in the KBs. Specifically, we label each candidate entity span by letting each word token in the entity span vote for several entity types that are most likely to involve this word token. For example, in Figure 2 sentence S1, \"[Methyl-14C]S-Thd\", which is short for \"4'-[methyl-14C]thiothymidine\" according to the original document, is an author-defined abbreviation that cannot be covered by the existing KBs. However, since \"Methyl-\" is a common functional group that is usually the prefix of the organic compounds, this word token in \"[Methyl-14C]S-Thd\" helps vote for the types \"OR-GANIC COMPOUNDS\" and \"ORGANIC POLY-MERS\". Another example is sentence S2, where three (\"suzuki\", \"coupling\", \"reaction\") out of the five word tokens in \"Suzuki-Miyaura crosscoupling reactions\" help vote for the type \"COU-PLING REACTIONS\".",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 333,
                        "end": 334,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "Formally, let e = [w 1 , w 2 , . . . , w n ], w i \u2208 V, where e denotes each candidate entity span, w i each word token in the entity span, and V the vocabulary. Let T denote the set of fine-grained types and D t the dictionary of entities for type t \u2208 T . The TF-IDF score of each word token w for each entity type t \u2208 T is calculated as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "T F -IDF (w, t) = T F (w, t) * IDF (w, t), T F (w, t) = f (w, D t ) w \u2208V f (w , D t ) , IDF (w, t) = log |T | |{t | t \u2208 T , w \u2208 D t }| ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "where f (w, D t ) denotes the frequency of the word token w appearing in the dictionary D t . We set a minimum TF-IDF threshold \u03b8 = 0.02 to eliminate the common words from voting for the entity types. Then we let each word token vote for several entity types that has the highest TF-IDF scores above the mininum TF-IDF threshold and generate the distant labels by taking the majority voting. Note that this step can generate multi-type labels for the candidate entity spans due to ties in the majority voting. We resolve this problem with an ontology-guided multi-type disambiguation method as the next step.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Flexible KB-Matching",
                "sec_num": "3.2"
            },
            {
                "text": "Based on the output of flexible KB-matching and the chemistry type ontology structure, we develop an ontology-guided multi-type disambiguation method to resolve the noisy annotation problem. An intuition of multi-type disambiguation is that the entities in the same sentence, paragraph or document usually follow a focused topic. For example, if a sentence is talking about organic chemistry, the entities in this sentence are more likely to have types related to organic chemistry. Following this intuition and the chemistry type ontology structure (Section 3.1), we draw two insights for an automated multi-type disambiguation: (1) the entity types in one sentence are usually confined to one big branch on the chemistry type ontology (e.g., organic or inorganic chemistry), and (2) the type of an entity under local context should be close to the types of the surrounding entities in the same sentence on the chemistry type ontology. For example, in Figure 2 , sentence S3 contains one entity \"palladium\" that has two candidate types: \"CAT-ALYSTS\" that falls under \"CHEMICAL REAC-TIONS\" and \"TRANSITION METALS\" that falls under \"CHEMICAL ELEMENTS\". By looking at its surrounding entities (e.g., \"cross-coupling\"), we see that the surrounding entity types (e.g., \"COUPLING REACTIONS\" for \"cross-coupling\") fall under the \"ORGANIC REACTIONS\" branch, which is also under the larger \"CHEMICAL RE-ACTIONS\" branch, on the type ontology. So the sentence S3 is likely talking about chemical reaction and \"palladium\" is more suitable to have a type \"CATALYSTS\" instead of \"TRANSITION METALS\" based on the local context. Formally, let s = [e 1 , e 2 , . . . , e n ], where s denotes a sentence and e i ith entity mention in it that has been assigned an initial label set T e i = {t 1 e i , . . . , t m e i } with flexible KB-matching. For an entity e i with multiple candidate types (|T e i | > 1) to be resolved, we calculate the inverse distance between this candidate type and the distribution of the surrounding types on the type ontology. The disambiguation score for each candidate type S d (t j e i ) is defined as follows:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 960,
                        "end": 961,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "S d (t j e i ) = k\u2208[1..n],k =i,|Te k |=1 dep(lca(t e k , t j e i )) n * dep(t j e i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": ",",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "where lca(\u2022, \u2022) denotes the lowest common ancestor of two types on the type ontology and dep(\u2022) denotes the depth of the type on the type ontology. S d (t j e i ) \u2208 (0, 1) and a larger score indicates that the candidate type t j e i is more likely to be the correct type for the entity e i in sentence s.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "If the surrounding types in the sentence still draw ties for the candidate type resolution, we could further enlarge the scope to a few surrounding sentences, the paragraph, the document or the corpus. We introduce a corpus-level global popularity score for each type based on our experimental observations. As shown in Figure 2 , we calculate the frequency of each type in our initially labeled corpus with flexible KB-matching. \"CATALYSTS\" is globally more popular with a frequency of 18,707 compared to \"TRANSITION METALS\" with a frequency of 9,618. The global popularity score for each candidate type S g (t j e i ) is defined as follows:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 327,
                        "end": 328,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "S g (t j e i ) = f c (t e i ) t \u2208T f c (t )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": ", where f c (\u2022) denotes the frequency of the type in the flexible KB-matched corpus. S g (t j e i ) \u2208 (0, 1] and a larger score indicates that the candidate type t j e i is more likely to be the correct type for the entity e i globally in the corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "The final score S(t j e i ) of the candidate type t j e i is a combination of the local disambiguation score S d (t j e i ) and the global popularity score S g (t j e i ):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "S(t j e i ) = S d (t j e i ) * S g (t j e i ) \u2208 (0, 1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "We choose the type t j e i for the entity e i that has a highest score S(t j e i ) for multi-type disambiguation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ontology-Guided Multi-Type Disambiguation",
                "sec_num": "3.3"
            },
            {
                "text": "The flexible KB-matching and multi-type disambiguation still rely on the signals from the KBs and ontologies, which cannot cover all the new entities in the corpus. Taken the output from the above two steps as distant supervision, we further train a sequence labeling model to solve the sparsity labeling problem. For example, in Figure 2 sentence 4, \"BBA\" is a new entity that cannot be labeled by flexible KB-matching since there is no obvious token-level signals. However, there is a \"boronic acid\" entity with the type \"OXOACIDS\" in its surrounding context. The sequence labeling models will be able to capture those context patterns such as \"either ... or ...\" that usually connect entities with similar types. Thus they are likely to recognize \"BBA\" with the type \"OXOACIDS\".",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 337,
                        "end": 338,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Sequence Labeling Models",
                "sec_num": "3.4"
            },
            {
                "text": "Based on the distant labels generated by the flexible KB-matching and multi-type disambiguation, we train a sequence labeling model (e.g., RoBERTa, ChemBERTa) without any constraints on the type of model to use. The loss function is defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sequence Labeling Models",
                "sec_num": "3.4"
            },
            {
                "text": "l = arg min \u03b8 n i loss(h \u03b8 (x i ), y),",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sequence Labeling Models",
                "sec_num": "3.4"
            },
            {
                "text": "where h \u03b8 (\u2022) is the output of the sequence labeling model and y is our generated distant label. This is equivalent to minimizing the cross-entropy error between the outputs of the sequence labeling model and our generated distant labels.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sequence Labeling Models",
                "sec_num": "3.4"
            },
            {
                "text": "We provide a chemistry NER dataset covering 62 fine-grained chemistry types such as chemical compounds and chemical reactions. This dataset can be used to benchmark distantly supervised NER methods for the fine-grained chemistry NER task. The input for training includes two parts:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "(1) a chemistry literature corpus with 69,806 unlabeled sentences, and (2) a chemistry type ontology with 62 fine-grained chemistry types and associated entity dictionaries for each type (Section 3.1). The test set contains 1,600 expert-annotated sentences on the fine-grained chemistry types. We use this test set to compare the performance of different NER methods in our experiments. We report the entity-level micro-precision, micro-recall, and micro-F1 scores4 of each NER method on the human-annotated test set. More details of the dataset preparation can be found in Appendix A.1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "We compare the performance of CHEMNER with different groups of baseline methods. More details of the paramter settings and runtime analysis of each model can be found in Appendix A.2. KB-Matching: This baseline is a simple string matching as (Peng et al., 2019) . It is a greedy search algorithm that walks through a sentence trying to find the longest strings that match the entities in the dictionaries. For the strings matched with multiple types, we simply discard those multilabels as (Liang et al., 2020) . KB-Matching (freq): This baseline is a simple improvement of KB-Matching. For the strings matched with multiple types, we choose the type that has the highest frequency in the corpus. BiLSTM-CRF: This baseline is the BiLSTM-CRF model (Ma and Hovy, 2016) that takes the results of KB-Matching (freq) as distant supervision. AutoNER: This baseline is the AutoNER model (Shang et al., 2018b) that directly takes the raw corpus and the dictionaries as the input. It has a builtin KB-matching algorithm that maximizes the total number of matched tokens on each sentence to generate distant supervision. For the strings matched with multiple types, it assigns equal probabilities to each candidate type during training. RoBERTa: This baseline is the RoBERTa model (Liu et al., 2019) that takes the results of KB-Matching (freq) as distant supervision. ChemBERTa: This baseline is the ChemBERTa model (Chithrananda et al., 2020) that takes the results of KB-Matching (freq) as distant supervision. The ChemBERTa language model is pre-trained on the SMILE strings of the chemical molecule structures instead of the chemistry corpus. To our knowledge, there is no domain-specific pre-trained language model on the chemistry corpus. BOND: This baseline is the BOND model (Liang et al., 2020) that takes the results of KB-Matching (freq) as distant supervision. The original distant supervision is our KB-Matching baseline according to the BOND paper. Here we use the improved KB-Matching (freq) baseline to give the BOND baseline an improved performance. CHEMNER F : This is an ablation model of CHEM-NER with the flexible KB-Matching only. For the strings matched with multiple types, we simply discard those multi-labels. CHEMNER FM : This is an ablation model of CHEMNER with the flexible KB-Matching and the ontology-guided multi-type resolution. CHEMNER BiLSTM-CRF : This is a variation of CHEMNER that takes the results of CHEMNER FM as distant supervision and trains a BiLSTM-CRF model for the final prediction. CHEMNER RoBERTa : This is a variation of CHEM-NER that takes the results of CHEMNER FM as distant supervision and trains a RoBERTa model for the final prediction. It is also the full model of CHEMNER that achieves the best performance.",
                "cite_spans": [
                    {
                        "start": 242,
                        "end": 261,
                        "text": "(Peng et al., 2019)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 490,
                        "end": 510,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 747,
                        "end": 766,
                        "text": "(Ma and Hovy, 2016)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 880,
                        "end": 901,
                        "text": "(Shang et al., 2018b)",
                        "ref_id": null
                    },
                    {
                        "start": 1271,
                        "end": 1289,
                        "text": "(Liu et al., 2019)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 1407,
                        "end": 1434,
                        "text": "(Chithrananda et al., 2020)",
                        "ref_id": null
                    },
                    {
                        "start": 1774,
                        "end": 1794,
                        "text": "(Liang et al., 2020)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "4.2"
            },
            {
                "text": "CHEMNER ChemBERTa : This is a variation of CHEMNER that takes the results of CHEMNER FM as distant supervision and trains a ChemBERTa model for the final prediction.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "4.2"
            },
            {
                "text": "CHEMNER BOND : This is a variation of CHEM-NER that takes the results of CHEMNER FM as distant supervision and trains a BOND model for the final prediction.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "4.2"
            },
            {
                "text": "Overall Results. Table 1 shows the overall results on the test set of our fine-grained chemistry NER dataset. CHEMNER achieves .25 absolute F1 score improvement over the best performing baseline model RoBERTa. As we have discussed, the KB-Matching method suffers from severe low precision (32%) and low recall (5%) for labeling the finegrained chemistry entities, which greatly limits the performance of the baseline NER methods that use KB-Matching for distant supervision. Ablation Study. Table 2 shows the results of ablation studies on the test set of our fine-grained chemistry NER dataset. We compared our CHEM-NER full model with several ablations and variations. Our ablation model CHEMNER F significantly improves the precision and recall over KBmatching and CHEMNER FM further improves the recall. These two ablations show the effectiveness of our proposed novel methods, flexible KBmatching and ontology-guided multi-type resolu- tion, for fine-grained chemistry NER under distant supervision. The four full model variations further shows that RoBERTa is the best sequence labeling model that takes the output of CHEMNER FM as distant supervision. Parameter Study. Table 3 shows the effect of different mininum TF-IDF threshold \u03b8 on the performance of CHEMNER F . This threshold \u03b8 is used to eliminate common word tokens from voting for the candidate entity types during the flexible KB-Matching. We observe that \u03b8 = 0.02 gives the best performance of of CHEMNER F .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 23,
                        "end": 24,
                        "text": "1",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 497,
                        "end": 498,
                        "text": "2",
                        "ref_id": "TABREF4"
                    },
                    {
                        "start": 1182,
                        "end": 1183,
                        "text": "3",
                        "ref_id": "TABREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "Table 4 shows the effect of different enlarged scopes on the performance of CHEMNER FM . This enlarged scope is used to control the performance of ontology-guided multi-type disambiguation. We observe that when the context types in one sentence still draw ties for multi-type disambiguation, it is more effective to directly go to the corpus-level to look at the popularity scores for each type instead of extending the ontology-guided multi-type disambiguation mechanism to the document level. Qualitative Analysis. Table 5 shows some example sentences from our test set. We compare the prediction results of CHEMNER with two baseline methods: KB-Matching and RoBERTa. We also show the prediction results of our ablation models, CHEMNER F and CHEMNER FM , to demonstrate the contribution of each component and how the CHEMNER full model achieves the best performance step by step.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "4",
                        "ref_id": "TABREF6"
                    },
                    {
                        "start": 523,
                        "end": 524,
                        "text": "5",
                        "ref_id": "TABREF8"
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "KB-Matching can only match entities that exactly appear in the KB dictionaries, which often leads to incomplete or missing annotations. Based on the results of KB-Matching, RoBERTa learns to give one context-specific label for each entity. For example, in Sentence # 1, KB-Matching failed to recognize \"aryl chlorides\" as a whole unit, yet it does match \"aryl\" to three types (i.e., \"ARO-MATIC COMPOUNDS\", \"SUBSTITUENTS', and \"FUNCTIONAL GROUPS\"). RoBERTa learns the best label (i.e., \"FUNCTIONAL GROUPS\") for the multi-type entity (i.e., \"aryl\") based on the context. Although \"FUNCTIONAL GROUPS\" is indeed the best type for \"aryl\" if we look at the word individually, RoBERTa still achieves imperfect performance due to the incomplete boundaries inherited from KB-Matching.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "With flexible KB-Matching, CHEMNER F detects the complete boundaries and assigns much more suitable types in most cases. Based on the results of CHEMNER F , using ontology-guided multi-type resolution, CHEMNER FM determines the context-specific label that fits the best. For example, in Sentence # 2, CHEMNER F matches \"narciclasine\" to two types (i.e., \"ALKALOIDS\" and \" BIOMOLECULES\"). Here \"ALKALOIDS\" is a more suitable type and can be detected by CHEMNER FM because \"ALKALOIDS\" and the context type \"ORGANIC REDOX REACTIONS\" are both under the ontology branch \"ORGANIC CHEMISTRY\". However, there are also a few cases that the ontology-guided multi-type resolutions are imperfect. For example, in Sentence # 1, CHEMNER FM choose the type \"CHLO-RIDES\" over \"ORGANOHALIDES\" for \"aryl chlorides\" because \"CHLORIDES\" and the context type \"OXOACIDS\" are both under the ontology branch \"INORGANIC COMPOUNDS\", whereas the ground truth label is just the opposite. This issue could further be resolved by the sequence labeling model trained on top of CHEMNER FM . For example, in Sentence # 1, CHEMNER finally chooses \"ORGANOHALIDES\" over \"OXOACIDS\" instead probably because the sequence labeling model captures the pattern on the co-occurrence of \"ORGANOHALIDES\" and \"OXOACIDS\". Interestingly, from the perspective of chemistry, organohalides and organoboron species (a sector of oxoacids) are the exact two couplers of the Suzuki Coupling reaction.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "We propose CHEMNER, an ontology-guided, distantly-supervised method for fine-grained chemistry NER. It leverages the chemistry type ontology structure to generate distant labels with novel methods of flexible KB-matching and ontology-guided multi-type disambiguation. We also provide an expert labeled, chemistry NER dataset with 62 finegrained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that CHEMNER is highly effective, outperforming substantially the state-of-the-art NER methods on fine-grained chemistry NER. Although achieving great performance, there is still large room for improvement of CHEMNER. In the future, we plan to further refine and enrich the type ontology and incorporate more information in the dictionaries (e.g., chemical structures in the KBs) for a better NER performance. We also plan to apply our finegrained NER method to other scientific domains.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "5"
            },
            {
                "text": "We have released all of our data and code for future studies, including the chemistry literature corpus, fine-grained entity type ontology and associated dictionaries collected from Wikipedia-Chemistry, manually-annotated test set for NER performance evaluation, and the code of CHEMNER.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A.1 Dataset Preparation",
                "sec_num": null
            },
            {
                "text": "Corpus Collection. We collected a corpus for Suzuki Coupling reactions in the chemistry domain. Suzuki coupling is an important reaction for carbon-carbon bond formation in organic chemistry. Recent studies have focused on the Suzuki coupling reactions to build AI-driven systems for molecular discovery, synthetic strategy designing, and manufacturing. This corpus contains 4,608 papers that are retrieved from PubChem 7 with the query \"Suzuki Coupling\", among which 319 papers have the full-text and all have the title and abstract. There are in total 71,406 sentences in this corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A.1 Dataset Preparation",
                "sec_num": null
            },
            {
                "text": "Dictionary Collection. We collected a finegrained chemistry entity type ontology from Wikipedia by treating category pages as types and the titles of the pages associated with each category as the entities for each type. We first conducted depth-first search (DFS) starting from the Chemistry category 8 and found that the search did not stop when one million categories had been visited, and it often happened that a category relevant to Chemistry has irrelevant children. Therefore, we decide to use a technical term list to filter out irrelevant categories. We collected a spell-checker dictionary (Azman, 2012) with over 104,000 technical chemistry terms, and dropped a category from the search if less than 20% of 1-grams in its name and the names of all its direct children were covered by the dictionary. The threshold of 20% was selected empirically. After this step, we obtained a fine-grained chemistry entity type ontology with 3,775 types and 101,415 entities. We future tailor the entity type ontology and their associated entities by removing some irrelevant types and merge some fine-grained types to their coarse-grained parent types based on their frequencies in our chemistry literature corpus. We also expand the entity dictionaries with synonyms collected from the Pub- Chem knowledge base. Finally, we obtained a finegrained chemistry entity type ontology with 62 types and 10,551 entities. Figure 4 shows our complete chemistry entity type ontology.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 1419,
                        "end": 1420,
                        "text": "4",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "A.1 Dataset Preparation",
                "sec_num": null
            },
            {
                "text": "Test Set Annotation. We randomly select 1,600 sentences from the corpus and ask three domain experts to annotate each sentence as our test sets. We leave the remaining sentences (69,806 sentences in the corpus) as the training set for distant supervision. We provide the annotators with an autocomplete drop-down menu consisting of our entity type vocabulary. Each pair of annotators reach a substantial agreement with a Fleiss's \u03ba of 0.72. The conflicts among annotators are resolved by another senior domain expert in the final annotated test set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A.1 Dataset Preparation",
                "sec_num": null
            },
            {
                "text": "Runtime with Parameters. We compared all sequence model we adopted during experiments. Our models are trained on a single NVIDIA Titan Xp (12GB) GPU. The details about the average runtime and the number of parameters are given in Table 6 . All training hyperparameters follow their original implementation. BiLSTM-CRF. We used the code base of BiLSTM-CRF9 . The hyperparameters are set to default values. We trained the BiLSTM-CRF on Suzuki Coupling data with 10 epoches with learning rate as 0.001, hidden dimension as 256, drop rate as 0.5 and use word embedding with dimension of 256.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 236,
                        "end": 237,
                        "text": "6",
                        "ref_id": "TABREF10"
                    }
                ],
                "eq_spans": [],
                "section": "A.2 Parameter Settings",
                "sec_num": null
            },
            {
                "text": "AutoNER. We adopted the code base from Au-toNER's original implementation10 . The hyperparameters are set to default values. We trained AutoNER model on Suzuki Coupling data with 50 epoches and learning rate as 0.05, hidden dimension as 300, drop rate as 0.5 and use pretrained word embedding with dimension of 200. RoBERTa. We use the HuggingFace11 Transform- ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A.2 Parameter Settings",
                "sec_num": null
            },
            {
                "text": "https://github.com/xuanwang91/ChemNER",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://pubchem.ncbi.nlm.nih.gov/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://en.wikipedia.org/wiki/ Category:Chemistry",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/chakki-works/ seqeval",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/Gxzzz/BiLSTM-CRF",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/shangjingbo1226/ AutoNER",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/huggingface/ transformers",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/cliang1453/BOND",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Acknowledgment This work was supported by the Molecule Maker Lab Institute: An AI Research Institutes program supported by NSF under Award No. 2019897, US DARPA KAIROS Program No. FA8750-19-2-1004, SocialSim Program No. W911NF-17-C-0099, and INCAS Program No. HR001121C0165, and National Science Foundation IIS-19-56151, IIS-17-41317, and IIS 17-04532. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the National Science Foundation, DARPA or the U.S. Government.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "acknowledgement",
                "sec_num": null
            },
            {
                "text": "We provide an expert-labeled, chemistry NER dataset with 62 fine-grained chemistry types on 1,600 sentences. The text corpus is collected from an open-source chemistry database PubChem 5 . The entity types are collected from Wikipedia 6 . We recruited 5 undergraduate annotators from the Chemistry Department in our university. Each of the annotators is compensated at an hourly salary of $15. Annotators are voluntary participants who were aware of any risks of harm associated with their participation and had given their informed consents. Our project is subjected to the review of and approved by the IRB at our university. This dataset can be used to benchmark the named entity recognition performance on fine-grained chemistry NER, which contains 1,600 carefully annotated sentences. Each sentence is labeled with groundtruth entities with both the entity boundaries and the entity types. We ask three domain experts to annotate each sentence. We provide the annotators with an auto-complete drop-down menu consisting of our entity type vocabulary. Each pair of annotators reach a substantial agreement with a Fleiss's \u03ba of 0.72. The conflicts among annotators are re-5 https://pubchem.ncbi.nlm.nih.gov/ 6 https://en.wikipedia.org/wiki/ Category:Chemistry solved by another senior domain expert in the final annotated test set. We've described many characteristics of the dataset in Section 3.1. More details of the dataset and the steps taken during the data collection and preparation process can be found in Appendix A.1. ers Python Interface to train the RoBERTa model on the Suzuki Coupling data using the roberta-base model with 10 epochs and a batch size of 32. The other hyperparameters are set to default values. ChemBERTa. For ChemBERTa also, we use the HuggingFace Transformers to train the BERT model on the Suzuki Coupling data using the seyonec/ChemBERTa-zinc-base-v1 model with 10 epochs and a batch size of 32. The other hyperparameters are set to default values. BOND. To train our Suzuki Coupling data using BOND, we use their publicly available code 12 that also uses the HuggingFace Transformers robertabase model as the base model for training. We train the model for 20 epochs with a learning rate of 2e-5. The other hyperparameters are set to default values.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ethics/Impact Statement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Swellshark: A generative model for biomedical named entity recognition without labeled data",
                "authors": [
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Fries",
                        "suffix": ""
                    },
                    {
                        "first": "Sen",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Ratner",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "R\u00e9",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jason Fries, Sen Wu, Alex Ratner, and Christopher R\u00e9. 2017. Swellshark: A generative model for biomed- ical named entity recognition without labeled data. ArXiv preprint, abs/1704.06360.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Entity linking via joint encoding of types, descriptions, and context",
                "authors": [
                    {
                        "first": "Nitish",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2681--2690",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D17-1284"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nitish Gupta, Sameer Singh, and Dan Roth. 2017. Entity linking via joint encoding of types, de- scriptions, and context. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2681-2690, Copen- hagen, Denmark. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Overview of chemu 2020: named entity recognition and event extraction of chemical reactions from patents",
                "authors": [
                    {
                        "first": "Jiayuan",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Quoc",
                        "middle": [],
                        "last": "Dat",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Saber",
                        "suffix": ""
                    },
                    {
                        "first": "Christian",
                        "middle": [],
                        "last": "Akhondi",
                        "suffix": ""
                    },
                    {
                        "first": "Camilo",
                        "middle": [],
                        "last": "Druckenbrodt",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Thorne",
                        "suffix": ""
                    },
                    {
                        "first": "Zubair",
                        "middle": [],
                        "last": "Hoessel",
                        "suffix": ""
                    },
                    {
                        "first": "Zenan",
                        "middle": [],
                        "last": "Afzal",
                        "suffix": ""
                    },
                    {
                        "first": "Biaoyan",
                        "middle": [],
                        "last": "Zhai",
                        "suffix": ""
                    },
                    {
                        "first": "Hiyori",
                        "middle": [],
                        "last": "Fang",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Yoshikawa",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "International Conference of the Cross-Language Evaluation Forum for European Languages",
                "volume": "",
                "issue": "",
                "pages": "237--254",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jiayuan He, Dat Quoc Nguyen, Saber A Akhondi, Christian Druckenbrodt, Camilo Thorne, Ralph Hoessel, Zubair Afzal, Zenan Zhai, Biaoyan Fang, Hiyori Yoshikawa, et al. 2020. Overview of chemu 2020: named entity recognition and event extraction of chemical reactions from patents. In International Conference of the Cross-Language Evaluation Forum for European Languages, pages 237-254. Springer.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Robust disambiguation of named entities in text",
                "authors": [
                    {
                        "first": "Johannes",
                        "middle": [],
                        "last": "Hoffart",
                        "suffix": ""
                    },
                    {
                        "first": "Mohamed",
                        "middle": [
                            "Amir"
                        ],
                        "last": "Yosef",
                        "suffix": ""
                    },
                    {
                        "first": "Ilaria",
                        "middle": [],
                        "last": "Bordino",
                        "suffix": ""
                    },
                    {
                        "first": "Hagen",
                        "middle": [],
                        "last": "F\u00fcrstenau",
                        "suffix": ""
                    },
                    {
                        "first": "Manfred",
                        "middle": [],
                        "last": "Pinkal",
                        "suffix": ""
                    },
                    {
                        "first": "Marc",
                        "middle": [],
                        "last": "Spaniol",
                        "suffix": ""
                    },
                    {
                        "first": "Bilyana",
                        "middle": [],
                        "last": "Taneva",
                        "suffix": ""
                    },
                    {
                        "first": "Stefan",
                        "middle": [],
                        "last": "Thater",
                        "suffix": ""
                    },
                    {
                        "first": "Gerhard",
                        "middle": [],
                        "last": "Weikum",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "782--792",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor- dino, Hagen F\u00fcrstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Ger- hard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 782-792, Edinburgh, Scotland, UK. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "A semantic approach for knowledge capture of microrna-target gene interactions",
                "authors": [
                    {
                        "first": "Jingshan",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Fernando",
                        "middle": [],
                        "last": "Gutierrez",
                        "suffix": ""
                    },
                    {
                        "first": "Dejing",
                        "middle": [],
                        "last": "Dou",
                        "suffix": ""
                    },
                    {
                        "first": "Judith",
                        "middle": [
                            "A"
                        ],
                        "last": "Blake",
                        "suffix": ""
                    },
                    {
                        "first": "Karen",
                        "middle": [],
                        "last": "Eilbeck",
                        "suffix": ""
                    },
                    {
                        "first": "Darren",
                        "middle": [
                            "A"
                        ],
                        "last": "Natale",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaowei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Zixing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)",
                "volume": "",
                "issue": "",
                "pages": "975--982",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jingshan Huang, Fernando Gutierrez, Dejing Dou, Ju- dith A Blake, Karen Eilbeck, Darren A Natale, Barry Smith, Yu Lin, Xiaowei Wang, Zixing Liu, et al. 2015. A semantic approach for knowledge cap- ture of microrna-target gene interactions. In 2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 975-982. IEEE.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Chemdner: The drugs and chemical names extraction challenge",
                "authors": [
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Krallinger",
                        "suffix": ""
                    },
                    {
                        "first": "Florian",
                        "middle": [],
                        "last": "Leitner",
                        "suffix": ""
                    },
                    {
                        "first": "Obdulia",
                        "middle": [],
                        "last": "Rabal",
                        "suffix": ""
                    },
                    {
                        "first": "Miguel",
                        "middle": [],
                        "last": "Vazquez",
                        "suffix": ""
                    },
                    {
                        "first": "Julen",
                        "middle": [],
                        "last": "Oyarzabal",
                        "suffix": ""
                    },
                    {
                        "first": "Alfonso",
                        "middle": [],
                        "last": "Valencia",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Journal of cheminformatics",
                "volume": "7",
                "issue": "1",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Martin Krallinger, Florian Leitner, Obdulia Rabal, Miguel Vazquez, Julen Oyarzabal, and Alfonso Valencia. 2015. Chemdner: The drugs and chemical names extraction challenge. Journal of cheminformatics, 7(1):S1.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Neural architectures for named entity recognition",
                "authors": [
                    {
                        "first": "Guillaume",
                        "middle": [],
                        "last": "Lample",
                        "suffix": ""
                    },
                    {
                        "first": "Miguel",
                        "middle": [],
                        "last": "Ballesteros",
                        "suffix": ""
                    },
                    {
                        "first": "Sandeep",
                        "middle": [],
                        "last": "Subramanian",
                        "suffix": ""
                    },
                    {
                        "first": "Kazuya",
                        "middle": [],
                        "last": "Kawakami",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "",
                "issue": "",
                "pages": "260--270",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N16-1030"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Guillaume Lample, Miguel Ballesteros, Sandeep Sub- ramanian, Kazuya Kawakami, and Chris Dyer. 2016. Neural architectures for named entity recog- nition. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 260-270, San Diego, Califor- nia. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Improving entity linking by modeling latent relations between mentions",
                "authors": [
                    {
                        "first": "Phong",
                        "middle": [],
                        "last": "Le",
                        "suffix": ""
                    },
                    {
                        "first": "Ivan",
                        "middle": [],
                        "last": "Titov",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1595--1604",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P18-1148"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Phong Le and Ivan Titov. 2018. Improving entity link- ing by modeling latent relations between mentions. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1595-1604, Melbourne, Australia. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "BOND: bert-assisted open-domain named entity recognition with distant supervision",
                "authors": [
                    {
                        "first": "Chen",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Yue",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Haoming",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Siawpeng",
                        "middle": [],
                        "last": "Er",
                        "suffix": ""
                    },
                    {
                        "first": "Ruijia",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Tuo",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Chao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "volume": "",
                "issue": "",
                "pages": "1054--1064",
                "other_ids": {
                    "DOI": [
                        "10.1145/3394486.3403149"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Chen Liang, Yue Yu, Haoming Jiang, Siawpeng Er, Ruijia Wang, Tuo Zhao, and Chao Zhang. 2020. BOND: bert-assisted open-domain named entity recognition with distant supervision. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 1054-1064. ACM.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Fine-grained entity recognition",
                "authors": [
                    {
                        "first": "Xiao",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [
                            "S"
                        ],
                        "last": "Weld",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiao Ling and Daniel S. Weld. 2012. Fine-grained en- tity recognition. In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, July 22-26, 2012, Toronto, Ontario, Canada. AAAI Press.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Roberta: A robustly optimized bert pretraining approach",
                "authors": [
                    {
                        "first": "Yinhan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Naman",
                        "middle": [],
                        "last": "Goyal",
                        "suffix": ""
                    },
                    {
                        "first": "Jingfei",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Mandar",
                        "middle": [],
                        "last": "Joshi",
                        "suffix": ""
                    },
                    {
                        "first": "Danqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Omer",
                        "middle": [],
                        "last": "Levy",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Lewis",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    },
                    {
                        "first": "Veselin",
                        "middle": [],
                        "last": "Stoyanov",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining ap- proach. ArXiv preprint, abs/1907.11692.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF",
                "authors": [
                    {
                        "first": "Xuezhe",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1064--1074",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P16-1101"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs- CRF. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1064-1074, Berlin, Germany. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Distantly supervised named entity recognition using positive-unlabeled learning",
                "authors": [
                    {
                        "first": "Minlong",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyu",
                        "middle": [],
                        "last": "Xing",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jinlan",
                        "middle": [],
                        "last": "Fu",
                        "suffix": ""
                    },
                    {
                        "first": "Xuanjing",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2409--2419",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P19-1231"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Minlong Peng, Xiaoyu Xing, Qi Zhang, Jinlan Fu, and Xuanjing Huang. 2019. Distantly supervised named entity recognition using positive-unlabeled learning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2409-2419, Florence, Italy. Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Deeptype: Multilingual entity linking by neural type system evolution",
                "authors": [
                    {
                        "first": "Jonathan",
                        "middle": [],
                        "last": "Raiman",
                        "suffix": ""
                    },
                    {
                        "first": "Olivier",
                        "middle": [],
                        "last": "Raiman",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)",
                "volume": "",
                "issue": "",
                "pages": "5406--5413",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jonathan Raiman and Olivier Raiman. 2018. Deeptype: Multilingual entity linking by neural type system evolution. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 5406-5413. AAAI Press.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Clustype: Effective entity recognition and typing by relation phrase-based clustering",
                "authors": [
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmed",
                        "middle": [],
                        "last": "El-Kishky",
                        "suffix": ""
                    },
                    {
                        "first": "Chi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Fangbo",
                        "middle": [],
                        "last": "Tao",
                        "suffix": ""
                    },
                    {
                        "first": "Clare",
                        "middle": [
                            "R"
                        ],
                        "last": "Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "volume": "",
                "issue": "",
                "pages": "995--1004",
                "other_ids": {
                    "DOI": [
                        "10.1145/2783258.2783362"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Xiang Ren, Ahmed El-Kishky, Chi Wang, Fangbo Tao, Clare R. Voss, and Jiawei Han. 2015. Clustype: Effective entity recognition and typing by relation phrase-based clustering. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Sydney, NSW, Australia, August 10-13, 2015, pages 995- 1004. ACM.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Automated phrase mining from massive text corpora",
                "authors": [
                    {
                        "first": "Jingbo",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Jialu",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Meng",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Clare",
                        "middle": [
                            "R"
                        ],
                        "last": "Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "30",
                "issue": "10",
                "pages": "1825--1837",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han. 2018a. Automated phrase mining from massive text corpora. IEEE Transactions on Knowledge and Data Engineering, 30(10):1825-1837.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Learning named entity tagger using domain-specific dictionary",
                "authors": [
                    {
                        "first": "Jingbo",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Liyuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaotao",
                        "middle": [],
                        "last": "Gu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Teng",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2054--2064",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1230"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jingbo Shang, Liyuan Liu, Xiaotao Gu, Xiang Ren, Teng Ren, and Jiawei Han. 2018b. Learning named entity tagger using domain-specific dictio- nary. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2054-2064, Brussels, Belgium. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Chemdataextractor: a toolkit for automated extraction of chemical information from the scientific literature",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Matthew",
                        "suffix": ""
                    },
                    {
                        "first": "Jacqueline",
                        "middle": [
                            "M"
                        ],
                        "last": "Swain",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Cole",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Journal of chemical information and modeling",
                "volume": "56",
                "issue": "10",
                "pages": "1894--1904",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matthew C Swain and Jacqueline M Cole. 2016. Chem- dataextractor: a toolkit for automated extraction of chemical information from the scientific litera- ture. Journal of chemical information and modeling, 56(10):1894-1904.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "The string database in 2017: quality-controlled protein-protein association networks, made broadly accessible",
                "authors": [
                    {
                        "first": "Damian",
                        "middle": [],
                        "last": "Szklarczyk",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [
                            "H"
                        ],
                        "last": "Morris",
                        "suffix": ""
                    },
                    {
                        "first": "Helen",
                        "middle": [],
                        "last": "Cook",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Kuhn",
                        "suffix": ""
                    },
                    {
                        "first": "Stefan",
                        "middle": [],
                        "last": "Wyder",
                        "suffix": ""
                    },
                    {
                        "first": "Milan",
                        "middle": [],
                        "last": "Simonovic",
                        "suffix": ""
                    },
                    {
                        "first": "Alberto",
                        "middle": [],
                        "last": "Santos",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Nadezhda",
                        "suffix": ""
                    },
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Doncheva",
                        "suffix": ""
                    },
                    {
                        "first": "Peer",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bork",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Nucleic acids research",
                "volume": "45",
                "issue": "1",
                "pages": "362--D368",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Damian Szklarczyk, John H Morris, Helen Cook, Michael Kuhn, Stefan Wyder, Milan Simonovic, Alberto Santos, Nadezhda T Doncheva, Alexander Roth, and Peer Bork. 2017. The string database in 2017: quality-controlled protein-protein association networks, made broadly accessible. Nucleic acids research, 45(D1):D362-D368.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Stitch 5: augmenting protein-chemical interaction networks with tissue and affinity data",
                "authors": [
                    {
                        "first": "Damian",
                        "middle": [],
                        "last": "Szklarczyk",
                        "suffix": ""
                    },
                    {
                        "first": "Alberto",
                        "middle": [],
                        "last": "Santos",
                        "suffix": ""
                    },
                    {
                        "first": "Lars",
                        "middle": [
                            "Juhl"
                        ],
                        "last": "Christian Von Mering",
                        "suffix": ""
                    },
                    {
                        "first": "Peer",
                        "middle": [],
                        "last": "Jensen",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Bork",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Kuhn",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Nucleic acids research",
                "volume": "44",
                "issue": "1",
                "pages": "380--D384",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Damian Szklarczyk, Alberto Santos, Christian von Mering, Lars Juhl Jensen, Peer Bork, and Michael Kuhn. 2015. Stitch 5: augmenting protein-chemical interaction networks with tissue and affinity data. Nucleic acids research, 44(D1):D380-D384.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Bidirectional inference with the easiest-first strategy for tagging sequence data",
                "authors": [
                    {
                        "first": "Yoshimasa",
                        "middle": [],
                        "last": "Tsuruoka",
                        "suffix": ""
                    },
                    {
                        "first": "Jun'ichi",
                        "middle": [],
                        "last": "Tsujii",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "467--474",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yoshimasa Tsuruoka and Jun'ichi Tsujii. 2005. Bidi- rectional inference with the easiest-first strategy for tagging sequence data. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 467-474, Vancouver, British Columbia, Canada. Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Pattern-enhanced named entity recognition with distant supervision",
                "authors": [
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yingjun",
                        "middle": [],
                        "last": "Guan",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "2020 IEEE International Conference on Big Data (Big Data)",
                "volume": "",
                "issue": "",
                "pages": "818--827",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuan Wang, Yingjun Guan, Yu Zhang, Qi Li, and Ji- awei Han. 2020a. Pattern-enhanced named entity recognition with distant supervision. In 2020 IEEE International Conference on Big Data (Big Data), pages 818-827. IEEE.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Fine-grained named entity recognition with distant supervision in covid-19 literature",
                "authors": [
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangchen",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Bangzheng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Kang",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)",
                "volume": "",
                "issue": "",
                "pages": "491--494",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuan Wang, Xiangchen Song, Bangzheng Li, Kang Zhou, Qi Li, and Jiawei Han. 2020b. Fine-grained named entity recognition with distant supervision in covid-19 literature. In 2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 491-494. IEEE.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Distantly supervised biomedical named entity recognition with dictionary expansion",
                "authors": [
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Jingbo",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)",
                "volume": "",
                "issue": "",
                "pages": "496--503",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuan Wang, Yu Zhang, Qi Li, Xiang Ren, Jingbo Shang, and Jiawei Han. 2019a. Distantly supervised biomedical named entity recognition with dictionary expansion. In 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 496-503. IEEE.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "2019b. Cross-type biomedical named entity recognition with deep multi-task learning",
                "authors": [
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Yuhao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Marinka",
                        "middle": [],
                        "last": "Zitnik",
                        "suffix": ""
                    },
                    {
                        "first": "Jingbo",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Curtis",
                        "middle": [],
                        "last": "Langlotz",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Bioinformatics",
                "volume": "35",
                "issue": "10",
                "pages": "1745--1752",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuan Wang, Yu Zhang, Xiang Ren, Yuhao Zhang, Marinka Zitnik, Jingbo Shang, Curtis Langlotz, and Jiawei Han. 2019b. Cross-type biomedical named entity recognition with deep multi-task learning. Bioinformatics, 35(10):1745-1752.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Multitask learning for chemical named entity recognition with chemical compound paraphrasing",
                "authors": [
                    {
                        "first": "Taiki",
                        "middle": [],
                        "last": "Watanabe",
                        "suffix": ""
                    },
                    {
                        "first": "Akihiro",
                        "middle": [],
                        "last": "Tamura",
                        "suffix": ""
                    },
                    {
                        "first": "Takashi",
                        "middle": [],
                        "last": "Ninomiya",
                        "suffix": ""
                    },
                    {
                        "first": "Takuya",
                        "middle": [],
                        "last": "Makino",
                        "suffix": ""
                    },
                    {
                        "first": "Tomoya",
                        "middle": [],
                        "last": "Iwakura",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "volume": "",
                "issue": "",
                "pages": "6244--6249",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D19-1648"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Taiki Watanabe, Akihiro Tamura, Takashi Ninomiya, Takuya Makino, and Tomoya Iwakura. 2019. Multi- task learning for chemical named entity recogni- tion with chemical compound paraphrasing. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6244-6249, Hong Kong, China. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "mircancer: a microrna-cancer association database constructed by text mining on literature",
                "authors": [
                    {
                        "first": "Boya",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Qin",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "Hongjin",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Di",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Bioinformatics",
                "volume": "29",
                "issue": "5",
                "pages": "638--644",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Boya Xie, Qin Ding, Hongjin Han, and Di Wu. 2013. mircancer: a microrna-cancer association database constructed by text mining on literature. Bioinformatics, 29(5):638-644.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "HYENA: Hierarchical type classification for entity names",
                "authors": [
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Amir Yosef",
                        "suffix": ""
                    },
                    {
                        "first": "Sandro",
                        "middle": [],
                        "last": "Bauer",
                        "suffix": ""
                    },
                    {
                        "first": "Johannes",
                        "middle": [],
                        "last": "Hoffart",
                        "suffix": ""
                    },
                    {
                        "first": "Marc",
                        "middle": [],
                        "last": "Spaniol",
                        "suffix": ""
                    },
                    {
                        "first": "Gerhard",
                        "middle": [],
                        "last": "Weikum",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of COLING 2012: Posters",
                "volume": "",
                "issue": "",
                "pages": "1361--1370",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohamed Amir Yosef, Sandro Bauer, Johannes Hof- fart, Marc Spaniol, and Gerhard Weikum. 2012. HYENA: Hierarchical type classification for entity names. In Proceedings of COLING 2012: Posters, pages 1361-1370, Mumbai, India. The COLING 2012 Organizing Committee.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Two major challenges of distant supervision for fine-grained chemistry NER: (a) incomplete annotation, and (b) noisy annotation. The KB-matching labels are marked in red and the true labels are marked in blue.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 3: Illustration of the chemistry type ontology construction and dictionary collection.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 4: The complete fine-grained chemistry entity type hierarchy for CHEMNER.",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>Entity Span Detection</td></tr><tr><td>Flexible KB-Matching</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td/><td/><td/><td/><td/><td>Ontology-guided Multi-type Disambiguation</td></tr><tr><td/><td/><td/><td/><td/><td>S3: Although it was necessary to employ a stoichiometric quantity of palladium ,</td></tr><tr><td/><td/><td/><td/><td/><td>it is noteworthy that the cross-coupling proceeded in the presence of a wide</td></tr><tr><td/><td/><td/><td/><td/><td>array of functional groups.</td></tr><tr><td/><td/><td/><td/><td/><td>CHEMICAL</td></tr><tr><td/><td/><td/><td/><td/><td>REACTIONS</td></tr><tr><td/><td/><td/><td/><td/><td>\u2026</td></tr><tr><td colspan=\"3\">ORGANIC COMPOUNDS, ORGANIC POLYMERS</td><td/><td/><td>TRANSITION</td></tr><tr><td/><td/><td/><td/><td/><td>CATALYSTS</td><td>METALS</td></tr><tr><td>TF-IDF Scores</td><td>ORGANIC COMPOUNDS</td><td>ORGANIC POLYMERS</td><td colspan=\"2\">Biomolecules \u2026</td><td>Sequence Labeling Models</td></tr><tr><td>methyl</td><td>0.0177</td><td>0.0139</td><td>0.0010</td><td>\u2026</td></tr><tr><td>thd</td><td>0.0256</td><td>0.0115</td><td>0.0417</td><td/></tr></table>",
                "type_str": "table",
                "text": "carried out ...",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>Input Corpus</td><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td>CATALYSTS, TRANSITION METALS</td></tr><tr><td colspan=\"3\">FUNCTIONAL GROUPS</td><td colspan=\"2\">COUPLING REACTIONS</td><td>Candidate Types</td></tr><tr><td/><td/><td colspan=\"2\">CHEMISTRY</td><td colspan=\"2\">Context Type</td></tr><tr><td/><td>\u2026</td><td>\u2026</td><td>CHEMICAL ELEMENTS</td><td/><td>Candidate Types CATALYSTS</td><td>Freq. 18,707</td></tr><tr><td>CATALYSIS</td><td>\u2026</td><td colspan=\"2\">ORGANIC REACTIONS</td><td/><td>TRANSITION_METALS</td><td>9,618</td></tr><tr><td>ORGANIC REACTIONS</td><td/><td colspan=\"2\">COUPLING</td><td/></tr><tr><td/><td>\u2026 \u2026</td><td colspan=\"2\">REACTIONS</td><td/></tr><tr><td/><td colspan=\"4\">ORGANOMETALLIC CHEMISTRY</td><td>??? [NOT IN KB] =&gt; OXOACIDS</td></tr><tr><td>COUPLING REACTIONS</td><td>OXOACIDS</td><td colspan=\"4\">\"either ... or \u2026\" pattern learned by Sequence Labeling Model</td></tr><tr><td colspan=\"6\">Figure 2: The overall framework of CHEMNER. It includes a distant label generation (entity span detection,</td></tr><tr><td colspan=\"6\">flexible KB-matching, and ontology-guided multi-type disambiguation) and a sequence labeling model training.</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td>Model</td><td>Prec</td><td>Rec</td><td>F1</td></tr><tr><td>KB-Matching</td><td>32.26</td><td>4.95</td><td>8.58</td></tr><tr><td>KB-Matching (freq)</td><td colspan=\"3\">20.51 11.88 15.05</td></tr><tr><td colspan=\"4\">BiLSTM-CRF (2016) 21.88 10.40 14.09</td></tr><tr><td>AutoNER (2018b)</td><td>20.51</td><td>3.96</td><td>6.64</td></tr><tr><td>RoBERTa (2019)</td><td colspan=\"3\">23.55 17.74 20.24</td></tr><tr><td>ChemBERTa (2020)</td><td colspan=\"3\">17.54 12.28 14.45</td></tr><tr><td>BOND (2020)</td><td colspan=\"3\">18.84 12.87 15.29</td></tr><tr><td>CHEMNER</td><td colspan=\"3\">69.47 34.34 45.96</td></tr><tr><td>Model</td><td>Prec</td><td>Rec</td><td>F1</td></tr><tr><td>CHEMNER</td><td colspan=\"3\">69.47 34.34 45.96</td></tr><tr><td>CHEMNERF</td><td colspan=\"3\">74.76 29.06 41.85</td></tr><tr><td>CHEMNERFM</td><td colspan=\"3\">71.90 32.83 45.08</td></tr><tr><td colspan=\"4\">CHEMNERBiLSTM-CRF 48.65 17.82 26.09</td></tr><tr><td>CHEMNERRoBERTa</td><td colspan=\"3\">69.47 34.34 45.96</td></tr><tr><td>CHEMNERChemBERTa</td><td colspan=\"3\">58.78 29.06 38.89</td></tr><tr><td>CHEMNERBOND</td><td colspan=\"3\">52.21 26.79 35.41</td></tr></table>",
                "type_str": "table",
                "text": "Overall results (%) on the test set.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Results (%) of CHEMNER ablation models.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td>CHEMNER F</td><td>Prec</td><td>Rec</td><td>F1</td></tr><tr><td>\u03b8 = 0.005</td><td colspan=\"3\">66.67 24.15 35.46</td></tr><tr><td>\u03b8 = 0.02</td><td colspan=\"3\">74.76 29.06 41.85</td></tr><tr><td>\u03b8 = 0.05</td><td colspan=\"3\">71.19 28.81 41.43</td></tr><tr><td>CHEMNER FM</td><td/><td>Prec</td><td>Rec</td><td>F1</td></tr><tr><td>Sentence Only</td><td/><td colspan=\"3\">73.64 30.57 43.20</td></tr><tr><td colspan=\"2\">Sentence+Document</td><td colspan=\"3\">74.04 29.06 41.73</td></tr><tr><td>Sentence+Corpus</td><td/><td colspan=\"3\">71.90 32.83 45.08</td></tr><tr><td colspan=\"5\">Sentence+Document+Corpus 70.83 32.07 44.15</td></tr></table>",
                "type_str": "table",
                "text": "Results (%) with different minimum TF-IDF threshold \u03b8 for the flexible KB-Matching.",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Results (%) with different enlarged scopes for the ontology-guided multi-type resolution.",
                "html": null,
                "num": null
            },
            "TABREF7": {
                "content": "<table><tr><td>Sentence # 2</td></tr></table>",
                "type_str": "table",
                "text": "Sentence # 1 ... two aryl chlorides ORGANOHALIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... KB-Matching ... two aryl AROMATIC COMPOUNDS, SUBSTITUENTS, FUNCTIONAL GROUPS chlorides CHLORIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... RoBERTa ... two aryl FUNCTIONAL GROUPS chlorides CHLORIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... CHEMNER F ... two aryl chlorides CHLORIDES, ORGANOHALIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... CHEMNER FM ... two aryl chlorides CHLORIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... CHEMNER ... two aryl chlorides ORGANOHALIDES can be coupled to one another without the isolation of the intermediate boronic acid OXOACIDS ... The total synthesis of narciclasine ALKALOIDS is accomplished by the late-stage, amide-directed C-H hydroxylation ORGANIC REDOX REACTIONS ... KB-Matching The total synthesis of narciclasine FREE RADICALS, ALKALOIDS, BIOMOLECULES is accomplished by the latestage, amide-directed C-H hydroxylation ORGANIC REDOX REACTIONS ... RoBERTa The total synthesis of narciclasine BIOMOLECULES is accomplished by the late-stage, amide-directed C-H hydroxylation ORGANIC REDOX REACTIONS ... CHEMNER F The total synthesis of narciclasine ALKALOIDS, BIOMOLECULES is accomplished by the late-stage, amidedirected C-H hydroxylation ORGANIC REDOX REACTIONS ... CHEMNER FM The total synthesis of narciclasine ALKALOIDS is accomplished by the late-stage, amide-directed C-H hydroxylation ORGANIC REDOX REACTIONS ... CHEMNER The total synthesis of narciclasine ALKALOIDS is accomplished by the late-stage, amide-directed C-H hydroxylation ORGANIC REDOX REACTIONS ...",
                "html": null,
                "num": null
            },
            "TABREF8": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Examples showing how CHEMNER improves the fine-grained chemistry NER performance. The ground truth labels are in blue and the model predictions are in red. The correct labels are in italics.",
                "html": null,
                "num": null
            },
            "TABREF9": {
                "content": "<table><tr><td>Model</td><td colspan=\"2\">Ave. runtime # parameters</td></tr><tr><td>BiLSTM-CRF</td><td>6h</td><td>2M</td></tr><tr><td>AutoNER</td><td>20h</td><td>8M</td></tr><tr><td>RoBERTa</td><td>4h</td><td>110M</td></tr><tr><td>ChemBERTa</td><td>3h</td><td>110M</td></tr><tr><td>BOND</td><td>8h</td><td>110M</td></tr></table>",
                "type_str": "table",
                "text": "7 https://pubchem.ncbi.nlm.nih.gov/ 8 https://en.wikipedia.org/wiki/ Category:Chemistry",
                "html": null,
                "num": null
            },
            "TABREF10": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Runtime and Number of Parameters",
                "html": null,
                "num": null
            }
        }
    }
}