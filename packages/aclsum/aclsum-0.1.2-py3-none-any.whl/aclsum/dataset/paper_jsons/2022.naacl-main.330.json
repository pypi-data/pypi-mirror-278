{
    "paper_id": "2022",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:11:52.966206Z"
    },
    "title": "Testing the Ability of Language Models to Interpret Figurative Language",
    "authors": [
        {
            "first": "Emmy",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Chenxuan",
            "middle": [],
            "last": "Cui",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {}
            },
            "email": "cxcui@cs.cmu.edu"
        },
        {
            "first": "Kenneth",
            "middle": [],
            "last": "Zheng",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {}
            },
            "email": "kzheng2@cs.cmu.edu"
        },
        {
            "first": "Graham",
            "middle": [],
            "last": "Neubig",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Carnegie Mellon University",
                "location": {}
            },
            "email": "gneubig@cs.cmu.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Figurative and metaphorical language are commonplace in discourse, and figurative expressions play an important role in communication and cognition. However, figurative language has been a relatively under-studied area in NLP, and it remains an open question to what extent modern language models can interpret nonliteral phrases. To address this question, we introduce Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. We evaluate the performance of several state-of-the-art language models on this task, and find that although language models achieve performance significantly over chance, they still fall short of human performance, particularly in zero-or few-shot settings. This suggests that further work is needed to improve the nonliteral reasoning capabilities of language models. 1",
    "pdf_parse": {
        "paper_id": "2022",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Figurative and metaphorical language are commonplace in discourse, and figurative expressions play an important role in communication and cognition. However, figurative language has been a relatively under-studied area in NLP, and it remains an open question to what extent modern language models can interpret nonliteral phrases. To address this question, we introduce Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. We evaluate the performance of several state-of-the-art language models on this task, and find that although language models achieve performance significantly over chance, they still fall short of human performance, particularly in zero-or few-shot settings. This suggests that further work is needed to improve the nonliteral reasoning capabilities of language models. 1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "All our words are but crumbs that fall down from the feast of the mind (Gibran, 1926) . When humans read such a metaphorical phrase, how do they interpret it? Conceptual metaphors structure our everyday language and are used to map everyday physical experiences and emotions onto abstract concepts (Lakoff and Johnson, 1981) . They allow us to communicate complex ideas, to emphasize emotions, and to make humorous statements (Fussell and Moss, 2008) . However, despite relating words in a way that differs from their accepted definition, these phrases are readily interpreted by human listeners, and are common in discourse (Shutova, 2011) , occurring on average every three sentences (Mio and Katz, 1996; Fussell and Moss, 2008) The ability to interpret figurative language has been viewed as a bottleneck in natural language un-derstanding, but it has not been studied as widely as literal language (Shutova, 2011; Tong et al., 2021) . Figurative language often relies on shared commonsense or cultural knowledge, and in some cases may be difficult to solve using language statistics. This presents a challenge to language models (LMs), as strong LMs trained only on text may not be able to make sense of the physical world, nor the social or cultural knowledge that language is grounded in (Bender and Koller, 2020; Bisk et al., 2020) .",
                "cite_spans": [
                    {
                        "start": 71,
                        "end": 85,
                        "text": "(Gibran, 1926)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 298,
                        "end": 324,
                        "text": "(Lakoff and Johnson, 1981)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 426,
                        "end": 450,
                        "text": "(Fussell and Moss, 2008)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 625,
                        "end": 640,
                        "text": "(Shutova, 2011)",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 686,
                        "end": 706,
                        "text": "(Mio and Katz, 1996;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 707,
                        "end": 730,
                        "text": "Fussell and Moss, 2008)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 902,
                        "end": 917,
                        "text": "(Shutova, 2011;",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 918,
                        "end": 936,
                        "text": "Tong et al., 2021)",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 1294,
                        "end": 1319,
                        "text": "(Bender and Koller, 2020;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 1320,
                        "end": 1338,
                        "text": "Bisk et al., 2020)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Most previous work on figurative language focuses on metaphor detection, where a model is trained to identify the existence of metaphors in text (Tsvetkov et al., 2014; Stowe and Palmer, 2018; Leong et al., 2020) , with datasets consisting mostly of conventionalized metaphors and idioms in wide use. However, identifying these common metaphors that already appear often in language may be an easy task for LMs, and not fully test their ability to interpret figurative language. The little work that exists on metaphor interpretation frames it as a task linking metaphorical phrases to literal rewordings, either through paraphrase detection (Bizzoni and Lappin, 2018) or paraphrase generation (Shutova, 2010; Su et al., 2017; Mao et al., 2018) (details in \u00a7 7) Another line of work probes for metaphorical understanding in LMs, but this is similar to the metaphor detection task, in that the LM is not actually asked to choose an interpretation for the metaphor (Pedinotti et al., 2021; Aghazadeh et al., 2022) . While interesting, this work does not take into account the fact that metaphors are rich with different implications that may vary depending on the context.",
                "cite_spans": [
                    {
                        "start": 145,
                        "end": 168,
                        "text": "(Tsvetkov et al., 2014;",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 169,
                        "end": 192,
                        "text": "Stowe and Palmer, 2018;",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 193,
                        "end": 212,
                        "text": "Leong et al., 2020)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 642,
                        "end": 668,
                        "text": "(Bizzoni and Lappin, 2018)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 694,
                        "end": 709,
                        "text": "(Shutova, 2010;",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 710,
                        "end": 726,
                        "text": "Su et al., 2017;",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 727,
                        "end": 744,
                        "text": "Mao et al., 2018)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 963,
                        "end": 987,
                        "text": "(Pedinotti et al., 2021;",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 988,
                        "end": 1011,
                        "text": "Aghazadeh et al., 2022)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this work, we ask whether or not LMs can correctly make inferences regarding creative, relatively novel metaphors generated by humans. This task is harder for two reasons: (1) inference is harder than identification or paraphrasing, as it requires understanding the underlying semantics, and (2) the metaphors in our dataset are novel cre-ations, and many may not appear even once in the LMs' training data. We propose a minimal task inspired by the Winograd schema (Levesque et al., 2012) , where LMs are tasked with choosing the entailed phrase from two opposite metaphorical phrases. An example of a paired sentence is \"Her commitment is as sturdy as (plywood/oak)\". The correct answer would be either \"She was (committed/uncommitted)\". This can also be seen as an entailment task, where input x is the premise, and the output y is the hypothesis. 2We crowdsource a benchmark Fig-QA, consisting of 10,256 such metaphors and implications ( \u00a7 2), which can be used to evaluate the nonliteral reasoning abilities of LMs or for more broad studies of figurative language in general (we provide preliminary analyses in \u00a7 3). Through extensive experiments over strong pre-trained LMs ( \u00a7 4), we find that although they can be fine-tuned to do reasonably well, their few-shot performance falls significantly short of human performance ( \u00a7 5). An in-depth analysis ( \u00a7 6) uncovers several insights:",
                "cite_spans": [
                    {
                        "start": 469,
                        "end": 492,
                        "text": "(Levesque et al., 2012)",
                        "ref_id": "BIBREF26"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(1) LMs do not make use of the metaphorical context well, instead relying on the predicted probability of interpretations alone, (2) the task of associating a metaphor with an interpretation is more difficult than the reverse, (3) even strong models such as GPT-3 make inexplicable errors that are not well-aligned with human ones, indicating that further work is needed to properly model nonliteral language.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2 Dataset Creation and Validation",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We crowdsourced data from workers on Amazon Mechanical Turk ( details in Appendix A). Workers were asked to generate paired metaphors with different meanings, as well as literal implications of the two metaphors in context. We instructed workers to try to generate rare or creative metaphors, namely \"metaphors that would not appear often in text on the internet, books, social media, or news sites, but that can still be easily understood by people.\" Workers were given examples of valid pairs that fit the format, and examples of invalid ones to discourage errors. Some examples of generated pairs are displayed in Table 1 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 623,
                        "end": 624,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Crowdsourcing Task",
                "sec_num": "2.1"
            },
            {
                "text": "In order to help workers, we employ the randomness as genesis and narrow limits of change principles of Cognitive Load Theory (Sweller, 2006) . To add soft constraints, we generate 3 different random words to be shown to each batch of workers. However, workers were not required to use these words, as we wanted to encourage maximal diversity. In order to ensure that the random words were metaphorically rich, we selected them based on metaphorical frames in Lakoff and Johnson (1981) .",
                "cite_spans": [
                    {
                        "start": 126,
                        "end": 141,
                        "text": "(Sweller, 2006)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 460,
                        "end": 485,
                        "text": "Lakoff and Johnson (1981)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Crowdsourcing Task",
                "sec_num": "2.1"
            },
            {
                "text": "The dataset was manually validated by three authors of this paper. Each author covered roughly one-third, evenly split between training, validation, and test. Examples were excluded if they (a) did not make sense given the figurative expression, (b) had grammar or spelling errors that rendered them unintelligible, or (c) did not follow the format of the task. Examples of excluded samples are included in Appendix B. We collected 13,324 sentences and interpretations from the crowdsourcing task, and 10,256 sentences remained after filtering.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data Validation",
                "sec_num": "2.2"
            },
            {
                "text": "The release version of our dataset contains the named data splits in Table 2 . The medium train, dev, and test splits were generated from partitioning the first stage of data collected. The large train split additionally contains all the new examples from the second collection stage, and the small train split is a small random sample.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 75,
                        "end": 76,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Final Dataset",
                "sec_num": "2.3"
            },
            {
                "text": "In this sample, we perform an analysis of the collected data to demonstrate its trends and categorize examples for further error analysis. Specifically, we examine (a) subjects, objects, and relations, and (b) types of common-sense knowledge needed to interpret the metaphor.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Typologies",
                "sec_num": "3"
            },
            {
                "text": "We note that most metaphors and similes can be characterized by three components, (S, R, O), where S is a subject, R is a relation, and O is an object. For instance, \"Her commitment is as sturdy as plywood\" can be written (Her commitment, sturdy, plywood) . Interpretation involves inferring an attribute of the subject by extracting a relational attribute from the object (Fauconnier and Turner, 2003) . In a simile, R is explicit, whereas it is usually implicit in a metaphor. The most common",
                "cite_spans": [
                    {
                        "start": 222,
                        "end": 255,
                        "text": "(Her commitment, sturdy, plywood)",
                        "ref_id": null
                    },
                    {
                        "start": 373,
                        "end": 402,
                        "text": "(Fauconnier and Turner, 2003)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Structure",
                "sec_num": "3.1"
            },
            {
                "text": "The pilot flew like a ballet dancer",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "The pilot flew in a (restrained way | creative way) The pilot flew like a modern dancer",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "The pilot flew in a (restrained way | creative way)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "The meteor was as bright as New York City The meteor was (very bright | not bright at all) The meteor was as bright as coal",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "The meteor was (very bright | not bright at all)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "The atom is like a solar system Electrons (orbit the nucleus | are in probability densities) The atom is like a cloud Electrons (orbit the nucleus | are in probability densities)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "He hustles like rent was due three days ago He (hustles hardcore. | doesn't hustle at all.) He hustles like he's a billionaire's son.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "He (hustles hardcore | doesn't hustle at all)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "Life is as easy as kindergarten for a high school senior Life is (basic | beyond comprehension) Life is as easy as kindergarten for a newborn Life is (basic | beyond comprehension) subjects, relations, and objects in the medium train dataset are shown in Figure 1 . These were obtained by first segmenting the phrases with syntactic patterns constructed from observation, followed by lemmatization and removal of punctuation and determiners \"the\", \"an\", \"a\" and \"that\". There are 441 unique subjects, 646 unique relations, and 1,198 unique objects in the medium training set.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 262,
                        "end": 263,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Possible answers",
                "sec_num": null
            },
            {
                "text": "Next, we examined the test set to determine the types of commonsense knowledge needed to interpret metaphors. Through thematic analysis, we devised 4 categories based on commonsense knowledge, which are not mutually exclusive: common-sense object knowledge, visual metaphors, common-sense social understanding, and cultural knowledge. The same 3 paper authors annotated the test set for these categories, with annotators responsible for separate categories.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "Common-sense object knowledge consisted of metaphors that made reference to properties of common objects and animals, such as volume, height or mass of objects, or properties of materials. 68.35% of the test-set was found to require common-sense object knowledge.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "Visual metaphors were a subset of commonsense object metaphors, primarily relying on the visual modality, including attributes such as brightness or colour. Some visual metaphors also sketched a vivid visual scene. These examples comprised 14.73% of the test set. As such, we can directly compute the probability of a sentence by multiplying the conditional probability of each token at every time step.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "P (w 1 ...w N ) = p(w 1 ) N i=2 p(w i |w 1 ...w i-1 )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "The ability to directly extract probabilities enables the zero-shot reasoning of these LMs. For a pair of metaphorical expressions x 1 and x 2 with two corresponding interpretations y 1 and y 2 , we feed in the concatenation of the metaphor and the interpretation to the pretrained model without finetuning. We define \"forward\" and \"backward\" probabilities assigned to interpretations and figurative language expressions, respectively. For the forward probability, for figurative phrase x i and correct answer y i , we take",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "P (y i |x i ) = P (x i , y i ) P (x i , y i ) + P (x i , y j )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "since there are only two answer options. From this, we can calculate accuracy when we taking the indicator of P (y i |x i ) > 0.5. Similarly for the backward probability (predicting phrase based on answer), we take",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "P (x i |y i ) = P (x i , y i ) P (x i , y i ) + P (x j , y i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "with analogous backward accuracy. 3We examine three state-of-the-art large transformer-based LMs of this category: GPT-2 (with 117M parameters, trained on 40GB of text), GPT-neo (with 1.3B parameters, trained on 800GB of text) and GPT-3 (4 variants between 350M and 175B parameters, trained on 45TB on text) (Radford et al., 2019; Black et al., 2021; Brown et al., 2020) . We also examine the performance of these models after finetuning on the training data. GPT-2 and GPT-neo were trained with a batch size of 8, with early stopping on the medium dataset with a patience of 1 epoch, and a minimal hyperparameter search was done with learning rates 1e-5 to 5e-5. GPT-3 was trained with the default parameters of the GPT-3 finetuning API.",
                "cite_spans": [
                    {
                        "start": 308,
                        "end": 330,
                        "text": "(Radford et al., 2019;",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 331,
                        "end": 350,
                        "text": "Black et al., 2021;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 351,
                        "end": 370,
                        "text": "Brown et al., 2020)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Common-sense Knowledge Types",
                "sec_num": "3.2"
            },
            {
                "text": "We also evaluate the performance of masked LMs on this task. Unlike auto-regressive LMs, masked LMs cannot directly output the probability of a sentence, so it is not possible to directly test the zero-shot performance of these models. Instead, we test the transfer performance by first finetuning them in two ways: on WinoGrande, which is also a binary choice task based on commonsense reasoning, and on several NLI datasets, including SNLI, MNLI, FEVER-NLI and ANLI (Nie et al., 2020; Sakaguchi et al., 2020) . The input to the model trained on WINOGRANDE is formatted as",
                "cite_spans": [
                    {
                        "start": 468,
                        "end": 486,
                        "text": "(Nie et al., 2020;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 487,
                        "end": 510,
                        "text": "Sakaguchi et al., 2020)",
                        "ref_id": "BIBREF38"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Masked Language Models",
                "sec_num": "4.2"
            },
            {
                "text": "[CLS][metaphor][SEP] [answer1][SEP][answer2]",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Masked Language Models",
                "sec_num": "4.2"
            },
            {
                "text": ", and we use an extra linear layer on the [CLS] token embedding to perform the classification. In addition to the transfer performance, we also use contrastive finetuning by feeding in each metaphor along with both answer choices, and training the model with our dataset to classify which answer is correct. For the NLI model, we examine accuracy using all three labels the model was originally trained with (entailment, neutral, and contradiction), as well as using a forced binary choice paradigm in which the logits for the contradiction label are subtracted from the logits for the entailment label, and the higher \"entailment score\" is the ending the model predicts. We treat these two conditions as the analog of \"zero-shot\" for these models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Masked Language Models",
                "sec_num": "4.2"
            },
            {
                "text": "We examine two masked LMs that are commonly used as baselines on many NLP tasks: BERT (Devlin et al., 2019) , a transformer-based LM jointly trained on the masked LM and next sen-tence prediction objectives, and RoBERTa (Liu et al., 2019) , an improved variant of BERT which consistently outperforms BERT across most tasks. We use the large variant of both models (350M parameters). BERT and RoBERTa were finetuned on the medium dataset for 8 epochs with batch size 8, following the setting in (Sakaguchi et al., 2020) . A hyperparameter search was done with learning rates 5e-6 to 2e-5. Both BERT and RoBERTa were used for the Winogrande experiments, while only RoBERTa was used for the NLI experiment.",
                "cite_spans": [
                    {
                        "start": 86,
                        "end": 107,
                        "text": "(Devlin et al., 2019)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 220,
                        "end": 238,
                        "text": "(Liu et al., 2019)",
                        "ref_id": null
                    },
                    {
                        "start": 494,
                        "end": 518,
                        "text": "(Sakaguchi et al., 2020)",
                        "ref_id": "BIBREF38"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Masked Language Models",
                "sec_num": "4.2"
            },
            {
                "text": "Due to the inherent creativity of metaphors, there may be different interpretations of the same metaphor. For instance, in Table 1 , the example \"he hustles like he's a billionaire's son\" could also be interpreted in other ways, for instance \"he uses his father's contacts and social privileges to make money\". In a structural-mapping context, the forced choice between two answers constrains the possible meaning of the metaphor to be along one axis (Gentnder and Bowdle, 2008) . In this case, it would be whether or not he is required to work hard.",
                "cite_spans": [
                    {
                        "start": 451,
                        "end": 478,
                        "text": "(Gentnder and Bowdle, 2008)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 129,
                        "end": 130,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Forced-choice Paradigm",
                "sec_num": "4.3"
            },
            {
                "text": "Of course, many of these metaphors have other valid interpretations. In the \"billionaire's son\" example, another valid axis of interpretation could be the manner in which he works. For instance, the alternative pair could be \"he hustles like he's a (billionaire's son | single mother working three jobs)\" with answers \"he (uses his contacts and social privileges to make money | works extremely long hours with multiple ventures to make money)\". It is possible that LMs could come up with other valid interpretations that are not the ones originally intended, motivating us to also look at generation performance in section \u00a7 5.2.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Forced-choice Paradigm",
                "sec_num": "4.3"
            },
            {
                "text": "To estimate the expected human performance on this task, we ran a benchmark on the test set with 10 human volunteers who were not authors of the paper. The human annotators were not shown any training examples, so this would be equivalent to the zero-shot setting for models. Participants ranged from 20 to 29 years old, and there were 5 male and 5 female participants. 5 each were nativeand non-native English speakers respectively. Participants were mainly graduate student volunteers.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Performance",
                "sec_num": "4.4"
            },
            {
                "text": "We examples were presented with pairs shuffled and separated, in order to create a better comparison with model performance. Due to differences in vocabulary or cultural background, we instructed participants to mark examples where they weren't confident, such as those that contained words or cultural references they didn't understand.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Performance",
                "sec_num": "4.4"
            },
            {
                "text": "The first question is whether strong LMs can interpret metaphors at all when presented with two opposing meanings, in zero-shot or supervised settings. These results are presented in Table 4. The results for masked language models are higher than those for autoregressive language models, and fine-tuning significantly improves performance for all models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Zero-shot Performance For the zero-shot setting, we examine the test accuracy based on zeroshot forward probabilities for the GPT models, and the pseudo \"zero-shot\" transfer performance for BERT and RoBERTa using models pretrained on the WinoGrande task (Sakaguchi et al., 2020) . As shown, the GPT-3 models outperform the GPT-2 and GPT-neo models. Among the GPT-3 models, there is a clear correlation between model size and performance, with the largest model (GPT-3 Davinci) achieving the highest zero-shot test accuracy. BERT and RoBERTa achieve accuracies within the range of GPT-3 models. While our models mostly perform much better than chance in the zero-shot setting, there is still a large gap of 26 percentage points between our best model and human level performance.",
                "cite_spans": [
                    {
                        "start": 254,
                        "end": 278,
                        "text": "(Sakaguchi et al., 2020)",
                        "ref_id": "BIBREF38"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Fine-tuned Performance For the fine-tuned setting, all listed models are fine-tuned on the small dataset split. GPT models were trained with language modeling loss, whereas BERT and RoBERTa are trained with contrastive loss. We did not evaluate fine-tuning of GPT-3 Davinci due to budget. Overall, fine-tuning improved accuracy significantly for all models, with GPT-3 models uniformly improving by about 13 percentage points, and BERT/RoBERTa improving by about 25 points. Our best model after fine-tuning is RoBERTa, which reaches within 5% of our human performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Prompting We also experiment with prompting methods. Firstly, we use a simple suffix prompting method, where we simply append the phrase \"that is to say\" between the metaphor and the interpretation, which we hypothesized may \"explain\" to the LM that the previous statement is figurative. We also evaluate the effectiveness of the examples method, by appending k random correct metaphor/interpretation pairs before the actual pair we are testing. The results of these experiments can be seen in Figure 2 . We found that the suffix method provided a small (1-2%) improvement over the baseline, while the example method was generally ineffective.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 501,
                        "end": 502,
                        "text": "2",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Backward accuracies Note the accuracies reported in this section are for the forward direction, and the backward direction is reported in Appendix C. Backward accuracies are lower, with GPT-3 Curie for example having a 7% reduction in accuracy in the zero-shot case. This suggests that selecting a metaphorical expression to match a literal phrase is more challenging than the reverse for LMs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Paired Evaluation Because our dataset is formatted as a Winograd schema, we can take advantage of group scoring to evaluate models more stringently (Elazar et al., 2021) . We found that performance for autoregressive models plummeted under this evaluation scheme, while masked language models also suffered in accuracy. The human scores were least affected. Details are in Ap-pendix D. This is most likely related to the phenomenon found in \u00a7 6.1. ",
                "cite_spans": [
                    {
                        "start": 148,
                        "end": 169,
                        "text": "(Elazar et al., 2021)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference Results",
                "sec_num": "5.1"
            },
            {
                "text": "Next, we examine if models can generate sensible interpretations for metaphors. Given the difficulty of evaluating text generation, compounded by the difficulty of figurative language, we opted for manual evaluation of one tenth of the test dataset using generations of the strongest autoregressive model: GPT-3 Davinci (\u2248175B parameters).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Results",
                "sec_num": "5.2"
            },
            {
                "text": "The metaphor was given as input to the model, and 4 completions were generated for each metaphor, with a maximum length of 100 tokens. Completions were also truncated to the first sentence, as initial experiments showed that contradictory statements (e.g. \"he was talented. But he was not very talented\") were often generated across subsequent sentences. Suffix prompting was also used because of the lack of context, with \"That is to say, \" appended to each metaphor. Only the first sentence of the output was evaluated. The temperature parameter was determined through grid search through values [0.2, 0.4, 0.6, 0.8, 1] on a small separate set of metaphors. A human annotator inspected the generated completions and found that a temperature of 0.4 produced the most correct results.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Results",
                "sec_num": "5.2"
            },
            {
                "text": "Three paper authors labelled completions generated by GPT-3 Davinci as either correct, incorrect, or literal. In some cases, there were valid interpretations that were not the same as the answer given by crowdworkers, which were also marked correct. If the model simply restated the metaphor with no interpretation, the completion was marked as literal. Because some metaphors are ambiguous when presented without context, those examples were not counted. The inter-rater reliability was moderate due to differing standards for correctness (Krippendorff's \u03b1 = 0.5567). The majority vote was taken between annotators' judgments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Results",
                "sec_num": "5.2"
            },
            {
                "text": "GPT-3 Davinci's accuracy, counting literalized metaphors as incorrect, was 50.8%. Not counting literalized metaphors, accuracy was 63.9%. In 37.7% of cases, GPT-3 generated contradictory completions among the 4 completions. There was at least one correct completion for 78.1% of the metaphors, but only 19.3% of metaphors had all completions correct. Examples of annotated generations can be found in Appendix G.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generation Results",
                "sec_num": "5.2"
            },
            {
                "text": "With these results in mind, we examine what kinds of errors models make, and what factors make the task difficult.. This is covered in \u00a7 6. We find that autoregressive models rely on the predicted probability of each answer by itself to predict the answer, and that this holds true for all models, before and after training. We find that models have difficulty in interpreting \"sarcastic\" metaphors, and sometimes inexplicably interpret very simple metaphors wrong. We also examine error typology according to the commonsense typology of \u00a7 3.2 and find that models improve significantly on object, visual and social commonsense when trained, but not on cultural commonsense.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Performance and Error Analysis",
                "sec_num": "6"
            },
            {
                "text": "We find that models often rely solely on the predicted probability of answers y 1 and y 2 to make their final predictions, regardless of the context. This led models to make the same prediction for the paired sentences in many cases. Figure 3 and Table 5 show that this trend improves with finetuning, and that GPT-3 is best able to disentangle the probability of y i and the probability of P (y i |x i ), but all three models show a heavy tendency to predict based on the relative probability of an answer alone.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 241,
                        "end": 242,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 253,
                        "end": 254,
                        "text": "5",
                        "ref_id": "TABREF7"
                    }
                ],
                "eq_spans": [],
                "section": "Reliance on Probability of Answers",
                "sec_num": "6.1"
            },
            {
                "text": "We hypothesize that this may be one reason why BERT and RoBERTa achieve the best finetuned performance; they use a contrastive finetuning strategy providing both the correct and incorrect options as input to the model. On the other hand, the GPT models were finetuned with only the correct option, making the comparison unfair. One way to finetune GPT models contrastively is to include both options into a cleverly engineered prompt, but we leave this as a direction for future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Reliance on Probability of Answers",
                "sec_num": "6.1"
            },
            {
                "text": "Figure 3 : Models over-rely on probability of the answer to do their predictions. y-axis is probability of the first interpretation (answer) given metaphor while x-axis is log odds of the first interpretation.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Reliance on Probability of Answers",
                "sec_num": "6.1"
            },
            {
                "text": "We also examined the influence of several other factors on correctness. The point-biserial correlation between length of the context phrase and the binary correctness value was -0.1544 with a p-value of 1.50 \u00d7 10 -7 , indicating that longer phrases are harder to interpret correctly. The point-biserial correlation between answer probability and binary correctness was 0.1840, with a p-value of 3.50\u00d710 -10 , indicating that examples where the answer was already more probable were more likely to be an-swered correctly, in line with our findings that models tended to predict the answer that was already more plausible alone. Furthermore, we conducted an analysis on subjects, objects, and relations as defined in \u00a7 3.1. We examined accuracy by part of speech patterns in each part of the metaphor, as well as by wordnet hypernyms present in each part of the metaphor. This is detailed in Appendix E and Appendix F (Fellbaum, 1998) . We used NLTK for POS tagging (Loper and Bird, 2002) .",
                "cite_spans": [
                    {
                        "start": 916,
                        "end": 932,
                        "text": "(Fellbaum, 1998)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 964,
                        "end": 986,
                        "text": "(Loper and Bird, 2002)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Other Factors Influencing Correctness",
                "sec_num": "6.2"
            },
            {
                "text": "Common Sense Knowledge We first examine the error tendencies by the type of common sense knowledge described in \u00a7 3.2. We find that both humans and trained models tend to find object commonsense and visual commonsense metaphors easier to interpret. We find that as models improve, most of the performance gain comes from the object, visual and social commonsense categories. Interestingly, the untrained models do quite well on cultural examples, but do not improve much on the culture category when trained. This makes sense, as the cultural examples tend to be quite disparate, so training would not help as much with other examples.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Qualitative Analysis of Error Trends",
                "sec_num": "6.3"
            },
            {
                "text": "For both humans and LMs, many of the errors are \"sarcastic\" metaphors, such as saying \"the girl was as bubbly as still water\" to mean \"the girl was bland\", rather than \"the girl was vivacious\". These sentences can be difficult if the model or human focuses on simple word association (bubbly with vivacious) without reading the entire sentence to understand the sarcasm.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sarcastic Metaphors",
                "sec_num": null
            },
            {
                "text": "We examined the errors made by GPT-3 Curie (trained) and found that there was little overlap with mistakes made by humans. Of the 64 human errors, 13 were also errors made by GPT-3. GPT-3 made many more \"obvious\" errors, such as predicting \"The ball is a big red sun\" to mean \"the ball is small\" rather than \"the ball is big and red\" This is in contrast to the sentences in which humans made errors, which often contained rare vocabulary or unfamiliar cultural references.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inexplicable Errors",
                "sec_num": null
            },
            {
                "text": "7 Related work",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inexplicable Errors",
                "sec_num": null
            },
            {
                "text": "Most existing work focuses on identifying figurative language at the word level. The VU Amsterdam Metaphor Corpus (VUA) is the largest available corpus of metaphorical language, annotated by humans (Steen et al., 2010) . Two shared tasks on metaphor identification have been run (Leong et al., 2018 (Leong et al., , 2020)) . Both have utilized the VUA corpus, and the latter also introduced the TOEFL corpus, sampled from essays written by non-native English speakers (Leong et al., 2020; Beigman Klebanov et al., 2018) . Most participants in the shared tasks used neural models, notably BERT, RoBERTa, and Bi-LSTMs (Leong et al., 2020; Bizzoni and Ghanimifard, 2018; Gao et al., 2018; Pramanick et al., 2018) . These models are generally improved when augmented with semantic data, such as concreteness, and multimodal information.",
                "cite_spans": [
                    {
                        "start": 198,
                        "end": 218,
                        "text": "(Steen et al., 2010)",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 279,
                        "end": 298,
                        "text": "(Leong et al., 2018",
                        "ref_id": null
                    },
                    {
                        "start": 299,
                        "end": 322,
                        "text": "(Leong et al., , 2020))",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 468,
                        "end": 488,
                        "text": "(Leong et al., 2020;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 489,
                        "end": 519,
                        "text": "Beigman Klebanov et al., 2018)",
                        "ref_id": null
                    },
                    {
                        "start": 588,
                        "end": 636,
                        "text": "BERT, RoBERTa, and Bi-LSTMs (Leong et al., 2020;",
                        "ref_id": null
                    },
                    {
                        "start": 637,
                        "end": 667,
                        "text": "Bizzoni and Ghanimifard, 2018;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 668,
                        "end": 685,
                        "text": "Gao et al., 2018;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 686,
                        "end": 709,
                        "text": "Pramanick et al., 2018)",
                        "ref_id": "BIBREF36"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Identification",
                "sec_num": "7.1"
            },
            {
                "text": "Another line of work focuses on probing models to determine the extent of metaphor recognition. For instance, BERT assigns higher pseudolog-likelihood scores to metaphors than nonsense expressions, and its contextualized representations show some signs of contextualizing the object domain (Pedinotti et al., 2021) . Another study uses linear probes trained on layers of BERT to predict whether a word usage is literal or nonliteral, and finds that this can be done effectively, especially using middle layers as a representation (Aghazadeh et al., 2022) , Despite the utility of these tasks and datasets, they have drawbacks. Most of the metaphor use is conventional, so this task does not capture novel metaphors well. The word-level annotation also does not lend itself well to capturing extended con-ceptual metaphors. Finally, metaphor interpretation may be a more difficult, although less studied, task.",
                "cite_spans": [
                    {
                        "start": 290,
                        "end": 314,
                        "text": "(Pedinotti et al., 2021)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 530,
                        "end": 554,
                        "text": "(Aghazadeh et al., 2022)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Identification",
                "sec_num": "7.1"
            },
            {
                "text": "Recent studies mostly focus on metaphor paraphrases, either through identification (Bizzoni and Lappin, 2018) or generation (Shutova, 2010; Su et al., 2017; Mao et al., 2018) . However, there has not been as much work done on interpretation as on detection, and framing metaphor interpretation as a paraphrase task may not capture the emergent meaning of metaphors, such as the intended emotion, or the interaction of subject, relation and object in the metaphor (Tong et al., 2021; Mohammad et al., 2016) .",
                "cite_spans": [
                    {
                        "start": 83,
                        "end": 109,
                        "text": "(Bizzoni and Lappin, 2018)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 124,
                        "end": 139,
                        "text": "(Shutova, 2010;",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 140,
                        "end": 156,
                        "text": "Su et al., 2017;",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 157,
                        "end": 174,
                        "text": "Mao et al., 2018)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 463,
                        "end": 482,
                        "text": "(Tong et al., 2021;",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 483,
                        "end": 505,
                        "text": "Mohammad et al., 2016)",
                        "ref_id": "BIBREF32"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Interpretation",
                "sec_num": "7.2"
            },
            {
                "text": "Other work has focused on interpreting figurative language in narratives in context, based on plausible continuations of figurative language such as idioms and similes from stories (Chakrabarty et al., 2021a) or dialogues (Jhamtani et al., 2021) . This represents a promising direction, and our work focuses on expanding our understanding of LMs' ability to interpret non-conventionalized metaphors.",
                "cite_spans": [
                    {
                        "start": 181,
                        "end": 208,
                        "text": "(Chakrabarty et al., 2021a)",
                        "ref_id": null
                    },
                    {
                        "start": 222,
                        "end": 245,
                        "text": "(Jhamtani et al., 2021)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Figurative Language Interpretation",
                "sec_num": "7.2"
            },
            {
                "text": "We note that there are several other challenging NLI datasets available which contain figurative language, including the DNC corpus, and the RTE dataset (Poliak et al., 2018; Chakrabarty et al., 2021b) . Other datasets, such as RiddleSense, explicitly test models through difficult commonsense inference, involving figurative language (Lin et al., 2021) .",
                "cite_spans": [
                    {
                        "start": 153,
                        "end": 174,
                        "text": "(Poliak et al., 2018;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 175,
                        "end": 201,
                        "text": "Chakrabarty et al., 2021b)",
                        "ref_id": null
                    },
                    {
                        "start": 335,
                        "end": 353,
                        "text": "(Lin et al., 2021)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Other Figurative Language Datasets",
                "sec_num": "7.3"
            },
            {
                "text": "Our work is distinguished by the Winograd schema format, as this format provides a better guard against the possibility that models have simply memorized common word associations that occur in figurative language. Additionally, we specifically instructed crowdworkers to be creative, and this resulted in longer figurative phrases which require more detailed commonsense knowledge. It is likely that a fair number of these figurative phrases have never appeared in any training corpus. However, our figurative phrases also differ from riddles, as they are not supposed to be difficult to reason about, given that the source, relation and object are properly contextualized.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Other Figurative Language Datasets",
                "sec_num": "7.3"
            },
            {
                "text": "Humans typically do not have any more difficulty processing metaphorical statements in context compared to literal statements (Fussell and Moss, 2008; Glucksberg, 2003) . This may be because certain words serve as a dual reference, which is to say they refer simultaneously to a physical referent and an abstract superordinate category (Glucksberg, 2003) . For instance, \"shark\" may refer to literal sharks, as well as anything that is considered vicious, leading to utterances such as \"that lawyer is a shark\".",
                "cite_spans": [
                    {
                        "start": 126,
                        "end": 150,
                        "text": "(Fussell and Moss, 2008;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 151,
                        "end": 168,
                        "text": "Glucksberg, 2003)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 336,
                        "end": 354,
                        "text": "(Glucksberg, 2003)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Language Processing",
                "sec_num": "7.4"
            },
            {
                "text": "Metaphorical language processing has also been studied in second-language learners, in the case of idioms. In most cases, the meaning of an unfamiliar idiom is inferred from the context or from word association (Cooper, 1999; Carston and Wearing, 2011; Wolff and Gentner, 2000) .",
                "cite_spans": [
                    {
                        "start": 211,
                        "end": 225,
                        "text": "(Cooper, 1999;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 226,
                        "end": 252,
                        "text": "Carston and Wearing, 2011;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 253,
                        "end": 277,
                        "text": "Wolff and Gentner, 2000)",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Language Processing",
                "sec_num": "7.4"
            },
            {
                "text": "As LMs excel at word-association based tasks, this is an encouraging finding. However, there is still a gap between LM and human performance even in our task, in which one answer is obviously wrong when the input is correctly understood.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Language Processing",
                "sec_num": "7.4"
            },
            {
                "text": "We take into account that these results are for conventionalized figurative language and that some of the more creative phrases in this dataset may take a longer time to process for humans as well. This is especially true for non-native English speakers. However, the high human accuracy on this task with half the participants being non-native English speakers suggests that this was not a major barrier.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Language Processing",
                "sec_num": "7.4"
            },
            {
                "text": "We present a Winograd-like benchmark task to test the ability of LMs to reason about figurative language, based on large-scale collection of creative metaphors written by humans. We find a large gap between LM zero-shot and human performance on this dataset, but show that models can be fine-tuned to perform well on this particular task.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "We hope that this work will encourage further study of nonliteral reasoning in LMs, especially in few-shot settings. Given that metaphorical reasoning may play a role in problem-solving and linguistic creativity, the development of models, training methods, or datasets that enable metaphorical reasoning may improve models' abilities to reason creatively and draw analogies between situations that may appear to be different on the surface. One avenue we hope to investigate is multimodal metaphors, as this dataset currently includes only text-based metaphors. Nonliteral expressions also remain understudied cross-linguistically, but further work on identifying and interpreting metaphors in other languages may also improve the abilities of multilingual models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "Figurative language has the potential to be used in a harmful way, especially against minority and historically disadvantaged groups. Such language is often emotionally charged or used to insult others, so we took care to remove any examples that were potentially offensive, especially toward protected groups. We acknowledge that this was based on our own judgment, and generically insulting language (for instance, a metaphor that implies that someone is ugly) was not removed because it was not insulting toward any particular individual.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Potential Risks",
                "sec_num": "9.1"
            },
            {
                "text": "All examples from Fig-QA are also in English, as it is the language that all authors speak, and this was a preliminary dataset, being the first of its type that the authors have worked on. However, figurative language is not just important in English, and we leave investigation of figurative language in other languages as future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Potential Risks",
                "sec_num": "9.1"
            },
            {
                "text": "Additional datasets we used were the Winogrande dataset, SNLI, MNLI, FEVER-NLI and ANLI. Winogrande is licensed under the Apache 2.0 license, which allows modification and distribution, fitting our use case. SNLI is licensed under a Creative Commons Attribution ShareAlike 4.0 International license, which allows us to share and adapt the work as long as we give attribution. The majority of MNLI is licensed under OANC, which allows free use. The fiction section of this dataset consists mostly of works in the public domain, but several stories are licensed: Seven Swords is available under a Creative Commons Share-Alike 3.0 Unported License, while Living History and Password Incorrect are available under Creative Commons Attribution 3.0 Unported Licenses. These licenses allow sharing and adaptation with attribution. FEVER-NLI is licensed under an MIT license, which also allows modification, distribution, and reuse. ANLI is licensed under Creative Commons Attribution-NonCommercial 4.0 International, which also allows sharing and reuse as long as we give attribution.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Terms of Use of Artefacts Used",
                "sec_num": "9.2"
            },
            {
                "text": "Models used were GPT-2, GPT-neo, GPT-3, BERT and RoBERTa. GPT-2 and GPT-neo are licensed under an MIT license, which does not place any restrictions on its use. BERT is licensed under an Apache License 2.0, which allows modification and distribution. RoBERTa is licensed under a GNU General Public License v2.0. This fits our use case as we are only running and studying the model. GPT-3 is licensed by Microsoft, and we used the public API to receive output.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Terms of Use of Artefacts Used",
                "sec_num": "9.2"
            },
            {
                "text": "To run our computational experiments, we had access to a compute cluster, but minimal compute is needed to run the experiments in this paper. We generally did not use more than 2 GPUs at a time.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Computational Infrastructure and Computing Budget",
                "sec_num": "9.3"
            },
            {
                "text": "The only models that required GPU parallelism were the GPT-neo models. An estimated 20 GPU hours are required.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Computational Infrastructure and Computing Budget",
                "sec_num": "9.3"
            },
            {
                "text": "Our computing budget was roughly 100 USD. We also used roughly 20 USD on credits for the GPT-3 API.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Computational Infrastructure and Computing Budget",
                "sec_num": "9.3"
            },
            {
                "text": "We crowdsource metaphorical expressions and their interpretations through Amazon Mechanical Turk. Workers were recruited from the United States and were limited to those who had a > 98% approval rating on the platform, and who had also completed more than 1000 Human Intelligence Tasks (HITs). Data collection was split into two stages: in the first stage, 1458 train examples, and all the dev and test examples were collected. In the second stage, the remaining 6558 training examples were collected. We identified some workers who created especially good examples in the first stage, and recruited them back for more examples in the second stage. Workers were paid $0.33 for each pair of sentences and were asked to generate 3 pairs at a time. An author of this paper wrote an initial pilot set of sentences, and timed themselves while writing some sentences. They found that each pair took around 1 minute to write, though this varied (less creative examples took less time, while more creative examples took more time). This extrapolates to an hourly rate of 19.80 USD, which is above the minimum wage in all US states, where workers were located.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Crowdsourcing Details",
                "sec_num": null
            },
            {
                "text": "Our HIT task was structured as follows: At the top of the page, the workers are shown the following instructions: \"Your task is to generate three pairs of sentences with opposite or very different meanings, both of which contain rare/creative metaphors, which means metaphors that would not appear often in text on the internet, books, social media or news sites, but that can still be easily understood by people. For each metaphor, you should also provide a literal (non-metaphorical) sentence with the same meaning.\" Then, we display one example of a valid sentence pair. There is a button that opens a modal with more detailed instructions and some more valid/invalid examples for reference. Below that, we display three random words, which workers are encouraged to use in their sentences if they get stuck. Finally, we display three sets of 5 text fields for workers to fill in: one for the start phrase, two for each metaphorical phrase, and two for each literal interpretation. As the user types in each start phrase, we prepend a copy of their phrase before the corresponding metaphor fields in the UI using some embedded JavaScript, which we found helped reduce confusion and resulted in less improperly formatted responses.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Crowdsourcing Details",
                "sec_num": null
            },
            {
                "text": "We launched many batches of these HITs until we had collected the desired quantity of data. Then, we converted the form responses into sentence pairs and validated each pair by hand before adding it to our dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "A Crowdsourcing Details",
                "sec_num": null
            },
            {
                "text": "Figurative language examples collected from crowdworkers were excluded if they (a) did not make sense given the meaning and the metaphorical expression, (b) had grammar or spelling errors that rendered them unintelligible, or (c) did not follow the format specified by the task template.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B Invalid Examples",
                "sec_num": null
            },
            {
                "text": "Examples are given below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B Invalid Examples",
                "sec_num": null
            },
            {
                "text": "1. Do not make sense given the meaning and the metaphorical expression",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B Invalid Examples",
                "sec_num": null
            },
            {
                "text": "He was resourceful like toilet paper He was very resourceful. He was resourceful like a mess He wasn't resourceful at all",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paired sentences Possible answers",
                "sec_num": null
            },
            {
                "text": "The night was as long as a spool of thread The night is long The night was as long as a winding road",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paired sentences Possible answers",
                "sec_num": null
            },
            {
                "text": "The night dragged on the concert of the lession is a main and a major we concert everyone the concert of the lession features we concert our loved one Efforts were made to ensure that the final dataset contains no offensive content or personally identifiable information. WorkerID and other potentailly personally identifying information were not included. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paired sentences Possible answers",
                "sec_num": null
            },
            {
                "text": "Generation examples can be found in Table 17 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 42,
                        "end": 44,
                        "text": "17",
                        "ref_id": "TABREF10"
                    }
                ],
                "eq_spans": [],
                "section": "G Generation examples",
                "sec_num": null
            },
            {
                "text": "Code and data are available at https://github.com/ nightingal3/Fig-QA, and a leaderboard can be found at https: //explainaboard.inspiredco.ai/leaderboards?dataset=fig_qa",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The opposing meanings help to avoid ambiguity in the correct answer, make the task intuitive for human annotators, and help prevent annotation artifacts that have plagued other NLI datasets(Gururangan et al., 2018).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In actuality, we use the length-normalized probability that a model assigns to a sentence as a heuristic for the total probability, to minimize the effect that the length of a sentence has on the decision (though this is not the probability of the sequence in a strict sense): P (w1...wN ) = exp(-1 N log P (w1...wN )). Initial experimentation showed marginal differences in accuracy when using these two methods, so we used normalized probabilities by default.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This is the accuracy score when transferring from Winogrande. Pretrained NLI results",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "were 50.47 when using original labels (entailment/contradiction/neutral), and 66.32 when forcing a binary decision.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We thank Pengfei Liu, Lyuyang Hu, and Chih-Hao Wang for helping us set up the leaderboard for this dataset on Explainaboard. We also thank Pengfei Liu for helping run GPT-3, Danish Pruthi for guidance on setting up the MTurk task, and all participants who contributed to the human benchmark. Lastly, we thank all the Turkers who contributed metaphors to the dataset.This work was supported in part by a CMU Presidential Fellowship and National Science Foundation Award No. 1761548.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": null
            },
            {
                "text": "His temper was a marshmallow. That is to say, he was very easily angered, and once he was, he was very hard to cool down Incorrect He's got the swimming ability of a pack of dolphins. That is to say, he's got none IncorrectThe villain is as beautiful as the Joker. That is to say, he's not CorrectThe child has the energy of a sloth. That is to say, he is lazy CorrectThe girl moved as fast as a turtle. That is to say, she moved at a turtle's pace LiteralThe sadness of her death was a flea.That is to say, It was a flea that was a sadness Literal ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Startphrase Completion Label",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Metaphors in pre-trained language models: Probing and generalization across datasets and languages",
                "authors": [
                    {
                        "first": "Ehsan",
                        "middle": [],
                        "last": "Aghazadeh",
                        "suffix": ""
                    },
                    {
                        "first": "Mohsen",
                        "middle": [],
                        "last": "Fayyaz",
                        "suffix": ""
                    },
                    {
                        "first": "Yadollah",
                        "middle": [],
                        "last": "Yaghoobzadeh",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/ARXIV.2203.14139"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ehsan Aghazadeh, Mohsen Fayyaz, and Yadollah Yaghoobzadeh. 2022. Metaphors in pre-trained lan- guage models: Probing and generalization across datasets and languages.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "A corpus of non-native written English annotated for metaphor",
                "authors": [
                    {
                        "first": "Beata",
                        "middle": [],
                        "last": "Beigman Klebanov",
                        "suffix": ""
                    },
                    {
                        "first": "Chee",
                        "middle": [],
                        "last": "Wee (ben) Leong",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Flor",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "2",
                "issue": "",
                "pages": "86--91",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-2014"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Beata Beigman Klebanov, Chee Wee (Ben) Leong, and Michael Flor. 2018. A corpus of non-native written English annotated for metaphor. In Proceedings of the 2018 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Pa- pers), pages 86-91, New Orleans, Louisiana. Asso- ciation for Computational Linguistics.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Climbing towards NLU: On meaning, form, and understanding in the age of data",
                "authors": [
                    {
                        "first": "Emily",
                        "middle": [
                            "M"
                        ],
                        "last": "Bender",
                        "suffix": ""
                    },
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Koller",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "5185--5198",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.463"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Emily M. Bender and Alexander Koller. 2020. Climb- ing towards NLU: On meaning, form, and under- standing in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Compu- tational Linguistics, pages 5185-5198, Online. As- sociation for Computational Linguistics.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Experience grounds language",
                "authors": [
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Bisk",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Holtzman",
                        "suffix": ""
                    },
                    {
                        "first": "Jesse",
                        "middle": [],
                        "last": "Thomason",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Andreas",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "Joyce",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    },
                    {
                        "first": "Angeliki",
                        "middle": [],
                        "last": "Lazaridou",
                        "suffix": ""
                    },
                    {
                        "first": "Jonathan",
                        "middle": [],
                        "last": "May",
                        "suffix": ""
                    },
                    {
                        "first": "Aleksandr",
                        "middle": [],
                        "last": "Nisnevich",
                        "suffix": ""
                    },
                    {
                        "first": "Nicolas",
                        "middle": [],
                        "last": "Pinto",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [],
                        "last": "Turian",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "8718--8735",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.emnlp-main.703"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella Lap- ata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, Nicolas Pinto, and Joseph Turian. 2020. Experience grounds language. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8718-8735, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Bigrams and BiLSTMs two neural networks for sequential metaphor detection",
                "authors": [
                    {
                        "first": "Yuri",
                        "middle": [],
                        "last": "Bizzoni",
                        "suffix": ""
                    },
                    {
                        "first": "Mehdi",
                        "middle": [],
                        "last": "Ghanimifard",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "91--101",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-0911"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yuri Bizzoni and Mehdi Ghanimifard. 2018. Bigrams and BiLSTMs two neural networks for sequential metaphor detection. In Proceedings of the Workshop on Figurative Language Processing, pages 91-101, New Orleans, Louisiana. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Predicting human metaphor paraphrase judgments with deep neural networks",
                "authors": [
                    {
                        "first": "Yuri",
                        "middle": [],
                        "last": "Bizzoni",
                        "suffix": ""
                    },
                    {
                        "first": "Shalom",
                        "middle": [],
                        "last": "Lappin",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "45--55",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-0906"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yuri Bizzoni and Shalom Lappin. 2018. Predicting hu- man metaphor paraphrase judgments with deep neu- ral networks. In Proceedings of the Workshop on Figurative Language Processing, pages 45-55, New Orleans, Louisiana. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow",
                "authors": [
                    {
                        "first": "Sid",
                        "middle": [],
                        "last": "Black",
                        "suffix": ""
                    },
                    {
                        "first": "Leo",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Phil",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Connor",
                        "middle": [],
                        "last": "Leahy",
                        "suffix": ""
                    },
                    {
                        "first": "Stella",
                        "middle": [],
                        "last": "Biderman",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.5281/zenodo.5297715"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2021. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh- Tensorflow.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Metaphor, hyperbole and simile: A pragmatic approach",
                "authors": [
                    {
                        "first": "Robyn",
                        "middle": [],
                        "last": "Carston",
                        "suffix": ""
                    },
                    {
                        "first": "Catherine",
                        "middle": [],
                        "last": "Wearing",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Language and Cognition",
                "volume": "3",
                "issue": "2",
                "pages": "283--312",
                "other_ids": {
                    "DOI": [
                        "10.1515/langcog.2011.010"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Robyn Carston and Catherine Wearing. 2011. Metaphor, hyperbole and simile: A pragmatic approach. Language and Cognition, 3(2):283-312.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "2021a. It's not rocket science : Interpreting figurative language in narratives",
                "authors": [
                    {
                        "first": "Tuhin",
                        "middle": [],
                        "last": "Chakrabarty",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Vered",
                        "middle": [],
                        "last": "Shwartz",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tuhin Chakrabarty, Yejin Choi, and Vered Shwartz. 2021a. It's not rocket science : Interpreting figura- tive language in narratives. ArXiv, abs/2109.00087.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "2021b. Figurative language in recognizing textual entailment",
                "authors": [
                    {
                        "first": "Tuhin",
                        "middle": [],
                        "last": "Chakrabarty",
                        "suffix": ""
                    },
                    {
                        "first": "Debanjan",
                        "middle": [],
                        "last": "Ghosh",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Poliak",
                        "suffix": ""
                    },
                    {
                        "first": "Smaranda",
                        "middle": [],
                        "last": "Muresan",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "volume": "",
                "issue": "",
                "pages": "3354--3361",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.findings-acl.297"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Tuhin Chakrabarty, Debanjan Ghosh, Adam Poliak, and Smaranda Muresan. 2021b. Figurative language in recognizing textual entailment. In Findings of the Association for Computational Linguistics: ACL- IJCNLP 2021, pages 3354-3361, Online. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Processing of idioms by l2 learners of english",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [
                            "C"
                        ],
                        "last": "Cooper",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "TESOL Quarterly",
                "volume": "33",
                "issue": "",
                "pages": "233--262",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas C. Cooper. 1999. Processing of idioms by l2 learners of english. TESOL Quarterly, 33:233-262.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Devlin",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understand- ing.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Back to square one: Artifact detection, training and commonsense disentanglement in the winograd schema",
                "authors": [
                    {
                        "first": "Yanai",
                        "middle": [],
                        "last": "Elazar",
                        "suffix": ""
                    },
                    {
                        "first": "Hongming",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/ARXIV.2104.08161"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yanai Elazar, Hongming Zhang, Yoav Goldberg, and Dan Roth. 2021. Back to square one: Artifact detec- tion, training and commonsense disentanglement in the winograd schema.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Conceptual blending, form and meaning",
                "authors": [
                    {
                        "first": "Gilles",
                        "middle": [],
                        "last": "Fauconnier",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Turner",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gilles Fauconnier and Mark Turner. 2003. Conceptual blending, form and meaning.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "WordNet: An Electronic Lexical Database",
                "authors": [
                    {
                        "first": "Christiane",
                        "middle": [],
                        "last": "Fellbaum",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. Bradford Books.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Figurative language in emotional communication",
                "authors": [
                    {
                        "first": "Susan",
                        "middle": [],
                        "last": "Fussell",
                        "suffix": ""
                    },
                    {
                        "first": "Mallie",
                        "middle": [],
                        "last": "Moss",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Susan Fussell and Mallie Moss. 2008. Figurative lan- guage in emotional communication.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Neural metaphor detection in context",
                "authors": [
                    {
                        "first": "Ge",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Eunsol",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "607--613",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1060"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ge Gao, Eunsol Choi, Yejin Choi, and Luke Zettle- moyer. 2018. Neural metaphor detection in context. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 607-613, Brussels, Belgium. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Metaphor as structure-mapping",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Gentnder",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bowdle",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "The Cambridge handbook of metaphor and thought",
                "volume": "",
                "issue": "",
                "pages": "109--128",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D Gentnder and B Bowdle. 2008. Metaphor as structure-mapping. In The Cambridge handbook of metaphor and thought, pages 109-128. Cambridge University Press.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Sand and Foam; a book of aphorisms",
                "authors": [
                    {
                        "first": "Kahlil",
                        "middle": [],
                        "last": "Gibran",
                        "suffix": ""
                    }
                ],
                "year": 1926,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kahlil Gibran. 1926. Sand and Foam; a book of apho- risms. A.A Knopf.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "The psycholinguistics of metaphor",
                "authors": [
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Glucksberg",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Trends in cognitive sciences",
                "volume": "7",
                "issue": "",
                "pages": "92--96",
                "other_ids": {
                    "DOI": [
                        "10.1016/S1364-6613(02)00040-2"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Sam Glucksberg. 2003. The psycholinguistics of metaphor. Trends in cognitive sciences, 7:92-96.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Annotation artifacts in natural language inference data",
                "authors": [
                    {
                        "first": "Suchin",
                        "middle": [],
                        "last": "Gururangan",
                        "suffix": ""
                    },
                    {
                        "first": "Swabha",
                        "middle": [],
                        "last": "Swayamdipta",
                        "suffix": ""
                    },
                    {
                        "first": "Omer",
                        "middle": [],
                        "last": "Levy",
                        "suffix": ""
                    },
                    {
                        "first": "Roy",
                        "middle": [],
                        "last": "Schwartz",
                        "suffix": ""
                    },
                    {
                        "first": "Samuel",
                        "middle": [],
                        "last": "Bowman",
                        "suffix": ""
                    },
                    {
                        "first": "Noah",
                        "middle": [
                            "A"
                        ],
                        "last": "Smith",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter",
                "volume": "2",
                "issue": "",
                "pages": "107--112",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-2017"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith. 2018. Annotation artifacts in natural lan- guage inference data. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 107-112, New Orleans, Louisiana. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Investigating robustness of dialog models to popular figurative language constructs",
                "authors": [
                    {
                        "first": "Harsh",
                        "middle": [],
                        "last": "Jhamtani",
                        "suffix": ""
                    },
                    {
                        "first": "Varun",
                        "middle": [],
                        "last": "Gangal",
                        "suffix": ""
                    },
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    },
                    {
                        "first": "Taylor",
                        "middle": [],
                        "last": "Berg-Kirkpatrick",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "7476--7485",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.emnlp-main.592"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Harsh Jhamtani, Varun Gangal, Eduard Hovy, and Tay- lor Berg-Kirkpatrick. 2021. Investigating robustness of dialog models to popular figurative language con- structs. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7476-7485, Online and Punta Cana, Domini- can Republic. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Metaphors we Live By",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Lakoff",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Johnson",
                        "suffix": ""
                    }
                ],
                "year": 1981,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Lakoff and M. Johnson. 1981. Metaphors we Live By. University of Chicago Press.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "A report on the 2020 VUA and TOEFL metaphor detection shared task",
                "authors": [
                    {
                        "first": "Chee",
                        "middle": [],
                        "last": "Wee",
                        "suffix": ""
                    },
                    {
                        "first": "(",
                        "middle": [],
                        "last": "Ben",
                        "suffix": ""
                    },
                    {
                        "first": ")",
                        "middle": [],
                        "last": "Leong",
                        "suffix": ""
                    },
                    {
                        "first": "Beata",
                        "middle": [
                            "Beigman"
                        ],
                        "last": "Klebanov",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Hamill",
                        "suffix": ""
                    },
                    {
                        "first": "Egon",
                        "middle": [],
                        "last": "Stemle",
                        "suffix": ""
                    },
                    {
                        "first": "Rutuja",
                        "middle": [],
                        "last": "Ubale",
                        "suffix": ""
                    },
                    {
                        "first": "Xianyang",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the Second Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "18--29",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.figlang-1.3"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Chee Wee (Ben) Leong, Beata Beigman Klebanov, Chris Hamill, Egon Stemle, Rutuja Ubale, and Xi- anyang Chen. 2020. A report on the 2020 VUA and TOEFL metaphor detection shared task. In Pro- ceedings of the Second Workshop on Figurative Lan- guage Processing, pages 18-29, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "A report on the 2018 VUA metaphor detection shared task",
                "authors": [
                    {
                        "first": "Chee",
                        "middle": [],
                        "last": "Wee",
                        "suffix": ""
                    },
                    {
                        "first": "(",
                        "middle": [],
                        "last": "Ben",
                        "suffix": ""
                    },
                    {
                        "first": ")",
                        "middle": [],
                        "last": "Leong",
                        "suffix": ""
                    },
                    {
                        "first": "Beata",
                        "middle": [],
                        "last": "Beigman Klebanov",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "56--66",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-0907"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Chee Wee (Ben) Leong, Beata Beigman Klebanov, and Ekaterina Shutova. 2018. A report on the 2018 VUA metaphor detection shared task. In Proceedings of the Workshop on Figurative Language Processing, pages 56-66, New Orleans, Louisiana. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "The winograd schema challenge",
                "authors": [
                    {
                        "first": "Hector",
                        "middle": [
                            "J"
                        ],
                        "last": "Levesque",
                        "suffix": ""
                    },
                    {
                        "first": "Ernest",
                        "middle": [],
                        "last": "Davis",
                        "suffix": ""
                    },
                    {
                        "first": "Leora",
                        "middle": [],
                        "last": "Morgenstern",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, KR'12",
                "volume": "",
                "issue": "",
                "pages": "552--561",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hector J. Levesque, Ernest Davis, and Leora Morgen- stern. 2012. The winograd schema challenge. In Proceedings of the Thirteenth International Confer- ence on Principles of Knowledge Representation and Reasoning, KR'12, page 552-561. AAAI Press.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Riddlesense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge",
                "authors": [
                    {
                        "first": "Ziyi",
                        "middle": [],
                        "last": "Bill Yuchen Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Yichi",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Dong-Ho",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/ARXIV.2101.00376"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Bill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee, and Xiang Ren. 2021. Riddlesense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Nltk: The natural language toolkit. CoRR",
                "authors": [
                    {
                        "first": "Edward",
                        "middle": [],
                        "last": "Loper",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bird",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Edward Loper and Steven Bird. 2002. Nltk: The natu- ral language toolkit. CoRR, cs.CL/0205028.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Word embedding and WordNet based metaphor identification and interpretation",
                "authors": [
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Mao",
                        "suffix": ""
                    },
                    {
                        "first": "Chenghua",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Frank",
                        "middle": [],
                        "last": "Guerin",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1222--1231",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P18-1113"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Rui Mao, Chenghua Lin, and Frank Guerin. 2018. Word embedding and WordNet based metaphor iden- tification and interpretation. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 1222-1231, Melbourne, Australia. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Metaphor: Implications and Applications",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Mio",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "N"
                        ],
                        "last": "Katz",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. S Mio and A. N Katz. 1996. Metaphor: Implications and Applications. Psychology Press.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Metaphor as a medium for emotion: An empirical study",
                "authors": [
                    {
                        "first": "Saif",
                        "middle": [],
                        "last": "Mohammad",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Turney",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics",
                "volume": "",
                "issue": "",
                "pages": "23--33",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/S16-2003"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Saif Mohammad, Ekaterina Shutova, and Peter Tur- ney. 2016. Metaphor as a medium for emotion: An empirical study. In Proceedings of the Fifth Joint Conference on Lexical and Computational Seman- tics, pages 23-33, Berlin, Germany. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Adversarial NLI: A new benchmark for natural language understanding",
                "authors": [
                    {
                        "first": "Yixin",
                        "middle": [],
                        "last": "Nie",
                        "suffix": ""
                    },
                    {
                        "first": "Adina",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    },
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Dinan",
                        "suffix": ""
                    },
                    {
                        "first": "Mohit",
                        "middle": [],
                        "last": "Bansal",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    },
                    {
                        "first": "Douwe",
                        "middle": [],
                        "last": "Kiela",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2020. Ad- versarial NLI: A new benchmark for natural lan- guage understanding. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "A howling success or a working sea? testing what BERT knows about metaphors",
                "authors": [
                    {
                        "first": "Paolo",
                        "middle": [],
                        "last": "Pedinotti",
                        "suffix": ""
                    },
                    {
                        "first": "Eliana",
                        "middle": [
                            "Di"
                        ],
                        "last": "Palma",
                        "suffix": ""
                    },
                    {
                        "first": "Ludovica",
                        "middle": [],
                        "last": "Cerini",
                        "suffix": ""
                    },
                    {
                        "first": "Alessandro",
                        "middle": [],
                        "last": "Lenci",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Proceedings of the Fourth Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
                "volume": "",
                "issue": "",
                "pages": "192--204",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2021.blackboxnlp-1.13"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Paolo Pedinotti, Eliana Di Palma, Ludovica Cerini, and Alessandro Lenci. 2021. A howling success or a working sea? testing what BERT knows about metaphors. In Proceedings of the Fourth Black- boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 192-204, Punta Cana, Dominican Republic. Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Collecting diverse natural language inference problems for sentence representation evaluation",
                "authors": [
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Poliak",
                        "suffix": ""
                    },
                    {
                        "first": "Aparajita",
                        "middle": [],
                        "last": "Haldar",
                        "suffix": ""
                    },
                    {
                        "first": "Rachel",
                        "middle": [],
                        "last": "Rudinger",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "Edward"
                        ],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    },
                    {
                        "first": "Aaron",
                        "middle": [],
                        "last": "Steven White",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "67--81",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1007"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Adam Poliak, Aparajita Haldar, Rachel Rudinger, J. Ed- ward Hu, Ellie Pavlick, Aaron Steven White, and Benjamin Van Durme. 2018. Collecting diverse nat- ural language inference problems for sentence rep- resentation evaluation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Lan- guage Processing, pages 67-81, Brussels, Belgium. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "An LSTM-CRF based approach to token-level metaphor detection",
                "authors": [
                    {
                        "first": "Malay",
                        "middle": [],
                        "last": "Pramanick",
                        "suffix": ""
                    },
                    {
                        "first": "Ashim",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Pabitra",
                        "middle": [],
                        "last": "Mitra",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "67--75",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-0908"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Malay Pramanick, Ashim Gupta, and Pabitra Mi- tra. 2018. An LSTM-CRF based approach to token-level metaphor detection. In Proceedings of the Workshop on Figurative Language Processing, pages 67-75, New Orleans, Louisiana. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Language models are unsupervised multitask learners",
                "authors": [
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Rewon",
                        "middle": [],
                        "last": "Child",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Luan",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Winogrande: An adversarial winograd schema challenge at scale",
                "authors": [
                    {
                        "first": "Keisuke",
                        "middle": [],
                        "last": "Sakaguchi",
                        "suffix": ""
                    },
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Ronan",
                        "suffix": ""
                    },
                    {
                        "first": "Chandra",
                        "middle": [],
                        "last": "Bras",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Bhagavatula",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat- ula, and Yejin Choi. 2020. Winogrande: An adver- sarial winograd schema challenge at scale. In AAAI.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Automatic metaphor interpretation as a paraphrasing task",
                "authors": [
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1029--1037",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ekaterina Shutova. 2010. Automatic metaphor inter- pretation as a paraphrasing task. In Human Lan- guage Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 1029-1037, Los Angeles, California. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Computational approaches to figurative language",
                "authors": [
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ekaterina Shutova. 2011. Computational approaches to figurative language.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "A Method for Linguistic Metaphor Identification: From MIP to MIPVU. John Benjamins",
                "authors": [
                    {
                        "first": "Alleta",
                        "middle": [
                            "G"
                        ],
                        "last": "Gerard J Steen",
                        "suffix": ""
                    },
                    {
                        "first": "Berenike",
                        "middle": [],
                        "last": "Dorst",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [
                            "A"
                        ],
                        "last": "Herrmann",
                        "suffix": ""
                    },
                    {
                        "first": "Tina",
                        "middle": [],
                        "last": "Kaal",
                        "suffix": ""
                    },
                    {
                        "first": "Trynetje",
                        "middle": [],
                        "last": "Krennmayr",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Pasma",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gerard J Steen, Alleta G Dorst, Berenike Herrmann, Anna A Kaal, Tina Krennmayr, and Trynetje Pasma. 2010. A Method for Linguistic Metaphor Identifica- tion: From MIP to MIPVU. John Benjamins.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Leveraging syntactic constructions for metaphor identification",
                "authors": [
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Stowe",
                        "suffix": ""
                    },
                    {
                        "first": "Martha",
                        "middle": [],
                        "last": "Palmer",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the Workshop on Figurative Language Processing",
                "volume": "",
                "issue": "",
                "pages": "17--26",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W18-0903"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Kevin Stowe and Martha Palmer. 2018. Leverag- ing syntactic constructions for metaphor identifica- tion. In Proceedings of the Workshop on Figurative Language Processing, pages 17-26, New Orleans, Louisiana. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Automatic detection and interpretation of nominal metaphor based on the theory of meaning",
                "authors": [
                    {
                        "first": "Chang",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "Shuman",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Yijiang",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Neurocomputing",
                "volume": "219",
                "issue": "",
                "pages": "300--311",
                "other_ids": {
                    "DOI": [
                        "10.1016/j.neucom.2016.09.030"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Chang Su, Shuman Huang, and Yijiang Chen. 2017. Automatic detection and interpretation of nominal metaphor based on the theory of meaning. Neuro- computing, 219:300-311.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Discussion of 'emerging topics in cognitive load research: Using learner and information characteristics in the design of powerful learning environments",
                "authors": [
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Sweller",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Applied Cognitive Psychology -APPL COGNITIVE PSYCHOL",
                "volume": "20",
                "issue": "",
                "pages": "353--357",
                "other_ids": {
                    "DOI": [
                        "10.1002/acp.1251"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "John Sweller. 2006. Discussion of 'emerging topics in cognitive load research: Using learner and informa- tion characteristics in the design of powerful learn- ing environments'. Applied Cognitive Psychology - APPL COGNITIVE PSYCHOL, 20:353-357.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Recent advances in neural metaphor processing: A linguistic, cognitive and social perspective",
                "authors": [
                    {
                        "first": "Xiaoyu",
                        "middle": [],
                        "last": "Tong",
                        "suffix": ""
                    },
                    {
                        "first": "Ekaterina",
                        "middle": [],
                        "last": "Shutova",
                        "suffix": ""
                    },
                    {
                        "first": "Martha",
                        "middle": [],
                        "last": "Lewis",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "NAACL 2021",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiaoyu Tong, Ekaterina Shutova, and Martha Lewis. 2021. Recent advances in neural metaphor process- ing: A linguistic, cognitive and social perspective. In NAACL 2021.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Metaphor detection with cross-lingual model transfer",
                "authors": [
                    {
                        "first": "Yulia",
                        "middle": [],
                        "last": "Tsvetkov",
                        "suffix": ""
                    },
                    {
                        "first": "Leonid",
                        "middle": [],
                        "last": "Boytsov",
                        "suffix": ""
                    },
                    {
                        "first": "Anatole",
                        "middle": [],
                        "last": "Gershman",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Nyberg",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "248--258",
                "other_ids": {
                    "DOI": [
                        "10.3115/v1/P14-1024"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman, Eric Nyberg, and Chris Dyer. 2014. Metaphor detec- tion with cross-lingual model transfer. In Proceed- ings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa- pers), pages 248-258, Baltimore, Maryland. Associ- ation for Computational Linguistics.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Evidence for roleneutral initial processing of metaphors",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Wolff",
                        "suffix": ""
                    },
                    {
                        "first": "Dedre",
                        "middle": [],
                        "last": "Gentner",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Journal of experimental psychology. Learning, memory, and cognition",
                "volume": "26",
                "issue": "",
                "pages": "529--541",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "P. Wolff and Dedre Gentner. 2000. Evidence for role- neutral initial processing of metaphors. Journal of experimental psychology. Learning, memory, and cognition, 26 2:529-41.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 2: Comparison of prompting methods with autoregressive models",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>S</td><td>Train M</td><td>L</td><td>Dev</td><td>Test</td></tr><tr><td colspan=\"5\">200 1,458 8,016 1,094 1,146</td></tr></table>",
                "type_str": "table",
                "text": "Example sentences from the dataset",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>Figure 1: Visualization of 25 most frequent subjects, relations, and objects in the medium train set.</td></tr></table>",
                "type_str": "table",
                "text": "Examples in each data split",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Metaphor types based on types of knowledge required (not mutually exclusive)",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td>Model</td><td colspan=\"3\">Zero-shot Tuned (L) Tuned (XL)</td></tr><tr><td>GPT-2</td><td>53.93</td><td>54.80</td><td>62.65</td></tr><tr><td>GPT-neo 1.3B</td><td>56.89</td><td>69.98</td><td>72.00</td></tr><tr><td>GPT-3 Ada</td><td>59.08</td><td>69.17</td><td>73.56</td></tr><tr><td>GPT-3 Babbage</td><td>62.91</td><td>73.97</td><td>77.31</td></tr><tr><td>GPT-3 Curie GPT-3 Davinci</td><td>65.35 68.41</td><td>79.04 -</td><td>81.94 -</td></tr><tr><td>BERT RoBERTa</td><td>58.14 66.18 4</td><td>83.16 89.22</td><td>85.69 90.32</td></tr><tr><td>Human</td><td>94.42</td><td>-</td><td>-</td></tr><tr><td>Human (confident)</td><td>95.39</td><td>-</td><td>-</td></tr><tr><td colspan=\"4\">Table 4: Zero-shot and finetuned test accuracies (%), finetuned is averaged across 5 seeds. Dev set accura-cies can be found on the leaderboard under the \"valida-tion\" split.</td></tr></table>",
                "type_str": "table",
                "text": "shuffled the test set and split it into 10 partitions of \u2248115 examples for each annotator. The",
                "html": null,
                "num": null
            },
            "TABREF7": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Spearman r-values and p-values between P (y i |x i ) and P (y i )",
                "html": null,
                "num": null
            },
            "TABREF8": {
                "content": "<table><tr><td>Model</td><td>Obj</td><td>Vis</td><td>Soc</td><td>Cul</td></tr><tr><td/><td colspan=\"2\">Untrained</td><td/><td/></tr><tr><td colspan=\"5\">GPT-2 GPT-neo GPT-3 Curie 75.00 71.00 72.47 78.42 52.17 52.07 55.38 58.42 56.38 55.62 56.01 62.10</td></tr><tr><td/><td colspan=\"2\">Trained</td><td/><td/></tr><tr><td colspan=\"5\">GPT-2 GPT-neo GPT-3 Curie 87.50 84.62 83.86 83.16 53.57 51.48 57.91 57.37 70.15 72.78 68.67 70.00 BERT 87.37 92.31 84.18 77.37 RoBERTa 91.20 94.08 89.56 83.68</td></tr><tr><td>Human</td><td colspan=\"4\">95.41 96.45 93.99 90.00</td></tr></table>",
                "type_str": "table",
                "text": "Table 6 summarizes accuracies for these types of commonsense questions compared to humans.",
                "html": null,
                "num": null
            },
            "TABREF9": {
                "content": "<table/>",
                "type_str": "table",
                "text": "The performance of models across different commonsense categories, in terms of accuracy on examples annotated with that category (%). The strongest category of each model is highlighted.",
                "html": null,
                "num": null
            },
            "TABREF10": {
                "content": "<table><tr><td colspan=\"2\">2. Significant grammar or spelling errors</td></tr><tr><td>Paired sentences</td><td>Possible answers</td></tr><tr><td>fallten data are very much trusted</td><td>fallten are nice</td></tr><tr><td>fallten data are very valuable</td><td>flatten are safe</td></tr><tr><td>CAR IS BIRD FEATHEAR</td><td>CAR SITE IS ROUGH</td></tr><tr><td>CAR IS COTTON</td><td>CAR SITE IS HARD</td></tr><tr><td>Inflation is as natural as Minnesota rainfall in June</td><td>Inflation is perfectly natural</td></tr><tr><td colspan=\"2\">Inflation is as natural as Minnesota snowfall in June Patient is in a natural result of other things</td></tr></table>",
                "type_str": "table",
                "text": "Examples that were rejected due to being nonsensical.",
                "html": null,
                "num": null
            },
            "TABREF11": {
                "content": "<table><tr><td>3. Do not follow format</td><td/></tr><tr><td>Paired sentences</td><td>Possible answers</td></tr><tr><td>This attack is as weak as a feather</td><td>The attack is useless</td></tr><tr><td>This attack is as weak as a breeze</td><td>The attack doesn't work</td></tr><tr><td>My car motor is dusty like old cave</td><td>Car motor is very rusty</td></tr><tr><td>My car motor is dusty like abandon building</td><td>car motor is very dusty</td></tr><tr><td>the writer is</td><td/></tr></table>",
                "type_str": "table",
                "text": "Examples that were rejected due to having significant spelling or grammar errors. stuck between a rock And another hard place He is just stuck doesnt have a choice the writer is stuck between a rock And a pebble The writer can get over the pebble",
                "html": null,
                "num": null
            },
            "TABREF12": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Examples that were rejected due to not following the specified format.",
                "html": null,
                "num": null
            },
            "TABREF13": {
                "content": "<table><tr><td>Model</td><td colspan=\"2\">Zero-shot Fine-tuned (L)</td></tr><tr><td>GPT-2</td><td>52.18</td><td>52.00</td></tr><tr><td>GPT-neo 1.3B</td><td>54.36</td><td>63.44</td></tr><tr><td>GPT-3 Curie</td><td>58.46</td><td>74.83</td></tr><tr><td colspan=\"2\">D Paired accuracies</td><td/></tr><tr><td>Model</td><td/><td>Accuracy (pairs correct)</td></tr><tr><td colspan=\"2\">GPT-2 zero-shot</td><td>6.63</td></tr><tr><td colspan=\"2\">GPT-2 finetuned</td><td>5.06</td></tr><tr><td colspan=\"2\">GPT-neo zero-shot</td><td>10.3</td></tr><tr><td colspan=\"2\">GPT-neo finetuned</td><td>10.3</td></tr><tr><td colspan=\"2\">GPT-3 Curie zero-shot</td><td>17.4</td></tr><tr><td colspan=\"2\">GPT-3 Curie finetuned</td><td>50.0</td></tr><tr><td colspan=\"2\">BERT finetuned</td><td>70.6</td></tr><tr><td colspan=\"2\">RoBERTa finetuned</td><td>80.4</td></tr><tr><td colspan=\"2\">Human</td><td>89.7</td></tr></table>",
                "type_str": "table",
                "text": "Zero-shot and finetuned backward autoregressive model accuracies on the test set",
                "html": null,
                "num": null
            },
            "TABREF14": {
                "content": "<table><tr><td colspan=\"2\">E Accuracy breakdown by Part-of-Speech</td><td/></tr><tr><td>E.1 Subject</td><td/><td/></tr><tr><td colspan=\"3\">Part of speech Accuracy Frequency</td></tr><tr><td>NN</td><td>0.8569</td><td>538</td></tr><tr><td>PRP</td><td>0.8526</td><td>156</td></tr><tr><td>PRP$ NN</td><td>0.9</td><td>110</td></tr><tr><td>NN NN</td><td>0.8889</td><td>63</td></tr><tr><td>DT NN</td><td>0.8182</td><td>44</td></tr><tr><td>NN NN NN</td><td>0.9375</td><td>32</td></tr><tr><td>JJ NN</td><td>0.9167</td><td>12</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy for models on the test set, counted in terms of pairs of sentences in which both are correct (%). Results are from one run.",
                "html": null,
                "num": null
            },
            "TABREF15": {
                "content": "<table><tr><td>E.2 Relation</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy breakdown and frequency of parts of speech in metaphor subjects. Only part-of-speech patterns with greater than 10 occurrences are shown.",
                "html": null,
                "num": null
            },
            "TABREF16": {
                "content": "<table><tr><td>E.3 Object</td><td/><td/></tr><tr><td colspan=\"3\">Part of speech Accuracy Frequency</td></tr><tr><td>NN</td><td>0.8788</td><td>429</td></tr><tr><td>NN NN</td><td>0.8992</td><td>129</td></tr><tr><td>JJ NN</td><td>0.8352</td><td>91</td></tr><tr><td>NN IN NN</td><td>0.8372</td><td>43</td></tr><tr><td>JJ NN NN</td><td>0.8710</td><td>31</td></tr><tr><td>NN NN NN</td><td>0.9130</td><td>23</td></tr><tr><td>VBG NN</td><td>0.9545</td><td>22</td></tr><tr><td>NN IN JJ NN</td><td>0.6154</td><td>13</td></tr><tr><td>PRP$ NN</td><td>1.0</td><td>11</td></tr><tr><td>JJ</td><td>0.6364</td><td>11</td></tr><tr><td>NN IN NN NN</td><td>0.8182</td><td>11</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy breakdown and frequency of parts of speech in metaphor relations. Only part-of-speech patterns with greater than 10 occurrences are shown.",
                "html": null,
                "num": null
            },
            "TABREF17": {
                "content": "<table><tr><td>F Accuracy breakdown by hypernyms</td></tr><tr><td>F.1 Subject</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy breakdown and frequency of parts of speech in metaphor objects. Only part-of-speech patterns with greater than 10 occurrences are shown.",
                "html": null,
                "num": null
            },
            "TABREF18": {
                "content": "<table><tr><td>F.2 Object</td></tr></table>",
                "type_str": "table",
                "text": "Accuracy breakdown and frequency of Word-Net hypernyms in metaphor subjects. Only hypernyms with 10 or greater occurrences are shown.",
                "html": null,
                "num": null
            },
            "TABREF19": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Accuracy breakdown and frequency of Word-Net hypernyms in metaphor objects. Only hypernyms with 10 or greater occurrences are shown.",
                "html": null,
                "num": null
            }
        }
    }
}