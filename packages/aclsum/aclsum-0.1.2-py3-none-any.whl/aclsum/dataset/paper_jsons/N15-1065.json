{
    "paper_id": "N15-1065",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:04:19.846365Z"
    },
    "title": "Expanding Paraphrase Lexicons by Exploiting Lexical Variants",
    "authors": [
        {
            "first": "Atsushi",
            "middle": [],
            "last": "Fujita",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National Institute of Information",
                "location": {
                    "addrLine": "3-5 Hikaridai, Seika-cho, Souraku-gun",
                    "postCode": "619-0289",
                    "settlement": "Kyoto",
                    "country": "Japan"
                }
            },
            "email": "atsushi.fujita@nict.go.jp"
        },
        {
            "first": "Pierre",
            "middle": [],
            "last": "Isabelle",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National Research Council",
                "location": {
                    "addrLine": "1200 Montreal Road",
                    "postCode": "K1A 0R6",
                    "settlement": "Ottawa",
                    "region": "Ontario",
                    "country": "Canada, Canada"
                }
            },
            "email": "pierre.isabelle@nrc.ca"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "This study tackles the problem of paraphrase acquisition: achieving high coverage as well as accuracy. Our method first induces paraphrase patterns from given seed paraphrases, exploiting the generality of paraphrases exhibited by pairs of lexical variants, e.g., \"amendment\" and \"amending,\" in a fully empirical way. It then searches monolingual corpora for new paraphrases that match the patterns. This can extract paraphrases comprising words that are completely different from those of the given seeds. In experiments, our method expanded seed sets by factors of 42 to 206, gaining 84% to 208% more coverage than a previous method that generalizes only identical word forms. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrases retained reasonable quality, given substantially high-quality seeds.",
    "pdf_parse": {
        "paper_id": "N15-1065",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "This study tackles the problem of paraphrase acquisition: achieving high coverage as well as accuracy. Our method first induces paraphrase patterns from given seed paraphrases, exploiting the generality of paraphrases exhibited by pairs of lexical variants, e.g., \"amendment\" and \"amending,\" in a fully empirical way. It then searches monolingual corpora for new paraphrases that match the patterns. This can extract paraphrases comprising words that are completely different from those of the given seeds. In experiments, our method expanded seed sets by factors of 42 to 206, gaining 84% to 208% more coverage than a previous method that generalizes only identical word forms. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrases retained reasonable quality, given substantially high-quality seeds.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "One of the characteristics of human languages is that the same semantic content can be expressed using several different linguistic expressions, i.e., paraphrases. Dealing with paraphrases is an important issue in a broad range of natural language processing (NLP) tasks (Madnani and Dorr, 2010; Androutsopoulos and Malakasiotis, 2010) .",
                "cite_spans": [
                    {
                        "start": 271,
                        "end": 295,
                        "text": "(Madnani and Dorr, 2010;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 296,
                        "end": 335,
                        "text": "Androutsopoulos and Malakasiotis, 2010)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "To adequately and robustly deal with paraphrases, a large-scale knowledge base containing words and phrases having approximately the same meaning is indispensable. Thus, the task of automatically creating such large-scale paraphrase lexicons has been drawing the attention of many researchers (see Section 2 for details). The challenge is to en-sure substantial coverage along with high accuracy despite the natural tension between these factors. Among the different types of language resources, monolingual corpora1 offer the largest coverage, but the quality of the extracted candidates is generally rather low. The difficulty lies in the manner of distinguishing paraphrases from expressions that stand in different semantic relations, e.g., antonyms and sibling words, using only the statistics estimated from such corpora. In contrast, highly accurate paraphrases can be extracted from parallel or comparable corpora, but their coverage is limited owing to the limited availability of such corpora for most languages.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "This study aims to improve coverage while maintaining accuracy. To that end, we propose a method that exploits the generality exhibited by pairs of lexical variants. Given a seed set of paraphrase pairs, our method first induces paraphrase patterns by generalizing not only identical word forms (Fujita et al., 2012) but also pairs of lexical variants. For instance, from a seed pair (1a), a pattern (1b) is acquired, where the pair of lexical variants (\"amendment\", \"amending\") and the shared word form \"regulation\" are generalized.",
                "cite_spans": [
                    {
                        "start": 295,
                        "end": 316,
                        "text": "(Fujita et al., 2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(1) a. amendment of regulation \u21d4 amending regulation b. X:ment of Y :\u03d5 \u21d4 X:ing Y :\u03d5 With such patterns, new paraphrase pairs that would have been missed using only the surface forms are extracted from a monolingual corpus. Obtainable pairs can include those comprising words that are completely different from those of the seed paraphrases, e.g., (2a) and (2b).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(2) a. investment of resources \u21d4 investing resources b. recruitment of engineers \u21d4 recruiting engineers While the generality underlying paraphrases has been exploited either by handcrafted rules (Harris, 1957; Mel'\u010duk and Polgu\u00e8re, 1987; Jacquemin, 1999; Fujita et al., 2007) or by data-driven techniques (Ganitkevitch et al., 2011; Fujita et al., 2012) , we still lack a robust and accurate way of identifying various types of lexical variants. Our method tackles this issue using affix patterns that are also acquired from high-quality seed paraphrases in a fully empirical way. Consequently, our method has the potential to apply to many languages.",
                "cite_spans": [
                    {
                        "start": 195,
                        "end": 209,
                        "text": "(Harris, 1957;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 210,
                        "end": 237,
                        "text": "Mel'\u010duk and Polgu\u00e8re, 1987;",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 238,
                        "end": 254,
                        "text": "Jacquemin, 1999;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 255,
                        "end": 275,
                        "text": "Fujita et al., 2007)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 305,
                        "end": 332,
                        "text": "(Ganitkevitch et al., 2011;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 333,
                        "end": 353,
                        "text": "Fujita et al., 2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Researchers have been intensively studying methods for automatically creating paraphrase lexicons using various types of corpora. There are two major streams: one that uses monolingual corpora and one that uses parallel or comparable corpora.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Creating Paraphrase Lexicons",
                "sec_num": "2.1"
            },
            {
                "text": "A monolingual corpus is the most promising resource when targeting increased coverage, thanks to the availability of Web-scale monolingual data. Techniques that use such corpora mostly extract pairs of expressions by exploiting the contextual similarity associated with the Distributional Hypothesis (Harris, 1954) . A given expression is represented with its co-occurring expressions such as adjacent word n-grams (Pas \u00b8ca and Dienes, 2005; Bhagat and Ravichandran, 2008; Marton, 2013) , nominal elements (Lin and Pantel, 2001; Szpektor et al., 2004; De Saeger et al., 2011) , and modifiers and modified words (Hagiwara et al., 2006) . The similarity of a pair of expressions is calculated by comparing the distributions of their contexts.",
                "cite_spans": [
                    {
                        "start": 300,
                        "end": 314,
                        "text": "(Harris, 1954)",
                        "ref_id": null
                    },
                    {
                        "start": 415,
                        "end": 441,
                        "text": "(Pas \u00b8ca and Dienes, 2005;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 442,
                        "end": 472,
                        "text": "Bhagat and Ravichandran, 2008;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 473,
                        "end": 486,
                        "text": "Marton, 2013)",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 506,
                        "end": 528,
                        "text": "(Lin and Pantel, 2001;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 529,
                        "end": 551,
                        "text": "Szpektor et al., 2004;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 552,
                        "end": 575,
                        "text": "De Saeger et al., 2011)",
                        "ref_id": null
                    },
                    {
                        "start": 611,
                        "end": 634,
                        "text": "(Hagiwara et al., 2006)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual Corpora",
                "sec_num": "2.1.1"
            },
            {
                "text": "Despite the quantitative advantage, this approach tends to result in low accuracy. This is because contextual information alone often fails to differentiate paraphrases from expressions that have other semantic relations, e.g., antonyms and sibling words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual Corpora",
                "sec_num": "2.1.1"
            },
            {
                "text": "Much effort has gone into compiling monolingual parallel corpora and extracting paraphrases from them by identifying corresponding parts of aligned sentences. Barzilay and McKeown (2001) and Pang et al. (2003) collected multiple human translations of the same source text. Multiple verbalizations of mathematical proofs were also used (Barzilay and Lee, 2002) . This triangulating method provides solid anchors that guarantee the semantic equivalence of sentences (or text fragments).",
                "cite_spans": [
                    {
                        "start": 159,
                        "end": 186,
                        "text": "Barzilay and McKeown (2001)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 191,
                        "end": 209,
                        "text": "Pang et al. (2003)",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 335,
                        "end": 359,
                        "text": "(Barzilay and Lee, 2002)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parallel and Comparable Corpora",
                "sec_num": "2.1.2"
            },
            {
                "text": "Monolingual comparable corpora are also useful sources of paraphrases. For instance, articles from different newswire services describing the same event can be used in that way (Shinyama et al., 2002; Barzilay and Elhadad, 2003; Dolan et al., 2004; Wubben et al., 2009) . Chen and Dolan (2011) created such corpora by collecting multiple descriptions of short movies through crowdsourcing. Webharvested definition sentences of the same term often contain paraphrases (Hashimoto et al., 2011; Yan et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 177,
                        "end": 200,
                        "text": "(Shinyama et al., 2002;",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 201,
                        "end": 228,
                        "text": "Barzilay and Elhadad, 2003;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 229,
                        "end": 248,
                        "text": "Dolan et al., 2004;",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 249,
                        "end": 269,
                        "text": "Wubben et al., 2009)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 272,
                        "end": 293,
                        "text": "Chen and Dolan (2011)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 467,
                        "end": 491,
                        "text": "(Hashimoto et al., 2011;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 492,
                        "end": 509,
                        "text": "Yan et al., 2013)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parallel and Comparable Corpora",
                "sec_num": "2.1.2"
            },
            {
                "text": "Bilingual parallel corpora have been recognized as sources of paraphrases since (Bannard and Callison-Burch, 2005) . First, a translation table is created using techniques developed for statistical machine translation. Then, pairs of expressions in the same language that share the same translations are extracted. For instance, a pair (\"under control\", \"in check\") will be extracted if they are both linked with the German translation \"unter controlle.\" Each paraphrase pair (e 1 , e 2 ) is assigned probabilities, p(e 2 |e 1 ) and p(e 1 |e 2 ), estimated by marginalizing over all the translations F shared by e 1 and e 2 , i.e., p(e 2 |e 1 ) = \u2211 f \u2208F p(e 2 |f )p(f |e 1 ). This bilingual pivoting approach inspired further techniques such as the use of syntactic information as the basis of constraints (Callison-Burch, 2008; Zhao et al., 2009) , learning patterns using synchronous grammar (Ganitkevitch et al., 2011) , uncovering missing links by combining multiple translation tables and other lexical resources (Kok and Brockett, 2010) , and re-ranking candidate pairs on the basis of contextual similarity (Chan et al., 2011) . Ganitkevitch and Callison-Burch (2014) compiled paraphrase lexicons for various languages on this approach.",
                "cite_spans": [
                    {
                        "start": 80,
                        "end": 114,
                        "text": "(Bannard and Callison-Burch, 2005)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 806,
                        "end": 828,
                        "text": "(Callison-Burch, 2008;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 829,
                        "end": 847,
                        "text": "Zhao et al., 2009)",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 894,
                        "end": 921,
                        "text": "(Ganitkevitch et al., 2011)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 1018,
                        "end": 1042,
                        "text": "(Kok and Brockett, 2010)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 1114,
                        "end": 1133,
                        "text": "(Chan et al., 2011)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 1136,
                        "end": 1174,
                        "text": "Ganitkevitch and Callison-Burch (2014)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parallel and Comparable Corpora",
                "sec_num": "2.1.2"
            },
            {
                "text": "Parallel/comparable corpora are useful sources of highly accurate paraphrases. However, for most languages, only small paraphrase lexicons can be created due to the limited availability of such corpora.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parallel and Comparable Corpora",
                "sec_num": "2.1.2"
            },
            {
                "text": "Unlike the above methods, which used only a single type of corpus as sources of paraphrases, Fujita et al. (2012) used both bilingual parallel and monolingual corpora as sources. In that method, paraphrase pairs, e.g., (3a), are first acquired from a bilingual parallel corpus using the bilingual pivoting method and several heuristic filters for drastic noise reduction. Second, each paraphrase pair is generalized into a paraphrase pattern2 , e.g., (3b). Finally, new pairs, e.g., (3c), are extracted from a monolingual corpus using the patterns.",
                "cite_spans": [
                    {
                        "start": 93,
                        "end": 113,
                        "text": "Fujita et al. (2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Combination of Multiple Corpora",
                "sec_num": "2.1.3"
            },
            {
                "text": "(3) a. amendment of regulation \u21d4 amending regulation b. amendment of X \u21d4 amending X c. amendment of documents \u21d4 amending documents Using that method, they were able to expand the seed lexicon by a large multiple (15 to 40 times), and the new paraphrase pairs were of reasonably good quality. However, they introduced variables only for identical word forms shared by both sides of each pair and left corresponding pairs of lexical variants, e.g., (\"amendment\", \"amending\") in (3a), untouched.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Combination of Multiple Corpora",
                "sec_num": "2.1.3"
            },
            {
                "text": "In this study, the term lexical variants covers, at least, the following three types of word groups. Lexical derivations: different words that share the same stem and a large part of their meaning, e.g., {\"develop\", \"developer\", \"development\", . . .}. Words in such a group can have different parts-of-speech. Morphological variants: different surface forms of the same word, e.g., {\"amend\", \"amends\", \"amending\", . . .}. These are derived based on processes such as inflection and conjugation. Orthographic variants: different spellings of the same inflectional/conjugation form of the same word, e.g., {\"color\", \"colour\"} and {\"authorize\", \"authorise\"}. Several syntactic and semantic theories, such as transformational grammar (Harris, 1957) and Meaning-Text Theory (Mel'\u010duk and Polgu\u00e8re, 1987) , propose a representation of paraphrases that involve alternations of lexical variants. Jacquemin (1999) and Fujita et al. (2007) addressed this type of paraphrase using manually described syntactic transformation patterns in combination with dictionaries of lexical variants.",
                "cite_spans": [
                    {
                        "start": 730,
                        "end": 744,
                        "text": "(Harris, 1957)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 769,
                        "end": 797,
                        "text": "(Mel'\u010duk and Polgu\u00e8re, 1987)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 887,
                        "end": 903,
                        "text": "Jacquemin (1999)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 908,
                        "end": 928,
                        "text": "Fujita et al. (2007)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dealing with Lexical Variants",
                "sec_num": "2.2"
            },
            {
                "text": "Catvar (Habash and Dorr, 2003 ) is a comprehensive lexical derivation database for English. Word-Net (Fellbaum, 1998 ) also contains information of that kind and is currently available for various languages. Despite its high accuracy, manual creation of rich lexical resources requires a large human effort. Gaussier (1999) and Fujita et al. (2007) extracted groups of lexical derivations from a list of headwords of dictionaries through mining affix patterns. This approach significantly reduces human effort, maintaining reasonable accuracy, but the coverage is still limited because of the reliance on manually compiled dictionaries.",
                "cite_spans": [
                    {
                        "start": 7,
                        "end": 29,
                        "text": "(Habash and Dorr, 2003",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 101,
                        "end": 116,
                        "text": "(Fellbaum, 1998",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 308,
                        "end": 323,
                        "text": "Gaussier (1999)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 328,
                        "end": 348,
                        "text": "Fujita et al. (2007)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dealing with Lexical Variants",
                "sec_num": "2.2"
            },
            {
                "text": "This study is the first attempt to exploit various types of lexical variants for acquiring paraphrases in a completely empirical way.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "3"
            },
            {
                "text": "Given a seed paraphrase lexicon (S Seed ) our method (henceforth LEXVAR) expands it in two steps (see also Figure 1 ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 114,
                        "end": 115,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "3"
            },
            {
                "text": "Step 1. Learning paraphrase patterns: From S Seed , we learn a set of paraphrase patterns, generalizing various types of lexical variants in addition to identical word forms.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "3"
            },
            {
                "text": "Step 2. Harvesting new paraphrase pairs: Using the learned paraphrase patterns, we harvest a set of new paraphrase pairs (S LV ) from monolingual corpora. LEXVAR subsumes Fujita et al. (2012) 's method explained in Section 2.1.3 (henceforth IDENT), and its output S LV always subsumes IDENT's output (S ID ). As LEXVAR and IDENT have the effect of expanding pre-existing paraphrase lexicons, they can be used as a complement to the other methods for acquiring paraphrases, provided they produce a",
                "cite_spans": [
                    {
                        "start": 171,
                        "end": 191,
                        "text": "Fujita et al. (2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Method",
                "sec_num": "3"
            },
            {
                "text": "Corpus",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "airports!in!Europe! !European!airports+ amendment!of!regula1on! !amending!regula1on+ should!be!noted!that! !is!worth!no1ng!that!",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "S Seed : seed paraphrase pairs",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "X:\u03c6!in!Y:\u03c6! !Y:an!X:\u03c6! X:ment!of!Y:\u03c6! !X:ing!Y:\u03c6! should!be!X:ed!that! !is!worth!X:ing!that! S LV : new paraphrase pairs Paraphrase patterns cohesion!in!Europe! !European!cohesion+ democracy!in!Europe! !European!democracy+ increase!in!Hai1! !Hai1an!increase+ transporta1on!in!suburb! !suburban!transporta1on+ economy!in!Uruguay! !Uruguayan!economy+ amendment!of!documents+ !amending!documents+ amendment!of!protocol+ !amending!protocol+ investment!of!resources+ !investing!resources+ recruitment!of!engineers+ !recruiting!engineers+ should!be!highlighted!that! !is!worth!highlighting!that! should!be!reiterated!that! !is!worth!reiterating!that! should!be!stated!that! !is!worth!stating!that!",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "Step 2. Harvesting New Paraphrase Pairs",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "Step 1. Learning Paraphrase Patterns sufficient number of high-quality pairs to make lexical generalization possible.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Monolingual",
                "sec_num": null
            },
            {
                "text": "Our method requires as input a seed paraphrase lexicon (S Seed ) that has high quality and preferably exhibits various lexical correspondences that our method will exploit. For this purpose, paraphrases acquired from bilingual or monolingual parallel corpora are preferable (see Section 2.1.2).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 0. Acquiring Seed Paraphrase Pairs",
                "sec_num": "3.0"
            },
            {
                "text": "In this study, we take the bilingual pivoting method as an example for the sake of reproducibility. However, the method also outputs a large number of non-paraphrases. To obtain further clean seeds, we apply several filters as described in (Fujita et al., 2012) and discard pairs that have low paraphrase probability, i.e., p(e 2 |e 1 ) < 0.01, following the convention in (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2010; Fujita et al., 2012) .",
                "cite_spans": [
                    {
                        "start": 240,
                        "end": 261,
                        "text": "(Fujita et al., 2012)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 373,
                        "end": 390,
                        "text": "(Du et al., 2010;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 391,
                        "end": 401,
                        "text": "Max, 2010;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 402,
                        "end": 428,
                        "text": "Denkowski and Lavie, 2010;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 429,
                        "end": 449,
                        "text": "Fujita et al., 2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 0. Acquiring Seed Paraphrase Pairs",
                "sec_num": "3.0"
            },
            {
                "text": "Previous work (Chan et al., 2011; Fujita et al., 2012; Ganitkevitch et al., 2013) has proved that the information obtained from monolingual data can be used for assessing bilingually originated paraphrases. Thus, pairs that have low contextual similarity are also filtered out. Among various recipes for computing contextual similarity, we use a simple one: cosine measure of two context vectors comprising adjacent word 1-4 grams of all of the phrase appearances in given monolingual data. For a fair com-parison with previous work, we eliminate only pairs that have no shared context, i.e., Sim(e 1 , e 2 ) = 0.",
                "cite_spans": [
                    {
                        "start": 14,
                        "end": 33,
                        "text": "(Chan et al., 2011;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 34,
                        "end": 54,
                        "text": "Fujita et al., 2012;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 55,
                        "end": 81,
                        "text": "Ganitkevitch et al., 2013)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 0. Acquiring Seed Paraphrase Pairs",
                "sec_num": "3.0"
            },
            {
                "text": "Given a set of seed paraphrases (S Seed ) we first induce a set of paraphrase patterns. From a seed paraphrase (4a), for instance, while IDENT learns (4b), LEXVAR generates (4c) by exploiting the generality exhibited by corresponding pairs of lexical variants, i.e., (\"amendment\", \"amending\").",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 1. Learning Paraphrase Patterns",
                "sec_num": "3.1"
            },
            {
                "text": "(4) a. amendment of regulation \u21d4 amending regulation b. amendment of X \u21d4 amending X c. X:ment of Y :\u03d5 \u21d4 X:ing Y :\u03d5",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 1. Learning Paraphrase Patterns",
                "sec_num": "3.1"
            },
            {
                "text": "The central issue at this stage is to robustly and accurately identify various types of lexical variants. We examine a data-driven approach, targeting for increased coverage, but manually created resources such as dictionaries can also be used.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 1. Learning Paraphrase Patterns",
                "sec_num": "3.1"
            },
            {
                "text": "As exemplified by (\"X:ment\", \"X:ing\") in (4c), we represent pairs of lexical variants with affix patterns. While Gaussier (1999) considered only suffix patterns, we also deal with prefix patterns such as those exhibited by (\"reliable\", \"unreliable\") and (\"exist\", \"coexist\") observed in the following paraphrase pairs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "(5) a. is not reliable \u21d4 is unreliable b. exist together with \u21d4 coexist with However, we currently do not consider prefix/suffix combinations, such as (\"directly\", \"indirect\") and (\"believed\", \"unbelievable\"), and other types of affixes than prefixes and suffixes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "Reliable affix patterns are collected from S Seed (cf., headwords of manually compiled dictionaries (Gaussier, 1999; Fujita et al., 2007) ). First, candidates of affix patterns are extracted from S Seed on the following assumption.",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 116,
                        "text": "(Gaussier, 1999;",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 117,
                        "end": 137,
                        "text": "Fujita et al., 2007)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "A pair of words will share a definite semantic relation if the words appear on opposite sides of a paraphrase pair and have the same stem.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "We do not rely on any language resources to identify the stems of words. Instead, we regard word pairs that share at least one character as candidate pairs of lexical variants and extract the longest common prefix/suffix as their corresponding affix patterns. From a paraphrase pair (6), for instance, we separately extract four pairs of words and their corresponding affix patterns, as shown in Table 1 . ( 6) is aimed at achieving \u21d4 aims to achieve Our candidate affix patterns are then filtered using the following criterion (Gaussier, 1999) .",
                "cite_spans": [
                    {
                        "start": 528,
                        "end": 544,
                        "text": "(Gaussier, 1999)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 402,
                        "end": 403,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "An affix pattern is retained iff it is associated with at least n unique stems that are at least k characters in length. This criterion relies on two parameters, n and k. The parameter n assesses whether a pattern is sufficiently productive. The other (k) is more linguistically motivated: a genuine pattern is more likely to be used for long stems, as affixation is a general operation for producing lexical derivations in many languages. In particular, we set k = 5 and n = 2, as proposed in (Gaussier, 1999) . Table 2 presents examples of filtering affix patterns eliminated and retained with this setting.",
                "cite_spans": [
                    {
                        "start": 494,
                        "end": 510,
                        "text": "(Gaussier, 1999)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 519,
                        "end": 520,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Collecting Affix Patterns",
                "sec_num": "3.1.1"
            },
            {
                "text": "Using the affix patterns acquired in the previous step, paraphrase patterns are generated from the seed paraphrase pairs in S Seed . In this step, we exhaustively consider all the combinations of word forms and lexical variants that match one of the affix patterns. From the paraphrase pair (6), the following pattern is generated. ( 7) is X:ed at Y :ing \u21d4 X:s to Y :e Thanks to the above filtering mechanism, spurious patterns, such as (8), are not generated.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generating Paraphrase Patterns",
                "sec_num": "3.1.2"
            },
            {
                "text": "(8) is X:imed at Y :chieving \u21d4 Y :ims to X:chieve",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generating Paraphrase Patterns",
                "sec_num": "3.1.2"
            },
            {
                "text": "Given a set of paraphrase patterns, e.g., (4c) and ( 7), new paraphrase pairs are harvested from monolingual corpora. In this process, each paraphrase pattern is used as a template such that the expressions that match both sides of the patterns are collected. Unlike IDENT's patterns, e.g., (4b), LEXVAR also collects corresponding pairs of lexical variants designated by each pattern. However, affix pattern alone cannot guarantee the semantic relation between a corresponding pair of words that each paraphrase pattern implicitly requires. For instance, the pattern (9b) is learned from (9a), where a definite relation is assumed between the two elements of (\"X:\u03d5\", \"X:an\").",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 2. Harvesting New Paraphrase Pairs",
                "sec_num": "3.2"
            },
            {
                "text": "(9) a. countries of Europe \u21d4 European nations b. countries of X:\u03d5 \u21d4 X:an nations Word pairs inappropriate for this pattern, e.g., (\"uncle\", \"unclean\") and (\"beg\", \"began\"), would be extracted alongside appropriate ones, e.g., (\"Haiti\", \"Haitian\") and (\"suburb\", \"suburban\"). Nonetheless, we suppose that the other surface parts of each paraphrase pair, e.g., \"countries of\" and \"nations\" in (9b), can effectively constrain instances, guaranteeing the existence of each entire phrase of the pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 2. Harvesting New Paraphrase Pairs",
                "sec_num": "3.2"
            },
            {
                "text": "Pattern matching alone can generate pairs that are not suitable as paraphrases in any context. Thus, we assess the reliability of each pair by calculating contextual similarity between two phrases in the same manner as cleaning S Seed : a pair of phrases is eliminated, if the phrases are used in completely dissimilar contexts.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Step 2. Harvesting New Paraphrase Pairs",
                "sec_num": "3.2"
            },
            {
                "text": "While LEXVAR exploits a kind of generality of paraphrases exhibited by pairs of lexical variants, it does not exploit paraphrase pairs comprising completely different surface forms such as those pairs in (10).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Limitation",
                "sec_num": "3.3"
            },
            {
                "text": "(10) a. look like \u21d4 resemble b. burst into tears \u21d4 cry",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Limitation",
                "sec_num": "3.3"
            },
            {
                "text": "To create further large paraphrase lexicons, we need to acquire these idiosyncratic paraphrases by improving existing methods and/or exploring yet another approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Limitation",
                "sec_num": "3.3"
            },
            {
                "text": "Another limitation of LEXVAR is that it considers only prefixes and suffixes of words as clues of lexical correspondences. We will need extensions to deal with a wider range of lexical correspondences. For instance, depending on the targeted language, other types of affixes, such as infixes and circumfixes, should be taken into account. Gaussier (1999) pointed out that some lexical derivations involve character-level alternations, e.g., \"c\" and \"c \u00b8. \" Fujita et al. (2007) demonstrated that lexical derivations in an ideographic language, i.e., Japanese, can be captured by considering both ideographs and their phonetic transcriptions.",
                "cite_spans": [
                    {
                        "start": 339,
                        "end": 354,
                        "text": "Gaussier (1999)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 455,
                        "end": 477,
                        "text": "\" Fujita et al. (2007)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Limitation",
                "sec_num": "3.3"
            },
            {
                "text": "Last but not least, as LEXVAR regards only corpus as source, it does not acquire paraphrases that do not appear in a given corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Limitation",
                "sec_num": "3.3"
            },
            {
                "text": "To what extent can our LEXVAR method expand a given paraphrase lexicon? We examined this, taking English as a target language and the bilingual pivoting method as the means of acquiring S Seed .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expanding Paraphrase Lexicons",
                "sec_num": "4"
            },
            {
                "text": "We conducted experiments on the following two corpora configurations. 2012), we used the stoplists available on the Web9 : 571 English and 463 French words. For Japanese, we manually listed 160 morphemes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Seed Paraphrase Pairs",
                "sec_num": "4.1"
            },
            {
                "text": "Paraphrase patterns were learned from the set of seed paraphrase pairs. Figure 2 shows the numbers of the acquired paraphrase patterns and the percentages of paraphrase pairs in the seed lexicon, S Seed , covered by the patterns. As illustrated by example (4), LEXVAR learns more general paraphrase patterns than IDENT. Applied to another seed paraphrase pair (11a), IDENT will generate another pattern (11b), but LEXVAR will not: the corresponding (4c) is already learned.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 79,
                        "end": 80,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Paraphrase Patterns",
                "sec_num": "4.2"
            },
            {
                "text": "(11) a. development of tourism \u21d4 developing tourism b. development of X \u21d4 developing X On the other hand, LEXVAR also learns patterns from seed paraphrase pairs that IDENT ignores, e.g., ( 6) and (9a). Consequently, a wider range of seed paraphrases were involved in learning patterns and more patterns were acquired.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Patterns",
                "sec_num": "4.2"
            },
            {
                "text": "Finally, new paraphrases were acquired from the monolingual data. At this time, only single words were regarded as potential slot-fillers for the patterns. Recall that S LV and S ID are the sets of paraphrases generated by LEXVAR and IDENT, respectively, and S LV \u2287 S ID . Pairs that appeared in S Seed and those used in completely dissimilar contexts were excluded from both S ID and S LV .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "New Paraphrase Pairs",
                "sec_num": "4.3"
            },
            {
                "text": "Figure 3 demonstrates that, irrespective of the size of the bilingual corpus, LEXVAR yielded far more (relative) coverage of paraphrase pairs S LV than not only S Seed but also S ID . When the full bilingual corpora were used, S LV contained 63.8 M and 137.6 M paraphrase pairs in the two respective settings, while S ID contained only 26.8 M and 53.0 M pairs. The seed set S Seed can be pooled with S LV ; thus, LEXVAR expanded S Seed by approximately 67 and 101 times in the two respective settings. Figure 4 illustrates the ratio of the expanded parts of the paraphrase lexicons S LV and S ID against the seed set S Seed . The ratio of S LV against S Seed ranged over 41-109 and 100-205 in the two respective settings. This figure also emphasizes the visible advantage of S LV over S ID : 84%-208% and 139%-159% more coverage. We expected that the more the bilingual data there are, the lower the leverage ratio is, because when a larger bilingual corpus is used, more seed paraphrases can be acquired, and the relative size of the monolingual data compared to the bilingual is lower. While the leverage ratio in the NTCIR setting follows this, the ratio in the Europarl setting does not: it peaks at approximately the middle of the scale. We found that from a very small bilingual corpus, we do not necessarily obtain seed paraphrases that exhibit the generality exploited by LEXVAR and IDENT. In this case, the leverage ratio cannot be extremely high despite the large difference in the corpora sizes.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 509,
                        "end": 510,
                        "text": "4",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "New Paraphrase Pairs",
                "sec_num": "4.3"
            },
            {
                "text": "LEXVAR also largely contributed to discovering paraphrases for phrases that were not paraphrased using only S Seed and S ID . The ratio of the numbers of unique left-hand side phrases in S LV to those in S Seed ranged over 65-147 and 92-415 in the two respective settings, gaining 76%-210% and 145%-175% more coverage than S ID .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "New Paraphrase Pairs",
                "sec_num": "4.3"
            },
            {
                "text": "The quality of the created paraphrase lexicons was manually evaluated through a paraphrase substitution test: we generated pairs of paraphrase sentences using the paraphrase lexicons and asked human evaluators to assess their quality.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Quality Assessment",
                "sec_num": "5"
            },
            {
                "text": "Generating paraphrased sentences by substituting words and phrases involves two different tasks: generating new sentences and ensuring that the meaning is preserved. It is therefore straightforward to separately evaluate the grammaticality and meaning equivalence of each paraphrased sentence (Callison-Burch, 2008) . Grammaticality: whether the paraphrased sentence is grammatical Meaning equivalence: whether the meaning of the original sentence is properly preserved by the paraphrased sentence We adopted the detailed criteria and procedure described in (Fujita, 2013) , as they resulted in a reasonably high inter-evaluator agreement ratio. The evaluation protocol is characterized by the following three features introduced for reducing human labor and making results consistent. Unit-wise: Several paraphrase examples for the same source are packaged into an example unit and provided at the same time. Two-phased: Evaluators are first asked to assess only the grammaticality of each paraphrased sentence without seeing the original sentence. Then, by comparing each pair of original and paraphrased sentences, they assess to what extent the paraphrased sentence retains the meaning of its counterpart.",
                "cite_spans": [
                    {
                        "start": 293,
                        "end": 315,
                        "text": "(Callison-Burch, 2008)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 558,
                        "end": 572,
                        "text": "(Fujita, 2013)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Criteria and Procedure",
                "sec_num": "5.1"
            },
            {
                "text": "Classification-based: Evaluators are asked to classify each example into one of the predetermined categories, guided by the decision trees respectively designed for evaluating grammaticality and meaning equivalence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Criteria and Procedure",
                "sec_num": "5.1"
            },
            {
                "text": "We used news sentences as in (Callison-Burch, 2008; Fujita et al., 2012) : the English sentences from WMT 2011-2013 \"newstest\" data (9,000 unique sentences). To reduce the human labor for the evaluation, they were restricted to those with moderate length: 10-30 words, which we expected to provide sufficient but succinct context of the substituted phrases. 5,850 sentences were retained. By substituting phrases in the above sentences using the paraphrase lexicons S Seed and S LV in the Europarl setting, 88,555 example units comprising 1,013,511 paraphrases were generated. For each example unit, 3-best paraphrases were then selected by a 5-gram language model trained on the monolingual data in the Europarl setting with modified Kneser-Ney smoothing using KenLM10 . Finally, from 31,149 units that contained at least three paraphrases, we randomly sampled 200 example units for 200 unique left-hand side phrases.",
                "cite_spans": [
                    {
                        "start": 29,
                        "end": 51,
                        "text": "(Callison-Burch, 2008;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 52,
                        "end": 72,
                        "text": "Fujita et al., 2012)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "5.2"
            },
            {
                "text": "We collected evaluations from three native English speakers. Table 3 summarizes the inter-evaluator agreement ratio, Cohen's \u03ba (Cohen, 1960) . The values for a coarse-grained binary decision11 were \"substantial\" for grammaticality and \"moderate\" for meaning equivalence (Landis and Koch, 1977) .",
                "cite_spans": [
                    {
                        "start": 127,
                        "end": 140,
                        "text": "(Cohen, 1960)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 282,
                        "end": 293,
                        "text": "Koch, 1977)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 67,
                        "end": 68,
                        "text": "3",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "The quality of the examined paraphrase lexicons is measured by the precision of the evaluated examples: an example was regarded as correct if and only if a majority of evaluators (two or three in our case) assigned a label corresponding to the positive class in the binary decision. paraphrases drawn from S Seed were of substantially high quality. Compared to S Seed , paraphrases sampled from S LV have relatively low precision in both grammaticality and meaning equivalence. However, these scores are reasonably high, considering that no use is made of rich language-specific resources12 . However, more grammatical errors occurred than with S Seed and S ID . A manual error analysis revealed that the majority of these errors were caused by the differences of syntactic categories between phrases, e.g., ( 12).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "(12) The safety issue was considered sufficiently ( \u21d2 sufficient consideration) serious for all affected parties to be informed.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "Differences of grammatical number and determiners were the other major error sources.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "(13) Federal Security Service now spread a big network of fake sites and there are tons of potential buyers ( \u21d2 a potential buyer) of military weapons.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "These types of pairs originally existed in S Seed but were amplified by LEXVAR. Ganitkevitch and Callison-Burch (2014) stated that morphological variants of the same word might be desirable depending on the downstream task. For instance, they could be useful for paraphrase recognition tasks including question answering and multi-document summarization. As they are morphological variants rather than genuine paraphrases, substituting them in a given context often degrades grammaticality.",
                "cite_spans": [
                    {
                        "start": 80,
                        "end": 118,
                        "text": "Ganitkevitch and Callison-Burch (2014)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5.3"
            },
            {
                "text": "We proposed a method for expanding given paraphrase lexicons by first inducing paraphrase patterns and then searching monolingual corpora with these patterns for new paraphrase pairs. To the best of our knowledge, this is the first attempt to exploit various types of lexical variants for acquiring paraphrases in a completely empirical way. Our method requires minimal language-dependent resources, i.e., stoplists and tokenizers, other than raw corpora. We demonstrated the quantitative impact of our method and confirmed the potential quality of the expanded paraphrase lexicon.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "Our future work is four-fold. (i) Paraphrase lexicons created by different methods and sources have different properties. Designing an overall model to harmonize such heterogeneous lexicons is an important issue. (ii) We aim to investigate an extensive collection of corpora: there are far more corpora than those we used in this experiment. We are also interested in expanding paraphrase lexicons created by a method other than bilingual pivoting; for instance, those extracted from a Web-harvested monolingual comparable corpus (Hashimoto et al., 2011; Yan et al., 2013) . (iii) We will apply our method to various languages for demonstrating its applicability, extending it for a wider range of lexical variants depending on the targeted language. (iv) Paraphrases are the fundamental linguistic phenomena that affect a wide range of NLP tasks. We are therefore interested in determining to what extent our paraphrase lexicons can improve the performance of application tasks such as machine translation, text summarization, and text simplification.",
                "cite_spans": [
                    {
                        "start": 530,
                        "end": 554,
                        "text": "(Hashimoto et al., 2011;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 555,
                        "end": 572,
                        "text": "Yan et al., 2013)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "The term \"monolingual corpora\" in this study refers to monolingual non-parallel corpora, unless otherwise explicitly noted. As reviewed in Section",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "2.1.2, monolingual parallel corpora have also been used as a source of paraphrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "If a constituency parser is available for the language of interest, one can learn syntax-based patterns during the bilingual pivoting process(Ganitkevitch et al., 2011).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://statmt.org/europarl/, release 7",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://statmt.org/wmt14/translation-task.html",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://ntcir.nii.ac.jp/PatentMT-2/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://psi.amu.edu.pl/en/index.php?title=SyMGIZA",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://statmt.org/moses/, RELEASE-2.1.1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://code.google.com/p/mecab/, version 0.996",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://members.unine.ch/jacques.savoy/clef/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://kheafield.com/code/kenlm/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We regarded \"Perfect\" and \"Awkward\" for grammaticality, and \"Equivalent\" and either of three categories of slight differences \"Missing Info.,\" \"Additional Info.,\" and \"Ignorable Change\" for meaning equivalence as positive. This is consistent with(Callison-Burch, 2008).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Although we cannot make a direct comparison owing to the differences of data and human evaluators, for reference, Callison-Burch (2008) achieved 0.68, 0.61, and 0.55 precision for grammaticality, meaning equivalence, and both, respectively, by introducing parser-oriented syntactic constraints in bilingual pivoting.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We are deeply grateful to Eiichiro Sumita, Masao Utiyama, Taro Watanabe, Kentaro Torisawa, and anonymous reviewers for their valuable comments on the earlier version of this paper. This work was partly supported by JSPS Postdoctoral Fellowship for Research Abroad (FYs 2011(FYs -2012) ) and JSPS KAKENHI Grant-in-Aid for Young Scientists (B) 25730139.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "A survey of paraphrasing and textual entailment methods",
                "authors": [],
                "year": 2010,
                "venue": "Ion Androutsopoulos and Prodromos Malakasiotis",
                "volume": "38",
                "issue": "",
                "pages": "135--187",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ion Androutsopoulos and Prodromos Malakasiotis. 2010. A survey of paraphrasing and textual entailment methods. Journal of Artificial Intelligence Research, 38:135-187.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Paraphrasing with bilingual parallel corpora",
                "authors": [
                    {
                        "first": "Colin",
                        "middle": [],
                        "last": "Bannard",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "597--604",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Colin Bannard and Chris Callison-Burch. 2005. Para- phrasing with bilingual parallel corpora. In Proceed- ings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 597-604.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Extracting paraphrases from a parallel corpus",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Kathleen",
                        "middle": [
                            "R"
                        ],
                        "last": "Mckeown",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "50--57",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Kathleen R. McKeown. 2001. Ex- tracting paraphrases from a parallel corpus. In Pro- ceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 50-57.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Bootstrapping lexical choice via multiple-sequence alignment",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "164--171",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Lillian Lee. 2002. Bootstrap- ping lexical choice via multiple-sequence alignment. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 164-171.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Sentence alignment for monolingual comparable corpora",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Noemie",
                        "middle": [],
                        "last": "Elhadad",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "25--32",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Noemie Elhadad. 2003. Sen- tence alignment for monolingual comparable corpora. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 25-32.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Large scale acquisition of paraphrases for learning surface patterns",
                "authors": [
                    {
                        "first": "Rahul",
                        "middle": [],
                        "last": "Bhagat",
                        "suffix": ""
                    },
                    {
                        "first": "Deepak",
                        "middle": [],
                        "last": "Ravichandran",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "161--170",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), pages 161-170.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Syntactic constraints on paraphrases extracted from parallel corpora",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "196--205",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Pro- ceedings of the 2008 Conference on Empirical Meth- ods in Natural Language Processing (EMNLP), pages 196-205.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Reranking bilingually extracted paraphrases using monolingual distributional similarity",
                "authors": [
                    {
                        "first": "Ping",
                        "middle": [],
                        "last": "Tsz",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Chan",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Workshop on Geometrical Models of Natual Language Semantics (GEMS)",
                "volume": "",
                "issue": "",
                "pages": "33--42",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tsz Ping Chan, Chris Callison-Burch, and Benjamin Van Durme. 2011. Reranking bilingually extracted para- phrases using monolingual distributional similarity. In Proceedings of the Workshop on Geometrical Models of Natual Language Semantics (GEMS), pages 33-42.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Collecting highly parallel data for paraphrase evaluation",
                "authors": [
                    {
                        "first": "David",
                        "middle": [
                            "L"
                        ],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [
                            "B"
                        ],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "190--200",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David L. Chen and William B. Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Pro- ceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 190-200.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "A coefficient of agreement for nominal scales",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Cohen",
                        "suffix": ""
                    }
                ],
                "year": 1960,
                "venue": "Educational and Psychological Measurement",
                "volume": "20",
                "issue": "1",
                "pages": "37--46",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Cohen. 1960. A coefficient of agreement for nom- inal scales. Educational and Psychological Measure- ment, 20(1):37-46.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Relation acquisition using word classes and partial patterns",
                "authors": [
                    {
                        "first": "Stijn",
                        "middle": [],
                        "last": "De Saeger",
                        "suffix": ""
                    },
                    {
                        "first": "Kentaro",
                        "middle": [],
                        "last": "Torisawa",
                        "suffix": ""
                    },
                    {
                        "first": "Masaaki",
                        "middle": [],
                        "last": "Tsuchida",
                        "suffix": ""
                    },
                    {
                        "first": "Jun'ichi",
                        "middle": [],
                        "last": "Kazama",
                        "suffix": ""
                    },
                    {
                        "first": "Chikara",
                        "middle": [],
                        "last": "Hashimoto",
                        "suffix": ""
                    },
                    {
                        "first": "Ichiro",
                        "middle": [],
                        "last": "Yamada",
                        "suffix": ""
                    },
                    {
                        "first": "Jong",
                        "middle": [],
                        "last": "Hoon Oh",
                        "suffix": ""
                    },
                    {
                        "first": "Istv\u00e1n",
                        "middle": [],
                        "last": "Varga",
                        "suffix": ""
                    },
                    {
                        "first": "Yulan",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "825--835",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida, Jun'ichi Kazama, Chikara Hashimoto, Ichiro Yamada, Jong Hoon Oh, Istv\u00e1n Varga, and Yulan Yan. 2011. Relation acquisition using word classes and partial patterns. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 825-835.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "METEOR-NEXT and the METEOR paraphrase tables: Improved evaluation support for five target languages",
                "authors": [
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Denkowski",
                        "suffix": ""
                    },
                    {
                        "first": "Alon",
                        "middle": [],
                        "last": "Lavie",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 5th Workshop on Statistical Machine Translation (WMT) and MetricsMATR",
                "volume": "",
                "issue": "",
                "pages": "339--342",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael Denkowski and Alon Lavie. 2010. METEOR- NEXT and the METEOR paraphrase tables: Improved evaluation support for five target languages. In Pro- ceedings of the 5th Workshop on Statistical Machine Translation (WMT) and MetricsMATR, pages 339- 342.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources",
                "authors": [
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Quirk",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of the 20th International Conference on Computational Linguistics (COLING)",
                "volume": "",
                "issue": "",
                "pages": "350--356",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase cor- pora: Exploiting massively parallel news sources. In Proceedings of the 20th International Conference on Computational Linguistics (COLING), pages 350- 356.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Facilitating translation using source language paraphrase lattices",
                "authors": [
                    {
                        "first": "Jinhua",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Andy",
                        "middle": [],
                        "last": "Way",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "420--429",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating translation using source language paraphrase lattices. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 420-429.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "WordNet: An Electronic Lexical Database",
                "authors": [
                    {
                        "first": "Christiane",
                        "middle": [],
                        "last": "Fellbaum",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. The MIT Press.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "A compositional approach toward dynamic phrasal thesaurus",
                "authors": [
                    {
                        "first": "Atsushi",
                        "middle": [],
                        "last": "Fujita",
                        "suffix": ""
                    },
                    {
                        "first": "Shuhei",
                        "middle": [],
                        "last": "Kato",
                        "suffix": ""
                    },
                    {
                        "first": "Naoki",
                        "middle": [],
                        "last": "Kato",
                        "suffix": ""
                    },
                    {
                        "first": "Satoshi",
                        "middle": [],
                        "last": "Sato",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing (WTEP)",
                "volume": "",
                "issue": "",
                "pages": "151--158",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Atsushi Fujita, Shuhei Kato, Naoki Kato, and Satoshi Sato. 2007. A compositional approach toward dy- namic phrasal thesaurus. In Proceedings of the ACL- PASCAL Workshop on Textual Entailment and Para- phrasing (WTEP), pages 151-158.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Enlarging paraphrase collections through generalization and instantiation",
                "authors": [
                    {
                        "first": "Atsushi",
                        "middle": [],
                        "last": "Fujita",
                        "suffix": ""
                    },
                    {
                        "first": "Pierre",
                        "middle": [],
                        "last": "Isabelle",
                        "suffix": ""
                    },
                    {
                        "first": "Roland",
                        "middle": [],
                        "last": "Kuhn",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)",
                "volume": "",
                "issue": "",
                "pages": "631--642",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Atsushi Fujita, Pierre Isabelle, and Roland Kuhn. 2012. Enlarging paraphrase collections through generaliza- tion and instantiation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan- guage Processing and Computational Natural Lan- guage Learning (EMNLP-CoNLL), pages 631-642.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "A consideration on the methodology for evaluating large-scale paraphrase lexicons",
                "authors": [
                    {
                        "first": "Atsushi",
                        "middle": [],
                        "last": "Fujita",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Information Processing Society of Japan SIG Notes",
                "volume": "",
                "issue": "",
                "pages": "1--8",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Atsushi Fujita. 2013. A consideration on the methodol- ogy for evaluating large-scale paraphrase lexicons. In Information Processing Society of Japan SIG Notes, NL-214-21, pages 1-8.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation",
                "authors": [
                    {
                        "first": "Juri",
                        "middle": [],
                        "last": "Ganitkevitch",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "1168--1179",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Juri Ganitkevitch, Chris Callison-Burch, Courtney Napoles, and Benjamin Van Durme. 2011. Learn- ing sentential paraphrases from bilingual parallel cor- pora for text-to-text generation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1168-1179.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "PPDB: The paraphrase database",
                "authors": [
                    {
                        "first": "Juri",
                        "middle": [],
                        "last": "Ganitkevitch",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT)",
                "volume": "",
                "issue": "",
                "pages": "758--764",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In Proceedings of Human Language Tech- nologies: The 2013 Annual Conference of the North American Chapter of the Association for Computa- tional Linguistics (NAACL-HLT), pages 758-764.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "The multilingual paraphrase database",
                "authors": [
                    {
                        "first": "Juri",
                        "middle": [],
                        "last": "Ganitkevitch",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC)",
                "volume": "",
                "issue": "",
                "pages": "4276--4282",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Juri Ganitkevitch and Chris Callison-Burch. 2014. The multilingual paraphrase database. In Proceedings of the 9th International Conference on Language Re- sources and Evaluation (LREC), pages 4276-4282.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Unsupervised learning of derivational morphology from inflectional lexicons",
                "authors": [
                    {
                        "first": "\u00c9ric",
                        "middle": [],
                        "last": "Gaussier",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Proceedings of the Workshop on Unsupervised Learning in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "24--30",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "\u00c9ric Gaussier. 1999. Unsupervised learning of deriva- tional morphology from inflectional lexicons. In Pro- ceedings of the Workshop on Unsupervised Learning in Natural Language Processing, pages 24-30.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A categorial variation database for English",
                "authors": [
                    {
                        "first": "Nizar",
                        "middle": [],
                        "last": "Habash",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "Jean"
                        ],
                        "last": "Dorr",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL)",
                "volume": "",
                "issue": "",
                "pages": "96--102",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nizar Habash and Bonnie Jean Dorr. 2003. A catego- rial variation database for English. In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), pages 96- 102.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Selection of effective contextual information for automatic synonym acquisition",
                "authors": [
                    {
                        "first": "Masato",
                        "middle": [],
                        "last": "Hagiwara",
                        "suffix": ""
                    },
                    {
                        "first": "Yasuhiro",
                        "middle": [],
                        "last": "Ogawa",
                        "suffix": ""
                    },
                    {
                        "first": "Katsuhiko",
                        "middle": [],
                        "last": "Toyama",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics and the 21st International Conference on Computational Linguistics (COLING-ACL)",
                "volume": "",
                "issue": "",
                "pages": "353--360",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Masato Hagiwara, Yasuhiro Ogawa, and Katsuhiko Toyama. 2006. Selection of effective contextual in- formation for automatic synonym acquisition. In Pro- ceedings of the 44th Annual Meeting of the Associ- ation for Computational Linguistics and the 21st In- ternational Conference on Computational Linguistics (COLING-ACL), pages 353-360.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Co-occurrence and transformation in linguistic structure",
                "authors": [
                    {
                        "first": "Zellig",
                        "middle": [],
                        "last": "Harris",
                        "suffix": ""
                    }
                ],
                "year": 1957,
                "venue": "Language",
                "volume": "33",
                "issue": "3",
                "pages": "283--340",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zellig Harris. 1957. Co-occurrence and transformation in linguistic structure. Language, 33(3):283-340.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Extracting paraphrases from definition sentences on the Web",
                "authors": [
                    {
                        "first": "Chikara",
                        "middle": [],
                        "last": "Hashimoto",
                        "suffix": ""
                    },
                    {
                        "first": "Kentaro",
                        "middle": [],
                        "last": "Torisawa",
                        "suffix": ""
                    },
                    {
                        "first": "Stijn",
                        "middle": [],
                        "last": "De Saeger",
                        "suffix": ""
                    },
                    {
                        "first": "Jun'ichi",
                        "middle": [],
                        "last": "Kazama",
                        "suffix": ""
                    },
                    {
                        "first": "Sadao",
                        "middle": [],
                        "last": "Kurohashi",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "1087--1097",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger, Jun'ichi Kazama, and Sadao Kurohashi. 2011. Ex- tracting paraphrases from definition sentences on the Web. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1087-1097.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Syntagmatic and paradigmatic representations of term variation",
                "authors": [
                    {
                        "first": "Christian",
                        "middle": [],
                        "last": "Jacquemin",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "341--348",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christian Jacquemin. 1999. Syntagmatic and paradig- matic representations of term variation. In Proceed- ings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 341-348.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Hitting the right paraphrases in good time",
                "authors": [
                    {
                        "first": "Stanley",
                        "middle": [],
                        "last": "Kok",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT)",
                "volume": "",
                "issue": "",
                "pages": "145--153",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stanley Kok and Chris Brockett. 2010. Hitting the right paraphrases in good time. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT), pages 145- 153.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "The measurement of observer agreement for categorical data",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Landis",
                        "suffix": ""
                    },
                    {
                        "first": "Gary",
                        "middle": [
                            "G"
                        ],
                        "last": "Koch",
                        "suffix": ""
                    }
                ],
                "year": 1977,
                "venue": "Biometrics",
                "volume": "33",
                "issue": "1",
                "pages": "159--174",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Richard Landis and Gary G. Koch. 1977. The mea- surement of observer agreement for categorical data. Biometrics, 33(1):159-174.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Discovery of inference rules for question answering",
                "authors": [
                    {
                        "first": "Dekang",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Patrick",
                        "middle": [],
                        "last": "Pantel",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Natural Language Engineering",
                "volume": "7",
                "issue": "4",
                "pages": "343--360",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dekang Lin and Patrick Pantel. 2001. Discovery of infer- ence rules for question answering. Natural Language Engineering, 7(4):343-360.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Generating phrasal and sentential paraphrases: A survey of data-driven methods",
                "authors": [
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "J"
                        ],
                        "last": "Dorr",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Computational Linguistics",
                "volume": "36",
                "issue": "3",
                "pages": "341--387",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nitin Madnani and Bonnie J. Dorr. 2010. Gener- ating phrasal and sentential paraphrases: A survey of data-driven methods. Computational Linguistics, 36(3):341-387.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Distributional phrasal paraphrase generation for statistical machine translation",
                "authors": [
                    {
                        "first": "Yuval",
                        "middle": [],
                        "last": "Marton",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "ACM Transactions on Intelligent Systems and Technology",
                "volume": "4",
                "issue": "3",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yuval Marton. 2013. Distributional phrasal paraphrase generation for statistical machine translation. ACM Transactions on Intelligent Systems and Technology, 4(3).",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Example-based paraphrasing for improved phrase-based statistical machine translation",
                "authors": [
                    {
                        "first": "Aur\u00e9lien",
                        "middle": [],
                        "last": "Max",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "656--666",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Aur\u00e9lien Max. 2010. Example-based paraphrasing for improved phrase-based statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 656-666.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "A formal lexicon in Meaning-Text Theory (or how to do lexica with words)",
                "authors": [
                    {
                        "first": "Igor",
                        "middle": [],
                        "last": "Mel",
                        "suffix": ""
                    },
                    {
                        "first": "'",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Alain",
                        "middle": [],
                        "last": "Polgu\u00e8re",
                        "suffix": ""
                    }
                ],
                "year": 1987,
                "venue": "Computational Linguistics",
                "volume": "13",
                "issue": "3-4",
                "pages": "261--275",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Igor Mel'\u010duk and Alain Polgu\u00e8re. 1987. A formal lexi- con in Meaning-Text Theory (or how to do lexica with words). Computational Linguistics, 13(3-4):261-275.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Aligning needles in a haystack: Paraphrase acquisition across the Web",
                "authors": [
                    {
                        "first": "Marius",
                        "middle": [],
                        "last": "Pas",
                        "suffix": ""
                    },
                    {
                        "first": "P\u00e9ter",
                        "middle": [],
                        "last": "Dienes",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP)",
                "volume": "",
                "issue": "",
                "pages": "119--130",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marius Pas \u00b8ca and P\u00e9ter Dienes. 2005. Aligning needles in a haystack: Paraphrase acquisition across the Web. In Proceedings of the 2nd International Joint Con- ference on Natural Language Processing (IJCNLP), pages 119-130.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences",
                "authors": [
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of the 2003 Human Language Technology Conference and the North American Chapter",
                "volume": "",
                "issue": "",
                "pages": "102--109",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Ex- tracting paraphrases and generating new sentences. In Proceedings of the 2003 Human Language Technol- ogy Conference and the North American Chapter of the Association for Computational Linguistics (HLT- NAACL), pages 102-109.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Automatic paraphrase acquisition from news articles",
                "authors": [
                    {
                        "first": "Yusuke",
                        "middle": [],
                        "last": "Shinyama",
                        "suffix": ""
                    },
                    {
                        "first": "Satoshi",
                        "middle": [],
                        "last": "Sekine",
                        "suffix": ""
                    },
                    {
                        "first": "Kiyoshi",
                        "middle": [],
                        "last": "Sudo",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Grishman",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the 2002 Human Language Technology Conference (HLT)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, and Ralph Grishman. 2002. Automatic paraphrase acqui- sition from news articles. In Proceedings of the 2002 Human Language Technology Conference (HLT).",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Scaling Web-based acquisition of entailment relations",
                "authors": [
                    {
                        "first": "Idan",
                        "middle": [],
                        "last": "Szpektor",
                        "suffix": ""
                    },
                    {
                        "first": "Hristo",
                        "middle": [],
                        "last": "Tanev",
                        "suffix": ""
                    },
                    {
                        "first": "Ido",
                        "middle": [],
                        "last": "Dagan",
                        "suffix": ""
                    },
                    {
                        "first": "Bonaventura",
                        "middle": [],
                        "last": "Coppola",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "41--48",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling Web-based acquisition of en- tailment relations. In Proceedings of the 2004 Confer- ence on Empirical Methods in Natural Language Pro- cessing (EMNLP), pages 41-48.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Clustering and matching headlines for automatic paraphrase acquisition",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Sander Wubben",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Van Den",
                        "suffix": ""
                    },
                    {
                        "first": "Emiel",
                        "middle": [],
                        "last": "Bosch",
                        "suffix": ""
                    },
                    {
                        "first": "Erwin",
                        "middle": [],
                        "last": "Krahmer",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Marsi",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the 12th European Workshop on Natural Language Generation (EWNLG)",
                "volume": "",
                "issue": "",
                "pages": "122--125",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sander Wubben, Antal van den Bosch, Emiel Krahmer, and Erwin Marsi. 2009. Clustering and matching headlines for automatic paraphrase acquisition. In Proceedings of the 12th European Workshop on Nat- ural Language Generation (EWNLG), pages 122-125.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Minimally supervised method for multilingual paraphrase extraction from definition sentences on the web",
                "authors": [
                    {
                        "first": "Yulan",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    },
                    {
                        "first": "Chikara",
                        "middle": [],
                        "last": "Hashimoto",
                        "suffix": ""
                    },
                    {
                        "first": "Kentaro",
                        "middle": [],
                        "last": "Torisawa",
                        "suffix": ""
                    },
                    {
                        "first": "Takao",
                        "middle": [],
                        "last": "Kawai",
                        "suffix": ""
                    },
                    {
                        "first": "Stijn",
                        "middle": [
                            "De"
                        ],
                        "last": "Jun'ichi Kazama",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Saeger",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT)",
                "volume": "",
                "issue": "",
                "pages": "63--73",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yulan Yan, Chikara Hashimoto, Kentaro Torisawa, Takao Kawai, Jun'ichi Kazama, and Stijn De Saeger. 2013. Minimally supervised method for multilingual para- phrase extraction from definition sentences on the web. In Proceedings of Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguis- tics (NAACL-HLT), pages 63-73.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Extracting paraphrase patterns from bilingual parallel corpora",
                "authors": [
                    {
                        "first": "Shiqi",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Haifeng",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Ting",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Sheng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Natural Language Engineering",
                "volume": "15",
                "issue": "4",
                "pages": "503--526",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2009. Extracting paraphrase patterns from bilin- gual parallel corpora. Natural Language Engineering, 15(4):503-526.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Overview of our proposed method.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Statistics for the acquired paraphrase patterns: number and coverage against S Seed .",
                "uris": null,
                "fig_num": "23",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 4: Ratio of S LV and S ID to S Seed .",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>Word 1</td><td>Word 2</td><td>Affix 1</td><td>Affix 2</td><td>Stem</td></tr><tr><td>aimed</td><td>aims</td><td>X:ed</td><td>X:s</td><td>aim</td></tr><tr><td>aimed</td><td colspan=\"2\">achieve X:imed</td><td colspan=\"2\">X:chieve a</td></tr><tr><td colspan=\"2\">achieving aims</td><td colspan=\"2\">X:chieving X:ims</td><td>a</td></tr><tr><td colspan=\"3\">achieving achieve X:ing</td><td>X:e</td><td>achiev</td></tr><tr><td/><td/><td colspan=\"2\"># of unique stems</td><td/></tr><tr><td>Affix 1</td><td>Affix 2</td><td>length</td><td>length</td><td>Result</td></tr><tr><td/><td/><td>\u22655</td><td>&lt;5</td><td/></tr><tr><td colspan=\"2\">X:chieve X:imed</td><td>0</td><td colspan=\"2\">1 Eliminated</td></tr><tr><td colspan=\"2\">X:chieving X:ims</td><td>0</td><td colspan=\"2\">1 Eliminated</td></tr><tr><td>X:ed</td><td>X:s</td><td>69</td><td colspan=\"2\">22 Retained</td></tr><tr><td>X:ing</td><td>X:e</td><td>330</td><td colspan=\"2\">70 Retained</td></tr></table>",
                "type_str": "table",
                "text": "Candidate pairs of lexical variants and corresponding affix patterns extracted from (6).",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Filtering affix patterns (# of unique stems taken from our experimental result of Europarl setting).",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>the 2006-2007 chapters of NTCIR unaligned</td></tr><tr><td>patent documents were used as a monolingual</td></tr><tr><td>corpus.</td></tr><tr><td>For learning curve experiments, several sizes of</td></tr><tr><td>bilingual sub-corpora were created by sub-sampling</td></tr><tr><td>sentence pairs for both settings.</td></tr><tr><td>The other language resources involved in this ex-</td></tr><tr><td>periment are as follows.</td></tr><tr><td>Phrase table learner: SyMGIZA++ 6 was used for</td></tr><tr><td>IBM2 alignment, then grow-diag-final phrase</td></tr><tr><td>extraction and phrase table pruning were per-</td></tr><tr><td>formed using toolkits in Moses 7 .</td></tr><tr><td>Tokenizer:</td></tr><tr><td>Europarl setting: The English-French version of</td></tr><tr><td>the Europarl Parallel Corpus 3 comprising</td></tr><tr><td>2.0 M sentence pairs (55.7 M words in English</td></tr><tr><td>and 61.9 M words in French) was used as a</td></tr><tr><td>bilingual corpus. Its English side and the 2011-</td></tr><tr><td>2013 editions of News Crawl corpora 4 com-</td></tr><tr><td>prising 52.0 M sentences (1.20 B words) were</td></tr><tr><td>used as a monolingual corpus.</td></tr><tr><td>NTCIR setting: The Japanese-English Patent</td></tr><tr><td>Translation data 5 comprising 3.2 M sentence</td></tr><tr><td>pairs (107 M words in English and 116 M</td></tr><tr><td>morphemes in Japanese) was used as a bilin-</td></tr><tr><td>gual parallel corpus, while its English side and</td></tr><tr><td>the 39.9 M sentences (1.36 B words) from</td></tr></table>",
                "type_str": "table",
                "text": "The tokenizer distributed with Moses was used for both English and French texts. For Japanese data, MeCab 8 was used. Stoplists: To perform several types of filtering proposed byFujita et al. (",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td>summa-</td></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td>Lexicon</td><td>n</td><td colspan=\"2\">Grammar Meaning Both</td></tr><tr><td>S Seed</td><td>66</td><td>0.85</td><td>0.91 0.76</td></tr><tr><td colspan=\"2\">S ID (\u2286S LV ) 339</td><td>0.84</td><td>0.78 0.66</td></tr><tr><td>S LV</td><td>534</td><td>0.74</td><td>0.78 0.59</td></tr><tr><td>Total</td><td>600</td><td>0.75</td><td>0.79 0.61</td></tr></table>",
                "type_str": "table",
                "text": "Cohen's \u03ba of pairwise agreement.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Precision of paraphrase substitution.",
                "html": null,
                "num": null
            }
        }
    }
}