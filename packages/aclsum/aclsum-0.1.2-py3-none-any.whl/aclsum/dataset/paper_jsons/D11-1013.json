{
    "paper_id": "D11-1013",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:15:32.906759Z"
    },
    "title": "Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews",
    "authors": [
        {
            "first": "Jianxing",
            "middle": [],
            "last": "Yu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National University",
                "location": {
                    "country": "Singapore"
                }
            },
            "email": "jianxing@comp.nus.edu"
        },
        {
            "first": "Zheng-Jun",
            "middle": [],
            "last": "Zha",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National University",
                "location": {
                    "country": "Singapore"
                }
            },
            "email": ""
        },
        {
            "first": "Meng",
            "middle": [],
            "last": "Wang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National University",
                "location": {
                    "country": "Singapore"
                }
            },
            "email": "wangm@comp.nus.edu"
        },
        {
            "first": "Kai",
            "middle": [],
            "last": "Wang",
            "suffix": "",
            "affiliation": {},
            "email": "kwang@i2r.a-star.edu.sg"
        },
        {
            "first": "Tat-Seng",
            "middle": [],
            "last": "Chua",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "National University",
                "location": {
                    "country": "Singapore"
                }
            },
            "email": "chuats@comp.nus.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "This paper presents a domain-assisted approach to organize various aspects of a product into a hierarchy by integrating domain knowledge (e.g., the product specifications), as well as consumer reviews. Based on the derived hierarchy, we generate a hierarchical organization of consumer reviews on various product aspects and aggregate consumer opinions on these aspects. With such organization, user can easily grasp the overview of consumer reviews. Furthermore, we apply the hierarchy to the task of implicit aspect identification which aims to infer implicit aspects of the reviews that do not explicitly express those aspects but actually comment on them. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach.",
    "pdf_parse": {
        "paper_id": "D11-1013",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "This paper presents a domain-assisted approach to organize various aspects of a product into a hierarchy by integrating domain knowledge (e.g., the product specifications), as well as consumer reviews. Based on the derived hierarchy, we generate a hierarchical organization of consumer reviews on various product aspects and aggregate consumer opinions on these aspects. With such organization, user can easily grasp the overview of consumer reviews. Furthermore, we apply the hierarchy to the task of implicit aspect identification which aims to infer implicit aspects of the reviews that do not explicitly express those aspects but actually comment on them. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "With the rapidly expanding e-commerce, most retail Web sites encourage consumers to write reviews to express their opinions on various aspects of products. Huge collections of consumer reviews are now available on the Web. These reviews have become an important resource for both consumers and firms. Consumers commonly seek quality information from online consumer reviews prior to purchasing a product, while many firms use online reviews as an important resource in their product development, marketing, and consumer relationship management. However, the reviews are disorganized, leading to the difficulty in information navigation and knowledge acquisition. It is impractical for user to grasp the overview of consumer reviews and opinions on various aspects of a product from such enormous reviews. Among hundreds of product aspects, it is also inefficient for user to browse consumer reviews and opinions on a specific aspect. Thus, there is a compelling need to organize consumer reviews, so as to transform the reviews into a useful knowledge structure. Since the hierarchy can improve information representation and accessibility (Cimiano, 2006) , we propose to organize the aspects of a product into a hierarchy and generate a hierarchical organization of consumer reviews accordingly.",
                "cite_spans": [
                    {
                        "start": 1140,
                        "end": 1155,
                        "text": "(Cimiano, 2006)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Towards automatically deriving an aspect hierarchy from the reviews, we could refer to traditional hierarchy generation methods in ontology learning, which first identify concepts from the text, then determine the parent-child relations between these concepts using either pattern-based or clusteringbased methods (Murthy et al., 2010) . However, pattern-based methods usually suffer from inconsistency of parent-child relationships among the concepts, while clustering-based methods often result in low accuracy. Thus, by directly utilizing these methods to generate an aspect hierarchy from consumer reviews, the resulting hierarchy is usually inaccurate, leading to unsatisfactory review organization. On the other hand, domain knowledge of products is now available on the Web. For example, there are more than 248,474 product specifications in the product selling Web site CNet.com (Beckham, 2005) . These product specifications cover some product aspects and provide coarse-grained parentchild relations among these aspects. Such domain knowledge is useful to help organize the product as-140 pects into a hierarchy. However, the initial hierarchy obtained from domain knowledge usually cannot fit the review data well. For example, the initial hierarchy is usually too coarse and may not cover the specific aspects commented in the reviews, while some aspects in the hierarchy may not be of interests to users in the reviews.",
                "cite_spans": [
                    {
                        "start": 314,
                        "end": 335,
                        "text": "(Murthy et al., 2010)",
                        "ref_id": null
                    },
                    {
                        "start": 878,
                        "end": 902,
                        "text": "CNet.com (Beckham, 2005)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Motivated by the above observations, we propose in this paper to organize the product aspects into a hierarchy by simultaneously exploiting the domain knowledge (e.g., the product specification) and consumer reviews. With derived aspect hierarchy, we generate a hierarchical organization of consumer reviews on various aspects and aggregate consumer opinions on these aspects. Figure 1 illustrates a sample of hierarchical review organization for the product \"iPhone 3G\". With such organization, users can easily grasp the overview of product aspects as well as conveniently navigate the consumer reviews and opinions on any aspect. For example, users can find that 623 reviews, out of 9,245 reviews, are about the aspect \"price\", with 241 positive and 382 negative reviews.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 384,
                        "end": 385,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Given a collection of consumer reviews on a specific product, we first automatically acquire an initial aspect hierarchy from domain knowledge and identify the aspects from the reviews. Based on the initial hierarchy, we develop a multi-criteria optimization approach to construct an aspect hierarchy to contain all the identified aspects. Our approach incrementally inserts the aspects into the initial hierarchy based on inter-aspect semantic distance, a metric used to measure the semantic relation among aspects. In order to derive reliable semantic distance, we propose to leverage external hierarchies, sampled from WordNet and Open Directory Project, to assist semantic distance learning. With resultant aspect hierarchy, the consumer reviews are then organized to their corresponding aspect nodes in the hierarchy. We then perform sentiment classification to determine consumer opinions on these aspects. Furthermore, we apply the hierarchy to the task of implicit aspect identification. This task aims to infer implicit aspects of the reviews that do not explicitly express those aspects but actually comment on them. For example, the implicit aspect of the review \"It is so expensive\" is \"price.\" Most existing aspect identification approaches rely on the appearance of aspect terms, and thus are not able to handle implicit aspect problem. Based on our aspect hierarchy, we can infer the implicit aspects by clustering the reviews into their corresponding aspect nodes in the hierarchy. We conduct experiments on 11 popular products in four domains. More details of the corpus are discussed in Section 4. The experimental results demonstrate the effectiveness of our approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The main contributions of this work can be summarized as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "1) We propose to hierarchically organize consumer reviews according to an aspect hierarchy, so as to transfer the reviews into a useful knowledge structure.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2) We develop a domain-assisted approach to generate an aspect hierarchy by integrating domain knowledge and consumer reviews. In order to derive reliable semantic distance between aspects, we propose to leverage external hierarchies to assist semantic distance learning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "3) We apply the aspect hierarchy to the task of implicit aspect identification, and achieve satisfactory performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The rest of this paper is organized as follows. Our approach is elaborated in Section 2 and applied to implicit aspect identification in Section 3. Section 4 presents the evaluations, while Section 5 reviews 141 related work. Finally, Section 6 concludes this paper with future works.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Our approach consists of four components, including initial hierarchy acquisition, aspect identification, semantic distance learning, and aspect hierarchy generation. Next, we first define some preliminary and notations and then elaborate these components.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Approach",
                "sec_num": "2"
            },
            {
                "text": "Preliminary 1. An aspect hierarchy is defined as a tree that consists of a set of unique aspects A and a set of parent-child relations R between these aspects.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preliminary and Notations",
                "sec_num": "2.1"
            },
            {
                "text": "Given the consumer reviews of a product, let A = {a 1 , \u2022 \u2022 \u2022 , a k } denotes the product aspects commented in the reviews. H 0 (A 0 , R 0 ) denotes the initial hierarchy derived from domain knowledge. It contains a set of aspects A 0 and relations R 0 . Our task is to construct an aspect hierarchy H(A, R), to cover all the aspects in A and their parent-child relations R, so that the consumer reviews are hierarchically organized. Note that H 0 can be empty.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preliminary and Notations",
                "sec_num": "2.1"
            },
            {
                "text": "As aforementioned, product specifications on product selling websites cover some product aspects and coarse-grained parent-child relations among these aspects. Such domain knowledge is useful to help organize aspects into a hierarchy. We here employ the approach proposed by Ye and Chua (2006) to automatically acquire an initial aspect hierarchy from the product specifications. The method first identifies the Web page region covering product descriptions and removes the irrelevant contents from the Web page. It then parses the region containing the product information to identify the aspects as well as their structure. Based on the aspects and their structure, it generates an aspect hierarchy.",
                "cite_spans": [
                    {
                        "start": 275,
                        "end": 293,
                        "text": "Ye and Chua (2006)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Initial Hierarchy Acquisition",
                "sec_num": "2.2"
            },
            {
                "text": "To identify aspects in consumer reviews, we first parse each review using the Stanford parser 1 . Since the aspects in consumer reviews are usually noun 1 http://nlp.stanford.edu/software/lex-parser.shtml or noun phrases (Liu, 2009) , we extract the noun phrases (NP) from the parse tree as aspect candidates. While these candidates may contain much noise, we leverage Pros and Cons reviews (see Figure 2 ), which are prevalent in forum Web sites, to assist identify aspects from the candidates. It has been shown that simply extracting the frequent noun terms from the Pros and Cons reviews can get high accurate aspect terms (Liu el al., 2005) . Thus, we extract the frequent noun terms from Pros and Cons reviews as features, then train a one-class SVM (Manevitz et al., 2002) to identify aspects from the candidates. While the obtained aspects may contain some synonym terms, such as \"earphone\" and \"headphone\", we further perform synonym clustering to get unique aspects. Specifically, we first expand each aspect term with its synonym terms obtained from the synonym terms Web site2 , then cluster them to obtain unique aspects based on unigram feature.",
                "cite_spans": [
                    {
                        "start": 221,
                        "end": 232,
                        "text": "(Liu, 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 627,
                        "end": 645,
                        "text": "(Liu el al., 2005)",
                        "ref_id": null
                    },
                    {
                        "start": 756,
                        "end": 779,
                        "text": "(Manevitz et al., 2002)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 403,
                        "end": 404,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Aspect Identification",
                "sec_num": "2.3"
            },
            {
                "text": "Our aspect hierarchy generation approach is essentially based on the semantic relations among aspects. We here define a metric, Semantic Distance, d(a x , a y ), to quantitatively measure the semantic relation between aspects a x and a y . We formulate d(a x , a y ) as the weighted sum of some underlying features,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "d(a x , a y ) = \u2211 j w j f j (a x , a y ),",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4"
            },
            {
                "text": "where w j is the weight for j-th feature function f j (\u2022).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4"
            },
            {
                "text": "Next, we first introduce the linguistic features used in our work and then present the semantic distance learning algorithm that aims to find the optimal weights in Eq.(1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4"
            },
            {
                "text": "Given two aspects a x and a y , a feature is defined as a function generating a numeric score f (a x , a y ) or a vector of scores. The features include Contextual, Co-occurrence, Syntactic, Pattern and Lexical features (Yang and Callan, 2009) . These features are generated based on auxiliary documents collected from Web.",
                "cite_spans": [
                    {
                        "start": 220,
                        "end": 243,
                        "text": "(Yang and Callan, 2009)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Specifically, we issue each aspect term and aspect term pair as queries to Google and Wikipedia, respectively, and collect the top 100 returned documents of each query. We then split the documents into sentences. Based on these documents and sentences, the features are generated as follows.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Contextual features. For each aspect, we collect the documents containing the aspect as context to build a unigram language model without smoothing. Given two aspects, the KL-divergence between their language models is computed as the Global-Context feature between them. Similarly, we collect the left two and right two words surrounding each aspect as context and build a unigram language model. The KL-divergence between the language models of two aspects is defined as the Local-Context feature.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Co-occurrence features. We measure the cooccurrence of two aspects by Pointwise Mutual Information (PMI): PMI(a x ,a y )=log(Count(a x ,a y )/ Count(a x ) Count(a y )), where Count(\u2022) stands for the number of documents or sentences containing the aspect(s), or the number of Google document hits for the aspect(s). Based on different definitions of Count(\u2022), we define the features of Document PMI, Sentence PMI, and Google PMI, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Syntactic features. We parse the sentences that contain each aspect pair into syntactic trees via the Stanford Parser. The Syntactic-path feature is defined as the average length of the shortest syntactic path between the aspect pair in the tree. In addition, for each aspect, we collect a set of sentences containing it, and label the semantic role of the sentences via ASSERT parser 3 . Given two aspects, the number of the Subject terms overlaps between their sentence sets is computed as the Subject Overlap feature. Similarly, for other semantic roles, such as objects, modifiers, and verbs, we define the features of Object Overlap, Modifier Overlap, and Verb 3 http://cemantix.org/assert.html Overlap, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Pattern features. 46 patterns are used in our work, including 6 patterns indicating the hypernym relations of two aspects (Hearst, 1992) , and 40 patterns measuring the part-of relations of two aspects (Girju et al., 2006) . These pattern features are asymmetric, and they take the parent-child relations among the aspects into consideration. All the patterns are listed in Appendix A (submitted as supplementary material). Based on these patterns, a 46dimensional score vector is obtained for each aspect pair. A score is 1 if two aspects match a pattern, and 0 otherwise.",
                "cite_spans": [
                    {
                        "start": 122,
                        "end": 136,
                        "text": "(Hearst, 1992)",
                        "ref_id": null
                    },
                    {
                        "start": 202,
                        "end": 222,
                        "text": "(Girju et al., 2006)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "Lexical features. We take the word length difference between two aspects, as Length Difference feature. In addition, we issue the query \"define:aspect\" to Google, and collect the definition of each aspect. We then count the word overlaps between the definitions of two aspects, as Definition Overlap feature.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "2.4.1"
            },
            {
                "text": "This section elaborates the learning algorithm that optimizes the semantic distance metric, i.e., the weighting parameters in Eq.( 1). Typically, we can utilize the initial hierarchy as training data. The ground-truth distance between two aspects d G (a x , a y ) is generated by summing up all the edge distances along the shortest path between a x and a y , where every edge weight is assumed as 1. The distance metric is then obtained by solving the following optimization problem, arg min",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "w j | m j=1 \u2211 ax,ay \u2208A 0 x<y (d G (ax, ay) - m \u2211 j=1 wjfj(ax, ay)) 2 +\u03b7\u2022 m \u2211 j=1 w 2 j ,",
                        "eq_num": "(2)"
                    }
                ],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "where m is the dimension of linguistic feature, \u03b7 is a tradeoff parameter. Eq.( 2) can be rewrote to its matrix form as,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "arg min w d -f T w 2 + \u03b7 \u2022 \u2225w\u2225 2 , (",
                        "eq_num": "3"
                    }
                ],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "where vector d contains the ground-truth distance of all the aspect pairs. Each element corresponds to the distance of certain aspect pair, and f is the corresponding feature vector. The optimal solution of w is given as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "w * = (f T f + \u03b7 \u2022 I) -1 (f T d) (",
                        "eq_num": "4"
                    }
                ],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "where I is the identity metric.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "The above learning algorithm can perform well when sufficient training data (i.e., aspect (term) pairs) is available. However, the initial hierarchy is usually too coarse and thus cannot provide sufficient information. On the other hand, abundant handcrafted hierarchies are available on the Web, such as WordNet and Open Directory Project (ODP). We here propose to leverage these external hierarchies to assist semantic distance learning. A distance metric w 0 is learned from the external hierarchies using the above algorithm. Since w 0 might be biased to the characteristics of the external hierarchies, directly using w 0 in our task may not perform well. Alternatively, we use w 0 as prior knowledge to assist learning the optimal distance metric w from the initial hierarchy. The learning problem is formulated as follows,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "arg min w d -f T w 2 + \u03b7 \u2022 \u2225w\u2225 2 + \u03b3 \u2022 \u2225w -w 0 \u2225 2 ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "(5) where \u03b7 and \u03b3 are tradeoff parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "The optimal solution of w can be obtained as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "w * = (f T f + (\u03b7 + \u03b3) \u2022 I) -1 (f T d + \u03b3 \u2022 w 0 ).",
                        "eq_num": "(6)"
                    }
                ],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "As a result, we can compute the semantic distance between each two aspects according to Eq.(1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Semantic Distance Learning",
                "sec_num": "2.4.2"
            },
            {
                "text": "Given the aspects A = {a 1 , \u2022 \u2022 \u2022 , a k } identified from reviews and the initial hierarchy H 0 (A 0 , R 0 ) obtained from domain knowledge, our task is to construct an aspect hierarchy to contain all the aspects in A. Inspired by Yang and Callan (2009) , we adopt a multi-criteria optimization approach to incrementally insert the aspects into appropriate positions in the hierarchy based on multiple criteria. Before going to the details, we first introduce an information function to measure the amount of information carried in a hierarchy. An information function Inf o(H) is defined as the sum of the semantic distances of all the aspect pairs in the hierarchy (Yang and Callan, 2009) .",
                "cite_spans": [
                    {
                        "start": 232,
                        "end": 254,
                        "text": "Yang and Callan (2009)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 668,
                        "end": 691,
                        "text": "(Yang and Callan, 2009)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Aspect Hierarchy Generation",
                "sec_num": "2.5"
            },
            {
                "text": "x<y;ax,ay\u2208A d(a x , a y ). (7)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "Based on this information function, we then introduce the following three criteria for aspect insertion: minimum Hierarchy Evolution, minimum Hierarchy Discrepancy and minimum Semantic Inconsistency.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "Hierarchy Evolution is designed to monitor the structure evolution of a hierarchy. The hierarchy is incrementally hosting more aspects until all the aspects are allocated. The insertion of a new aspect a into different positions in the current hierarchy H (i) leads to different new hierarchies. Among these new hierarchies, we here assume that the optimal one H (i+1) should introduce the least changes of information to H (i) .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "\u0124(i+1) = arg min H (i+1) \u2206Inf o(H (i+1) -H (i) ). (8)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "By plugging in Eq.( 7) and using least square to measure the information changes, we have,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "obj 1 = arg min H (i+1) ( \u2211 x<y;ax,ay\u2208A i \u222a{a} d(a x , a y ) - \u2211 x<y;ax,ay\u2208A i d(a x , a y )) 2 , (",
                        "eq_num": "9"
                    }
                ],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": ") Hierarchy Discrepancy is used to measure the global changes of the structure. We assume a good hierarchy should bring the least changes to the initial hierarchy, \u0124(i+1) = arg min",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "H (i+1) \u2206Inf o(H (i+1) -H (0) ) i + 1 .",
                        "eq_num": "(10)"
                    }
                ],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "We then get, obj 2 = arg min",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "H (i+1) 1 i+1 ( \u2211 x<y;ax,ay\u2208A i \u222a{a} d(a x , a y ) - \u2211 x<y;ax,ay\u2208A 0 d(a x , a y )) 2 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "(11) Semantic Inconsistency is introduced to quantify the inconsistency between the semantic distance estimated via the hierarchy and that computed from the feature functions. We assume that a good hierarchy should precisely reflect the semantic distance between aspects. For two aspects, their semantic distance reflected by the hierarchy is computed as the sum of adjacent distances along the shortest path between them, d H (a x , a y ) = \u2211 p<q;(ap,aq)\u2208SP (ax,ay) d(a p , a q ), (12) where SP (a x , a y ) is the shortest path between the aspects (a x , a y ), (a p , a q ) are the adjacent nodes along the path.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "We then define the following criteria to find the hierarchy with minimum semantic inconsistency, obj3 = arg min",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "H (i+1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "\u2211 x<y;ax,ay \u2208A i \u222a{a};",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "(d H (ax, ay)-d(ax, ay)) 2 , (13) where d(a x , a y ) is the distance computed based on the feature functions in Section 2.4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "Through integrating the above criteria, the multicriteria optimization framework is formulated as, obj = arg min",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "H (i+1) (\u03bb 1 \u2022 obj 1 + \u03bb 2 \u2022 obj 2 + \u03bb 3 \u2022 obj 3 ) \u03bb 1 + \u03bb 2 + \u03bb 3 = 1; 0 \u2264 \u03bb 1 , \u03bb 2 , \u03bb 3 \u2264 1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "(14) where \u03bb 1 , \u03bb 2 , \u03bb 3 are the tradeoff parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "To summarize, our aspect hierarchy generation process starts from an initial hierarchy and inserts the aspects into it one-by-one until all the aspects are allocated. Each aspect is inserted to the optimal position found by Eq.( 14). It is worth noting that the insertion order may influence the result. To avoid such influence, we select the aspect with the least objective function value in Eq.( 14) to insert. Based on resultant hierarchy, the consumer reviews are then organized to their corresponding aspect nodes in the hierarchy. We further prune out the nodes without reviews from the hierarchy.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "Moreover, we perform sentiment classification to determine consumer opinions on various aspects. In particular, we train a SVM sentiment classifier based on the Pros and Cons reviews described in Section 2.3. We collect sentiment terms in the reviews as features and represent reviews as feature vectors using Boolean weighting. Note that we define sentiment terms as those appear in the sentiment lexicon provided by MPQA project (Wilson et al., 2005) .",
                "cite_spans": [
                    {
                        "start": 431,
                        "end": 452,
                        "text": "(Wilson et al., 2005)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inf o(H(A, R)) = \u2211",
                "sec_num": null
            },
            {
                "text": "In this section, we apply the aspect hierarchy to the task of implicit aspect identification. This task aims to infer the aspects of reviews that do not explicitly express those aspects but actually comment on them (Liu et al. 2005) . Take the review \"The phone is too large\" as an example, the task is to infer its implicit aspect \"size.\" It has been observed that the reviews commenting on a same aspect usually use some same sentiment terms (Su et al., 2008) . Therefore, sentiment term is an effective feature for identifying implicit aspects. We here collect the sentiment terms as features to represent each review into a feature vector. For each aspect node in the hierarchy, we define its centroid as the average of its feature vectors, i.e., the feature vectors of all the reviews that are allocated at this node. We then calculate the cosine similarity of each implicit-aspect review to the centriods of all the aspect nodes, and allocate the review into the node with maximum similarity. As a result, the implicit aspect reviews are grouped to their related aspect nodes. In other word, their aspects are identified as the corresponding aspect nodes.",
                "cite_spans": [
                    {
                        "start": 215,
                        "end": 232,
                        "text": "(Liu et al. 2005)",
                        "ref_id": null
                    },
                    {
                        "start": 444,
                        "end": 461,
                        "text": "(Su et al., 2008)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Implicit Aspect Identification",
                "sec_num": "3"
            },
            {
                "text": "In this section, we evaluate the effectiveness of our approach on aspect identification, aspect hierarchy generation, and implicit aspect identification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluations",
                "sec_num": "4"
            },
            {
                "text": "The details of our product review corpus are given in Table 1 . This corpus contains consumer reviews on 11 popular products in four domains. These reviews were crawled from several prevalent forum Web sites, including cnet.com, viewpoints.com, reevoo.com and gsmarena.com . All of the reviews were posted between June, 2009 and Sep 2010. The aspects of the reviews, as well as the opinions on the aspects were manually annotated. We also invited five annotators to construct the gold-standard hierarchies for the products by providing them the initial hierarchies and the aspects in reviews. The conflicts between annotators were resolved through their discussions. For semantic distance learning, we collected 50 hierarchies from WordNet and ODP, respectively. The details are shown in Table 2 . We listed the topics of the hierarchies in Appendix B (submitted as supplementary material). We employed F 1 -measure, which is the combination of precision and recall, as the evaluation metric for all the evaluations. For the evaluation on aspect hierarchy, we defined precision as the percentage of correctly returned parent-child pairs out of the total returned pairs, and recall as the percentage of correctly returned parent-child pairs out of the total pairs in the gold standard. Throughout the experiments, we empirically set \u03bb 1 = 0.4, \u03bb 2 = 0.3, \u03bb 3 = 0.3, \u03b7 = 0.4 and \u03b3 = 0.6.",
                "cite_spans": [
                    {
                        "start": 198,
                        "end": 272,
                        "text": "Web sites, including cnet.com, viewpoints.com, reevoo.com and gsmarena.com",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 60,
                        "end": 61,
                        "text": "1",
                        "ref_id": "TABREF0"
                    },
                    {
                        "start": 794,
                        "end": 795,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Data and Experimental Setting",
                "sec_num": "4.1"
            },
            {
                "text": "We compared our approach against two state-of-theart methods: a) the method proposed by Hu and Liu (2004) , which is based on the association rule mining, and b) the method proposed by Wu et al. (2009) , which is based on the dependency parser. The results are presented in Figure 3 . On average, our approach significantly outperforms Hu's and Wu's method in terms of F 1 -measure by over 5.87% and 3.27%, respectively.",
                "cite_spans": [
                    {
                        "start": 95,
                        "end": 105,
                        "text": "Liu (2004)",
                        "ref_id": null
                    },
                    {
                        "start": 185,
                        "end": 201,
                        "text": "Wu et al. (2009)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 281,
                        "end": 282,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Aspect Identification",
                "sec_num": "4.2"
            },
            {
                "text": "We compared our approach against four traditional hierarchy generation methods in the researches on ontology learning, including a) patternbased method (Hearst, 1992) and b) clustering-based method by Shi et al. (2008) , c) the method proposed by Snow et al. (2006) which was based on a probabilistic model, and d) the method proposed by Yang and Callan (2009) . Since our approach and Yang's method can utilize initial hierarchy to assist hierarchy generation, we evaluated their performance with or without initial hierarchy, respectively. For the sake of fair comparison, Snow's, Yang's and our methods used the same linguistic features in Section 2.4.1.",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 218,
                        "text": "Shi et al. (2008)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 247,
                        "end": 265,
                        "text": "Snow et al. (2006)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 338,
                        "end": 360,
                        "text": "Yang and Callan (2009)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparisons with the State-of-the-Arts",
                "sec_num": "4.3.1"
            },
            {
                "text": "Figure 4 shows the performance comparisons of these five methods. We can see that our approach without using initial hierarchy outperforms the pattern-based, clustering-based, Snow's, and Yang's methods by over 17.9%, 19.8%, 2.9% and 6.1% respectively in terms of average F 1 -measure. By exploiting initial hierarchy, our approach improves the performance significantly. As compared to the pattern-based, clustering-based and Snow's methods, it improves the average performance by over 49.4%, 51.2% and 34.3% respectively. Compared to Yang's method with initial hierarchy, it achieves 4.7% improvements on the average performance.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "4",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Comparisons with the State-of-the-Arts",
                "sec_num": "4.3.1"
            },
            {
                "text": "The results show that pattern-based and clustering-based methods perform poor. Patternbased method may suffer from the problem of low coverage of patterns, especially when the patterns are manually pre-defined, while the clusteringbased method (Shi et al., 2008) may sustain to the bisection clustering mechanism which can only generate a binary-tree. The results also illustrate that our approach outperforms Snow's and Yang's methods. By exploiting external hierarchies, our approach is able to derive reliable semantic distance between aspects and thus improve the performance.",
                "cite_spans": [
                    {
                        "start": 244,
                        "end": 262,
                        "text": "(Shi et al., 2008)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Comparisons with the State-of-the-Arts",
                "sec_num": "4.3.1"
            },
            {
                "text": "In this section, we show that even based on a small part of the initial hierarchy, our approach can still generate a satisfactory hierarchy. We explored different proportion of initial hierarchy, including 0%, 20%, 40%, 60% and 80% of the aspect pairs which are collected top-down from the initial hierarchy. As shown in Figure 5 , the performance increases when larger proportion of the initial hierarchy is used. Thus, we can speculate that domain knowledge is valuable in aspect hierarchy generation.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 328,
                        "end": 329,
                        "text": "5",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Effectiveness of Initial Hierarchy",
                "sec_num": "4.3.2"
            },
            {
                "text": "We conducted a leave-one-out study to evaluate the effectiveness of each optimization criterion. In particular, we set one of the tradeoff parameters (\u03bb 1 , \u03bb 2 , \u03bb 3 ) in Eq.( 14) to zero, and distributed its weight to the rest parameters averagely. From Figure 6 , we find that removing any optimization criterion would degrade the performance on most products. It is interesting to note that removing the third optimization criterion, i.e., minimum semantic inconsistency, slightly increases the performance on two products (ipad touch and sony MP3). The reason might be that the values of the three tradeoff parameters (empirically set in Section 4.1) are not suitable for these two products. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 263,
                        "end": 264,
                        "text": "6",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Effectiveness of Optimization Criteria",
                "sec_num": "4.3.3"
            },
            {
                "text": "In this section, we evaluated the impact of the features and external hierarchies in semantic distance learning. We investigated five sets of features as described in Section 2.4.1, including contextual, cooccurrence, syntactic, pattern and lexical features. From Figure 7 , we observe that the co-occurrence and pattern features perform much better than contextual and syntactic features. A possible reason is that co-occurrence and pattern features are more likely to indicate parent-child aspect relationships, while contextual and syntactic features are probable to measure sibling aspect relationships. Among these features, the lexical features perform the worst. The combination of all the features achieves the best performance.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 271,
                        "end": 272,
                        "text": "7",
                        "ref_id": "FIGREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Semantic Distance Learning",
                "sec_num": "4.3.4"
            },
            {
                "text": "Next, we evaluated the effectiveness of external hierarchies in semantic distance learning. We compared the performance of our approach with or without the external hierarchies. From Figure 8 , we find that by exploiting the external hierarchies, our ap- proach improves the performance significantly. The improvement is over 2.81% in terms of average F 1measure. This implies that by using external hierarchies, our approach can obtain effective semantic distance, and thus improve the performance of aspect hierarchy generation.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 190,
                        "end": 191,
                        "text": "8",
                        "ref_id": "FIGREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Semantic Distance Learning",
                "sec_num": "4.3.4"
            },
            {
                "text": "Additionally, for sentiment classification, our SVM classifier achieves an average F 1 -measure of 0.787 in the 11 products.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluations on Semantic Distance Learning",
                "sec_num": "4.3.4"
            },
            {
                "text": "To evaluate the performance of our approach on implicit aspect identification, we collected 29,657 implicit aspect review sentences on the 11 products from the four forum Web sites introduced in Section 4.1. While most existing approaches for implicit aspect identification rely on hand-crafted rules (Liu, 2009) , the method proposed in Su et al. (2008) can identify implicit aspects without hand-crafted rules based on mutual clustering. Therefore, we adopt Su's method as the baseline here. Figure 9 illustrates the performance comparison between Su's and our approach. We can see that our approach outperforms Su's method by over 9.18% in terms of average F 1measure. This shows that our approach can identify the implicit aspects accurately by exploiting the underlying associations among the sentiment terms and each aspect in the hierarchy.",
                "cite_spans": [
                    {
                        "start": 301,
                        "end": 312,
                        "text": "(Liu, 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 338,
                        "end": 354,
                        "text": "Su et al. (2008)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 501,
                        "end": 502,
                        "text": "9",
                        "ref_id": "FIGREF7"
                    }
                ],
                "eq_spans": [],
                "section": "Evaluations on Implicit Aspect Identification",
                "sec_num": "4.4"
            },
            {
                "text": "Some researches treated review organization as a multi-document summarization problem, and generated a summary by selecting and ordering sentences taken from multiple reviews (Nishikawa et al., 2010). These works did not drill down to the fine-grained level to explore the opinions on the product aspects. Other researchers proposed to produce a summary covering consumer opinions on each aspect. For example, Hu and Liu ( 2004) focused on extracting the aspects and determining opinions on the aspects. However, their generated summary was unstructured, where the possible relationships between aspects were not recognized (Cadilhac et al., 2010) . Subsequently, Carenini et al. (2006) proposed to map the aspect to a userdefined taxonomy, but the taxonomy was handcrafted which was not scalable. Different from the previous works, we focus on automatically generating an aspect hierarchy to hierarchically organize consumer reviews. There are some related works on ontology learning, which first identify concepts from text, and then determine parent-child relations between these concepts using either pattern-based or clustering-based methods (Murthy et al., 2010) . Pattern-based methods usually defined some lexical syntactic patterns to extract the relations, while clustering-based methods mostly utilized the hierarchical clustering methods to build a hierarchy (Roy et al., 2006) . Some works proposed to integrate the pattern-based and clustering-based methods in a general model, such as the probabilistic model (Snow et al., 2006) and metric-based model (Yang and Callan, 2009) .",
                "cite_spans": [
                    {
                        "start": 624,
                        "end": 647,
                        "text": "(Cadilhac et al., 2010)",
                        "ref_id": null
                    },
                    {
                        "start": 664,
                        "end": 686,
                        "text": "Carenini et al. (2006)",
                        "ref_id": null
                    },
                    {
                        "start": 1147,
                        "end": 1168,
                        "text": "(Murthy et al., 2010)",
                        "ref_id": null
                    },
                    {
                        "start": 1371,
                        "end": 1389,
                        "text": "(Roy et al., 2006)",
                        "ref_id": null
                    },
                    {
                        "start": 1524,
                        "end": 1543,
                        "text": "(Snow et al., 2006)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 1567,
                        "end": 1590,
                        "text": "(Yang and Callan, 2009)",
                        "ref_id": "BIBREF22"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "5"
            },
            {
                "text": "The researches on aspect identification are also related to our work. Various aspect identification methods have been proposed (Popescu et al., 2005) , including supervised methods (Liu el al., 2005) , and unsupervised methods (Mei et al., 2007) . Different features have been investigated for this task. For example, Wu et al. (2009) identified aspects based on the features explored by dependency parser. For implicit aspect identification, some works proposed to define rules for identification (Liu el al., 2005) , while others suggested to automatically generate rules via mutual clustering (Su et al., 2008) . On the other hand, there are some related works on sentiment classification (Pang and Lee, 2008) . These works can be categorized into four granularities: document-level, sentence-level, aspect-level and word-level sentiment classification (Liu, 2009) . Existing researches have been studied unsupervised (Kim et al., 2004) , supervised (Pang et al., 2002; Pang et al., 2005) and semi-supervised classification approaches (Goldberg et al., 2006; Li et al., 2009) on these four levels.",
                "cite_spans": [
                    {
                        "start": 127,
                        "end": 149,
                        "text": "(Popescu et al., 2005)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 181,
                        "end": 199,
                        "text": "(Liu el al., 2005)",
                        "ref_id": null
                    },
                    {
                        "start": 227,
                        "end": 245,
                        "text": "(Mei et al., 2007)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 318,
                        "end": 334,
                        "text": "Wu et al. (2009)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 498,
                        "end": 516,
                        "text": "(Liu el al., 2005)",
                        "ref_id": null
                    },
                    {
                        "start": 596,
                        "end": 613,
                        "text": "(Su et al., 2008)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 692,
                        "end": 712,
                        "text": "(Pang and Lee, 2008)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 856,
                        "end": 867,
                        "text": "(Liu, 2009)",
                        "ref_id": null
                    },
                    {
                        "start": 921,
                        "end": 939,
                        "text": "(Kim et al., 2004)",
                        "ref_id": null
                    },
                    {
                        "start": 953,
                        "end": 972,
                        "text": "(Pang et al., 2002;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 973,
                        "end": 991,
                        "text": "Pang et al., 2005)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 1038,
                        "end": 1061,
                        "text": "(Goldberg et al., 2006;",
                        "ref_id": null
                    },
                    {
                        "start": 1062,
                        "end": 1078,
                        "text": "Li et al., 2009)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "5"
            },
            {
                "text": "In this paper, we have developed a domain-assisted approach to generate product aspect hierarchy by integrating domain knowledge and consumer reviews. Based on the derived hierarchy, we can generate a hierarchical organization of consumer reviews as well as consumer opinions on the aspects. With such organization, user can easily grasp the overview of consumer reviews, as well as seek consumer reviews and opinions on any specific aspect by navigating through the hierarchy. We have further applied the hierarchy to the task of implicit aspect identification. We have conducted evaluations on 11 different products in four domains. The experimental results have demonstrated the effectiveness of our approach. In the future, we will explore other linguistic features to learn the semantic distance between aspects, as well as apply our approach to other applications.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Works",
                "sec_num": "6"
            },
            {
                "text": "http://thesaurus.com",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "This work is supported by NUS-Tsinghua Extreme Search (NExT) project under the grant number: R-252-300-001-490. We give warm thanks to the project and anonymous reviewers for their valuable comments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            },
            {
                "text": "P. Beineke, T. Hastie, C. Manning, and S. Vaithyanathan. An Exploration of Sentiment Summarization. AAAI, 2003. J. Beckham. The Cnet E-commerce Data set. Technical Reports, 2005. G. Carenini, R. Ng, and E. Zwart. Multi-document Summarization of Evaluative Text. ACL, 2006. A. Cadilhac, F. Benamara, and N. Aussenac-Gilles. Ontolexical Resources for Feature based Opinion Mining: a Case-study. Ontolex, 2010. P. Cimiano, A. Madche, S. Staab, and J. Volker. Ontology Learning. Handbook on Ontologies, Springer, 2004. P. Cimiano, A. Hotho, and S. Staab. Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis. Artificial Intelligence, 2005. P. Cimiano. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications. Springer-Verlag New York, Inc. Secaucus, NJ, USA, 2006. S. Dasgupta and V. Ng. Mine the Easy, Classify the Hard: A Semi-supervised Approach to Automatic Sentiment Classification. ACL, 2009. O. Etzioni, M. Cafarella, D. Downey, A. Popescu, T. Shaked, S. Soderland, D. Weld, and A. Yates. Unsupervised Named-entity Extraction from the Web: An Experimental Study. Artificial Intelligence, 2005. A. Esuli and F. Sebastiani. A Publicly Available Lexical Resource for Opinion Mining. LREC, 2006. M. Gamon, A. Aue, S. Corston-Oliver, and E. Ringger. Pulse: Mining Customer Opinions from Free Text. IDA, 2005. R. Girju and A. Badulescu. Automatic Discovery of Partwhole Relations Computational Linguistics, 2006. A. Goldberg and X. Zhu. Seeing Stars When There Aren't Many Stars: Graph-based Semi-supervised Learning for Sentiment Categorization. ACL, 2006. M.A. Hearst. Automatic Acquisition of Hyponyms from Large Text Corpora. Coling, 1992. M. Hu and B. Liu. Mining and Summarizing Customer Reviews. SIGKDD, 2004. X. Hu, N. Sun, C. Zhang, and T.-S. Chua Exploiting Internal and External Semantics for the Clustering of Short Texts Using World Knowledge. CIKM, 2009. S. Kim and E. Hovy. Determining the Sentiment of Opinions. COLING, 2004. A. C. Konig and E. Brill. Reducing the Human Overhead in Text Categorization. KDD, 2006. Z. Kozareva, E. Riloff, and E. Hovy. Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. ACL, 2008. T. Li, Y. Zhang, and V. Sindhwani. A Non-negative Matrix Tri-factorization Approach to Sentiment Classification with Lexical Prior Knowledge. ACL, 2009. B. Liu, M. Hu, and J. Cheng. Opinion Observer: Analyzing and Comparing Opinions on the Web. WWW, 2005.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "References",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Sentiment Analysis and Subjectivity. Handbook of Natural Language Processing",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Handbook",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Chapter",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Liu. Handbook Chapter: Sentiment Analysis and Sub- jectivity. Handbook of Natural Language Processing. Marcel Dekker, Inc. New York, NY, USA, 2009.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "One-class SVMs for Document Classification",
                "authors": [
                    {
                        "first": "L",
                        "middle": [
                            "M"
                        ],
                        "last": "Manevitz",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Yousef",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Machine Learning",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "L.M. Manevitz and M. Yousef. One-class SVMs for Doc- ument Classification. Machine Learning, 2002.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs",
                "authors": [
                    {
                        "first": "Q",
                        "middle": [],
                        "last": "Mei",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Wondra",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [
                            "X"
                        ],
                        "last": "Zhai",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs. WWW, 2007.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Mining User Reviews: from Specification to Summarization",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Meng",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Meng and H. Wang. Mining User Reviews: from Specification to Summarization. ACL-IJCNLP, 2009.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Generating Term-frequency-induced Taxonomies",
                "authors": [],
                "year": 2010,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Generating Term-frequency-induced Taxonomies. ACL, 2010.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Optimizing Informativeness and Readability for Sentiment Summarization",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Nishikawa",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Hasegawa",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Matsuo",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Kikui",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Nishikawa, T. Hasegawa, Y. Matsuo, and G. Kikui. Optimizing Informativeness and Readability for Senti- ment Summarization. ACL, 2010.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Vaithyanathan",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? Sen- timent Classification using Machine Learning Tech- niques. EMNLP, 2002.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with respect to Rating Scales",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Pang and L. Lee. Seeing Stars: Exploiting Class Rela- tionships for Sentiment Categorization with respect to Rating Scales. ACL, 2005.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Opinion mining and sentiment analysis",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Foundations and Trends in Information Retrieval",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Pang and L. Lee. Opinion mining and sentiment anal- ysis. Foundations and Trends in Information Retrieval, 2008.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Privacy-Preserving, Similarity-Based Text Retrieval",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Hh",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Krishnan",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "ACM Transactions on Internet Technology",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "HH. Pang, J. Shen, and R. Krishnan Privacy-Preserving, Similarity-Based Text Retrieval. ACM Transactions on Internet Technology, 2010.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Extracting Product Features and Opinions from Reviews. HLT/EMNLP",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "M"
                        ],
                        "last": "Popescu",
                        "suffix": ""
                    },
                    {
                        "first": "O",
                        "middle": [],
                        "last": "Etzioni",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A.M. Popescu and O. Etzioni. Extracting Product Fea- tures and Opinions from Reviews. HLT/EMNLP, 2005.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Unsupervised Ontology Induction from Text. ACL",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Poon",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Domingos",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Poon and P. Domingos. Unsupervised Ontology In- duction from Text. ACL, 2010.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Expanding Domain Sentiment Lexicon through Double Propagation",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Bu",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Qiu, B. Liu, J. Bu, and C. Chen. Expanding Domain Sentiment Lexicon through Double Propagation. IJ- CAI, 2009.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Automatic Generation of Domain Models for Call Centers from Noisy Transcriptions",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Roy",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [
                            "V"
                        ],
                        "last": "Subramaniam",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Roy and L.V. Subramaniam. Automatic Generation of Domain Models for Call Centers from Noisy Tran- scriptions. ACL, 2009.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Generating a Concept Hierarchy for Sentiment Analysis",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "SMC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Shi and K. Chang. Generating a Concept Hierarchy for Sentiment Analysis. SMC, 2008.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Semantic Taxonomy Induction from Heterogenous Evidence",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Snow",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Snow and D. Jurafsky. Semantic Taxonomy Induction from Heterogenous Evidence. ACL, 2006.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Hidden Sentiment Association in Chinese Web Opinion Mining",
                "authors": [
                    {
                        "first": "Q",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Swen",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Q. Su, X. Xu, H. Guo, X. Wu, X. Zhang, B. Swen, and Z. Su. Hidden Sentiment Association in Chinese Web Opinion Mining. WWW, 2008.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "A Joint Model of Text and Aspect Ratings for Sentiment Summarization",
                "authors": [
                    {
                        "first": "I",
                        "middle": [],
                        "last": "Titov",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "I. Titov and R. McDonald. A Joint Model of Text and Aspect Ratings for Sentiment Summarization. ACL, 2008.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Thumbs up or thumbs down? Semantic Orientation Applied to Unsupervised Classification of Reviews",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Turney",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "P. Turney. Thumbs up or thumbs down? Semantic Orien- tation Applied to Unsupervised Classification of Re- views. ACL, 2002.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Phrase Dependency Parsing for Opinion Mining",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Q",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Wu, Q. Zhang, X. Huang, and L. Wu. Phrase Depen- dency Parsing for Opinion Mining. ACL, 2009.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Recognizing Contextual Polarity in Phrase-level Sentiment Analysis",
                "authors": [
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Wilson",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Wiebe",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Hoffmann",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing Contextual Polarity in Phrase-level Sentiment Analy- sis. HLT/EMNLP, 2005.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Metric-based Framework for Automatic Taxonomy Induction",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Callan",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Yang and J. Callan A Metric-based Framework for Automatic Taxonomy Induction. ACL, 2009.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Learning Object Models from Semi-structured Web Documents",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "T.-S",
                        "middle": [],
                        "last": "Chua",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Ye and T.-S. Chua. Learning Object Models from Semi-structured Web Documents. IEEE Transactions on Knowledge and Data Engineering, 2006.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Sentiment Analyzer: Extracting Sentiments about a Given Topic using Natural Language Processing Techniques. ICDM",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Yi",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Nasukawa",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Niblack",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Bunescu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Yi, T. Nasukawa, W. Niblack, and R. Bunescu. Senti- ment Analyzer: Extracting Sentiments about a Given Topic using Natural Language Processing Techniques. ICDM, 2003.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Sample hierarchical organization for iPhone 3G",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Sample Pros and Cons reviews",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 4: Evaluations on Aspect Hierarchy Generation. ttest, p-values<0.05. w/ H denotes the methods with initial hierarchy, accordingly, w/o H refers to the methods without initial hierarchy.",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 5: Evaluations on the Impact of Initial Hierarchy. t-test, p-values<0.05.",
                "uris": null,
                "fig_num": "5",
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "text": "Figure 6: Evaluations of the Optimization Criteria. % of change in F 1 -measure when a single criterion is removed. t-test, p-values<0.05.",
                "uris": null,
                "fig_num": "6",
                "type_str": "figure"
            },
            "FIGREF5": {
                "num": null,
                "text": "Figure 7: Evaluations on the Impact of Linguistic Features. t-test, p-values<0.05.",
                "uris": null,
                "fig_num": "7",
                "type_str": "figure"
            },
            "FIGREF6": {
                "num": null,
                "text": "Figure 8: Evaluations on the Impact of External Hierarchy. t-test, p-values<0.05.",
                "uris": null,
                "fig_num": "8",
                "type_str": "figure"
            },
            "FIGREF7": {
                "num": null,
                "text": "Figure 9: Evaluations on Implicit Aspects Identification. t-test, p-values<0.05",
                "uris": null,
                "fig_num": "9",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>Product Name</td><td>Domain</td><td>Review#</td><td>Sentence#</td></tr><tr><td>Canon EOS 450D (Canon EOS) Fujifilm Finepix AX245W (Fujifilm) Panasonic Lumix DMC-TZ7 (Panasonic)</td><td>camera camera camera</td><td>440 541 650</td><td>628 839 1,546</td></tr><tr><td>Apple MacBook Pro (MacBook) Samsung NC10 (Samsung)</td><td>laptop laptop</td><td>552 2,712</td><td>4,221 4,946</td></tr><tr><td>Apple iPod Touch 2nd (iPod Touch) Sony NWZ-S639 16GB (Sony NWZ)</td><td>MP3 MP3</td><td>4,567 341</td><td>10,846 773</td></tr><tr><td>BlackBerry Bold 9700 (BlackBerry) iPhone 3GS 16GB (iPhone 3GS) Nokia 5800 XpressMusic (Nokia 5800) Nokia N95</td><td>phone phone phone phone</td><td>4,070 12,418 28,129 15,939</td><td>11,008 43,527 75,001 44,379</td></tr></table>",
                "type_str": "table",
                "text": "Statistics of the reviews corpus, # denotes the size of the reviews/sentences",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Statistics of the External Hierarchies",
                "html": null,
                "num": null
            }
        }
    }
}