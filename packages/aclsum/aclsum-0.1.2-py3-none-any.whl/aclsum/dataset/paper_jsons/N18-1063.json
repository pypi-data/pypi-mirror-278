{
    "paper_id": "N18-1063",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:59:50.983715Z"
    },
    "title": "Semantic Structural Evaluation for Text Simplification",
    "authors": [
        {
            "first": "Elior",
            "middle": [],
            "last": "Sulem",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Hebrew University of Jerusalem",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Omri",
            "middle": [],
            "last": "Abend",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Hebrew University of Jerusalem",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Ari",
            "middle": [],
            "last": "Rappoport",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "The Hebrew University of Jerusalem",
                "location": {}
            },
            "email": ""
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Current measures for evaluating text simplification systems focus on evaluating lexical text aspects, neglecting its structural aspects. In this paper we propose the first measure to address structural aspects of text simplification, called SAMSA. It leverages recent advances in semantic parsing to assess simplification quality by decomposing the input based on its semantic structure and comparing it to the output. SAMSA provides a reference-less automatic evaluation procedure, avoiding the problems that reference-based methods face due to the vast space of valid simplifications for a given sentence. Our human evaluation experiments show both SAMSA's substantial correlation with human judgments, as well as the deficiency of existing reference-based measures in evaluating structural simplification. 1 ",
    "pdf_parse": {
        "paper_id": "N18-1063",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Current measures for evaluating text simplification systems focus on evaluating lexical text aspects, neglecting its structural aspects. In this paper we propose the first measure to address structural aspects of text simplification, called SAMSA. It leverages recent advances in semantic parsing to assess simplification quality by decomposing the input based on its semantic structure and comparing it to the output. SAMSA provides a reference-less automatic evaluation procedure, avoiding the problems that reference-based methods face due to the vast space of valid simplifications for a given sentence. Our human evaluation experiments show both SAMSA's substantial correlation with human judgments, as well as the deficiency of existing reference-based measures in evaluating structural simplification. 1 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Text simplification (TS) addresses the translation of an input sentence into one or more simpler sentences. It is a useful preprocessing step for several NLP tasks, such as machine translation (Chandrasekar et al., 1996; Mishra et al., 2014) and relation extraction (Niklaus et al., 2016) , and has also been shown useful in the development of reading aids, e.g., for people with dyslexia (Rello et al., 2013) or non-native speakers (Siddharthan, 2002) .",
                "cite_spans": [
                    {
                        "start": 193,
                        "end": 220,
                        "text": "(Chandrasekar et al., 1996;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 221,
                        "end": 241,
                        "text": "Mishra et al., 2014)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 266,
                        "end": 288,
                        "text": "(Niklaus et al., 2016)",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 389,
                        "end": 409,
                        "text": "(Rello et al., 2013)",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 433,
                        "end": 452,
                        "text": "(Siddharthan, 2002)",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The task has attracted much attention in the past decade (Zhu et al., 2010; Woodsend and Lapata, 2011; Wubben et al., 2012; Siddharthan and Angrosh, 2014; Narayan and Gardent, 2014) , but has yet to converge on an evaluation protocol that yields comparable results across different methods and strongly correlates with human judgments. This is in part due to the difficulty to combine the effects of different simplification operations (e.g., deletion, splitting and substitution). Xu et al. (2016) has recently made considerable progress towards that goal, and proposed to tackle it both by using an improved reference-based measure, named SARI, and by increasing the number of references. However, their research focused on lexical, rather than structural simplification, which provides a complementary view of TS quality as this paper will show.",
                "cite_spans": [
                    {
                        "start": 57,
                        "end": 75,
                        "text": "(Zhu et al., 2010;",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 76,
                        "end": 102,
                        "text": "Woodsend and Lapata, 2011;",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 103,
                        "end": 123,
                        "text": "Wubben et al., 2012;",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 124,
                        "end": 154,
                        "text": "Siddharthan and Angrosh, 2014;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 155,
                        "end": 181,
                        "text": "Narayan and Gardent, 2014)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 482,
                        "end": 498,
                        "text": "Xu et al. (2016)",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "This paper focuses on the evaluation of the structural aspects of the task. We introduce the semantic measure SAMSA (Simplification Automatic evaluation Measure through Semantic Annotation), the first structure-aware measure for TS in general, and the first to use semantic structure in this context in particular. SAMSA stipulates that an optimal split of the input is one where each predicate-argument structure is assigned its own sentence, and measures to what extent this assertion holds for the input-output pair in question, by using semantic structure. SAMSA focuses on the core semantic components of the sentence, and is tolerant towards the deletion of other units. 2For example, SAMSA will assign a high score to the output split \"John got home. John gave Mary a call.\" for the input sentence \"John got home and gave Mary a call.\", as it splits each of its predicate-argument structures to a different sentence. Splits that alter predicate-argument relations such as \"John got home and gave. Mary called.\" are penalized by SAMSA.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "SAMSA's use of semantic structures for TS evaluation has several motivations. First, it provides means to measure the extent to which the meaning of the source is preserved in the output. Second, it provides means for measuring whether the input sentence was split to semantic units of the right granularity. Third, defining a semantic measure that does not require references avoids the difficulties incurred by their non-uniqueness, and the difficulty in collecting high quality references, as reported by Xu et al. (2015) and by Narayan and Gardent (2014) with respect to the Parallel Wikipedia Corpus (PWKP; Zhu et al., 2010) . SAMSA is further motivated by its use of semantic annotation only on the source side, which allows to evaluate multiple systems using same source-side annotation, and avoids the need to parse system outputs, which can be garbled.",
                "cite_spans": [
                    {
                        "start": 508,
                        "end": 524,
                        "text": "Xu et al. (2015)",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 532,
                        "end": 558,
                        "text": "Narayan and Gardent (2014)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 612,
                        "end": 629,
                        "text": "Zhu et al., 2010)",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper we use the UCCA scheme for defining semantic structure (Abend and Rappoport, 2013) . UCCA has been shown to be preserved remarkably well across translations (Sulem et al., 2015) and has also been successfully used for machine translation evaluation (Birch et al., 2016) (Section 2). We note, however, that SAMSA can be adapted to work with any semantic scheme that captures predicate-argument relations, such as AMR (Banarescu et al., 2013) or Discourse Representation Structures (Kamp, 1981) , as used by Narayan and Gardent (2014) .",
                "cite_spans": [
                    {
                        "start": 69,
                        "end": 96,
                        "text": "(Abend and Rappoport, 2013)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 171,
                        "end": 191,
                        "text": "(Sulem et al., 2015)",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 263,
                        "end": 283,
                        "text": "(Birch et al., 2016)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 430,
                        "end": 454,
                        "text": "(Banarescu et al., 2013)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 494,
                        "end": 506,
                        "text": "(Kamp, 1981)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 520,
                        "end": 546,
                        "text": "Narayan and Gardent (2014)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We experiment with SAMSA both where semantic annotation is carried out manually, and where it is carried out by a parser. See Section 4. We conduct human rating experiments and compare the resulting system rankings with those predicted by SAMSA. We find that SAMSA's rankings obtain high correlations with human rankings, and compare favorably to existing referencebased measures for TS. Moreover, our results show that existing measures, which mainly target lexical simplification, are ill-suited to predict human judgments where structural simplification is involved. Finally, we apply SAMSA to the dataset of the QATS shared task on simplification evaluation ( \u0160tajner et al., 2016) . We find that SAMSA obtains comparative correlation with human judgments on the task, despite operating in a more restricted setting, as it does not use human ratings as training data and focuses only on structural aspects of simplicity. Section 2 presents previous work. Section 3 discusses UCCA. Section 4 presents SAMSA. Section 5 details the collection of human judgments. Our experimental setup for comparing our human and automatic rankings is given in Section 6, and results are given in Section 7, showing superior results for SAMSA. A discussion on the results is presented in Section 8.",
                "cite_spans": [
                    {
                        "start": 662,
                        "end": 685,
                        "text": "( \u0160tajner et al., 2016)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Section 9 presents experiments with SAMSA on the QATS evaluation benchmark.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Evaluation Metrics for Text Simplification. As pointed out by Xu et al. (2016) , many of the existing measures for TS evaluation do not generalize across systems, because they fail to capture the combined effects of the different simplification operations. The two main directions pursued are direct human judgments and automatic measures borrowed from machine translation (MT) evaluation. Human judgments generally include grammaticality (or fluency), meaning preservation (or adequacy) and simplicity. Human evaluation is usually carried out with a small number of sentences (18 to 20), randomly selected from the test set (Wubben et al., 2012; Narayan and Gardent, 2014, 2016) .",
                "cite_spans": [
                    {
                        "start": 62,
                        "end": 78,
                        "text": "Xu et al. (2016)",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 625,
                        "end": 646,
                        "text": "(Wubben et al., 2012;",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 647,
                        "end": 658,
                        "text": "Narayan and",
                        "ref_id": null
                    },
                    {
                        "start": 659,
                        "end": 679,
                        "text": "Gardent, 2014, 2016)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "The most commonly used automatic measure for TS is BLEU (Papineni et al., 2002) . Using 20 source sentences from the PWKP test corpus with 5 simplified sentences for each of them, Wubben et al. ( 2012) investigated the correlation of BLEU with human evaluation, reporting positive correlation for simplicity, but no correlation for adequacy. \u0160tajner et al. (2014) explored the correlation with human judgments of six automatic metrics: cosine similarity with a bag-of-words representation, METEOR (Denkowski and Lavie, 2011) , TERp (Snover et al., 2009) , TINE (Rios et al., 2011) and two sub-components of TINE: T-BLEU (a variant of BLEU which uses lower n-grams when no 4grams are found) and SRL (based on semantic role labeling). Using 280 pairs of a source sentence and a simplified output with only structural modifications, they found positive correlations for all the metrics except TERp with respect to meaning preservation and positive albeit lower correlations for METEOR, T-BLEU and TINE with respect to grammaticality. Human simplicity judgments were not considered in this experiment. In this paper we collect human judgments for grammaticality, meaning preservation and structural simplicity. To our knowledge, this is the first work to target structural simplicity evaluation, and it does so both through elicitation of human judgments and through the definition of SAMSA. Xu et al. (2016) were the first to propose two evaluation measures tailored for simplification, focusing on lexical simplification. The first metric is FKBLEU, a combination of iBLEU (Sun and Zhou, 2012) , originally proposed for evaluating paraphrase generation by comparing the output both to the reference and to the input, and of the Flesch-Kincaid Index (FK), a measure of the readability of the text (Kincaid et al., 1975) . The second one is SARI (System output Against References and against the Input sentence) which compares the n-grams of the system output with those of the input and the human references, separately evaluating the quality of words that are added, deleted and kept by the systems. They found that FKBLEU and even more so SARI correlate better with human simplicity judgments than BLEU. On the other hand, BLEU (with multiple references) outperforms the other metrics on the dimensions of grammaticality and meaning preservation.",
                "cite_spans": [
                    {
                        "start": 56,
                        "end": 79,
                        "text": "(Papineni et al., 2002)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 342,
                        "end": 363,
                        "text": "\u0160tajner et al. (2014)",
                        "ref_id": null
                    },
                    {
                        "start": 497,
                        "end": 524,
                        "text": "(Denkowski and Lavie, 2011)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 532,
                        "end": 553,
                        "text": "(Snover et al., 2009)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 561,
                        "end": 580,
                        "text": "(Rios et al., 2011)",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 1388,
                        "end": 1404,
                        "text": "Xu et al. (2016)",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 1571,
                        "end": 1591,
                        "text": "(Sun and Zhou, 2012)",
                        "ref_id": null
                    },
                    {
                        "start": 1794,
                        "end": 1816,
                        "text": "(Kincaid et al., 1975)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "As the Parallel Wikipedia Corpus (PWKP), usually used in simplification research, has been shown to contain a large portion of problematic simplifications (Xu et al., 2015; Hwang et al., 2015) , Xu et al. (2016) further proposed to use multiple references (instead of a single reference) in the evaluation measures. SAMSA addresses this issue by directly comparing the input and the output of the simplification system, without requiring manually curated references.",
                "cite_spans": [
                    {
                        "start": 155,
                        "end": 172,
                        "text": "(Xu et al., 2015;",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 173,
                        "end": 192,
                        "text": "Hwang et al., 2015)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 195,
                        "end": 211,
                        "text": "Xu et al. (2016)",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Structural Measures for Text-to-text Generation. Other than measuring the number of splits (Narayan and Gardent, 2014, 2016) , which only assesses the frequency of this operation and not its quality, no structural measures were previously proposed for the evaluation of structural simplification. The need for such a measure is pressing, given recent interest in structural simplification, e.g., in the Split and Rephrase task (Narayan et al., 2017) , which focuses on sentence splitting.",
                "cite_spans": [
                    {
                        "start": 91,
                        "end": 103,
                        "text": "(Narayan and",
                        "ref_id": null
                    },
                    {
                        "start": 104,
                        "end": 124,
                        "text": "Gardent, 2014, 2016)",
                        "ref_id": null
                    },
                    {
                        "start": 427,
                        "end": 449,
                        "text": "(Narayan et al., 2017)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "In the task of sentence compression, which is similar to simplification in that they both involve deletion and paraphrasing, Clarke and Lapata (2006) showed that a metric that uses syntactic dependencies better correlates with human evaluation than a metric based on surface sub-strings. Toutanova et al. (2016) found that structure-aware metrics obtain higher correlation with human evaluation over bigram-based metrics, in particular with grammaticality judgments, but that they do not significantly outperform bigram-based metrics on any parameter. Both Clarke and Lapata (2006) and Toutanova et al. (2016) use reference-based metrics that use syntactic structure on both the output and the references. SAMSA on the other hand uses linguistic annotation only on the source side, with semantic structures instead of syntactic ones.",
                "cite_spans": [
                    {
                        "start": 125,
                        "end": 149,
                        "text": "Clarke and Lapata (2006)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 288,
                        "end": 311,
                        "text": "Toutanova et al. (2016)",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 557,
                        "end": 581,
                        "text": "Clarke and Lapata (2006)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 586,
                        "end": 609,
                        "text": "Toutanova et al. (2016)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Semantic structures were used in MT evaluation, for example in the MEANT metric (Lo et al., 2012) , which compares the output and the reference sentences, both annotated using SRL (Semantic Role Labeling). Lo et al. (2014) proposes the XMEANT variant, which compares the SRL structures of the source and output (without using references). As some frequent constructions like nominal argument structures are not addressed by the SRL annotation, Birch et al. (2016) proposed HUME, a human evaluation metric based on UCCA, using the semantic annotation only on the source side when comparing it to the output. We differ from HUME in proposing an automatic metric, tackling monolingual text simplification, rather than MT.",
                "cite_spans": [
                    {
                        "start": 80,
                        "end": 97,
                        "text": "(Lo et al., 2012)",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 206,
                        "end": 222,
                        "text": "Lo et al. (2014)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 444,
                        "end": 463,
                        "text": "Birch et al. (2016)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "The UCCA annotation has also been recently used for the evaluation of Grammatical Error Correction (GEC). The USIM metric (Choshen and Abend, 2018) measures the semantic faithfulness of the output to the source by comparing their respective UCCA graphs.",
                "cite_spans": [
                    {
                        "start": 122,
                        "end": 147,
                        "text": "(Choshen and Abend, 2018)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Semantic Structures in Text Simplification. In most of the work investigating the structural operations involved in text simplification, both in rulebased systems (Siddharthan and Angrosh, 2014) and in statistical systems (Zhu et al., 2010; Woodsend and Lapata, 2011) , the structures that were considered were syntactic. Narayan and Gardent (2014, 2016) proposed to use semantic structures in the simplification model, in particular in order to avoid splits and deletions which are inconsistent with the semantic structures. SAMSA identifies such incoherent splits, e.g., a split of a phrase describing a single event, and penalizes them. Glavas and \u0160tajner (2013) presented two simplification systems based on event extraction. One of them, named Event-wise Simplification, transforms each factual event motion into a separate sentence. This approach fits with SAMSA's stipulation, that an optimal structural simplification is one where each (UCCA-) event in the input sentence is assigned a separate output sentence. However, unlike in their model, SAMSA stipulates that not only should multiple events evoked by a verb in the same sentence be avoided in a simplification, but penalizes sentences containing multiple events evoked by a lexical item of any category. For example, the sentence \"John's un-expected kick towards the gate saved the game\" which has two events, one evoked by \"kick\" (a noun) and another by \"saving\" (a verb) can be converted to \"John kicked the ball towards the gate. It saved the game.\"",
                "cite_spans": [
                    {
                        "start": 163,
                        "end": 194,
                        "text": "(Siddharthan and Angrosh, 2014)",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 222,
                        "end": 240,
                        "text": "(Zhu et al., 2010;",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 241,
                        "end": 267,
                        "text": "Woodsend and Lapata, 2011)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 322,
                        "end": 333,
                        "text": "Narayan and",
                        "ref_id": null
                    },
                    {
                        "start": 334,
                        "end": 354,
                        "text": "Gardent (2014, 2016)",
                        "ref_id": null
                    },
                    {
                        "start": 640,
                        "end": 665,
                        "text": "Glavas and \u0160tajner (2013)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "In this section we will briefly describe the UCCA scheme, focusing on the concepts of Scenes and Centers which are key in the definition of SAMSA. UCCA (Universal Cognitive Conceptual Annotation; Abend and Rappoport, 2013 ) is a semantic annotation scheme based on typological (Dixon, 2010b (Dixon, ,a, 2012) ) and cognitive (Langacker, 2008) theories which aims to represent the main semantic phenomena in the text, abstracting away from syntactic detail. UCCA structures are directed acyclic graphs whose nodes (or units) correspond either to the leaves of the graph (including the words of the text) or to several elements jointly viewed as a single entity according to some semantic or cognitive consideration. Unlike AMR, UCCA semantic units are directly anchored in the text (Abend and Rappoport, 2017; Birch et al., 2016) , which allows easy inclusion of a word-toword alignment in the metric model (Section 4). UCCA Scenes. A Scene, which is the most basic notion of the foundational layer of UCCA considered here, describes a movement, an action or a state which persists in time. Every Scene contains one main relation, which can be either a Process or a State. The Scene may contain one or more Participants, which are interpreted in a broad sense, including locations and destinations. For example, the sentence \"He ran into the park\" has a single Scene whose Process is \"ran\". The two Participants are \"He\" and \"into the park\".",
                "cite_spans": [
                    {
                        "start": 196,
                        "end": 221,
                        "text": "Abend and Rappoport, 2013",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 277,
                        "end": 290,
                        "text": "(Dixon, 2010b",
                        "ref_id": null
                    },
                    {
                        "start": 291,
                        "end": 310,
                        "text": "(Dixon, ,a, 2012) )",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 325,
                        "end": 342,
                        "text": "(Langacker, 2008)",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 781,
                        "end": 808,
                        "text": "(Abend and Rappoport, 2017;",
                        "ref_id": null
                    },
                    {
                        "start": 809,
                        "end": 828,
                        "text": "Birch et al., 2016)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "Scenes can have several roles in the text. First, they can provide additional information about an established entity (Elaborator Scenes) as for example the Scene \"who entered the house\" in the sentence \"The man who entered the house is John\". They can also be one of the Participants of another Scene, for example, \"he will be late\" in the sentence: \"He said he will be late\". In the other cases, the Scenes are annotated as parallel Scenes (H) which can be linked by a Linker (L): \"When L [he will arrive at home] H , [he will call them] H \".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "Unit Centers. With regard to units which are not Scenes, the category Center denotes the semantic head of the unit. For example, \"dogs\" is the center of the expression \"big brown dogs\" and \"box\" is the center of \"in the box\". There could be more than one Center in a non-Scene unit, for example in the case of coordination, where all conjuncts are Centers.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "4 The SAMSA Metric SAMSA's main premise is that a structurally correct simplification is one where: (1) each sentence contains a single event from the input (UCCA Scene), (2) the main relation of each of the events and their participants are retained in the output.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "For example, consider \"John wrote a book. I read that book.\" as a simplification of \"I read the book that John wrote.\". Each output sentence contains one Scene, which has the same Scene elements as the source, and would thus be deemed correct by SAMSA. On the other hand, the output \"John wrote. I read the book.\" is an incorrect split of that sentence, since a participant of the \"writing\" Scene, namely \"the book\" is absent in the split sentence. SAMSA would indeed penalize such a case.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "Similarly, Scenes which have elements across several sentences receive a zero score by SAMSA.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "As an example, consider the sentence \"The combination of new weapons and tactics marks this battle as the end of chivalry\", and erroneous split \"The combination of new weapons and tactics. It is the end of chivalry.\" (adapted from the output of a recent system on the PWKP corpus), which does not preserve the original meaning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "UCCA's Semantic Structures",
                "sec_num": "3"
            },
            {
                "text": "SAMSA is based on two external linguistic resources. One is a semantic annotation (UCCA in our experiments) of the source side, which can be carried out either manually or automatically, using the TUPA parser3 (Transition-based UCCA parser; Hershcovich et al., 2017) for UCCA. UCCA decomposes each sentence s into a set of Scenes {sc 1 , sc 2 , .., sc n }, where each scene sc i contains a main relation mr i (sub-span of sc i ) and a set of zero or more participants A i .",
                "cite_spans": [
                    {
                        "start": 241,
                        "end": 266,
                        "text": "Hershcovich et al., 2017)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Matching Scenes to Sentences",
                "sec_num": "4.1"
            },
            {
                "text": "The second resource is a word-to-word alignment A between the words in the input and one or zero words in the output. The monolingual alignment thus permits SAMSA not to penalize outputs that involve lexical substitutions (e.g., \"com-mence\" might be aligned with \"start\"). We denote by n inp the number of UCCA Scenes in the input sentence and by n out the number of sentences in the output.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Matching Scenes to Sentences",
                "sec_num": "4.1"
            },
            {
                "text": "Given an input sentence's UCCA Scenes sc 1 , . . . , sc n inp , a non-annotated output of a simplification system split into sentences s 1 , . . . , s nout , and their word alignment A, we distinguish between two cases: 1. n inp \u2265 n out : in this case, we compute the maximal Many-to-1 correspondence between Scenes and sentences. A Scene is matched to a sentence in the following way. We say that a leaf l in a Scene sc is consistent in a Scenesentence mapping M which maps sc to a sentence s, if there is a word w \u2208 s which l aligns to (according to the word alignment A). The score of matching a Scene sc to a sentence s is then defined to be the total number of consistent leaves in sc. We traverse the Scenes in their order of occurrence in the text, selecting for each the sentence that maximizes the score.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Matching Scenes to Sentences",
                "sec_num": "4.1"
            },
            {
                "text": "If n inp = n out , once a sentence is matched to a Scene, it cannot be matched to another one. Ties between sentences are broken towards the sentence that appeared first in the output. For example, the center of the unit \"The previous president of the commission\" (u 1 ) is \"president of the commission\". The center of the latter is \"president\", which is a leaf in the graph. So the minimal center of u 1 is \"president\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Matching Scenes to Sentences",
                "sec_num": "4.1"
            },
            {
                "text": "the input sentence Scenes {sc 1 , ..., sc n inp }, the output sentences {s 1 , ..., s nout }, and a mapping between them M * , SAMSA is defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Given",
                "sec_num": null
            },
            {
                "text": "nout ninp 1 2ninp sc i 1 M * (sc i ) (M Ri) + 1 ki k i j=1 1 M * (sc i ) (Par (j) i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Given",
                "sec_num": null
            },
            {
                "text": "where MR i is the minimal center of the main relation (Process or State) of sc i , and Par (j) i (j = 1, . . . , k i ) are the minimal centers of the Participants of sc i .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Given",
                "sec_num": null
            },
            {
                "text": "For an output sentence s, 1 s (u) is a function from the input units to {0, 1}, which returns 1 iff u is aligned (according to A) with a word in s. 4The role of the non-splitting penalty term n out /n inp in the SAMSA formula is to penalize cases where the number of sentences in the output is smaller than the number of Scenes. In order to isolate the effect of the non-splitting penalty, we experiment with an additional metric SAMSA abl (reads \"SAMSA ablated\"), which is identical to SAMSA but does not take this term into account. Corpus-level SAMSA and SAMSA abl scores are obtained by averaging their sentence scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Given",
                "sec_num": null
            },
            {
                "text": "In the case of implicit units i.e. omitted units that do not appear explicitly in the text (Abend and Rappoport, 2013) , since the unit preservation cannot be directly captured, the score t for the relevant unit will be set to 0.5. For example, in the Scene \"traveling is fun\", the people who are traveling correspond to an implicit Participant. As implicit units are not covered by TUPA, this will only be relevant for the semi-automatic implementation of the metric (see Section 6).",
                "cite_spans": [
                    {
                        "start": 91,
                        "end": 118,
                        "text": "(Abend and Rappoport, 2013)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Given",
                "sec_num": null
            },
            {
                "text": "For testing the automatic metric, we first build a human evaluation benchmark, using 100 sentences from the complex part of the PWKP corpus and the outputs of six recent simplification systems for these sentences:5 (1) TSM (Zhu et al., 2010) using Tree-Based SMT, (2) RevILP (Woodsend and Lapata, 2011) using Quasi-Synchronous Grammars, (3) PBMT-R (Wubben et al., 2012) using Phrase-Based SMT, (4) Hybrid (Narayan and Gardent, 2014 ), a supervised system using DRS, (5) UN-SUP (Narayan and Gardent, 2016) , an unsupervised system using DRS, and (6) Split-Deletion (Narayan and Gardent, 2016) , the unsupervised system with only structural operations.",
                "cite_spans": [
                    {
                        "start": 223,
                        "end": 241,
                        "text": "(Zhu et al., 2010)",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 275,
                        "end": 302,
                        "text": "(Woodsend and Lapata, 2011)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 405,
                        "end": 431,
                        "text": "(Narayan and Gardent, 2014",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 477,
                        "end": 504,
                        "text": "(Narayan and Gardent, 2016)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 564,
                        "end": 591,
                        "text": "(Narayan and Gardent, 2016)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Protocol",
                "sec_num": "5.1"
            },
            {
                "text": "All these systems explicitly address at least one type of structural simplification operation. The last system, Split-Deletion, performs only structural (i.e., no lexical) operations. It is thus an interesting test case for SAMSA since here the aligner can be replaced by a simple match between identical words. In total we obtain 600 system outputs from the six systems, as well as 100 sentences from the simple Wikipedia side of the corpus, which serve as references. Five in-house annotators with high proficiency in English evaluated the resulting 700 input-output pairs by answering the questions in Table 1 . 6 Qa addresses grammaticality, Qb and Qc capture two complementary aspects of meaning preservation (the addition and the removal of information) and Qd addresses structural simplicity. Possible answers are: 1 (\"no\"), 2 (\"maybe\") and 3 (\"yes\"). Following Glavas and \u0160tajner (2013) , we used a 3 point Likert scale, which has recently been shown to be preferable over a 5 point scale through human studies on sentence compression (Toutanova et al., 2016) .",
                "cite_spans": [
                    {
                        "start": 869,
                        "end": 894,
                        "text": "Glavas and \u0160tajner (2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 1043,
                        "end": 1067,
                        "text": "(Toutanova et al., 2016)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 611,
                        "end": 612,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Evaluation Protocol",
                "sec_num": "5.1"
            },
            {
                "text": "Question Qd was accompanied by a negative example 7 showing a case of lexical simplification, where a complex word is replaced by a simple one. A positive example was not included so as not to bias the annotators by revealing the nature of the operations our experiments focus on (i.e., splitting and deletion).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Protocol",
                "sec_num": "5.1"
            },
            {
                "text": "The PWKP test corpus (Zhu et al., 2010) was selected for our experiments over the development and test sets used in (Xu et al., 2016) , as the latter's selection process was explicitly biased towards input-output pairs that mainly contain lexical simplifications.",
                "cite_spans": [
                    {
                        "start": 21,
                        "end": 39,
                        "text": "(Zhu et al., 2010)",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 116,
                        "end": 133,
                        "text": "(Xu et al., 2016)",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Protocol",
                "sec_num": "5.1"
            },
            {
                "text": "Is the output grammatical?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Qa",
                "sec_num": null
            },
            {
                "text": "Qb Does the output add information, compared to the input? Qc Does the output remove important information, compared to the input?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Qa",
                "sec_num": null
            },
            {
                "text": "Is the output simpler than the input, ignoring the complexity of the words?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Qd",
                "sec_num": null
            },
            {
                "text": "Table 1 : Questions for the human evaluation 6 Each input-output pair was rated by all five annotators. 7 Other questions appeared without any example.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Qd",
                "sec_num": null
            },
            {
                "text": "Given the annotator's answers, we consider the following scores. First, the grammaticality score G is the answer to Qa. By inverting (changing 1 to 3 and 3 to 1) the answer for Qb, we obtain a Non-Addition score indicating to which extent no additional information has been added. Similarly, inverting the answer to Qc yields the Non-Removal score. Averaging these two scores, we obtain the meaning preservation score P. Finally, the structural simplicity score S is the answer to Qd. Each of these scores is averaged over the five annotators.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Score Computation",
                "sec_num": "5.2"
            },
            {
                "text": "We further compute an average human score:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Score Computation",
                "sec_num": "5.2"
            },
            {
                "text": "AvgHuman = 1 3 (G + P + S)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human Score Computation",
                "sec_num": "5.2"
            },
            {
                "text": "Inter-annotator agreement rates are computed in two ways. Table 2 presents the absolute agreement and Cohen's quadratic weighted \u03ba (Cohen, 1968) . Table 3 presents Spearman's correlation (\u03c1) between the human ratings of the input-output pairs (top row), and between the resulting system scores (bottom row). In both cases, the agreement between the five annotators is computed as the average agreement over the 10 annotator pairs. ",
                "cite_spans": [
                    {
                        "start": 131,
                        "end": 144,
                        "text": "(Cohen, 1968)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 64,
                        "end": 65,
                        "text": "2",
                        "ref_id": "TABREF2"
                    },
                    {
                        "start": 153,
                        "end": 154,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Inter-annotator Agreement",
                "sec_num": "5.3"
            },
            {
                "text": "We further compute SAMSA for the 100 sentences of the PWKP test set and the corresponding system outputs. Experiments are conducted in two settings: (1) a semi-automatic setting where UCCA annotation was carried out manually by a single expert UCCA annotator using the UC-CAApp annotation software (Abend et al., 2017) , and according to the standard annotation guidelines;8 (2) an automatic setting where the UCCA annotation was carried out by the TUPA parser (Hershcovich et al., 2017) . Sentence segmentation of the outputs was carried out using the NLTK package (Loper and Bird, 2002) . For word alignments, we used the aligner of Sultan et al. ( 2014).9 ",
                "cite_spans": [
                    {
                        "start": 298,
                        "end": 318,
                        "text": "(Abend et al., 2017)",
                        "ref_id": null
                    },
                    {
                        "start": 461,
                        "end": 487,
                        "text": "(Hershcovich et al., 2017)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 566,
                        "end": 588,
                        "text": "(Loper and Bird, 2002)",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "6"
            },
            {
                "text": "We compare the system rankings obtained by SAMSA and by the four human parameters. We find that the two leading systems according to AvgHuman and SAMSA turn out to be the same: Split-Deletion and RevILP. This is the case both for the semi-automatic and the automatic implementations of the metric. A Spearman \u03c1 correlation between the human and SAMSA scores (comparing their rankings) is presented in Table 4 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 407,
                        "end": 408,
                        "text": "4",
                        "ref_id": "TABREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "We compare SAMSA and SAMSA abl to the reference-based measures SARI 10 (Xu et al., 2016) and BLEU, as well as to the negative Levenshtein distance to the reference (-LD SR ). We use the only available reference for this corpus, in accordance with the standard practice. SARI is a reference-based measure, based on n-gram overlap between the source, output and reference, and focuses on lexical (rather than structural) simplification. For completeness, we include the other two measures reported in Narayan and Gardent (2016) , which are measures of similarity to the input (i.e., they quantify the tendency of the systems to introduce changes to the input): the negative Levenshtein distances between the output and input compared to the original complex corpus (-LD SC ), and the number of sentences split by each of the systems.",
                "cite_spans": [
                    {
                        "start": 499,
                        "end": 525,
                        "text": "Narayan and Gardent (2016)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "The highest correlation with AvgHuman and grammaticality is obtained by semi-automatic SAMSA (0.58 and 0.54), a high correlation especially in comparison to the inter-annotator agreement on AvgHuman (0.64, Table 3 ). The automatic version obtains high correlation with human judgments in these settings, where for struc-tural simplicity, it scores somewhat higher than the semi-automatic SAMSA. The highest correlation with structural simplicity is obtained by the number of sentences with splitting, where SAMSA (automatic and semi-automatic) is second and third highest, although when restricted to multi-Scene sentences, the correlation for SAMSA (semi-automatic) is higher (0.89, p = 0.009 and 0.77, p = 0.04).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 212,
                        "end": 213,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "The highest correlation for meaning preservation is obtained by SAMSA abl which provides further evidence that the retainment of semantic structures is a strong predictor of meaning preservation (Sulem et al., 2015) . SAMSA in itself does not correlate with meaning preservation, probably due to its penalization of under-splitting sentences.",
                "cite_spans": [
                    {
                        "start": 195,
                        "end": 215,
                        "text": "(Sulem et al., 2015)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "Note that the standard reference-based measures for simplification, BLEU and SARI, obtain low and often negative correlation with human ratings. We believe that this is the case because SARI and BLEU admittedly focus on lexical simplification, and are difficult to use to rank systems which also perform structural simplification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "Our results thus suggest that SAMSA provides additional value in predicting the quality of a simplification system and should be reported in tandem with more lexically-oriented measures.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation with Human Evaluation",
                "sec_num": "7"
            },
            {
                "text": "Human evaluation parameters. The fact that the highest correlations for structural simplicity and meaning preservation are obtained by different metrics (SAMSA and SAMSA abl respectively) highlights the complementarity of these two parameters for evaluating TS quality but also the difficulty of capturing them together. Indeed, a given sentence-level operation could both change the original meaning by adding or removing information (affecting the P score) and increase simplicity (S). On the other hand, the identity transformation perfectly preserves the meaning of the original sentence without making it simpler.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "8"
            },
            {
                "text": "For examining this phenomenon, we compute Spearman's correlation at the system-level between the simplicity and meaning preservation human scores. We obtain a correlation of -0.77 (p = 0.04) between S and P. The correlation between S and the two sub-components of P, the Non-Addition and the Non-Removal scores, are -0.43 (p = 0.2) and -0.77 (p = 0.04) respectively. These negative correlations support our use and p-values) , between evaluation measures (columns) and human judgments (rows). The ranking is between the six simplification systems experimented with. The left block of columns corresponds to the SAMSA and SAMSA abl measures, in their semi-automatic and automatic forms. The middle block of columns corresponds to the reference-based measures SARI and BLEU, as well as -LD SR , which is the negative Levenshtein distances of the system output from the reference. The right block corresponds to measures of conservatism, and reflect how well the tendency of the systems to introduce changes to the input correlates with the human rankings. The block includes -LD SC , the negative Levenshtein distance from the source sentence, and the number of input sentences split by each of the systems. Levenshtein distances are taken as negative in order to capture similarity between the output and source/reference. The measure with the highest correlation in each row is boldfaced.",
                "cite_spans": [
                    {
                        "start": 411,
                        "end": 424,
                        "text": "and p-values)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "8"
            },
            {
                "text": "of an average human score for assessing the overall quality of the simplification. system in QATS obtained a correlation of 0.23. This correlation by SAMSA was obtained in more restricted conditions, compared to the measures that competed in QATS. First, SAMSA computes its score by only considering the UCCA structure of the source, and an automatic wordto-word alignment between the source and output. Most QATS systems, including OSVCML and OSVCML2 (Nisioi and Nauze, 2016) which scored highest on the shared task, use an ensemble of classifiers based on bag-of-words, POS tags, sentiment information, negation, readability measures and other resources. Second, the systems participating in the shared task had training data available to them, annotated by the same annotators as the test data. This was used to train classifiers for predicting their score. This gives the QATS measures much predictive strength, but hampers their interpretability. SAMSA on the other hand is conceptually simple and interpretable. Third, the QATS shared task does not focus on structural simplification, but experiments on different types of systems. Indeed, some of the data was annotated by systems that exclusively perform lexical simplification, which is orthogonal to SAMSA's structural focus.",
                "cite_spans": [
                    {
                        "start": 452,
                        "end": 476,
                        "text": "(Nisioi and Nauze, 2016)",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "8"
            },
            {
                "text": "Given these factors, SAMSA's competitive correlation with the participating systems in QATS suggests that structural simplicity, as reflected by the correct splitting of UCCA Scenes, captures a major component in overall simplification quality, underscoring SAMSA's value. These promising results also motivate a future combination of SAMSA with classifier-based metrics.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "8"
            },
            {
                "text": "We presented the first structure-aware metric for text simplification, SAMSA, and the first evaluation experiments that directly target the structural simplification component, separately from the lexical component. We argue that the structural and lexical dimensions of simplification are loosely related, and that TS evaluation protocols should assess both. We empirically demonstrate that strong measures that assess lexical simplification quality (notably SARI), fail to correlate with human judgments when structural simplification is performed by the evaluated systems. Our experiments show that SAMSA correlates well with human judgments in such settings, which demonstrates its usefulness for evaluating and tuning statistical simplification systems, and shows that structural evaluation provides a complementary perspective on simplification quality.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "10"
            },
            {
                "text": "All data and code are available in https://github. com/eliorsulem/SAMSA.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We do not consider other structural operations, such as passive to active transformations(Canning, 2002), that are currently not treated by corpus-based simplification systems.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/danielhers/tupa",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In some cases, the unit u can be a sequence of centers (if there are several minimal centers). In these cases, 1s(u) returns 1 iff the condition holds for all centers.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "All the data can be found here: http: //homepages.inf.ed.ac.uk/snaraya2/data/ simplification-2016.tgz.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www.cs.huji.ac.il/ \u02dcoabend/ ucca.html",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/ma-sultan/ monolingual-word-aligner",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Data and code for can be found in https://github. com/cocoxu/simplification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "takelab.fer.hr/data/symplify",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We would like to thank Zhemin Zhu and Sander Wubben for sharing their data, as well as the annotators for participating in our evaluation and UCCA annotation experiments. We also thank Daniel Hershcovich and the anonymous reviewers for their helpful comments. This work was partially supported by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) and by the Israel Science Foundation (grant No. 929/17), as well as by the HUJI Cyber Security Research Center in conjunction with the Israel National Cyber Bureau in the Prime Minister's Office.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            },
            {
                "text": "Distribution at the sentence level. In addition to the system-level analysis presented in Section 7, we also investigate the behavior of SAMSA at the sentence level by examining its joint distribution with the human evaluation scores. Focusing on the AvgHuman score and the automatic implementation of SAMSA and using the same data as in Section 7, we consider a single pair of scores (AvgHuman i , SAMSA i ), 1 \u2264 i \u2264 100, for each of the 100 source sentences, averaging over the SAMSA and human scores obtained for the 6 simplification systems (See Figure 1 ).The joint distribution indicates a positive correlation between SAMSA and AvgHuman. The corresponding Pearson correlation is indeed 0.27 (p = 0.03).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 557,
                        "end": 558,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "annex",
                "sec_num": null
            },
            {
                "text": "In order to provide further validation for SAMSA predictive value for quality of simplification systems, we report SAMSA's correlation with a recently proposed benchmark, used for the QATS (Quality Assessment for Text Simplification) shared task ( \u0160tajner et al., 2016) .Setup. The test corpus contains 126 sentences taken from 3 datasets described in \u0160tajner et al. (2016) 11 : (1) EventS: original sentences from the EMM News-Brief 12 and their syntactically simplified versions (with significant content reduction) by the EventSimplify TS system (Glavas 11 http://qats2016.github.io/shared.html 12 emm.newsbrief.eu/NewsBrief/ clusteredition/en/latest.html and \u0160tajner, 2013) 13 (the test corpus contains 54 pairs from this dataset), (2) EncBrit: original sentences from the Encyclopedia Britannica (Barzilay and Elhadad, 2003) and their automatic simplifications obtained using ATS systems based on several phrase-based statistical MT systems ( \u0160tajner et al., 2015) trained on Wikipedia TS corpus (Coster and Kauchak, 2011 ) (24 pairs), and (3) LSLight: sentences from English Wikipedia and their automatic simplifications (Glava\u0161 and \u0160tajner, 2015) by three different lexical simplification systems (Biran et al., 2011; Horn et al., 2014; Glava\u0161 and \u0160tajner, 2015) (48 pairs).Human evaluation is also provided by this resource, with scores for overall quality, grammaticality, meaning preservation and simplicity. Importantly, the simplicity score does not explicitly refer to the output's structural simplicity, but rather to its readability. We focus on the overall human score, and compare it to SAMSA. Since different systems were used to simplify different portions of the input, correlation is taken at the sentence level.We use the same implementations of SAMSA. Manual UCCA annotation is here performed by one of the authors of this paper. Results. We follow \u0160tajner et al. (2016) and report the Pearson correlations (at the sentence level) between the rankings of the metrics and the human evaluation scores. Results show that the semi-automatic/automatic SAMSA obtains a Pearson correlation of 0.32 and 0.28 with the human scores. This places these measures in the 3rd and 4th places in the shared task, where the only two systems that surpassed it are marginally better, with scores of 0.33 and 0.34, and where the next",
                "cite_spans": [
                    {
                        "start": 246,
                        "end": 269,
                        "text": "( \u0160tajner et al., 2016)",
                        "ref_id": null
                    },
                    {
                        "start": 352,
                        "end": 373,
                        "text": "\u0160tajner et al. (2016)",
                        "ref_id": null
                    },
                    {
                        "start": 659,
                        "end": 677,
                        "text": "and \u0160tajner, 2013)",
                        "ref_id": null
                    },
                    {
                        "start": 801,
                        "end": 829,
                        "text": "(Barzilay and Elhadad, 2003)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 946,
                        "end": 969,
                        "text": "( \u0160tajner et al., 2015)",
                        "ref_id": null
                    },
                    {
                        "start": 1001,
                        "end": 1026,
                        "text": "(Coster and Kauchak, 2011",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 1127,
                        "end": 1153,
                        "text": "(Glava\u0161 and \u0160tajner, 2015)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 1204,
                        "end": 1224,
                        "text": "(Biran et al., 2011;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 1225,
                        "end": 1243,
                        "text": "Horn et al., 2014;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1244,
                        "end": 1269,
                        "text": "Glava\u0161 and \u0160tajner, 2015)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 1872,
                        "end": 1893,
                        "text": "\u0160tajner et al. (2016)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation on the QATS Benchmark",
                "sec_num": "9"
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Universal Conceptual Cognitive Annotation (UCCA)",
                "authors": [
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Rappoport",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proc. of ACL-13",
                "volume": "",
                "issue": "",
                "pages": "228--238",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Omri Abend and Ari Rappoport. 2013. Universal Con- ceptual Cognitive Annotation (UCCA). In Proc. of ACL-13. pages 228-238. http://aclweb. org/anthology/P/P13/P13-1023.pdf.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "The state of the art in semantic representation",
                "authors": [
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Rappoport",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proc. of ACL'17",
                "volume": "",
                "issue": "",
                "pages": "77--89",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Omri Abend and Ari Rappoport. 2017. The state of the art in semantic representation. In Proc. of ACL'17. pages 77-89. http://aclweb.org/ anthology/P/P17/P17-1008.pdf.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "UCCAApp: Web-application for syntactic and semantic phrase-based annotation",
                "authors": [
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Shai",
                        "middle": [],
                        "last": "Yerushalmi",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Rappoport",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proc. of ACL'17, System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "109--114",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Omri Abend, Shai Yerushalmi, and Ari Rap- poport. 2017. UCCAApp: Web-application for syntactic and semantic phrase-based annota- tion. In Proc. of ACL'17, System Demonstrations. pages 109-114. http://www.aclweb.org/ anthology/P17-4019.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Abstract Meaning Rrepresentation for sembanking",
                "authors": [
                    {
                        "first": "Laura",
                        "middle": [],
                        "last": "Banarescu",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Bonial",
                        "suffix": ""
                    },
                    {
                        "first": "Shu",
                        "middle": [],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Madalina",
                        "middle": [],
                        "last": "Georgescu",
                        "suffix": ""
                    },
                    {
                        "first": "Kira",
                        "middle": [],
                        "last": "Griffitt",
                        "suffix": ""
                    },
                    {
                        "first": "Ulf",
                        "middle": [],
                        "last": "Hermjakob",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    },
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Martha",
                        "middle": [],
                        "last": "Palmer",
                        "suffix": ""
                    },
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Schneider",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proc. of Linguistic Annotation Workshop and Interoperability with Discourse pages",
                "volume": "",
                "issue": "",
                "pages": "178--186",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract Meaning Rrepresen- tation for sembanking. Proc. of Linguistic An- notation Workshop and Interoperability with Dis- course pages 178-186. http://aclweb.org/ anthology/W/W13/W13-2322.pdf.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Sentence alignment for monolingual comparable corpora",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Noemie",
                        "middle": [],
                        "last": "Elhadad",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proc. of EMNLP'03",
                "volume": "",
                "issue": "",
                "pages": "25--32",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Noemie Elhadad. 2003. Sen- tence alignment for monolingual comparable cor- pora. In Proc. of EMNLP'03. pages 25- 32. http://www.aclweb.org/anthology/ W/W03/W03-1004.pdf.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Putting it simply: a context-aware approach to lexical simplification",
                "authors": [
                    {
                        "first": "Or",
                        "middle": [],
                        "last": "Biran",
                        "suffix": ""
                    },
                    {
                        "first": "Samuel",
                        "middle": [],
                        "last": "Brody",
                        "suffix": ""
                    },
                    {
                        "first": "No\u00e9mie",
                        "middle": [],
                        "last": "Elhadad",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proc. of ACL'11",
                "volume": "",
                "issue": "",
                "pages": "465--501",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Or Biran, Samuel Brody, and No\u00e9mie Elhadad. 2011. Putting it simply: a context-aware approach to lex- ical simplification. In Proc. of ACL'11. pages 465- 501. http://aclweb.org/anthology/P/ P11/P11-2087.pdf.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "HUME: Human UCCA-based evaluation of machine translation",
                "authors": [
                    {
                        "first": "Alexandra",
                        "middle": [],
                        "last": "Birch",
                        "suffix": ""
                    },
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Ond\u0159ej",
                        "middle": [],
                        "last": "Bojar",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Haddow",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proc. of EMNLP'16",
                "volume": "",
                "issue": "",
                "pages": "1264--1274",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alexandra Birch, Omri Abend, Ond\u0159ej Bojar, and Barry Haddow. 2016. HUME: Human UCCA-based evaluation of machine transla- tion. In Proc. of EMNLP'16. pages 1264-1274. http://aclweb.org/anthology/D/D16/ D16-1134.pdf.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Syntactic simplification of text",
                "authors": [
                    {
                        "first": "Yvonne",
                        "middle": [],
                        "last": "Margaret",
                        "suffix": ""
                    },
                    {
                        "first": "Canning",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yvonne Margaret Canning. 2002. Syntactic simplifica- tion of text. Ph.D. thesis, University of Sunderland, UK.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Motivations and methods for sentence simplification",
                "authors": [
                    {
                        "first": "Raman",
                        "middle": [],
                        "last": "Chandrasekar",
                        "suffix": ""
                    },
                    {
                        "first": "Christine",
                        "middle": [],
                        "last": "Doran",
                        "suffix": ""
                    },
                    {
                        "first": "Bangalore",
                        "middle": [],
                        "last": "Srinivas",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Proc. of COL-ING'96",
                "volume": "",
                "issue": "",
                "pages": "1041--1044",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Raman Chandrasekar, Christine Doran, and Banga- lore Srinivas. 1996. Motivations and methods for sentence simplification. In Proc. of COL- ING'96. pages 1041-1044. http://aclweb. org/anthology/C/C96/C96-2183.pdf.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Referenceless measure of faithfulness for grammatical error correction",
                "authors": [
                    {
                        "first": "Leshem",
                        "middle": [],
                        "last": "Choshen",
                        "suffix": ""
                    },
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proc. of NAACL'18",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Leshem Choshen and Omri Abend. 2018. Reference- less measure of faithfulness for grammatical error correction. In Proc. of NAACL'18 (Short papers). To appear.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Models for sentence compression: A comparison across domains, training requirements and evaluation measures",
                "authors": [
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Clarke",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proc. of ACL-COLING'06",
                "volume": "",
                "issue": "",
                "pages": "377--384",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "James Clarke and Mirella Lapata. 2006. Models for sentence compression: A comparison across do- mains, training requirements and evaluation mea- sures. In Proc. of ACL-COLING'06. pages 377- 384. http://aclweb.org/anthology/P/ P06/P06-1048.pdf.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Cohen",
                        "suffix": ""
                    }
                ],
                "year": 1968,
                "venue": "Psychological bulletin",
                "volume": "70",
                "issue": "4",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Cohen. 1968. Weighted kappa: Nominal scale agreement provision for scaled disagreement or par- tial credit. Psychological bulletin 70(4):213.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Simple English Wikipedia: A new text simplification task",
                "authors": [
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Coster",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Kauchak",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proc. of ACL'11",
                "volume": "",
                "issue": "",
                "pages": "665--669",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "William Coster and David Kauchak. 2011. Sim- ple English Wikipedia: A new text simplifica- tion task. In Proc. of ACL'11. pages 665- 669. http://aclweb.org/anthology/P/ P11/P11-2117.pdf.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems",
                "authors": [
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Denkowski",
                        "suffix": ""
                    },
                    {
                        "first": "Alon",
                        "middle": [],
                        "last": "Lavie",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proc. of WMT'11",
                "volume": "",
                "issue": "",
                "pages": "85--91",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems. In Proc. of WMT'11. pages 85-91. http://aclweb. org/anthology/W/W11/W11-2107.pdf.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Basic Linguistic Theory: Grammatical Topics",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "W"
                        ],
                        "last": "Robert",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Dixon",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert M.W. Dixon. 2010a. Basic Linguistic Theory: Grammatical Topics, volume 2. Oxford University Press.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Basic Linguistic Theory: Methodology",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "W"
                        ],
                        "last": "Robert",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Dixon",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "1",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert M.W. Dixon. 2010b. Basic Linguistic Theory: Methodology, volume 1. Oxford University Press.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Basic Linguistic Theory: Further Grammatical Topics",
                "authors": [
                    {
                        "first": "M",
                        "middle": [
                            "W"
                        ],
                        "last": "Robert",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Dixon",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert M.W. Dixon. 2012. Basic Linguistic Theory: Further Grammatical Topics, volume 3. Oxford University Press.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Event-centered simplification of news stories",
                "authors": [
                    {
                        "first": "Goran",
                        "middle": [],
                        "last": "Glavas",
                        "suffix": ""
                    },
                    {
                        "first": "Sanja",
                        "middle": [],
                        "last": "\u0160tajner",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proc. of the Student Research Workshop associated with RANLP 2013",
                "volume": "",
                "issue": "",
                "pages": "71--78",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Goran Glavas and Sanja \u0160tajner. 2013. Event-centered simplification of news stories. In Proc. of the Stu- dent Research Workshop associated with RANLP 2013. pages 71-78. http://aclweb.org/ anthology/R13-2011.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Simplifying lexical simplification: Do we need simplified corpora?",
                "authors": [
                    {
                        "first": "Goran",
                        "middle": [],
                        "last": "Glava\u0161",
                        "suffix": ""
                    },
                    {
                        "first": "Sanja",
                        "middle": [],
                        "last": "\u0160tajner",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proc. of ACL'15",
                "volume": "",
                "issue": "",
                "pages": "63--68",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Goran Glava\u0161 and Sanja \u0160tajner. 2015. Simplifying lexical simplification: Do we need simplified cor- pora? In Proc. of ACL'15 (Short papers). pages 63- 68. http://www.aclweb.org/anthology/ P15-2011.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "A transition-based directed acyclic graph parser for UCCA",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Hershcovich",
                        "suffix": ""
                    },
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Rappoport",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proc. of ACL'17",
                "volume": "",
                "issue": "",
                "pages": "1127--1138",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Hershcovich, Omri Abend, and Ari Rappoport. 2017. A transition-based directed acyclic graph parser for UCCA. In Proc. of ACL'17. pages 1127- 1138. http://aclweb.org/anthology/P/ P17/P17-1104.pdf.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Learning a lexical simplifier using Wikipedia",
                "authors": [
                    {
                        "first": "Colby",
                        "middle": [],
                        "last": "Horn",
                        "suffix": ""
                    },
                    {
                        "first": "Cathryn",
                        "middle": [],
                        "last": "Manduca",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Kauchak",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of ACL'14 (Short papers)",
                "volume": "",
                "issue": "",
                "pages": "458--463",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Colby Horn, Cathryn Manduca, and David Kauchak. 2014. Learning a lexical simplifier using Wikipedia. In Proc. of ACL'14 (Short papers). pages 458- 463. http://aclweb.org/anthology/P/ P14/P14-2075.pdf.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Aligning sentences from Standard Wikipedia to Simple Wikipedia",
                "authors": [
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Hwang",
                        "suffix": ""
                    },
                    {
                        "first": "Hannaneh",
                        "middle": [],
                        "last": "Hajishirzi",
                        "suffix": ""
                    },
                    {
                        "first": "Mari",
                        "middle": [],
                        "last": "Ostendorf",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proc. of NAACL'15",
                "volume": "",
                "issue": "",
                "pages": "211--217",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "William Hwang, Hannaneh Hajishirzi, Mari Ostendorf, and Wei Wu. 2015. Aligning sentences from Stan- dard Wikipedia to Simple Wikipedia. In Proc. of NAACL'15. pages 211-217. http://aclweb. org/anthology/N/N15/N15-1022.pdf.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A theory of truth and semantic representation",
                "authors": [
                    {
                        "first": "Hans",
                        "middle": [],
                        "last": "Kamp",
                        "suffix": ""
                    }
                ],
                "year": 1981,
                "venue": "Formal methods in the study of language. Mathematisch Centrum",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hans Kamp. 1981. A theory of truth and seman- tic representation. In J.A.G. Groenendijk, T.M.V. Jassen, B.J. Stokhof, and M.J.B/ Stokhof, editors, Formal methods in the study of language. Mathema- tisch Centrum. Number pt.1 in Mathematical Centre tracts.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Derivation of new readability formulas (automated readability index, fog count and Flesch reading ease formula) for Navy enlisted personnel",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Kincaid",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "P"
                        ],
                        "last": "Fishburne",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Richard",
                        "suffix": ""
                    },
                    {
                        "first": "Brad",
                        "middle": [
                            "S"
                        ],
                        "last": "Rogers",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Chissom",
                        "suffix": ""
                    }
                ],
                "year": 1975,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Peter Kincaid, Robert P. Fishburne Jr., Richard L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (automated readability in- dex, fog count and Flesch reading ease formula) for Navy enlisted personnel. Technical report, DTIC Document.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Cognitive Grammar: A Basic Introduction",
                "authors": [
                    {
                        "first": "Ronald",
                        "middle": [
                            "W"
                        ],
                        "last": "Langacker",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ronald W. Langacker. 2008. Cognitive Grammar: A Basic Introduction. Oxford University Press, USA.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "XMEANT: Better semantic mt evaluation without reference translations",
                "authors": [
                    {
                        "first": "Chi-Kiu",
                        "middle": [],
                        "last": "Lo",
                        "suffix": ""
                    },
                    {
                        "first": "Meriem",
                        "middle": [],
                        "last": "Beloucif",
                        "suffix": ""
                    },
                    {
                        "first": "Markus",
                        "middle": [],
                        "last": "Saers",
                        "suffix": ""
                    },
                    {
                        "first": "Dekai",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of ACL'14 (Short Papers)",
                "volume": "",
                "issue": "",
                "pages": "765--771",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chi-kiu Lo, Meriem Beloucif, Markus Saers, and Dekai Wu. 2014. XMEANT: Better seman- tic mt evaluation without reference translations. In Proc. of ACL'14 (Short Papers). pages 765- 771. http://aclweb.org/anthology/P/ P14/P14-2124.pdf.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Fully automatic semantic MT evaluation",
                "authors": [
                    {
                        "first": "Chi-Kiu",
                        "middle": [],
                        "last": "Lo",
                        "suffix": ""
                    },
                    {
                        "first": "Anand",
                        "middle": [],
                        "last": "Karthik Tumuluru",
                        "suffix": ""
                    },
                    {
                        "first": "Dekai",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proc. of WMT'12",
                "volume": "",
                "issue": "",
                "pages": "243--252",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu. 2012. Fully automatic semantic MT eval- uation. In Proc. of WMT'12. pages 243- 252. http://aclweb.org/anthology/W/ W12/W12-3129.pdf.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "NLTK: the natural language toolkit",
                "authors": [
                    {
                        "first": "Edward",
                        "middle": [],
                        "last": "Loper",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bird",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proc. of EMNLP'02",
                "volume": "",
                "issue": "",
                "pages": "63--70",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Edward Loper and Steven Bird. 2002. NLTK: the natural language toolkit. In Proc. of EMNLP'02. pages 63-70. http://www.aclweb.org/ anthology/W/W02/W02-0109.pdf.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Exploring the effects of sentence simplification on Hindi to English Machine Translation systems",
                "authors": [
                    {
                        "first": "Kshitij",
                        "middle": [],
                        "last": "Mishra",
                        "suffix": ""
                    },
                    {
                        "first": "Ankush",
                        "middle": [],
                        "last": "Soni",
                        "suffix": ""
                    },
                    {
                        "first": "Rahul",
                        "middle": [],
                        "last": "Sharma",
                        "suffix": ""
                    },
                    {
                        "first": "Dipti",
                        "middle": [
                            "Misra"
                        ],
                        "last": "Sharma",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of the Workshop on Automatic Text Simplification: Methods and Applications in the Multilingual Society",
                "volume": "",
                "issue": "",
                "pages": "21--29",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kshitij Mishra, Ankush Soni, Rahul Sharma, and Dipti Misra Sharma. 2014. Exploring the effects of sentence simplification on Hindi to English Ma- chine Translation systems. In Proc. of the Work- shop on Automatic Text Simplification: Methods and Applications in the Multilingual Society. pages 21- 29. http://www.aclweb.org/anthology/ W14-5603.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Hybrid simplification using deep semantics and machine translation",
                "authors": [
                    {
                        "first": "Shashi",
                        "middle": [],
                        "last": "Narayan",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Gardent",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of ACL14",
                "volume": "",
                "issue": "",
                "pages": "435--445",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shashi Narayan and Claire Gardent. 2014. Hy- brid simplification using deep semantics and ma- chine translation. In Proc. of ACL14. pages 435- 445. http://aclweb.org/anthology/P/ P14/P14-1041.pdf.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Unsupervised sentence simplification using deep semantics",
                "authors": [
                    {
                        "first": "Shashi",
                        "middle": [],
                        "last": "Narayan",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Gardent",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proc. of INLG'16",
                "volume": "",
                "issue": "",
                "pages": "111--120",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shashi Narayan and Claire Gardent. 2016. Un- supervised sentence simplification using deep se- mantics. In Proc. of INLG'16. pages 111- 120. http://aclweb.org/anthology/W/ W16/W16-6620.pdf.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Split and rephrase",
                "authors": [
                    {
                        "first": "Shashi",
                        "middle": [],
                        "last": "Narayan",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Gardent",
                        "suffix": ""
                    },
                    {
                        "first": "Shay",
                        "middle": [
                            "B"
                        ],
                        "last": "Cohen",
                        "suffix": ""
                    },
                    {
                        "first": "Anastasia",
                        "middle": [],
                        "last": "Shimorina",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proc. of EMNLP'17",
                "volume": "",
                "issue": "",
                "pages": "617--627",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shashi Narayan, Claire Gardent, Shay B. Cohen, and Anastasia Shimorina. 2017. Split and rephrase. In Proc. of EMNLP'17. pages 617- 627. http://aclweb.org/anthology/D/ D17/D17-1065.pdf.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "A sentence simplification system for improving relation extraction",
                "authors": [
                    {
                        "first": "Christina",
                        "middle": [],
                        "last": "Niklaus",
                        "suffix": ""
                    },
                    {
                        "first": "Bernahard",
                        "middle": [],
                        "last": "Bermeitinger",
                        "suffix": ""
                    },
                    {
                        "first": "Siegfried",
                        "middle": [],
                        "last": "Handschuh",
                        "suffix": ""
                    },
                    {
                        "first": "Andr\u00e9",
                        "middle": [],
                        "last": "Freitas",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proc. of COLING'16",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christina Niklaus, Bernahard Bermeitinger, Siegfried Handschuh, and Andr\u00e9 Freitas. 2016. A sentence simplification system for improving relation extrac- tion. In Proc. of COLING'16. http://aclweb. org/anthology/C/C16/C16-2036.pdf.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "An ensemble method for quality assessment of text simplification",
                "authors": [
                    {
                        "first": "Sergiu",
                        "middle": [],
                        "last": "Nisioi",
                        "suffix": ""
                    },
                    {
                        "first": "Fabrice",
                        "middle": [],
                        "last": "Nauze",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Workshop on Quality Assessment for Text Simplification (QATS)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sergiu Nisioi and Fabrice Nauze. 2016. An ensemble method for quality assessment of text simplification. In Workshop on Quality Assessment for Text Simpli- fication (QATS).",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "BLEU: a method for automatic evaluation of machine translation",
                "authors": [
                    {
                        "first": "Kishore",
                        "middle": [],
                        "last": "Papineni",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    },
                    {
                        "first": "Todd",
                        "middle": [],
                        "last": "Ward",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Jing",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proc. of ACL'02",
                "volume": "",
                "issue": "",
                "pages": "311--318",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for auto- matic evaluation of machine translation. In Proc. of ACL'02. pages 311-318. http://aclweb. org/anthology/P/P02/P02-1040.pdf.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Simplify or help?: text simplification strategies for people with dyslexia",
                "authors": [
                    {
                        "first": "Luz",
                        "middle": [],
                        "last": "Rello",
                        "suffix": ""
                    },
                    {
                        "first": "Ricardo",
                        "middle": [],
                        "last": "Baeza-Yates",
                        "suffix": ""
                    },
                    {
                        "first": "Stefan",
                        "middle": [],
                        "last": "Bott",
                        "suffix": ""
                    },
                    {
                        "first": "Horacio",
                        "middle": [],
                        "last": "Saggion",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proc. of the 10th International Cross-Disciplinary Conference on Web Accesibility",
                "volume": "15",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Luz Rello, Ricardo Baeza-Yates, Stefan Bott, and Ho- racio Saggion. 2013. Simplify or help?: text simpli- fication strategies for people with dyslexia. In Proc. of the 10th International Cross-Disciplinary Confer- ence on Web Accesibility. pages 15:1 -15:10.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "TINE: A metric to assess MT adequacy",
                "authors": [
                    {
                        "first": "Miguel",
                        "middle": [],
                        "last": "Rios",
                        "suffix": ""
                    },
                    {
                        "first": "Wilker",
                        "middle": [],
                        "last": "Aziz",
                        "suffix": ""
                    },
                    {
                        "first": "Lucia",
                        "middle": [],
                        "last": "Specia",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proc. of WMT'11",
                "volume": "",
                "issue": "",
                "pages": "116--122",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Miguel Rios, Wilker Aziz, and Lucia Specia. 2011. TINE: A metric to assess MT adequacy. In Proc. of WMT'11. pages 116-122. http://aclweb. org/anthology/W/W11/W11-2112.pdf.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "An architecture for a text simplification system",
                "authors": [
                    {
                        "first": "Advaith",
                        "middle": [],
                        "last": "Siddharthan",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proc. of LEC",
                "volume": "",
                "issue": "",
                "pages": "64--71",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Advaith Siddharthan. 2002. An architecture for a text simplification system. In Proc. of LEC. pages 64- 71.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Hybrid text simplification using synchronous dependency grammars with hand-written and automatically harvested rules",
                "authors": [
                    {
                        "first": "Advaith",
                        "middle": [],
                        "last": "Siddharthan",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [
                            "A"
                        ],
                        "last": "Angrosh",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of EACL'14",
                "volume": "",
                "issue": "",
                "pages": "722--731",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Advaith Siddharthan and M. A. Angrosh. 2014. Hybrid text simplification using synchronous dependency grammars with hand-written and automatically har- vested rules. In Proc. of EACL'14. pages 722- 731. http://aclweb.org/anthology/E/ E14/E14-1076.pdf.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Snover",
                        "suffix": ""
                    },
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "J"
                        ],
                        "last": "Dorr",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Schwartz",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proc. of WMT'09",
                "volume": "",
                "issue": "",
                "pages": "85--91",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matthew Snover, Nitin Madnani, Bonnie J. Dorr, and Richard Schwartz. 2009. Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric. In Proc. of WMT'09. pages 85- 91. http://www.aclweb.org/anthology/ W09-0441.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Conceptual annotations preserve structure across translations",
                "authors": [
                    {
                        "first": "Elior",
                        "middle": [],
                        "last": "Sulem",
                        "suffix": ""
                    },
                    {
                        "first": "Omri",
                        "middle": [],
                        "last": "Abend",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Rappoport",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proc. of 1st Workshop on Semantics-Driven Statistical Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "11--22",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Elior Sulem, Omri Abend, and Ari Rappoport. 2015. Conceptual annotations preserve structure across translations. In Proc. of 1st Workshop on Semantics-Driven Statistical Machine Translation (S2Mt 2015). pages 11-22. http://aclweb. org/anthology/W/W15/W15-3502.pdf.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Back to basics for monolingual alignment: Exploiting word similarity and contextual evidence",
                "authors": [
                    {
                        "first": "Md",
                        "middle": [],
                        "last": "Arafat Sultan",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bethard",
                        "suffix": ""
                    },
                    {
                        "first": "Tamara",
                        "middle": [],
                        "last": "Sumner",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proc. of ACL'12",
                "volume": "2",
                "issue": "",
                "pages": "38--42",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Md Arafat Sultan, Steven Bethard, and Tamara Sum- ner. 2014. Back to basics for monolingual align- ment: Exploiting word similarity and contextual ev- idence. TACL 2:219-230. http://aclweb. org/anthology/Q/Q14/Q14-1018.pdf. Hong Sun and Ming Zhou. 2012. Joint learn- ing of a dual SMT system for paraphrase gen- eration. In Proc. of ACL'12. pages 38- 42. http://aclweb.org/anthology/P/ P12/P12-2008.pdf.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "A dataset and evaluation metrics for abstractive compression of sentences and short paragraphs",
                "authors": [
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Ke",
                        "middle": [
                            "M"
                        ],
                        "last": "Tran",
                        "suffix": ""
                    },
                    {
                        "first": "Saleema",
                        "middle": [],
                        "last": "Amershi",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proc. of EMNLP'16",
                "volume": "",
                "issue": "",
                "pages": "340--350",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kristina Toutanova, Chris Brockett, Ke M. Tran, and Saleema Amershi. 2016. A dataset and evaluation metrics for abstractive compression of sentences and short paragraphs. In Proc. of EMNLP'16. pages 340-350. http://aclweb. org/anthology/D/D16/D16-1033.pdf.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "A deeper exploration of the standard PB-SMT approach to text simplification and its evaluation",
                "authors": [
                    {
                        "first": "Sanja",
                        "middle": [],
                        "last": "\u0160tajner",
                        "suffix": ""
                    },
                    {
                        "first": "Hannah",
                        "middle": [],
                        "last": "Bechara",
                        "suffix": ""
                    },
                    {
                        "first": "Horacio",
                        "middle": [],
                        "last": "Saggion",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proc. of ACL'15, Short papers",
                "volume": "",
                "issue": "",
                "pages": "823--828",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sanja \u0160tajner, Hannah Bechara, and Horacio Saggion. 2015. A deeper exploration of the standard PB- SMT approach to text simplification and its evalu- ation. In Proc. of ACL'15, Short papers. pages 823- 828. http://aclweb.org/anthology/P/ P15/P15-2135.pdf.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "One step closer to automatic evaluation of text simplification systems",
                "authors": [
                    {
                        "first": "Sanja",
                        "middle": [],
                        "last": "\u0160tajner",
                        "suffix": ""
                    },
                    {
                        "first": "Ruslan",
                        "middle": [],
                        "last": "Mitkov",
                        "suffix": ""
                    },
                    {
                        "first": "Horacio",
                        "middle": [],
                        "last": "Saggion",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proc. of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations",
                "volume": "",
                "issue": "",
                "pages": "1--10",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sanja \u0160tajner, Ruslan Mitkov, and Horacio Saggion. 2014. One step closer to automatic evaluation of text simplification systems. Proc. of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations pages 1-10. http:// www.aclweb.org/anthology/W14-1201.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Shared task on quality assessment for text simplification",
                "authors": [
                    {
                        "first": "Sanja",
                        "middle": [],
                        "last": "\u0160tajner",
                        "suffix": ""
                    },
                    {
                        "first": "Maja",
                        "middle": [],
                        "last": "Popovi\u0107",
                        "suffix": ""
                    },
                    {
                        "first": "Horacio",
                        "middle": [],
                        "last": "Saggion",
                        "suffix": ""
                    },
                    {
                        "first": "Lucia",
                        "middle": [],
                        "last": "Specia",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Fishel",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Workshop on Quality Assessment for Text Simplification (QATS)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sanja \u0160tajner, Maja Popovi\u0107, Horacio Saggion, Lu- cia Specia, and Mark Fishel. 2016. Shared task on quality assessment for text simplification. In Work- shop on Quality Assessment for Text Simplification (QATS).",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Learning to simplify sentences with quasi-synchronous grammar and integer programming",
                "authors": [
                    {
                        "first": "Kristian",
                        "middle": [],
                        "last": "Woodsend",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proc. of EMNLP'11",
                "volume": "",
                "issue": "",
                "pages": "409--420",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kristian Woodsend and Mirella Lapata. 2011. Learn- ing to simplify sentences with quasi-synchronous grammar and integer programming. In Proc. of EMNLP'11. pages 409-420. http://aclweb. org/anthology/D/D11/D11-1038.pdf.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Sentence simplification by monolingual machine translation",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Sander Wubben",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Van Den",
                        "suffix": ""
                    },
                    {
                        "first": "Emiel",
                        "middle": [],
                        "last": "Bosch",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Krahmer",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proc. of ACL'12",
                "volume": "",
                "issue": "",
                "pages": "1015--1024",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sander Wubben, Antal van den Bosch, and Emiel Krahmer. 2012. Sentence simplification by mono- lingual machine translation. In Proc. of ACL'12. pages 1015-1024. http://aclweb.org/ anthology/P/P12/P12-1107.pdf.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Problems in current text simplification research: new data can help",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "TACL",
                "volume": "3",
                "issue": "",
                "pages": "283--297",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Xu, Chris Callison-Burch, and Courtney Napoles. 2015. Problems in current text simplification research: new data can help. TACL 3:283- 297. http://aclweb.org/anthology/Q/ Q15/Q15-1021.pdf.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Optimizing statistical machine translation for text simplification",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    },
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    },
                    {
                        "first": "Quanze",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "TACL",
                "volume": "4",
                "issue": "",
                "pages": "401--415",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016. Optimiz- ing statistical machine translation for text simplifica- tion. TACL 4:401-415. http://aclweb.org/ anthology/Q/Q16/Q16-1029.pdf.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "A monolingual tree-based translation model for sentence simplification",
                "authors": [
                    {
                        "first": "Zhemin",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Delphine",
                        "middle": [],
                        "last": "Bernhard",
                        "suffix": ""
                    },
                    {
                        "first": "Iryna",
                        "middle": [],
                        "last": "Gurevych",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proc. of COL-ING'10",
                "volume": "",
                "issue": "",
                "pages": "1353--1361",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proc. of COL- ING'10. pages 1353-1361. http://aclweb. org/anthology/C/C10/C10-1152.pdf.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure1: Joint distribution of the automatic SAMSA and the AvgHuman scores at the sentence level. Each point in the graph corresponds to a single source sentence. In addition to the scatter plot, a least-squares regression line is presented.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "TABREF2": {
                "content": "<table><tr><td>Sen. Sys.</td><td>Qa 0.63  *  0.92  *  *</td><td>Qb 0.30  *  0.54 (0.1) 0.64 (0.06) 0.14 (0.4) Qc Qd 0.48  *  0.11  *  *</td><td>AvgHuman 0.49  *  0.64 (0.06)</td></tr></table>",
                "type_str": "table",
                "text": "Inter-annotator absolute agreement (and quadratic weighted \u03ba), averaged over the 10 annotator pairs. Rows correspond to systems, columns to questions. The top \"Total\" row refers to the concatenation of the outputs of all 6 systems together with the reference sentences.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Spearman's correlation (and p-values)  of the system-level (top row) and sentence-level (bottom row) ratings of the five annotators. * p < 10 -5 , * * p = 0.002.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Spearman's correlation of system scores i.e. Pearson's correlation of system rankings (",
                "html": null,
                "num": null
            }
        }
    }
}