{
    "paper_id": "P08-1116",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:08:27.952032Z"
    },
    "title": "Combining Multiple Resources to Improve SMT-based Paraphrasing Model *",
    "authors": [
        {
            "first": "Shiqi",
            "middle": [],
            "last": "Zhao",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Harbin Institute of Technology",
                "location": {
                    "settlement": "Harbin",
                    "country": "China"
                }
            },
            "email": "zhaosq@ir.hit.edu.cn"
        },
        {
            "first": "Cheng",
            "middle": [],
            "last": "Niu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Microsoft Research Asia",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "chengniu@microsoft.com"
        },
        {
            "first": "Ming",
            "middle": [],
            "last": "Zhou",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Microsoft Research Asia",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "mingzhou@microsoft.com"
        },
        {
            "first": "Ting",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Harbin Institute of Technology",
                "location": {
                    "settlement": "Harbin",
                    "country": "China"
                }
            },
            "email": "tliu@ir.hit.edu.cn"
        },
        {
            "first": "Sheng",
            "middle": [],
            "last": "Li",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Harbin Institute of Technology",
                "location": {
                    "settlement": "Harbin",
                    "country": "China"
                }
            },
            "email": "lisheng@ir.hit.edu.cn"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing. In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation. Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources. The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively. In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality.",
    "pdf_parse": {
        "paper_id": "P08-1116",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing. In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation. Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources. The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively. In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Paraphrases are alternative ways of conveying the same meaning. Paraphrases are important in many natural language processing (NLP) applications, such as machine translation (MT), question answering (QA), information extraction (IE), multidocument summarization (MDS), and natural language generation (NLG).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "This paper addresses the problem of sentencelevel paraphrase generation, which aims at generating paraphrases for input sentences. An example of sentence-level paraphrases can be seen below: S1: The table was set up in the carriage shed. S2: The table was laid under the cart-shed.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Paraphrase generation can be viewed as monolingual machine translation (Quirk et al., 2004) , which typically includes a translation model and a language model. The translation model can be trained using monolingual parallel corpora. However, acquiring such corpora is not easy. Hence, data sparseness is a key problem for the SMT-based paraphrasing. On the other hand, various methods have been presented to extract phrasal paraphrases from different resources, which include thesauri, monolingual corpora, bilingual corpora, and the web. However, little work has been focused on using the extracted phrasal paraphrases in sentence-level paraphrase generation.",
                "cite_spans": [
                    {
                        "start": 71,
                        "end": 91,
                        "text": "(Quirk et al., 2004)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we exploit multiple resources to improve the SMT-based paraphrase generation. In detail, six kinds of resources are utilized, including: (1) an automatically constructed thesaurus, (2) a monolingual parallel corpus from novels, (3) a monolingual comparable corpus from news articles, (4) a bilingual phrase table, (5) word definitions from Encarta dictionary, and (6) a corpus of similar user queries. Among the resources, (1), ( 2), (3), and (4) have been investigated by other researchers, while (5) and ( 6) are first used in this paper. From those resources, six phrasal paraphrase tables are extracted, which are then used in a log-linear SMTbased paraphrasing model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Both phrase-level and sentence-level evaluations were carried out in the experiments. In the former one, phrase substitutes occurring in the paraphrase sentences were evaluated. While in the latter one, the acceptability of the paraphrase sentences was evaluated. Experimental results show that: (1) The SMT-based paraphrasing is enhanced using multiple resources. The phrase-level and sentence-level precision of the generated paraphrases exceed 60% and 55%, respectively. (2) Although the contributions of the resources differ a lot, all the resources are useful.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(3) The performance of the method varies greatly on different test sets and it performs best on the test set of news sentences, which are from the same source as most of the training data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The rest of the paper is organized as follows: Section 2 reviews related work. Section 3 introduces the log-linear model for paraphrase generation. Section 4 describes the phrasal paraphrase extraction from different resources. Section 5 presents the parameter estimation method. Section 6 shows the experiments and results. Section 7 draws the conclusion.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Paraphrases have been used in many NLP applications. In MT, Callison-Burch et al. (2006) utilized paraphrases of unseen source phrases to alleviate data sparseness. Kauchak and Barzilay (2006) used paraphrases of the reference translations to improve automatic MT evaluation. In QA, Lin and Pantel (2001) and Ravichandran and Hovy (2002) paraphrased the answer patterns to enhance the recall of answer extraction. In IE, Shinyama et al. (2002) automatically learned paraphrases of IE patterns to reduce the cost of creating IE patterns by hand. In MDS, McKeown et al. (2002) identified paraphrase sentences across documents before generating summarizations. In NLG, Iordanskaja et al. (1991) used paraphrases to generate more varied and fluent texts.",
                "cite_spans": [
                    {
                        "start": 56,
                        "end": 88,
                        "text": "MT, Callison-Burch et al. (2006)",
                        "ref_id": null
                    },
                    {
                        "start": 165,
                        "end": 192,
                        "text": "Kauchak and Barzilay (2006)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 283,
                        "end": 304,
                        "text": "Lin and Pantel (2001)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 309,
                        "end": 337,
                        "text": "Ravichandran and Hovy (2002)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 421,
                        "end": 443,
                        "text": "Shinyama et al. (2002)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 548,
                        "end": 574,
                        "text": "MDS, McKeown et al. (2002)",
                        "ref_id": null
                    },
                    {
                        "start": 666,
                        "end": 691,
                        "text": "Iordanskaja et al. (1991)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Previous work has examined various resources for acquiring paraphrases, including thesauri, monolingual corpora, bilingual corpora, and the web. Thesauri, such as WordNet, have been widely used for extracting paraphrases. Some researchers extract synonyms as paraphrases (Kauchak and Barzilay, 2006) , while some others use looser definitions, such as hypernyms and holonyms (Barzilay and Elhadad, 1997) . Besides, the automatically constructed thesauri can also be used. Lin (1998) constructed a thesaurus by automatically clustering words based on context similarity. Barzilay and McKeown (2001) used monolingual parallel corpora for identifying paraphrases. They exploited a corpus of multiple English translations of the same source text written in a foreign language, from which phrases in aligned sentences that appear in similar contexts were extracted as paraphrases. In addition, Finch et al. (2005) applied MT evaluation methods (BLEU, NIST, WER and PER) to build classifiers for paraphrase identification.",
                "cite_spans": [
                    {
                        "start": 271,
                        "end": 299,
                        "text": "(Kauchak and Barzilay, 2006)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 375,
                        "end": 403,
                        "text": "(Barzilay and Elhadad, 1997)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 472,
                        "end": 482,
                        "text": "Lin (1998)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 570,
                        "end": 597,
                        "text": "Barzilay and McKeown (2001)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 889,
                        "end": 908,
                        "text": "Finch et al. (2005)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Monolingual parallel corpora are difficult to find, especially in non-literature domains. Alternatively, some researchers utilized monolingual comparable corpora for paraphrase extraction. Different news articles reporting on the same event are commonly used as monolingual comparable corpora, from which both paraphrase patterns and phrasal paraphrases can be derived (Shinyama et al., 2002; Barzilay and Lee, 2003; Quirk et al., 2004) . Lin and Pantel (2001) learned paraphrases from a parsed monolingual corpus based on an extended distributional hypothesis, where if two paths in dependency trees tend to occur in similar contexts it is hypothesized that the meanings of the paths are similar. The monolingual corpus used in their work is not necessarily parallel or comparable. Thus it is easy to obtain. However, since this resource is used to extract paraphrase patterns other than phrasal paraphrases, we do not use it in this paper. Bannard and Callison-Burch (2005) learned phrasal paraphrases using bilingual parallel corpora. The basic idea is that if two phrases are aligned to the same translation in a foreign language, they may be paraphrases. This method has been demonstrated effective in extracting large volume of phrasal paraphrases. Besides, Wu and Zhou (2003) exploited bilingual corpora and translation information in learning synonymous collocations.",
                "cite_spans": [
                    {
                        "start": 369,
                        "end": 392,
                        "text": "(Shinyama et al., 2002;",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 393,
                        "end": 416,
                        "text": "Barzilay and Lee, 2003;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 417,
                        "end": 436,
                        "text": "Quirk et al., 2004)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 439,
                        "end": 460,
                        "text": "Lin and Pantel (2001)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 942,
                        "end": 975,
                        "text": "Bannard and Callison-Burch (2005)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 1264,
                        "end": 1282,
                        "text": "Wu and Zhou (2003)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "In addition, some researchers extracted paraphrases from the web. For example, Ravichandran and Hovy (2002) retrieved paraphrase patterns from the web using hand-crafted queries. Pasca and Dienes (2005) extracted sentence fragments occurring in identical contexts as paraphrases from one billion web documents. Since web mining is rather time consuming, we do not exploit the web to extract paraphrases in this paper.",
                "cite_spans": [
                    {
                        "start": 79,
                        "end": 107,
                        "text": "Ravichandran and Hovy (2002)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 179,
                        "end": 202,
                        "text": "Pasca and Dienes (2005)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "So far, two kinds of methods have been proposed for sentence-level paraphrase generation, i.e., the pattern-based and SMT-based methods. Automatically learned patterns have been used in para-phrase generation. For example, Barzilay and Lee (2003) applied multiple-sequence alignment (MSA) to parallel news sentences and induced paraphrasing patterns for generating new sentences. Pang et al. (2003) built finite state automata (FSA) from semantically equivalent translation sets based on syntactic alignment and used the FSAs in paraphrase generation. The pattern-based methods can generate complex paraphrases that usually involve syntactic variation. However, the methods were demonstrated to be of limited generality (Quirk et al., 2004) . Quirk et al. (2004) first recast paraphrase generation as monolingual SMT. They generated paraphrases using a SMT system trained on parallel sentences extracted from clustered news articles. In addition, Madnani et al. (2007) also generated sentence-level paraphrases based on a SMT model. The advantage of the SMT-based method is that it achieves better coverage than the pattern-based method. The main difference between their methods and ours is that they only used bilingual parallel corpora as paraphrase resource, while we exploit and combine multiple resources.",
                "cite_spans": [
                    {
                        "start": 223,
                        "end": 246,
                        "text": "Barzilay and Lee (2003)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 380,
                        "end": 398,
                        "text": "Pang et al. (2003)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 720,
                        "end": 740,
                        "text": "(Quirk et al., 2004)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 743,
                        "end": 762,
                        "text": "Quirk et al. (2004)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 947,
                        "end": 968,
                        "text": "Madnani et al. (2007)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "The SMT-based paraphrasing model used by Quirk et al. (2004) was the noisy channel model of Brown et al. (1993) , which identified the optimal paraphrase T * of a sentence S by finding:",
                "cite_spans": [
                    {
                        "start": 41,
                        "end": 60,
                        "text": "Quirk et al. (2004)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 92,
                        "end": 111,
                        "text": "Brown et al. (1993)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "T * = arg max T {P (T |S)} = arg max T {P (S|T )P (T )}",
                        "eq_num": "(1)"
                    }
                ],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "In contrast, we adopt a log-linear model (Och and Ney, 2002) in this work, since multiple paraphrase tables can be easily combined in the loglinear model. Specifically, feature functions are derived from each paraphrase resource and then combined with the language model feature 1 :",
                "cite_spans": [
                    {
                        "start": 41,
                        "end": 60,
                        "text": "(Och and Ney, 2002)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "T * = arg max T { N i=1 \u03bb T M i h T M i (T, S)+ \u03bb LM h LM (T, S)} (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "where N is the number of paraphrase tables. h T M i (T, S) is the feature function based on the ith paraphrase table P T i . h LM (T, S) is the language 1 The reordering model is not considered in our model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "model feature. \u03bb T M i and \u03bb LM are the weights of the feature functions. h T M i (T, S) is defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "h T M i (T, S) = log Ki k=1 Score i (T k , S k ) (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "where K i is the number of phrase substitutes from S to T based on P T i . T k in T and S k in S are phrasal paraphrases in P T i . Score i (T k , S k ) is the paraphrase likelihood according to P T i2 . A 5-gram language model is used, therefore:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "h LM (T, S) = log J j=1 p(t j |t j-4 , ..., t j-1 ) (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "where J is the length of T , t j is the j-th word of T .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SMT-based Paraphrasing Model",
                "sec_num": "3"
            },
            {
                "text": "This section describes the extraction of phrasal paraphrases using various resources. Similar to Pharaoh (Koehn, 2004) , our decoder3 uses top 20 paraphrase options for each input phrase in the default setting. Therefore, we keep at most 20 paraphrases for a phrase when extracting phrasal paraphrases using each resource.",
                "cite_spans": [
                    {
                        "start": 105,
                        "end": 118,
                        "text": "(Koehn, 2004)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Exploiting Multiple Resources",
                "sec_num": "4"
            },
            {
                "text": "The thesaurus4 used in this work was automatically constructed by Lin (1998) . The similarity of two words e 1 and e 2 was calculated through the surrounding context words that have dependency relations with the investigated words:",
                "cite_spans": [
                    {
                        "start": 66,
                        "end": 76,
                        "text": "Lin (1998)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "Sim(e1, e2) = P (r,e)\u2208Tr (e 1 )\u2229Tr (e 2 ) (I(e1, r, e) + I(e2, r, e)) P (r,e)\u2208Tr (e 1 ) I(e1, r, e) + P (r,e)\u2208Tr (e 2 ) I(e2, r, e)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "where T r (e i ) denotes the set of words that have dependency relation r with word e i . I(e i , r, e) is the mutual information between e i , r and e.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "For each word, we keep 20 most similar words as paraphrases. In this way, we extract 502,305 pairs of paraphrases. The paraphrasing score Score 1 (p 1 , p 2 ) used in Equation ( 3) is defined as the similarity based on Equation (5).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "2 -Monolingual parallel corpus: Following Barzilay and McKeown (2001) , we exploit a corpus of multiple English translations of foreign novels, which contains 25,804 parallel sentence pairs. We find that most paraphrases extracted using the method of Barzilay and McKeown (2001) are quite short. Thus we employ a new approach for paraphrase extraction. Specifically, we parse the sentences with CollinsParser5 and extract the chunks from the parsing results. Let S 1 and S 2 be a pair of parallel sentences, p 1 and p 2 two chunks from S 1 and S 2 , we compute the similarity of p 1 and p 2 as:",
                "cite_spans": [
                    {
                        "start": 42,
                        "end": 69,
                        "text": "Barzilay and McKeown (2001)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 251,
                        "end": 278,
                        "text": "Barzilay and McKeown (2001)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "Sim(p 1 , p 2 ) = \u03b1Sim content (p 1 , p 2 )+ (1 -\u03b1)Sim context (p 1 , p 2 ) (6)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "where, Sim content (p 1 , p 2 ) is the content similarity, which is the word overlapping rate of p 1 and p 2 . Sim context (p 1 , p 2 ) is the context similarity, which is the word overlapping rate of the contexts of p 1 and p 26 . If the similarity of p 1 and p 2 exceeds a threshold T h 1 , they are identified as paraphrases. We extract 18,698 pairs of phrasal paraphrases from this resource. The paraphrasing score Score 2 (p 1 , p 2 ) is defined as the similarity in Equation ( 6). For the paraphrases occurring more than once, we use their maximum similarity as the paraphrasing score.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "3 -Monolingual comparable corpus: Similar to the methods in (Shinyama et al., 2002; Barzilay and Lee, 2003) , we construct a corpus of comparable documents from a large corpus D of news articles. The corpus D contains 612,549 news articles. Given articles d 1 and d 2 from D, if their publication date interval is less than 2 days and their similarity7 exceeds a threshold T h 2 , they are recognized as comparable documents. In this way, a corpus containing 5,672,864 pairs of comparable documents is constructed. From the comparable corpus, parallel sentences are extracted. Let s 1 and s 2 be two sentences from comparable documents d 1 and d 2 , if their similarity based on word overlapping rate is above a threshold T h 3 , s 1 and s 2 are identified as parallel sentences. In this way, 872,330 parallel sentence pairs are extracted.",
                "cite_spans": [
                    {
                        "start": 60,
                        "end": 83,
                        "text": "(Shinyama et al., 2002;",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 84,
                        "end": 107,
                        "text": "Barzilay and Lee, 2003)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "We run Giza++ (Och and Ney, 2000) on the parallel sentences and then extract aligned phrases as described in (Koehn, 2004) . The generated paraphrase table is pruned by keeping the top 20 paraphrases for each phrase. After pruning, 100,621 pairs of paraphrases are extracted. Given phrase p 1 and its paraphrase p 2 , we compute Score 3 (p 1 , p 2 ) by relative frequency (Koehn et al., 2003) :",
                "cite_spans": [
                    {
                        "start": 14,
                        "end": 33,
                        "text": "(Och and Ney, 2000)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 109,
                        "end": 122,
                        "text": "(Koehn, 2004)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 372,
                        "end": 392,
                        "text": "(Koehn et al., 2003)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Score3(p1, p2) = p(p2|p1) = count(p2, p1) P p count(p , p1)",
                        "eq_num": "(7)"
                    }
                ],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "People may wonder why we do not use the same method on the monolingual parallel and comparable corpora. This is mainly because the volumes of the two corpora differ a lot. In detail, the monolingual parallel corpus is fairly small, thus automatical word alignment tool like Giza++ may not work well on it. In contrast, the monolingual comparable corpus is quite large, hence we cannot conduct the timeconsuming syntactic parsing on it as we do on the monolingual parallel corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Thesaurus:",
                "sec_num": "1"
            },
            {
                "text": "We first construct a bilingual phrase table that contains 15,352,469 phrase pairs from an English-Chinese parallel corpus. We extract paraphrases from the bilingual phrase table and compute the paraphrasing score of phrases p 1 and p 2 as in (Bannard and Callison-Burch, 2005) :",
                "cite_spans": [
                    {
                        "start": 242,
                        "end": 276,
                        "text": "(Bannard and Callison-Burch, 2005)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "Score 4 (p 1 , p 2 ) = f p(f |p 1 )p(p 2 |f ) (8)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "where f denotes a Chinese translation of both p 1 and p 2 . p(f |p 1 ) and p(p 2 |f ) are the translation probabilities provided by the bilingual phrase table. For each phrase, the top 20 paraphrases are kept according to the score in Equation ( 8). As a result, 3,177,600 pairs of phrasal paraphrases are extracted.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "5 -Encarta dictionary definitions: Words and their definitions can be regarded as paraphrases. Here are some examples from Encarta dictionary: \"hurricane: severe storm\", \"clever: intelligent\", \"travel: go on journey\". In this work, we extract words' definitions from Encarta dictionary web pages 8 . If a word has more than one definition, all of them are extracted. Note that the words and definitions in the dictionary are lemmatized, but words in sentences are usually inflected. Hence, we expand the word -definition pairs by providing the inflected forms.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "Here we use an inflection list and some rules for inflection. After expanding, 159,456 pairs of phrasal paraphrases are extracted. Let < p 1 , p 2 > be a word -definition pair, the paraphrasing score is defined according to the rank of p 2 in all of p 1 's definitions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "Score 5 (p 1 , p 2 ) = \u03b3 i-1 (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "where \u03b3 is a constant (we empirically set \u03b3 = 0.9) and i is the rank of p 2 in p 1 's definitions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "6 -Similar user queries: Clusters of similar user queries have been used for query expansion and suggestion (Gao et al., 2007) . Since most queries are at the phrase level, we exploit similar user queries as phrasal paraphrases. In our experiment, we use the corpus of clustered similar MSN queries constructed by Gao et al. (2007) . The similarity of two queries p 1 and p 2 is computed as:",
                "cite_spans": [
                    {
                        "start": 108,
                        "end": 126,
                        "text": "(Gao et al., 2007)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 314,
                        "end": 331,
                        "text": "Gao et al. (2007)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "Sim(p 1 , p 2 ) = \u03b2Sim content (p 1 , p 2 )+ (1 -\u03b2)Sim click-through (p 1 , p 2 ) (10)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "where Sim content (p 1 , p 2 ) is the content similarity, which is computed as the word overlapping rate of p 1 and p 2 . Sim click-through (p 1 , p 2 ) is the click through similarity, which is the overlapping rate of the user clicked documents for p 1 and p 2 . For each query q, we keep the top 20 similar queries, whose similarity with q exceeds a threshold T h 4 . As a result, 395,284 pairs of paraphrases are extracted. The score Score 6 (p 1 , p 2 ) is defined as the similarity in Equation (10).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Bilingual phrase table:",
                "sec_num": "4"
            },
            {
                "text": "In addition to the six resources introduced above, a special paraphrase table is used, which is made up of pairs of identical words. The reason why this paraphrase table is necessary is that a word should be allowed to keep unchanged in paraphrasing. This is a difference between paraphrasing and MT, since all words should be translated in MT. In our experiments, all the words that occur in the six paraphrase table extracted above are gathered to form the self-paraphrase table, which contains 110,403 word pairs. The score Score 7 (p 1 , p 2 ) is set 1 for each identical word pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "-Self-paraphrase:",
                "sec_num": "7"
            },
            {
                "text": "The weights of the feature functions, namely \u03bb T M i (i = 1, 2, ..., 7) and \u03bb LM , need estimation9 . In MT, the max-BLEU algorithm is widely used to estimate parameters. However, it may not work in our case, since it is more difficult to create a reference set of paraphrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "We propose a new technique to estimate parameters in paraphrasing. The assumption is that, since a SMT-based paraphrase is generated through phrase substitution, we can measure the quality of a generated paraphrase by measuring its phrase substitutes. Generally, the paraphrases containing more correct phrase substitutes are judged as better paraphrases10 . We therefore present the phrase substitution error rate (PSER) to score a generated paraphrase T :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "P SER(T ) = P S0(T ) / P S(T )",
                        "eq_num": "(11)"
                    }
                ],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "where P S(T ) is the set of phrase substitutes in T and P S 0 (T ) is the set of incorrect substitutes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "In practice, we keep top n paraphrases for each sentence S. Thus we calculate the PSER for each source sentence S as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "P SER(S) = n [ i=1 P S0(Ti) / n [ i=1 P S(Ti)",
                        "eq_num": "(12)"
                    }
                ],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "where T i is the i-th generated paraphrase of S. Suppose there are N sentences in the development set, the overall PSER is computed as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "P SER = N X j=1 P SER(Sj) (13)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "where S j is the j-th sentence in the development set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "Our development set contains 75 sentences (described in detail in Section 6). For each sentence, all possible phrase substitutes are extracted from the six paraphrase tables above. The extracted phrase substitutes are then manually labeled as \"correct\" or \"incorrect\". A phrase substitute is considered as correct only if the two phrases have the same meaning in the given sentence and the sentence generated by substituting the source phrase with the target phrase remains grammatical. In decoding, the phrase substitutes are printed out and then the PSER is computed based on the labeled data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "Using each set of parameters, we generate paraphrases for the sentences in the development set based on Equation (2). PSER is then computed as in Equation ( 13). We use the gradient descent algorithm (Press et al., 1992) to minimize PSER on the development set and get the optimal parameters.",
                "cite_spans": [
                    {
                        "start": 200,
                        "end": 220,
                        "text": "(Press et al., 1992)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Parameter Estimation",
                "sec_num": "5"
            },
            {
                "text": "To evaluate the performance of the method on different types of test data, we used three kinds of sentences for testing, which were randomly extracted from Google news, free online novels, and forums, respectively. For each type, 50 sentences were extracted as test data and another 25 were extracted as development data. For each test sentence, top 10 of the generated paraphrases were kept for evaluation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "6"
            },
            {
                "text": "The phrase-level evaluation was carried out to investigate the contributions of the paraphrase tables. For each test sentence, all possible phrase substitutes were first extracted from the paraphrase tables and manually labeled as \"correct\" or \"incorrect\". Here, the criterion for identifying paraphrases is the same as that described in Section 5. Then, in the stage of decoding, the phrase substitutes were printed out and evaluated using the labeled data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "Two metrics were used here. The first is the number of distinct correct substitutes (#DCS). Obviously, the more distinct correct phrase substitutes a paraphrase table can provide, the more valuable it is. The second is the accuracy of the phrase substitutes, which is computed as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Accuracy = #correct phrase substitutes #all phrase substitutes",
                        "eq_num": "(14)"
                    }
                ],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "To evaluate the PTs learned from different resources, we first used each PT (from 1 to 6) along with PT-7 in decoding. The results are shown in Table 1. It can be seen that PT-4 is the most useful, as it provides the most correct substitutes and the accuracy is the highest. We believe that it is because PT-4 is much larger than the other PTs. PT-1: from the thesaurus; PT-2: from the monolingual parallel corpus; PT-3: from the monolingual comparable corpus; PT-4: from the bilingual parallel corpus; PT-5: from the Encarta dictionary definitions; PT-6: from the similar MSN user queries; PT-7: self-paraphrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "low. This is because those PTs are smaller, thus they can provide fewer correct phrase substitutes. As a result, plenty of incorrect substitutes were included in the top 10 generated paraphrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "PT-6 provides the least correct phrase substitutes and the accuracy is the lowest. There are several reasons. First, many phrases in PT-6 are not real phrases but only sets of keywords (e.g., \"lottery results ny\"), which may not appear in sentences. Second, many words in this table have spelling mistakes (e.g., \"widows vista\"). Third, some phrase pairs in PT-6 are not paraphrases but only \"related queries\" (e.g., \"back tattoo\" vs. \"butterfly tattoo\"). Fourth, many phrases of PT-6 contain proper names or out-of-vocabulary words, which are difficult to be matched. The accuracy based on PT-1 is also quite low. We found that it is mainly because the phrase pairs in PT-1 are automatically clustered, many of which are merely \"similar\" words rather than synonyms (e.g., \"borrow\" vs. \"buy\").",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "Next, we try to find out whether it is necessary to combine all PTs. Thus we conducted several runs, each of which added the most useful PT from the left ones. The results are shown in Table 2 . We can see that all the PTs are useful, as each PT provides some new correct phrase substitutes and the accuracy increases when adding each PT except PT-1.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 191,
                        "end": 192,
                        "text": "2",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "Since the PTs are extracted from different resources, they have different contributions. Here we only discuss the contributions of PT-5 and PT-6, which are first used in paraphrasing in this paper. PT-5 is useful for paraphrasing uncommon concepts since it can \"explain\" concepts with their definitions. For instance, in the following test sentence S 1 , the word \"amnesia\" is a relatively uncommon word, especially for the people using English as the second language. Based on PT-5, S 1 can be paraphrased into T 1 , which is much easier to understand.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Phrase-level Evaluation",
                "sec_num": "6.1"
            },
            {
                "text": "S 1 : I was suffering from amnesia.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "PT combination #DCS",
                "sec_num": null
            },
            {
                "text": "T 1 : I was suffering from memory loss.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "PT combination #DCS",
                "sec_num": null
            },
            {
                "text": "The disadvantage of PT-5 is that substituting words with the definitions sometimes leads to grammatical errors. For instance, substituting \"heat shield\" in the sentence S 2 with \"protective barrier against heat\" keeps the meaning unchanged. However, the paraphrased sentence T 2 is ungrammatical.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "PT combination #DCS",
                "sec_num": null
            },
            {
                "text": "S 2 : The U.S. space agency has been cautious about heat shield damage. T 2 : The U.S. space administration has been cautious about protective barrier against heat damage.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "PT combination #DCS",
                "sec_num": null
            },
            {
                "text": "As previously mentioned, PT-6 is less effective compared with the other PTs. However, it is useful for paraphrasing some special phrases, such as digital products, computer software, etc, since these phrases often appear in user queries. For example, S 3 below can be paraphrased into T 3 using PT-6. The phrase \"canon powershot\" can hardly be paraphrased using the other PTs. It suggests that PT-6 is useful for paraphrasing new emerging concepts and expressions. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "PT combination #DCS",
                "sec_num": null
            },
            {
                "text": "In this section, we evaluated the sentence-level quality of the generated paraphrases11 . In detail, each generated paraphrase was manually labeled as \"acceptable\" or \"unacceptable\". Here, the criterion for counting a sentence T as an acceptable paraphrase of sentence S is that T is understandable and its meaning is not evidently changed compared with S. For example, for the sentence S 4 , T 4 is an acceptable paraphrase generated using our method.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "S 4 : The strain on US forces of fighting in Iraq and Afghanistan was exposed yesterday when the Pentagon published a report showing that the number of suicides among US troops is at its highest level since the 1991 Gulf war. T 4 : The pressure on US troops of fighting in Iraq and Afghanistan was revealed yesterday when the Pentagon released a report showing that the amount of suicides among US forces is at its top since the 1991 Gulf conflict.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "We carried out sentence-level evaluation using the top-1, top-5, and top-10 results of each test sentence. The accuracy of the top-n results was computed as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Accuracy top-n = N i=1 n i N \u00d7 n (",
                        "eq_num": "15"
                    }
                ],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "where N is the number of test sentences. n i is the number of acceptable paraphrases in the top-n paraphrases of the i-th test sentence. We computed the accuracy on the whole test set (150 sentences) as well as on the three subsets, i.e., the 50 news sentences, 50 novel sentences, and 50 forum sentences. The results are shown in table 3 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 337,
                        "end": 338,
                        "text": "3",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "It can be seen that the accuracy varies greatly on different test sets. The accuracy on the news sentences is the highest, while that on the forum sentences is the lowest. There are several reasons. First, the largest PT used in the experiments is extracted using the bilingual parallel data, which are mostly from news documents. Thus, the test set of news sentences is more similar to the training data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "Second, the news sentences are formal while the novel and forum sentences are less formal. Especially, some of the forum sentences contain spelling mistakes and grammar mistakes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "Third, we find in the results that, most phrases paraphrased in the novel and forum sentences are commonly used phrases or words, such as \"food\", \"good\", \"find\", etc. These phrases are more difficult to paraphrase than the less common phrases, since they usually have much more paraphrases in the PTs. Therefore, it is more difficult to choose the right paraphrase from all the candidates when conducting sentence-level paraphrase generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "Fourth, the forum sentences contain plenty of words such as \"board (means computer board)\", \"site (means web site)\", \"mouse (means computer mouse)\", etc. These words are polysemous and have particular meanings in the domains of computer science and internet. Our method performs poor when paraphrasing these words since the domain of a context sentence is hard to identify.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "After observing the results, we find that there are three types of errors: (1) syntactic errors: the generated sentences are ungrammatical. About 32% of the unacceptable results are due to syntactic errors. (2) semantic errors: the generated sentences are incomprehensible. Nearly 60% of the unacceptable paraphrases have semantic errors. (3) non-paraphrase: the generated sentences are well formed and comprehensible but are not paraphrases of the input sentences. 8% of the unacceptable results are of this type. We believe that many of the errors above can be avoided by applying syntactic constraints and by making better use of context information in decoding, which is left as our future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sentence-level Evaluation",
                "sec_num": "6.2"
            },
            {
                "text": "This paper proposes a method that improves the SMT-based sentence-level paraphrase generation using phrasal paraphrases automatically extracted from different resources. Our contribution is that we combine multiple resources in the framework of SMT for paraphrase generation, in which the dic-tionary definitions and similar user queries are first used as phrasal paraphrases. In addition, we analyze and compare the contributions of different resources.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            },
            {
                "text": "Experimental results indicate that although the contributions of the exploited resources differ a lot, they are all useful to sentence-level paraphrase generation. Especially, the dictionary definitions and similar user queries are effective for paraphrasing some certain types of phrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            },
            {
                "text": "In the future work, we will try to use syntactic and context constraints in paraphrase generation to enhance the acceptability of the paraphrases. In addition, we will extract paraphrase patterns that contain more structural variation and try to combine the SMT-based and pattern-based systems for sentencelevel paraphrase generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            },
            {
                "text": "If none of the phrase substitutes from S to T is from P Ti (i.e., Ki = 0), we cannot compute hT M i(T , S) as in Equation(3). In this case, we assign hT M i(T , S) a minimum value.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The decoder used here is a re-implementation of Pharaoh.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www.cs.ualberta.ca/ lindek/downloads.htm.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://people.csail.mit.edu/mcollins/code.html",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The context of a chunk is made up of 6 words around the chunk, 3 to the left and 3 to the right.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The similarity of two documents is computed using the vector space model and the word weights are based on tf\u2022idf.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://encarta.msn.com/encnet/features/dictionary/dictionaryhome.aspx",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that, we also use some other parameters when extracting phrasal paraphrases from different resources, such as the thresholds T h1, T h2, T h3, T h4, as well as \u03b1 and \u03b2 in Equation (6) and (10). These parameters are estimated using different development sets from the investigated resources. We do not describe the estimation of them due to space",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "limitation.10 Paraphrasing a word to itself (based on the 7-th paraphrase table above) is not regarded as a substitute.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The evaluation was based on the paraphrasing results using the combination of all seven PTs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We would like to thank Mu Li for providing us with the SMT decoder. We are also grateful to Dongdong Zhang for his help in the experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Paraphrasing with Bilingual Parallel Corpora",
                "authors": [
                    {
                        "first": "Colin",
                        "middle": [],
                        "last": "Bannard",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "597--604",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Colin Bannard and Chris Callison-Burch. 2005. Para- phrasing with Bilingual Parallel Corpora. In Proceed- ings of ACL, pages 597-604.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Using Lexical Chains for Text Summarization",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Elhadad",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization",
                "volume": "",
                "issue": "",
                "pages": "10--17",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Michael Elhadad. 1997. Using Lex- ical Chains for Text Summarization. In Proceedings of the ACL Workshop on Intelligent Scalable Text Sum- marization, pages 10-17.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "16--23",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Lillian Lee. 2003. Learning to Para- phrase: An Unsupervised Approach Using Multiple- Sequence Alignment. In Proceedings of HLT-NAACL, pages 16-23.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Extracting Paraphrases from a Parallel Corpus",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Kathleen",
                        "middle": [
                            "R"
                        ],
                        "last": "Mckeown",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "50--57",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Kathleen R. McKeown. 2001. Ex- tracting Paraphrases from a Parallel Corpus. In Pro- ceedings of ACL, pages 50-57.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "The Mathematics of Statistical Machine Translation: Parameter Estimation",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Peter",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [
                            "A"
                        ],
                        "last": "Brown",
                        "suffix": ""
                    },
                    {
                        "first": "Vincent",
                        "middle": [
                            "J"
                        ],
                        "last": "Della Pietra",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "L"
                        ],
                        "last": "Della Pietra",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mercer",
                        "suffix": ""
                    }
                ],
                "year": 1993,
                "venue": "Computational Linguistics",
                "volume": "19",
                "issue": "",
                "pages": "263--311",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estima- tion. In Computational Linguistics 19(2): 263-311.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Improved Statistical Machine Translation Using Paraphrases",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Miles",
                        "middle": [],
                        "last": "Osborne",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "17--24",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Callison-Burch, Philipp Koehn, and Miles Os- borne. 2006. Improved Statistical Machine Trans- lation Using Paraphrases. In Proceedings of HLT- NAACL, pages 17-24.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Using Machine Translation Evaluation Techniques to Determine Sentence-level Semantic Equivalence",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Finch",
                        "suffix": ""
                    },
                    {
                        "first": "Young-Sook",
                        "middle": [],
                        "last": "Hwang",
                        "suffix": ""
                    },
                    {
                        "first": "Eiichiro",
                        "middle": [],
                        "last": "Sumita",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of IWP",
                "volume": "",
                "issue": "",
                "pages": "17--24",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrew Finch, Young-Sook Hwang, and Eiichiro Sumita. 2005. Using Machine Translation Evalua- tion Techniques to Determine Sentence-level Semantic Equivalence. In Proceedings of IWP, pages 17-24.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Cross-Lingual Query Suggestion Using Query Logs of Different Languages",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Cheng",
                        "middle": [],
                        "last": "Niu",
                        "suffix": ""
                    },
                    {
                        "first": "Jian-Yun",
                        "middle": [],
                        "last": "Nie",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Jian",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Kam-Fai",
                        "middle": [],
                        "last": "Wong",
                        "suffix": ""
                    },
                    {
                        "first": "Hsiao-Wuen",
                        "middle": [],
                        "last": "Hon",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of SIGIR",
                "volume": "",
                "issue": "",
                "pages": "463--470",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wei Gao, Cheng Niu, Jian-Yun Nie, Ming Zhou, Jian Hu, Kam-Fai Wong, and Hsiao-Wuen Hon. 2007. Cross- Lingual Query Suggestion Using Query Logs of Dif- ferent Languages. In Proceedings of SIGIR, pages 463-470.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Lexical Selection and Paraphrase in a Meaning-Text Generation Model",
                "authors": [
                    {
                        "first": "Lidija",
                        "middle": [],
                        "last": "Iordanskaja",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Kittredge",
                        "suffix": ""
                    },
                    {
                        "first": "Alain",
                        "middle": [],
                        "last": "Polgu\u00e8re",
                        "suffix": ""
                    }
                ],
                "year": 1991,
                "venue": "Natural Language Generation in Artificial Intelligence and Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "293--312",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lidija Iordanskaja, Richard Kittredge, and Alain Polgu\u00e8re. 1991. Lexical Selection and Paraphrase in a Meaning-Text Generation Model. In Natural Lan- guage Generation in Artificial Intelligence and Com- putational Linguistics, pages 293-312.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Paraphrasing for Automatic Evaluation",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Kauchak",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "455--462",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Kauchak and Regina Barzilay. 2006. Paraphras- ing for Automatic Evaluation. In Proceedings of HLT- NAACL, pages 455-462.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Pharaoh: a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models: User Manual and Description for Version 1.2. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation",
                "authors": [
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "127--133",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Philipp Koehn. 2004. Pharaoh: a Beam Search De- coder for Phrase-Based Statistical Machine Transla- tion Models: User Manual and Description for Version 1.2. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Pro- ceedings of HLT-NAACL, pages 127-133.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Automatic Retrieval and Clustering of Similar Words",
                "authors": [
                    {
                        "first": "De-Kang",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Proceedings of COLING/ACL",
                "volume": "",
                "issue": "",
                "pages": "768--774",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "De-Kang Lin. 1998. Automatic Retrieval and Clustering of Similar Words. In Proceedings of COLING/ACL, pages 768-774.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Discovery of Inference Rules for Question Answering",
                "authors": [
                    {
                        "first": "De-Kang",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Patrick",
                        "middle": [],
                        "last": "Pantel",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Natural Language Engineering",
                "volume": "7",
                "issue": "4",
                "pages": "343--360",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "De-Kang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for Question Answering. In Natural Language Engineering 7(4): 343-360.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Using Paraphrases for Parameter Tuning in Statistical Machine Translation",
                "authors": [
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Necip",
                        "middle": [],
                        "last": "Fazil Ayan",
                        "suffix": ""
                    },
                    {
                        "first": "Philip",
                        "middle": [],
                        "last": "Resnik",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "J"
                        ],
                        "last": "Dorr",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the Second Workshop on Statistical Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "120--127",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie J. Dorr. 2007. Using Paraphrases for Parame- ter Tuning in Statistical Machine Translation. In Pro- ceedings of the Second Workshop on Statistical Ma- chine Translation, pages 120-127.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Tracking and Summarizing News on a Daily Basis with Columbia's Newsblaster",
                "authors": [
                    {
                        "first": "Kathleen",
                        "middle": [
                            "R"
                        ],
                        "last": "Mckeown",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Evans",
                        "suffix": ""
                    },
                    {
                        "first": "Vasileios",
                        "middle": [],
                        "last": "Hatzivassiloglou",
                        "suffix": ""
                    },
                    {
                        "first": "Judith",
                        "middle": [
                            "L"
                        ],
                        "last": "Klavans",
                        "suffix": ""
                    },
                    {
                        "first": "Ani",
                        "middle": [],
                        "last": "Nenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Carl",
                        "middle": [],
                        "last": "Sable",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Schiffman",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Sigelman",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of HLT",
                "volume": "",
                "issue": "",
                "pages": "280--285",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kathleen R. Mckeown, Regina Barzilay, David Evans, Vasileios Hatzivassiloglou, Judith L. Klavans, Ani Nenkova, Carl Sable, Barry Schiffman, and Sergey Sigelman. 2002. Tracking and Summarizing News on a Daily Basis with Columbia's Newsblaster. In Pro- ceedings of HLT, pages 280-285.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Improved Statistical Alignment Models",
                "authors": [
                    {
                        "first": "Josef",
                        "middle": [],
                        "last": "Franz",
                        "suffix": ""
                    },
                    {
                        "first": "Hermann",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ney",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "440--447",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franz Josef Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In Proceedings of ACL, pages 440-447.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Discriminative Training and Maximum Entropy Models for Statistical Machine Translation",
                "authors": [
                    {
                        "first": "Josef",
                        "middle": [],
                        "last": "Franz",
                        "suffix": ""
                    },
                    {
                        "first": "Hermann",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ney",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "295--302",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franz Josef Och and Hermann Ney. 2002. Discrimina- tive Training and Maximum Entropy Models for Sta- tistical Machine Translation. In Proceedings of ACL, pages 295-302.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences",
                "authors": [
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "102--109",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based Alignment of Multiple Translations: Ex- tracting Paraphrases and Generating New Sentences. In Proceedings of HLT-NAACL, pages 102-109.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Aligning Needles in a Haystack: Paraphrase Acquisition Across the Web",
                "authors": [
                    {
                        "first": "Marius",
                        "middle": [],
                        "last": "Pasca",
                        "suffix": ""
                    },
                    {
                        "first": "P\u00e9ter",
                        "middle": [],
                        "last": "Dienes",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of IJCNLP",
                "volume": "",
                "issue": "",
                "pages": "119--130",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marius Pasca and P\u00e9ter Dienes. 2005. Aligning Nee- dles in a Haystack: Paraphrase Acquisition Across the Web. In Proceedings of IJCNLP, pages 119-130.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Numerical Recipes in C: The Art of Scientific Computing",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "William",
                        "suffix": ""
                    },
                    {
                        "first": "Saul",
                        "middle": [
                            "A"
                        ],
                        "last": "Press",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [
                            "T"
                        ],
                        "last": "Teukolsky",
                        "suffix": ""
                    },
                    {
                        "first": "Brian",
                        "middle": [
                            "P"
                        ],
                        "last": "Vetterling",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Flannery",
                        "suffix": ""
                    }
                ],
                "year": 1992,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "412--420",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "William H. Press, Saul A. Teukolsky, William T. Vetter- ling, and Brian P. Flannery. 1992. Numerical Recipes in C: The Art of Scientific Computing. Cambridge University Press, Cambridge, U.K., 1992, 412-420.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Monolingual Machine Translation for Paraphrase Generation",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Quirk",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of EMNLP",
                "volume": "",
                "issue": "",
                "pages": "142--149",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Quirk, Chris Brockett, and William Dolan. 2004. Monolingual Machine Translation for Paraphrase Generation. In Proceedings of EMNLP, pages 142- 149.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Learning Surface Text Patterns for a Question Answering System",
                "authors": [
                    {
                        "first": "Deepak",
                        "middle": [],
                        "last": "Ravichandran",
                        "suffix": ""
                    },
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "41--47",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Deepak Ravichandran and Eduard Hovy. 2002. Learn- ing Surface Text Patterns for a Question Answering System. In Proceedings of ACL, pages 41-47.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Automatic Paraphrase Acquisition from News Articles",
                "authors": [
                    {
                        "first": "Yusuke",
                        "middle": [],
                        "last": "Shinyama",
                        "suffix": ""
                    },
                    {
                        "first": "Satoshi",
                        "middle": [],
                        "last": "Sekine",
                        "suffix": ""
                    },
                    {
                        "first": "Kiyoshi",
                        "middle": [],
                        "last": "Sudo",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of HLT",
                "volume": "",
                "issue": "",
                "pages": "40--46",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo. 2002. Automatic Paraphrase Acquisition from News Articles. In Proceedings of HLT, pages 40-46.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Synonymous Collocation Extraction Using Translation Information",
                "authors": [
                    {
                        "first": "Hua",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "120--127",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hua Wu and Ming Zhou. 2003. Synonymous Collo- cation Extraction Using Translation Information. In Proceedings of ACL, pages 120-127.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "I have a canon powershot S230 that uses CF memory cards. T 3 : I have a canon digital camera S230 that uses CF memory cards.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td colspan=\"3\">PT combination #DCS Accuracy</td></tr><tr><td>1+7</td><td>178</td><td>14.61%</td></tr><tr><td>2+7</td><td>94</td><td>25.06%</td></tr><tr><td>3+7</td><td>202</td><td>18.35%</td></tr><tr><td>4+7</td><td>553</td><td>56.93%</td></tr><tr><td>5+7</td><td>231</td><td>20.48%</td></tr><tr><td>6+7</td><td>21</td><td>14.42%</td></tr></table>",
                "type_str": "table",
                "text": "Compared with PT-4, the accuracies of the other PTs are fairly Contributions of the paraphrase tables.",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Performances of different combinations of paraphrase tables.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Top-n accuracy on different test sentences.",
                "html": null,
                "num": null
            }
        }
    }
}