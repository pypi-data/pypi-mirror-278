{
    "paper_id": "2021",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:10:10.479863Z"
    },
    "title": "Neural Stylistic Response Generation with Disentangled Latent Variables",
    "authors": [
        {
            "first": "Qingfu",
            "middle": [],
            "last": "Zhu",
            "suffix": "",
            "affiliation": {},
            "email": "qfzhu@ir.hit.edu.cn"
        },
        {
            "first": "Weinan",
            "middle": [],
            "last": "Zhang",
            "suffix": "",
            "affiliation": {},
            "email": "wnzhang@ir.hit.edu.cn"
        },
        {
            "first": "Ting",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {},
            "email": "tliu@ir.hit.edu.cn"
        },
        {
            "first": "William",
            "middle": [
                "Yang"
            ],
            "last": "Wang",
            "suffix": "",
            "affiliation": {},
            "email": "william@cs.ucsb.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Generating open-domain conversational responses in the desired style usually suffers from the lack of parallel data in the style. Meanwhile, using monolingual stylistic data to increase style intensity often leads to the expense of decreasing content relevance. In this paper, we propose to disentangle the content and style in latent space by diluting sentence-level information in style representations. Combining the desired style representation and a response content representation will then obtain a stylistic response. Our approach achieves a higher BERT-based style intensity score and comparable BLEU scores, compared with baselines. Human evaluation results show that our approach significantly improves style intensity and maintains content relevance.",
    "pdf_parse": {
        "paper_id": "2021",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Generating open-domain conversational responses in the desired style usually suffers from the lack of parallel data in the style. Meanwhile, using monolingual stylistic data to increase style intensity often leads to the expense of decreasing content relevance. In this paper, we propose to disentangle the content and style in latent space by diluting sentence-level information in style representations. Combining the desired style representation and a response content representation will then obtain a stylistic response. Our approach achieves a higher BERT-based style intensity score and comparable BLEU scores, compared with baselines. Human evaluation results show that our approach significantly improves style intensity and maintains content relevance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Linguistic style is an essential aspect of natural language interaction and provides particular ways of using language to engage with the audiences (Kabbara and Cheung, 2016) . In human-bot conversations, it is crucial to generate stylistic responses for increasing user engagement to conversational systems (Gan et al., 2017) . Currently, most of the existing parallel datasets are not stylistically consistent. Samples in these datasets are usually contributed by a variety of users, resulting in an averaging effect across style characteristics (Zhang et al., 2018a) . Meanwhile, constructing a parallel stylistic dataset for training the open-domain conversational agents is both labor-intensive and time-consuming.",
                "cite_spans": [
                    {
                        "start": 148,
                        "end": 174,
                        "text": "(Kabbara and Cheung, 2016)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 308,
                        "end": 326,
                        "text": "(Gan et al., 2017)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 548,
                        "end": 569,
                        "text": "(Zhang et al., 2018a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Recent studies show the effect of stylizing responses using a monolingual dataset in the desired style and a conventional conversational dataset (Niu and Bansal, 2018; Gao et al., 2019b) . However, increasing style intensity often leads to (Niu and Bansal, 2018) , Style Fusion (Gao et al., 2019b) , and our approach, targeting the Holmes style, which is quite formal and polite.",
                "cite_spans": [
                    {
                        "start": 145,
                        "end": 167,
                        "text": "(Niu and Bansal, 2018;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 168,
                        "end": 186,
                        "text": "Gao et al., 2019b)",
                        "ref_id": null
                    },
                    {
                        "start": 240,
                        "end": 262,
                        "text": "(Niu and Bansal, 2018)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 278,
                        "end": 297,
                        "text": "(Gao et al., 2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "the expense of decreasing content relevance between dialogue history and response. As an example in Figure 1 shows, Niu and Bansal (2018) independently train a response generation model and a stylistic language model and subsequently interpolates them in the inference phase. Lacking the interaction between the stylistic language model and response generation encoder, it usually yields a trade-off between style intensity and content relevance. Gao et al. (2019a,b) fuse a structured latent space where the direction denotes the diversity, and the distance denotes style intensity and content relevance. The main issue is that style intensity and content relevance are contradictory in measurement but are coupling to the same \"distance\" metric of the latent space. To sum up, the key issue of the above studies is the improper entanglement of style and content.",
                "cite_spans": [
                    {
                        "start": 116,
                        "end": 137,
                        "text": "Niu and Bansal (2018)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 447,
                        "end": 467,
                        "text": "Gao et al. (2019a,b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 107,
                        "end": 108,
                        "text": "1",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "To address the issue, we propose to disentangle the style and content of a response. The disentanglement is conducted on the structured latent space, where each sentence (dialogue history, response, and stylistic sentence) is projected into a vector representation. We further split the representation into two components: style and content representations. The former is a corpus-level feature since sentences within a dataset have the same style. In contrast, the content representation is a sentence-level feature decided by a sentence itself. We thus disentangle the content and style by diluting sentence-level information in the style representation. This encourages the encoding of content information into the content representation. Otherwise, the content information will be corrupted in the style representation, making it hard to reconstruct the original content in the subsequent decoding process. We conduct experiments on DailyDialogue conversational dataset (Li et al., 2017) and Holmes monolingual stylistic dataset (Gao et al., 2019b) . Experimental results show that our proposed approach improves style intensity and maintains content relevance. Our contributions are listed below:",
                "cite_spans": [
                    {
                        "start": 974,
                        "end": 991,
                        "text": "(Li et al., 2017)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 1033,
                        "end": 1052,
                        "text": "(Gao et al., 2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 We propose a unified framework to simultaneously improve style intensity and maintain content relevance for neural stylistic response generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 We introduce a scheme of learning latent variables by a diluting strategy to disentangle the style and content.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Experimental results show that our approach achieves higher performance in style intensity without decreasing content relevance, compared with previous approaches.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The task of stylistic response generation is defined as follows: given a monolingual stylistic dataset S = {S 1 , ..., S N } 1 and a conversational dataset",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "C = {(X 1 , Y 1 ), ..., (X M , Y M )}, where S i , X i ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "and Y i denote a stylistic sentence, dialogue history, and a response respectively, the goal is to learn a generation model P ( \u0176 |X), where \u0176 is a generated response expected to be in the style of S (called the desired style in the following sections). We will first briefly review the concept of structured latent space and then introduce our disentanglement approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "1 Throughout the paper, we use bold letters to denote vectors, i.e., V = {V1, V2, ..., VN }. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "2 Z S2S (X i ) Z AE (Y i ) Z AE (Y i ) Z(Y i ) Z AE (S j )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "(X i ). The k-th re- sponse representation Z AE (Y k i ) (denoted by a black point) is optimized to be distributed around Z S2S (X i ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "The red point Z AE (S j ) and the purple point Z( \u0176i ) are representations of a monolingual stylistic sentence and a stylistic response, respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task Definition",
                "sec_num": "2.1"
            },
            {
                "text": "Overview The structured latent space is constructed by two main mechanisms: (i) sharing a decoder between a sequence-to-sequence (S2S) model and an auto-encoder (AE), and (ii) fusion and smoothness objectives. As an example in Figure 2 shows, a response representation Z AE (Y i ) is regularized by the two mechanisms to be distributed around its dialogue history representation Z S2S (X i ). The notations Z AE (\u2022) and Z S2S (\u2022) denote the representations computed by AE encoder and S2S encoder, respectively. Such a latent space makes it possible to predict a response \u0176 by sampling nearby the dialogue history representation. Based on that, Gao et al. (2019b) further align stylistic sentence representations into the latent space, which improves the style intensity of generated responses. In summary, the construction of the structred latent space is a process of aligning the three spaces (Z S2S (X i ), Z AE (Y i ), and Z AE (S j )) by two mechanisms (sharing the decoder, and fusion and smoothness objectives).",
                "cite_spans": [
                    {
                        "start": 644,
                        "end": 662,
                        "text": "Gao et al. (2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 234,
                        "end": 235,
                        "text": "2",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "Fusion Objective cross-aligns sentences of different spaces. Since X i and Y i are paired, we align them by minimizing their pair-wise dissimilarity:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "d conv = i\u2208batch d E (Z S2S (X i ), Z AE (Y i )) n \u221a l ,",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "where d E denotes the Euclidean distance, n is the batch size, and l is the dimensionality of the latent space. In contrast, the pair-wise dissimilarity can-not be applied to stylistic sentences since they are not paired with conversational data. To this end, the fusion objective instead optimizes the nearest neighbor distance between the two datasets:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "d style = 1 2 d cross NN ({Z S2S (X i )}, {Z AE (S j )}) + 1 2 d cross NN ({Z AE (S j )}, {Z S2S (X i )}),",
                        "eq_num": "(2)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "where d cross NN ({a i }, {b j }) denotes the batch average distance between a i and its nearest neighbor in the set {b j }. To further encourage the representations spread-out the latent space, a inner-distance loss is introduced:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "d spread-out = min{d inner NN (Z S2S (X i )), d inner NN (Z AE (Y i )), d inner NN (Z AE (S j ))},",
                        "eq_num": "(3)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "where d inner NN ({a i }) denotes the batch average distance between a i and its nearest neighbor in the set {a i }. The final fusion objective is defined as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "L fuse = d conv + d style -d spread-out .",
                        "eq_num": "(4)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "Smoothness Objective aims to make the structured latent space a continuous space, where each point can decode a natural sentence. Given three discrete points Z S2S (X i ), Z AE (Y i ), and Z AE (S j ), the objective encourages points in the area between Z S2S (X i ) and Z AE (Y i ) to generate Y i :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Z conv = U Z S2S (X i ) + (1 -U )Z AE (Y i ) + , L smooth,conv = -log P (Y i |Z conv ),",
                        "eq_num": "(5)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "where \u223c N (0, \u03c3 2 I), and U \u223c U (0, 1). Meanwhile, as a point moves from Z AE (Y i ) to Z AE (S j ), the corresponding generation is expected to gradually move from Y i to S j :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Z style = U Z AE (Y i ) + (1 -U )Z AE (S j ) + L smooth,style = -U log P (Y i |Z style ) -(1 -U ) log P (S j |Z style ).",
                        "eq_num": "(6)"
                    }
                ],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "The smoothness objective L smooth is the sum of L smooth,conv and L smooth,style , and is added to the final loss function along with the fusion objective and response generation loss of S2S.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background: Structured Latent Space",
                "sec_num": "2.2"
            },
            {
                "text": "Despite aligning monolingual stylistic sentences into the structured latent space helps stylize generated responses, their style intensity is still limited.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "We conjecture this is due to the coupling of the style and the content in sentence representations. To this end, we propose to disentangle the two aspects in the structured latent space.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "In our proposed approach, a sentence representation Z \u2208 R l in the latent space consists of two components: content representation Z c \u2208 R lc and style representation Z s \u2208 R ls , where l is the dimensionality of latent space and l c + l s = l. Z s encodes all the style information of a sentence. It is a corpus-level feature because Z s for different sentences in the same corpus should be similar. In contrast, Z c can be seen as a sentence-level feature which only decided by the content of its corresponding sentence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "Figure 3 shows an example of our approach, where Z c and Z s can be seen as two \"containers\". Colored squares represent the content and style information. We encourage the disentanglement of the two types of information by diluting sentence-level content information in Z s . As an example in Figure 3 (a) shows, the content and style information may be mixed in both Z c and Z s . During the decoding process of a sentence, i.e., Y i , we replace its style representation",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": "FIGREF4"
                    },
                    {
                        "start": 300,
                        "end": 301,
                        "text": "3",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "Z s AE (Y i ) with its batch average style representation Zs AE (Y i ) = 1 n j\u2208batch Z s AE (Y j ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "In this way, its sentence-level content information will be diluted since it greatly varies from other sentences' content information, which introduces extra noise. In contrast, its corpus-level style information, which is similar to that of other sentences within the batch, will remain unaffected. As the training processes, the content information will be encouraged to be encoded into Z c where it can remain unchanged, as an example in Figure 3 (b) shows. Otherwise, the content information will be corrupted in Z s , making it hard to recover the content of Y i . As a result, the encoding process will be punished by the response generation loss of S2S and the reconstruction loss of AE, as shown in Figure 3 (a) .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 448,
                        "end": 449,
                        "text": "3",
                        "ref_id": "FIGREF4"
                    },
                    {
                        "start": 714,
                        "end": 719,
                        "text": "3 (a)",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "Based on that, we update the response generation process by replacing its style representation Z s with the corresponding batch average style representation Zs :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "L S2S = -log P (Y i |[Z c S2S (X i ) : Zs S2S (X i )]),",
                        "eq_num": "(7)"
                    }
                ],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "where the bracket [:] denotes concatenation. The decoding process in the smoothness objective is updated similarly. Note that when we move from Y i to S j , and from X i to Y i , we only interpolate their content representations Z c in the latent space:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Z c conv = U Z c S2S (X i ) + (1 -U )Z c AE (Y i ) + , Z c style = U Z c AE (Y i ) + (1 -U )Z c AE (S j ) + .",
                        "eq_num": "(8)"
                    }
                ],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "The batch average style representation Zs remains consistent with the target, i.e., being Zs AE (S j ) when the target is S j . The updated smoothness objective is as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "L smooth,conv = -log P (Y i |[Z c conv : Zs AE (Y i )]), L smooth,style = -U log P (Y i |[Z c style : Zs AE (Y i )]) -(1 -U ) log P (S j |[Z c style : Zs AE (S j )]). (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "The final training loss is the sum of the response generation loss, fusion objective, and smoothness objective:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "L =L S2S + L fuse + L smooth .",
                        "eq_num": "(10)"
                    }
                ],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "Here, we do not employ pre-training models, i.e., DialoGPT (Zhang et al., 2020b) and OpenAI GPT2 (Radford et al., 2019) . This is because the disentanglement is usually conducted on a sentence representation. While most of the pre-training models depend on the attention mechanism, and there is no static global sentence representation during the decoding process.",
                "cite_spans": [
                    {
                        "start": 59,
                        "end": 80,
                        "text": "(Zhang et al., 2020b)",
                        "ref_id": null
                    },
                    {
                        "start": 97,
                        "end": 119,
                        "text": "(Radford et al., 2019)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Our Method",
                "sec_num": "2.3"
            },
            {
                "text": "To generate a stylistic response \u0176i given dialogue history X i during the inference process, we first obtain Z c S2S (X i ) by S2S encoder and subsequently sample Z c ( \u0176i ) from the hypersphere of Z c S2S (X i ) with a mannually tuned radius r. After that, we generate \u0176i by concatenating Z c ( \u0176i ) and Zs AE (S j ), which is the batch average style representation of randomly sampled stylistic sentences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "Considering the discrepancy between training and inference that content and style representations in different corpora have never been concatenated for generation, we propose a soft combination approach to introduce the desired style by interpolating Z s S2S (X i ) and Zs AE (S j ):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Z s soft = Z s S2S (X i ) + \u03b1 * Zs AE (S j ), (",
                        "eq_num": "11"
                    }
                ],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "where \u03b1 is the weight of the desired style. After that, \u0176i is generated by the decoder whose hidden state is set to [Z c ( \u0176i ) : Z s soft ]. To further balance style intensity and content relevance, we also employ the re-ranking strategy following Gao et al. (2019b) . It samples N y candidate responses and re-ranks them by:",
                "cite_spans": [
                    {
                        "start": 249,
                        "end": 267,
                        "text": "Gao et al. (2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "s r = \u03b3 * P S2S ( \u0176i |X i ) + (1 -\u03b3) * P style ( \u0176i ), (",
                        "eq_num": "12"
                    }
                ],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": ")",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "where P S2S ( \u0176i |X i ) is the generation probability under a S2S model measuring the relevance. P style ( \u0176i ) is the probability that \u0176i has the desired style. It is a interpolation between the probabilities of a neural-based classifier and a n-gram classifier: where w n is a weight which is set to the accuracy of the corresponding classifier.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "P style ( \u0176i ) =\u03b7 * P neural ( \u0176i ) + (1 -\u03b7) * N n=1 w n * P n-gram ( \u0176i ),",
                        "eq_num": "(13)"
                    }
                ],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "3 Experiments We do not use the arXiv dataset as it contains too many special tokens, i.e., equations, and incomplete sentences, such as \"is concerned\" and \"exactly identical restrictions\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference",
                "sec_num": "2.4"
            },
            {
                "text": "We compare the proposed approach with the following baselines:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 S2S, the sequence-to-sequence response generation model (Shang et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 58,
                        "end": 78,
                        "text": "(Shang et al., 2015)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 S2S+LM, a S2S trained on C and a stylistic language model trained on S (Niu and Bansal, 2018) . During the inference process, it generates a stylistic response by interpolating outputs of the two models. \u2022 Style Fusion, a multi-task learning based model whose latent space fuses dialogue history, responses, and stylistic sentences with a specific structure (Gao et al., 2019b) .",
                "cite_spans": [
                    {
                        "start": 73,
                        "end": 95,
                        "text": "(Niu and Bansal, 2018)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 360,
                        "end": 379,
                        "text": "(Gao et al., 2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "3.2"
            },
            {
                "text": "Note that we do not consider the Label-Fine-Tuning model and Polite Reinforcement Learning model (Niu and Bansal, 2018) , because they require some training samples in the conversational dataset to have the desired style (Gao et al., 2019b) .",
                "cite_spans": [
                    {
                        "start": 97,
                        "end": 119,
                        "text": "(Niu and Bansal, 2018)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 221,
                        "end": 240,
                        "text": "(Gao et al., 2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baselines",
                "sec_num": "3.2"
            },
            {
                "text": "We implement the proposed approach based on the released code of Style Fusion model4 . The vocabulary table consists of the most frequent 20,000 words. S2S encoder, AE encoder, and the shared decoder are two-layer LSTMs. The number of their hidden units is 1000, which is also the size of the structured latent space. The dimension of Z c and Z s is 950 and 50, respectively. The maximum length is set to 90 for the dialogue history and 30 for the response.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment Settings",
                "sec_num": "3.3"
            },
            {
                "text": "During the training process, we use the ADAM optimizer, whose learning rate is 0.0003. \u03c32 for sampling in Equation 8 is 0.1 2 . Table 2 shows the average running time on a single TITAN X (Pascal) GPU. During the inference process, the weights \u03b3 and \u03b7 for re-ranking are set to 0.5. The weight (accuracy) of n-gram classifier is 0.93, 0.87, 0.77, and 0.65 for n from 1 to 4. The number of candidate responses, N y , is set to 10. The radius r is set to 3.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 134,
                        "end": 135,
                        "text": "2",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Experiment Settings",
                "sec_num": "3.3"
            },
            {
                "text": "Automatic Evaluation Considering that it is unfair to evaluate a response by the classifiers that are used for selecting the response (Song et al., 2020) , we fine-tune a BERT (Devlin et al., 2019) randomly selected from DailyDialog's responses, which are of the same amount of sentences as the positive samples. Given the fine-tuned BERT classifier (whose accuracy achieves 0.96 on the validation set), we report the average probability of responses being positive as a measurement of the style intensity. For brevity, we denote this metric as SI. The content relevance is evaluated by BLEU.",
                "cite_spans": [
                    {
                        "start": 134,
                        "end": 153,
                        "text": "(Song et al., 2020)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 176,
                        "end": 197,
                        "text": "(Devlin et al., 2019)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Metrics",
                "sec_num": "4.1"
            },
            {
                "text": "Since it may correlate weakly with human judgments of quality in a single reference setting (Liu et al., 2016) , we employ the expanded responses in multi-reference DailyDialog test set (Gupta et al., 2019) as references to alleviate the problem. Meanwhile, we evaluate the diversity by Dist-k (Li et al., 2016) , which is the number of distinct k-grams normalized by the total number of words of responses.",
                "cite_spans": [
                    {
                        "start": 92,
                        "end": 110,
                        "text": "(Liu et al., 2016)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 186,
                        "end": 206,
                        "text": "(Gupta et al., 2019)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 294,
                        "end": 311,
                        "text": "(Li et al., 2016)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Metrics",
                "sec_num": "4.1"
            },
            {
                "text": "Human Evaluation We randomly sample 200 messages from the test set of C to conduct the human evaluation from two aspects: style intensity and content relevance. Each aspect is independently evaluated by five Amazon Mechanical Turk (AMT)5 workers whose approval rate is greater than 95%, and the number of approved is greater than 500. Given dialogue history and two responses generated by a baseline and our approach, the workers are asked to give a preference of which one is better (ties are also permitted).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Evaluation Metrics",
                "sec_num": "4.1"
            },
            {
                "text": "Figure 4 shows the trade-off between style intensity and content relevance in our approach. There is an improvement in SI and a decrease in BLEU associated with the increase of \u03b1 in Equation 11.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "4",
                        "ref_id": "FIGREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.2"
            },
            {
                "text": "To assess the overall performance, we also compute their harmonic mean, whose maximum lies around \u03b1 = 0.5. We thus conduct the human evaluation and analysis in this parameter setting. We report the human evaluation results in Table 4. Our approach is clearly preferred in style intensity because the percentage of Win is significantly higher than that of Lose (p <0.001, T-test). In terms of content relevance, the ratios of Win in \"vs. S2S\" and \"vs. Style Fusion\" are similar to those of Lose. This suggests that our approach can significantly improve the style intensity without decreasing the content relevance. In contrast, S2S+LM loses in most of the cases in the content relevance. Following Zhou et al. (2018) and Ke et al. (2018) , we evaluate the agreement of annotators via inter-rater consistency. The percentage of samples that at least three annotators have the same preference (3/5 agreement) is 81.80%. And the percentage for 4/5 agreement is 32.15%.",
                "cite_spans": [
                    {
                        "start": 698,
                        "end": 716,
                        "text": "Zhou et al. (2018)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 721,
                        "end": 737,
                        "text": "Ke et al. (2018)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.2"
            },
            {
                "text": "Table 3 shows the results of the automatic evaluation. Our approach has the highest mean score, which indicates that it achieves the best overall performance. S2S+LM has a high SI score, but its BLEU scores are not as good as others, i.e., S2S. This is in line with our human evaluation results and Niu and Bansal (2018)'s observation that biasing a decoder with a stylistic language model may harm the content relevance. In contrast, our approach (\u03b1 = 0.25) significantly outperforms S2S and is comparable to Style Fusion. By increasing \u03b1 to 0.5, the BLEU score drops slightly but is comparable to baselines (evidenced by the human evaluation results). Meanwhile, there is a significant improvement (up to 95.37%) in SI comparing with Style Fusion. This verifies the effectiveness of our disentanglement approach in improving the style intensity and maintaining the content relevance. Besides, the Dist-k results in Table 3 also indicate that the diversity of our approach is comparable to the best-performed Style Fusion.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": "TABREF5"
                    },
                    {
                        "start": 923,
                        "end": 924,
                        "text": "3",
                        "ref_id": "TABREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.2"
            },
            {
                "text": "We conduct ablation studies to investigate the contributions of the fusion objective, smoothness objective, and our disentanglement approach. To focus on their effects on the generation process, in this section, we sample a single response without using the re-ranking strategy (Equation 12).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ablation Study",
                "sec_num": "4.3"
            },
            {
                "text": "Table 5 shows the results of the ablation study. There is a significant decline in SI and a slight change in BLEU-3 and BLEU-4 after removing each component. This indicates that a multi-task learning architecture without the three components can achieve a good content relevance performance but fails to stylize a response. By removing the disentanglement component, our approach degenerates into Style Fusion. In this case, the SI score decreases significantly while BLEU scores are nearly unchanged, which demonstrates the disentanglement could improve the style intensity and maintain the relevance at the same time. The decreases in SI after removing the fusion objective and smoothness objective are more significant than that after removing the disentanglement. This is because the two objectives are bottom components for constructing the structured latent space, where our approach and Style Fusion are built upon.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "5",
                        "ref_id": "TABREF8"
                    }
                ],
                "eq_spans": [],
                "section": "Ablation Study",
                "sec_num": "4.3"
            },
            {
                "text": "In this section, we analyze whether style information is disentangled into Z s . To achieve this goal, we train style classifiers taking as input a latent variable and use the validation accuracy as an indicator. Taking our approach as an instance, we first freeze the parameters of our well-trained model. Then we independently learn two style classifiers whose inputs are the full latent variable ([Z c : Z s ]) and Z s respectively. Note that Z c and Z s in Style Fusion are a simple partition of its latent variable.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis",
                "sec_num": "4.4"
            },
            {
                "text": "There are not any disentanglement approaches applied to obtain the two representations. As shown in Table 6 , Style Fusion achieves 0.83 validation accuracy training on its full latent variable. And the accuracy decreases by 13.02% when the classification is only based on Z s . In contrast, the decrease of our approach is only 1.71%, indicating that most of the style information is disentangled into Z s . We show a visualization of the disentanglement of the latent variable by MDS (Borg and Groenen, 2005) in Figure 5 . Each figure consists of Z s (black) and three continuous sub-sequences extracted from the head (yellow), middle (red), and tail (blue) of Z c . The sub-sequences are of the same length with Z s . For both stylistic and conversational samples, all the sub-sequences and Z s are mixed in Style Fusion. In contrast, there is a clear separation between Z s and the sub-sequences in our approach. This is because most of the style information is disentangled into Z s in our approach, making its distribution different from sub-sequences of Z c .",
                "cite_spans": [
                    {
                        "start": 486,
                        "end": 510,
                        "text": "(Borg and Groenen, 2005)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 106,
                        "end": 107,
                        "text": "6",
                        "ref_id": "TABREF10"
                    },
                    {
                        "start": 521,
                        "end": 522,
                        "text": "5",
                        "ref_id": "FIGREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Analysis",
                "sec_num": "4.4"
            },
            {
                "text": "Table 7 shows some examples of generated responses. There is no significant Holmes style in responses of S2S. Similarly, the style intensity of responses in Style Fusion is also limited. The semantics of S2S+LM's response in the first example is not very clear, making it less relevant to the dialogue history than other responses. We believe this is also due to the lack of interaction between the response generation encoder and the stylistic language model. In contrast, our approach not only achieves a good content relevance performance but also has a significant Holmes style, which is quite polite and formal.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "7",
                        "ref_id": "TABREF12"
                    }
                ],
                "eq_spans": [],
                "section": "Case Study",
                "sec_num": "4.5"
            },
            {
                "text": "5 Related Work",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Case Study",
                "sec_num": "4.5"
            },
            {
                "text": "The task of text style transfer aims at transferring the style of a sentence while preserving its meaning. One way is to disentangle the content and style, and subsequently combine the content with the desired style. The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018) , reinforcement learning (Jain et al., 2019 ), back-translation (Prabhumoye et al., 2018; Nogueira dos Santos et al., 2018) , multi-task learning (John et al., 2019) , and removing stylistic phrases (Li et al., 2018; Xu et al., 2018; Zhang et al., 2018b) . The other way transfers the style without disentangled representations, for example using generator-evaluator architecture (Gong et al., 2019) , cycle reconstruction (Dai et al., 2019) , parameter sharing (Wang et al., 2020) , and data augmentation (Zhang et al., 2020a) .",
                "cite_spans": [
                    {
                        "start": 277,
                        "end": 296,
                        "text": "(Shen et al., 2017;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 297,
                        "end": 313,
                        "text": "Hu et al., 2017;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 314,
                        "end": 330,
                        "text": "Fu et al., 2018;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 331,
                        "end": 349,
                        "text": "Yang et al., 2018;",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 350,
                        "end": 374,
                        "text": "Logeswaran et al., 2018)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 400,
                        "end": 418,
                        "text": "(Jain et al., 2019",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 419,
                        "end": 464,
                        "text": "), back-translation (Prabhumoye et al., 2018;",
                        "ref_id": null
                    },
                    {
                        "start": 465,
                        "end": 498,
                        "text": "Nogueira dos Santos et al., 2018)",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 521,
                        "end": 540,
                        "text": "(John et al., 2019)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 574,
                        "end": 591,
                        "text": "(Li et al., 2018;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 592,
                        "end": 608,
                        "text": "Xu et al., 2018;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 609,
                        "end": 629,
                        "text": "Zhang et al., 2018b)",
                        "ref_id": null
                    },
                    {
                        "start": 755,
                        "end": 774,
                        "text": "(Gong et al., 2019)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 798,
                        "end": 816,
                        "text": "(Dai et al., 2019)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 837,
                        "end": 856,
                        "text": "(Wang et al., 2020)",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 881,
                        "end": 902,
                        "text": "(Zhang et al., 2020a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Text Style Transfer without Parallel Data",
                "sec_num": "5.1"
            },
            {
                "text": "The main difference between our task and text style transfer lies in two aspects. First, all the content to be generated is available in the input in text style transfer, while our task needs to create new (response) content. And the key is content relevance to the dialogue history, rather than content preservation of the input. Second, the data for text style transfer is isomorphic. Data in different styles are in the same free-text format. However, our conversational data are context-response pairs while the stylistic data are free-texts, which is heterogeneous and requires more sophisticated structures, i.e., the structured latent space (Gao et al., 2019b) .",
                "cite_spans": [
                    {
                        "start": 648,
                        "end": 667,
                        "text": "(Gao et al., 2019b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Text Style Transfer without Parallel Data",
                "sec_num": "5.1"
            },
            {
                "text": "Parallel Stylistic Data Niu and Bansal(2018) propose three weaksupervised models based on reinforcement learning, conditional text generation, and language model. Gao et al. (2019b) fuses the latent spaces of a response generation model and a stylistic autoencoder to improve the style intensity of sampled responses. Yang et al. (2020) inject the style information by introducing a word-level KL loss and a sentence-level style classifier to the fine-turning process of DialoGPT (Zhang et al., 2020b) . Distinct from previous work, we explicitly disentangle the style and content in the latent space and employ a unified architecture to jointly optimize the style intensity and content relevance.",
                "cite_spans": [
                    {
                        "start": 24,
                        "end": 44,
                        "text": "Niu and Bansal(2018)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 163,
                        "end": 181,
                        "text": "Gao et al. (2019b)",
                        "ref_id": null
                    },
                    {
                        "start": 318,
                        "end": 336,
                        "text": "Yang et al. (2020)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 480,
                        "end": 501,
                        "text": "(Zhang et al., 2020b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Stylistic Response Generation without",
                "sec_num": "5.2"
            },
            {
                "text": "We propose a uniform framework to simultaneously improve the style intensity and maintain the content relevance for neural stylistic response generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "In contrast to existing approaches, our approach disentangles the style and the content in the latent space by a diluting strategy. Experiments show that our approach improves the style intensity of generated responses and maintains the content relevance at the same time, which demonstrates the effectiveness of this approach.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6"
            },
            {
                "text": "http://yanran.li/dailydialog",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/golsun/StyleFusion",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://github.com/golsun/StyleFusion",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://www.mturk.com",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "The authors would like to thank all the anonymous reviewers for their insightful comments. The authors from HIT are supported by the National Natural Science Foundation of China (No. 62076081, No. 61772153, and No. 61936010) and Science and Technology Innovation 2030 Major Project of China (No. 2020AAA0108605). The author from UCSB is not supported by any of the projects above.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            },
            {
                "text": "This paper honors the ACL Code of Ethics. Stylistic response generation intends to improve the engagement of a dialogue system in human-bot conversations. It responds to users with the desired style, i.e., being polite, humorous, or romantic, rather than imitating any specific person. Meanwhile, style is a linguistic aspect of natural language interaction. There is not any identity characteristic being used as a variable.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Ethical Statement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Modern multidimensional scaling: Theory and applications",
                "authors": [
                    {
                        "first": "Ingwer",
                        "middle": [],
                        "last": "Borg",
                        "suffix": ""
                    },
                    {
                        "first": "Patrick",
                        "middle": [],
                        "last": "Jf Groenen",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ingwer Borg and Patrick JF Groenen. 2005. Modern multidimensional scaling: Theory and applications. Springer Science & Business Media.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Style transformer: Unpaired text style transfer without disentangled latent representation",
                "authors": [
                    {
                        "first": "Ning",
                        "middle": [],
                        "last": "Dai",
                        "suffix": ""
                    },
                    {
                        "first": "Jianze",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Xipeng",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Xuanjing",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "5997--6007",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ning Dai, Jianze Liang, Xipeng Qiu, and Xuanjing Huang. 2019. Style transformer: Unpaired text style transfer without disentangled latent represen- tation. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguistics, pages 5997-6007.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Devlin",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "4171--4186",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1423"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Style transfer in text: Exploration and evaluation",
                "authors": [
                    {
                        "first": "Zhenxin",
                        "middle": [],
                        "last": "Fu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoye",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Nanyun",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Dongyan",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Thirty-Second AAAI Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, and Rui Yan. 2018. Style transfer in text: Explo- ration and evaluation. In Thirty-Second AAAI Con- ference on Artificial Intelligence.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Stylenet: Generating attractive visual captions with styles",
                "authors": [
                    {
                        "first": "Chuang",
                        "middle": [],
                        "last": "Gan",
                        "suffix": ""
                    },
                    {
                        "first": "Zhe",
                        "middle": [],
                        "last": "Gan",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodong",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of CVPR",
                "volume": "",
                "issue": "",
                "pages": "955--964",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chuang Gan, Zhe Gan, Xiaodong He, Jianfeng Gao, and Li Deng. 2017. Stylenet: Generating attractive visual captions with styles. In Proceedings of CVPR, pages 955-964. IEEE.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Jointly optimizing diversity and relevance in neural response generation",
                "authors": [
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Sungjin",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Yizhe",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter",
                "volume": "1",
                "issue": "",
                "pages": "1229--1238",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1125"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Xiang Gao, Sungjin Lee, Yizhe Zhang, Chris Brockett, Michel Galley, Jianfeng Gao, and Bill Dolan. 2019a. Jointly optimizing diversity and relevance in neural response generation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1229-1238, Minneapolis, Minnesota. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Structuring latent spaces for stylized response generation",
                "authors": [
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Yizhe",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Sungjin",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "volume": "",
                "issue": "",
                "pages": "1814--1823",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D19-1190"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Xiang Gao, Yizhe Zhang, Sungjin Lee, Michel Gal- ley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2019b. Structuring latent spaces for stylized re- sponse generation. In Proceedings of the 2019 Con- ference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer- ence on Natural Language Processing (EMNLP- IJCNLP), pages 1814-1823, Hong Kong, China. As- sociation for Computational Linguistics.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Reinforcement learning based text style transfer without parallel training corpus",
                "authors": [
                    {
                        "first": "Hongyu",
                        "middle": [],
                        "last": "Gong",
                        "suffix": ""
                    },
                    {
                        "first": "Suma",
                        "middle": [],
                        "last": "Bhat",
                        "suffix": ""
                    },
                    {
                        "first": "Lingfei",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Jinjun",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Wen-Mei",
                        "middle": [],
                        "last": "Hwu",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "3168--3180",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N19-1320"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Hongyu Gong, Suma Bhat, Lingfei Wu, JinJun Xiong, and Wen-mei Hwu. 2019. Reinforcement learning based text style transfer without parallel training cor- pus. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technolo- gies, Volume 1, pages 3168-3180.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Investigating evaluation of open-domain dialogue systems with human generated multiple references",
                "authors": [
                    {
                        "first": "Prakhar",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Shikib",
                        "middle": [],
                        "last": "Mehri",
                        "suffix": ""
                    },
                    {
                        "first": "Tiancheng",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Amy",
                        "middle": [],
                        "last": "Pavel",
                        "suffix": ""
                    },
                    {
                        "first": "Maxine",
                        "middle": [],
                        "last": "Eskenazi",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Bigham",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue",
                "volume": "",
                "issue": "",
                "pages": "379--391",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W19-5944"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Prakhar Gupta, Shikib Mehri, Tiancheng Zhao, Amy Pavel, Maxine Eskenazi, and Jeffrey Bigham. 2019. Investigating evaluation of open-domain dialogue systems with human generated multiple references. In Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, pages 379-391, Stock- holm, Sweden. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Toward controlled generation of text",
                "authors": [
                    {
                        "first": "Zhiting",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Zichao",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodan",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Ruslan",
                        "middle": [],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [
                            "P"
                        ],
                        "last": "Xing",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 34th International Conference on Machine Learning",
                "volume": "70",
                "issue": "",
                "pages": "1587--1596",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. 2017. Toward controlled generation of text. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1587-1596. JMLR. org.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Unsupervised controllable text formalization",
                "authors": [
                    {
                        "first": "Parag",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Abhijit",
                        "middle": [],
                        "last": "Mishra",
                        "suffix": ""
                    },
                    {
                        "first": "Amar",
                        "middle": [],
                        "last": "Prakash Azad",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Sankaranarayanan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "volume": "33",
                "issue": "",
                "pages": "6554--6561",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Parag Jain, Abhijit Mishra, Amar Prakash Azad, and Karthik Sankaranarayanan. 2019. Unsupervised controllable text formalization. In Proceedings of the AAAI Conference on Artificial Intelligence, vol- ume 33, pages 6554-6561.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Disentangled representation learning for non-parallel text style transfer",
                "authors": [
                    {
                        "first": "Vineet",
                        "middle": [],
                        "last": "John",
                        "suffix": ""
                    },
                    {
                        "first": "Lili",
                        "middle": [],
                        "last": "Mou",
                        "suffix": ""
                    },
                    {
                        "first": "Hareesh",
                        "middle": [],
                        "last": "Bahuleyan",
                        "suffix": ""
                    },
                    {
                        "first": "Olga",
                        "middle": [],
                        "last": "Vechtomova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "424--434",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vineet John, Lili Mou, Hareesh Bahuleyan, and Olga Vechtomova. 2019. Disentangled representation learning for non-parallel text style transfer. In Pro- ceedings of the 57th Annual Meeting of the Associa- tion for Computational Linguistics, pages 424-434.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Stylistic transfer in natural language generation systems using recurrent neural networks",
                "authors": [
                    {
                        "first": "Jad",
                        "middle": [],
                        "last": "Kabbara",
                        "suffix": ""
                    },
                    {
                        "first": "Jackie",
                        "middle": [],
                        "last": "Chi",
                        "suffix": ""
                    },
                    {
                        "first": "Kit",
                        "middle": [],
                        "last": "Cheung",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods",
                "volume": "",
                "issue": "",
                "pages": "43--47",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/W16-6010"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jad Kabbara and Jackie Chi Kit Cheung. 2016. Stylis- tic transfer in natural language generation systems using recurrent neural networks. In Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods, pages 43-47.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Generating informative responses with controlled sentence function",
                "authors": [
                    {
                        "first": "Pei",
                        "middle": [],
                        "last": "Ke",
                        "suffix": ""
                    },
                    {
                        "first": "Jian",
                        "middle": [],
                        "last": "Guan",
                        "suffix": ""
                    },
                    {
                        "first": "Minlie",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1499--1508",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pei Ke, Jian Guan, Minlie Huang, and Xiaoyan Zhu. 2018. Generating informative responses with con- trolled sentence function. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1), pages 1499-1508.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "A diversity-promoting objective function for neural conversation models",
                "authors": [
                    {
                        "first": "Jiwei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference of the North American Chapter",
                "volume": "",
                "issue": "",
                "pages": "110--119",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N16-1014"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A diversity-promoting objec- tive function for neural conversation models. In Pro- ceedings of the 2016 Conference of the North Amer- ican Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110-119.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Delete, retrieve, generate: a simple approach to sentiment and style transfer",
                "authors": [
                    {
                        "first": "Juncen",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Robin",
                        "middle": [],
                        "last": "Jia",
                        "suffix": ""
                    },
                    {
                        "first": "He",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Percy",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter",
                "volume": "1",
                "issue": "",
                "pages": "1865--1874",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-1169"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Juncen Li, Robin Jia, He He, and Percy Liang. 2018. Delete, retrieve, generate: a simple approach to sen- timent and style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics,Volume 1, pages 1865-1874.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
                "authors": [
                    {
                        "first": "Yanran",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Hui",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyu",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "Wenjie",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Ziqiang",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Shuzi",
                        "middle": [],
                        "last": "Niu",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "986--995",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: A manually labelled multi-turn dialogue dataset. In Proceedings of the Eighth International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 986-995.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
                "authors": [
                    {
                        "first": "Chia-Wei",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Lowe",
                        "suffix": ""
                    },
                    {
                        "first": "Iulian",
                        "middle": [],
                        "last": "Serban",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Noseworthy",
                        "suffix": ""
                    },
                    {
                        "first": "Laurent",
                        "middle": [],
                        "last": "Charlin",
                        "suffix": ""
                    },
                    {
                        "first": "Joelle",
                        "middle": [],
                        "last": "Pineau",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2122--2132",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D16-1230"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Nose- worthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation. In Proceedings of the 2016 Conference on Empirical Methods in Natu- ral Language Processing, pages 2122-2132, Austin, Texas. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Content preserving text generation with attribute controls",
                "authors": [
                    {
                        "first": "Lajanugen",
                        "middle": [],
                        "last": "Logeswaran",
                        "suffix": ""
                    },
                    {
                        "first": "Honglak",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Samy",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "5103--5113",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lajanugen Logeswaran, Honglak Lee, and Samy Ben- gio. 2018. Content preserving text generation with attribute controls. In Advances in Neural Informa- tion Processing Systems, pages 5103-5113.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Polite dialogue generation without parallel data",
                "authors": [
                    {
                        "first": "Tong",
                        "middle": [],
                        "last": "Niu",
                        "suffix": ""
                    },
                    {
                        "first": "Mohit",
                        "middle": [],
                        "last": "Bansal",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "6",
                "issue": "",
                "pages": "373--389",
                "other_ids": {
                    "DOI": [
                        "10.1162/tacl_a_00027"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Tong Niu and Mohit Bansal. 2018. Polite dialogue gen- eration without parallel data. Transactions of the As- sociation for Computational Linguistics, 6:373-389.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Style transfer through back-translation",
                "authors": [
                    {
                        "first": "Yulia",
                        "middle": [],
                        "last": "Shrimai Prabhumoye",
                        "suffix": ""
                    },
                    {
                        "first": "Ruslan",
                        "middle": [],
                        "last": "Tsvetkov",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [
                            "W"
                        ],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Black",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "866--876",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P18-1080"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhut- dinov, and Alan W Black. 2018. Style transfer through back-translation. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1), pages 866-876.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Language models are unsupervised multitask learners",
                "authors": [
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Rewon",
                        "middle": [],
                        "last": "Child",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Luan",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Fighting offensive language on social media with unsupervised text style transfer",
                "authors": [
                    {
                        "first": "Cicero",
                        "middle": [],
                        "last": "Nogueira Dos Santos",
                        "suffix": ""
                    },
                    {
                        "first": "Igor",
                        "middle": [],
                        "last": "Melnyk",
                        "suffix": ""
                    },
                    {
                        "first": "Inkit",
                        "middle": [],
                        "last": "Padhi",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "2",
                "issue": "",
                "pages": "189--194",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P18-2031"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Cicero Nogueira dos Santos, Igor Melnyk, and Inkit Padhi. 2018. Fighting offensive language on so- cial media with unsupervised text style transfer. In Proceedings of the 56th Annual Meeting of the As- sociation for Computational Linguistics (Volume 2), pages 189-194, Melbourne, Australia.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Neural responding machine for short-text conversation",
                "authors": [
                    {
                        "first": "Lifeng",
                        "middle": [],
                        "last": "Shang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhengdong",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Hang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing",
                "volume": "1",
                "issue": "",
                "pages": "1577--1586",
                "other_ids": {
                    "DOI": [
                        "10.3115/v1/P15-1152"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Lifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neu- ral responding machine for short-text conversation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan- guage Processing (Volume 1), pages 1577-1586.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Style transfer from non-parallel text by cross-alignment",
                "authors": [
                    {
                        "first": "Tianxiao",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Lei",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Tommi",
                        "middle": [],
                        "last": "Jaakkola",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Advances in neural information processing systems",
                "volume": "",
                "issue": "",
                "pages": "6830--6841",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2017. Style transfer from non-parallel text by cross-alignment. In Advances in neural informa- tion processing systems, pages 6830-6841.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Generating persona consistent dialogues by exploiting natural language inference",
                "authors": [
                    {
                        "first": "Haoyu",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Nan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jingwen",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Ting",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "volume": "34",
                "issue": "",
                "pages": "8878--8885",
                "other_ids": {
                    "DOI": [
                        "10.1609/aaai.v34i05.6417"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Haoyu Song, Wei-Nan Zhang, Jingwen Hu, and Ting Liu. 2020. Generating persona consistent dialogues by exploiting natural language inference. Proceed- ings of the AAAI Conference on Artificial Intelli- gence, 34(05):8878-8885.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Formality style transfer with shared latent space",
                "authors": [
                    {
                        "first": "Yunli",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Lili",
                        "middle": [],
                        "last": "Mou",
                        "suffix": ""
                    },
                    {
                        "first": "Zhoujun",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Wenhan",
                        "middle": [],
                        "last": "Chao",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2236--2249",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and Wen- han Chao. 2020. Formality style transfer with shared latent space. In Proceedings of the 28th Inter- national Conference on Computational Linguistics, pages 2236-2249.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Unpaired sentiment-to-sentiment translation: A cycled reinforcement learning approach",
                "authors": [
                    {
                        "first": "Jingjing",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Zeng",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xuancheng",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Houfeng",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Wenjie",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "979--988",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P18-1090"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jingjing Xu, Xu Sun, Qi Zeng, Xiaodong Zhang, Xu- ancheng Ren, Houfeng Wang, and Wenjie Li. 2018. Unpaired sentiment-to-sentiment translation: A cy- cled reinforcement learning approach. In Proceed- ings of the 56th Annual Meeting of the Association for Computational Linguistics, Volume 1, pages 979- 988.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "StyleDGPT: Stylized response generation with pretrained language models",
                "authors": [
                    {
                        "first": "Ze",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Can",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xinnian",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Jiaqi",
                        "middle": [],
                        "last": "Bai",
                        "suffix": ""
                    },
                    {
                        "first": "Liran",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhoujun",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "volume": "",
                "issue": "",
                "pages": "1548--1559",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.findings-emnlp.140"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ze Yang, Wei Wu, Can Xu, Xinnian Liang, Jiaqi Bai, Liran Wang, Wei Wang, and Zhoujun Li. 2020. StyleDGPT: Stylized response generation with pre- trained language models. In Findings of the Associ- ation for Computational Linguistics: EMNLP 2020, pages 1548-1559, Online. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Unsupervised text style transfer using language models as discriminators",
                "authors": [
                    {
                        "first": "Zichao",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiting",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [
                            "P"
                        ],
                        "last": "Xing",
                        "suffix": ""
                    },
                    {
                        "first": "Taylor",
                        "middle": [],
                        "last": "Berg-Kirkpatrick",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "7287--7298",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zichao Yang, Zhiting Hu, Chris Dyer, Eric P Xing, and Taylor Berg-Kirkpatrick. 2018. Unsupervised text style transfer using language models as discrimina- tors. In Advances in Neural Information Processing Systems, pages 7287-7298.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "SHAPED: Shared-private encoder-decoder for text style adaptation",
                "authors": [
                    {
                        "first": "Ye",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "Radu",
                        "middle": [],
                        "last": "Soricut",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "1528--1538",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/N18-1138"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ye Zhang, Nan Ding, and Radu Soricut. 2018a. SHAPED: Shared-private encoder-decoder for text style adaptation. In Proceedings of the 2018 Con- ference of the North American Chapter of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies, Volume 1, pages 1528-1538.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "2020a. Parallel data augmentation for formality style transfer",
                "authors": [
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Ge",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "3221--3228",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.294"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yi Zhang, Tao Ge, and Xu Sun. 2020a. Parallel data augmentation for formality style transfer. In Pro- ceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 3221- 3228, Online. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Learning sentiment memories for sentiment modification without parallel data",
                "authors": [
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jingjing",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Pengcheng",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1103--1108",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D18-1138"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yi Zhang, Jingjing Xu, Pengcheng Yang, and Xu Sun. 2018b. Learning sentiment memories for sentiment modification without parallel data. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1103-1108.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "DIALOGPT : Largescale generative pre-training for conversational response generation",
                "authors": [
                    {
                        "first": "Yizhe",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Siqi",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Yen-Chun",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Jingjing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "270--278",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-demos.30"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020b. DIALOGPT : Large- scale generative pre-training for conversational re- sponse generation. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270- 278, Online. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Commonsense knowledge aware conversation generation with graph attention",
                "authors": [
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Young",
                        "suffix": ""
                    },
                    {
                        "first": "Minlie",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Haizhou",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Jingfang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "the 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "4623--4629",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. 2018. Com- monsense knowledge aware conversation generation with graph attention. In the 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence, pages 4623-4629.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "My friend had a considerable share in clearing the matter up.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 1: An example of responses generated by S2S, S2S+LM(Niu and Bansal, 2018), Style Fusion(Gao  et al., 2019b), and our approach, targeting the Holmes style, which is quite formal and polite.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "text": "Figure3: An example of disentangling content and style. The purple block is the content information of the first sentence. The yellow block is the content information of the second sentence. Style information in both two sentences is denoted by red blocks as it is a corpus-level feature shared among samples within the corpus. (a): A negative example whose content and style information is mixed in Z c and Z s . Its content information is corrupted after averaging Z s within the batch and fails to recover the input content. (b): A positive example. Content information in Z c and style information in Z s will not be affected after averaging Z s .",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF5": {
                "num": null,
                "text": "Figure4: The trade-off between style intensity measured by SI and content relevance measured by BLEU-4. The x-axis corresponds to \u03b1. The harmonic mean achieves the maximum around \u03b1=0.5.",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            },
            "FIGREF6": {
                "num": null,
                "text": "Figure 5: MDS visualization of Z s (black) and three continuous sub-sequences extracted from the head (yellow), middle (red), and tail (blue) of Z c .",
                "uris": null,
                "fig_num": "5",
                "type_str": "figure"
            },
            "TABREF2": {
                "content": "<table><tr><td colspan=\"2\">Training Dialogues 11,118</td></tr><tr><td>Validation Dialogues</td><td>1,000</td></tr><tr><td>Test Dialogues</td><td>1,000</td></tr><tr><td>Average Tokens Per Dialogue</td><td>114.7</td></tr><tr><td>Average Tokens Per Utterance</td><td>14.6</td></tr></table>",
                "type_str": "table",
                "text": "Statistics of the DailyDialog dataset.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td>3.1 Data</td></tr><tr><td>Conversational Dataset We employ DailyDia-</td></tr><tr><td>log 2 (</td></tr></table>",
                "type_str": "table",
                "text": "Li et al., 2017) as our conversational dataset C. It is a human-written multi-turn dataset covering various topics of daily life. Table1shows some statistics of its training, validation, and test set. We split dialogue of K utterances into K-1 samples.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td>Model</td><td colspan=\"2\">Time (s) # of parameters</td></tr><tr><td>S2S</td><td>4.55</td><td>63M</td></tr><tr><td>Style Fusion</td><td>4.60</td><td>75M</td></tr><tr><td>Ours</td><td>4.60</td><td>75M</td></tr></table>",
                "type_str": "table",
                "text": "The average running time (in seconds per batch) and the number of parameters.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td>Model</td><td colspan=\"6\">SI(%) Dist-1 Dist-2 BLEU-3 BLEU-4 Mean</td></tr><tr><td>S2S (Shang et al., 2015)</td><td>6.32</td><td>0.035</td><td>0.227</td><td>0.70</td><td>0.20</td><td>0.10</td></tr><tr><td colspan=\"2\">S2S+LM (Niu and Bansal, 2018) 32.79</td><td>0.015</td><td>0.086</td><td>0.55</td><td>0.08</td><td>0.13</td></tr><tr><td>Style Fusion (Gao et al., 2019b)</td><td>10.58</td><td>0.043</td><td>0.280</td><td>0.82</td><td>0.22</td><td>0.14</td></tr><tr><td>Ours (\u03b1=0.25)</td><td>11.91</td><td>0.041</td><td>0.275</td><td>0.79</td><td>0.23</td><td>0.16</td></tr><tr><td>Ours (\u03b1=0.50)</td><td>20.67</td><td>0.040</td><td>0.275</td><td>0.64</td><td>0.17</td><td>0.19</td></tr><tr><td>Ours (\u03b1=0.75)</td><td>34.85</td><td>0.038</td><td>0.285</td><td>0.47</td><td>0.10</td><td>0.16</td></tr></table>",
                "type_str": "table",
                "text": "to measure style intensity. Concretely, positive samples are the stylistic sentences. Negative samples are Automatic evaluation results of SI, Dist-1, Dist-2, and BLEU. The last column is the harmonic mean of SI and BLEU-4 measuring the overall performance of style intensity and content relevance.",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table><tr><td/><td colspan=\"4\">Content Relevance Style Intensity</td></tr><tr><td/><td>Win</td><td>Lose</td><td>Win</td><td>Lose</td></tr><tr><td>vs. S2S</td><td>40.21</td><td>39.79</td><td colspan=\"2\">49.37 36.84</td></tr><tr><td>vs. S2S+LM</td><td>65.00</td><td>20.00</td><td colspan=\"2\">53.30 32.50</td></tr><tr><td colspan=\"2\">vs. Style Fusion 43.32</td><td>42.67</td><td colspan=\"2\">48.77 36.68</td></tr></table>",
                "type_str": "table",
                "text": "Pair-wise human evaluation results of content relevance and style intensity.",
                "html": null,
                "num": null
            },
            "TABREF8": {
                "content": "<table><tr><td>Style Fusion</td><td>Ours</td></tr><tr><td>Stylistic</td><td/></tr><tr><td>Samples</td><td/></tr><tr><td>Conversational</td><td/></tr><tr><td>Samples</td><td/></tr></table>",
                "type_str": "table",
                "text": "Results of the ablation study.",
                "html": null,
                "num": null
            },
            "TABREF10": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Style classification accuracy of the full latent variable ([Z c : Z s ]) and Z s .",
                "html": null,
                "num": null
            },
            "TABREF12": {
                "content": "<table/>",
                "type_str": "table",
                "text": "An example of responses generated by baselines and our approach.",
                "html": null,
                "num": null
            }
        }
    }
}