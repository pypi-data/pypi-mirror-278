{
    "paper_id": "D13-1158",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:59:14.723998Z"
    },
    "title": "Single-Document Summarization as a Tree Knapsack Problem",
    "authors": [
        {
            "first": "Tsutomu",
            "middle": [],
            "last": "Hirao",
            "suffix": "",
            "affiliation": {},
            "email": ""
        },
        {
            "first": "Yasuhisa",
            "middle": [],
            "last": "Yoshida",
            "suffix": "",
            "affiliation": {},
            "email": ""
        },
        {
            "first": "Masaaki",
            "middle": [],
            "last": "Nishino",
            "suffix": "",
            "affiliation": {},
            "email": ""
        },
        {
            "first": "Norihito",
            "middle": [],
            "last": "Yasuda",
            "suffix": "",
            "affiliation": {},
            "email": "yasuda@erato.ist.hokudai.ac.jp"
        },
        {
            "first": "Masaaki",
            "middle": [],
            "last": "Nagata",
            "suffix": "",
            "affiliation": {},
            "email": "nagata.masaaki@lab.ntt.co.jp"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Recent studies on extractive text summarization formulate it as a combinatorial optimization problem such as a Knapsack Problem, a Maximum Coverage Problem or a Budgeted Median Problem. These methods successfully improved summarization quality, but they did not consider the rhetorical relations between the textual units of a source document. Thus, summaries generated by these methods may lack logical coherence. This paper proposes a single document summarization method based on the trimming of a discourse tree. This is a two-fold process. First, we propose rules for transforming a rhetorical structure theorybased discourse tree into a dependency-based discourse tree, which allows us to take a treetrimming approach to summarization. Second, we formulate the problem of trimming a dependency-based discourse tree as a Tree Knapsack Problem, then solve it with integer linear programming (ILP). Evaluation results showed that our method improved ROUGE scores.",
    "pdf_parse": {
        "paper_id": "D13-1158",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Recent studies on extractive text summarization formulate it as a combinatorial optimization problem such as a Knapsack Problem, a Maximum Coverage Problem or a Budgeted Median Problem. These methods successfully improved summarization quality, but they did not consider the rhetorical relations between the textual units of a source document. Thus, summaries generated by these methods may lack logical coherence. This paper proposes a single document summarization method based on the trimming of a discourse tree. This is a two-fold process. First, we propose rules for transforming a rhetorical structure theorybased discourse tree into a dependency-based discourse tree, which allows us to take a treetrimming approach to summarization. Second, we formulate the problem of trimming a dependency-based discourse tree as a Tree Knapsack Problem, then solve it with integer linear programming (ILP). Evaluation results showed that our method improved ROUGE scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "State-of-the-art extractive text summarization methods regard a document (or a document set) as a set of textual units (e.g. sentences, clauses, phrases) and formulate summarization as a combinatorial optimization problem, i.e. selecting a subset of the set of textual units that maximizes an objective without violating a length constraint. For example, Mc-Donald (2007) formulated text summarization as a Knapsack Problem, where he selects a set of textual units that maximize the sum of significance scores of each unit. Filatova et al. (2004) proposed a summarization method based on a Maximum Coverage Problem, in which they select a set of textual units that maximizes the weighted sum of the conceptual units (e.g. unigrams) contained in the set. Although, their greedy solution is only an approximation, Takamura et al. (2009a) extended it to obtain the exact solution. More recently, Takamura et al. (2009b) regarded summarization as a Budgeted Median Problem and obtain exact solutions with integer linear programming.",
                "cite_spans": [
                    {
                        "start": 355,
                        "end": 371,
                        "text": "Mc-Donald (2007)",
                        "ref_id": null
                    },
                    {
                        "start": 524,
                        "end": 546,
                        "text": "Filatova et al. (2004)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 812,
                        "end": 835,
                        "text": "Takamura et al. (2009a)",
                        "ref_id": null
                    },
                    {
                        "start": 893,
                        "end": 916,
                        "text": "Takamura et al. (2009b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "These methods successfully improved ROUGE (Lin, 2004) scores, but they still have one critical shortcoming. Since these methods are based on subset selection, the summaries they generate cannot preserve the rhetorical structure of the textual units of a source document. Thus, the resulting summary may lack coherence and may not include significant textual units from a source document.",
                "cite_spans": [
                    {
                        "start": 42,
                        "end": 53,
                        "text": "(Lin, 2004)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "One powerful and potential way to overcome the problem is to include discourse tree constraints in the summarization procedure. Marcu (1998) regarded a document as a Rhetorical Structure Theory (RST) (William Charles, Mann and Sandra Annear, Thompson, 1988) -based discourse tree (RST-DT) and selected textual units according to a preference ranking derived from the tree structure to make a summary. Daum\u00e9 et al. (2002) proposed a document compression method that directly models the probability of a summary given an RST-DT by using a noisy-channel model. These methods generate well-organized summaries, however, since they do not formulate summarizations as combinatorial op-Figure 1 : Example RST-DT from (Marcu, 1998) .",
                "cite_spans": [
                    {
                        "start": 128,
                        "end": 140,
                        "text": "Marcu (1998)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 209,
                        "end": 257,
                        "text": "Charles, Mann and Sandra Annear, Thompson, 1988)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 401,
                        "end": 420,
                        "text": "Daum\u00e9 et al. (2002)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 710,
                        "end": 723,
                        "text": "(Marcu, 1998)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 686,
                        "end": 687,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "timization problems, the optimality of the generated summaries is not guaranteed.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we propose a single document summarization method based on the trimming of a discourse tree based on the Tree Knapsack Problem. If a discourse tree explicitly represents parent-child relationships between textual units, we can apply the well-known tree-trimming approach to a discourse tree and reap the benefit of combinatorial optimization methods. In other words, to apply the treetrimming approach, we need a tree whose all nodes represent textual units. Unfortunately, the RST-DT does not allow it, because textual units in the RST-DT are located only on leaf nodes and parent-child relationship between textual units are represented implicitly at higher positions in a tree. Therefore, we first propose rules that transform an RST-DT into a dependency-based discourse tree (DEP-DT) that explicitly defines the parent-child relationships. Second, we treat it as a rooted subtree selection, in other words, a Tree Knapsack Problem and formulate the problem as an ILP.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2 From RST-DT to DEP-DT",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "According to RST, a document is represented as an RST-DT whose terminal nodes correspond to elementary discourse units (EDU)s 1 and whose nonterminal nodes indicate the role of the contiguous EDUs namely, 'nucleus (N)' or 'satellite (S)'. A nucleus is more important than a satellite in terms of the writer's purpose. That is, a satellite is a child of a nucleus in the RST-DT. Some discourse relations such as 'Elaboration', 'Contrast' and 'Evidence' between a nucleus and a satellite or two nuclei are defined. Figure 1 shows an example of an RST-DT.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 520,
                        "end": 521,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "RST-DT",
                "sec_num": "2.1"
            },
            {
                "text": "An RST-DT is not suitable for tree trimming because it does not always explicitly define parent-child relationships between textual units. For example, if we consider how to trim the RST-DT in Figure 1 , when we drop e 8 , we have to drop e 7 because of the parent-child relationship defined between e 7 and e 8 , i.e. e 7 is a satellite (child) of the nucleus (parent) e 8 . On the other hand, we cannot judge whether we have to drop e 9 or e 10 because the parent-child relationships are not explicitly defined between e 8 and e 9 , e 8 and e 10 . This view motivates us to produce a discourse tree that explicitly defines parent-child relationships and whose root node represents the most important EDU in a source document. If we can obtain such a tree, it is easy to formulate summarization as a Tree Knapsack Problem.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 200,
                        "end": 201,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "To construct a discourse tree that represents the parent-child relationships between EDUs, we propose rules for transforming an RST-DT to a dependency-based discourse tree (DEP-DT). The procedure is defined as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "1. For each non-terminal node excluding the par- ent of an EDU in the RST-DT, we define a 'head'. Here, a 'head' of a non-terminal node is the leftmost descendant EDU whose parent is N. In Figure 2 , 'H' indicates the 'head' of each node.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 196,
                        "end": 197,
                        "text": "2",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "2. For each EDU whose parent is N, we pick the nearest S with a 'head' from the EDU's ancestors and we add the EDU to the DEP-DT as a child of the head of the S's parent. If there is no nearest S, the EDU is the root of the DEP-DT. For example, in Figure 2 , the nearest S to e 3 that has a head is node 5 and the head of node 5's parent is e 2 . Thus, e 3 is a child of e 2 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 255,
                        "end": 256,
                        "text": "2",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "3. For each EDU whose parent is S, we pick the nearest non-terminal with a 'head' from the ancestors and we add the EDU to the DEP-DT as a child of the head of the non-terminal node.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "For example, the nearest non-terminal node of e 9 that has a head is node 16 and the head of node 16 is e 10 . Thus, e 9 is a child of e 10 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "Figure 3 shows the DEP-DT obtained from the RST-DT in Figure 1 . The DEP-DT expresses the parent-child relationship between the EDUs. Therefore, we have to drop e 7 , e 9 and e 10 when we drop e 8 . Note that, by applying the rules, discourse relations defined between non-terminals of an RST-DT are eliminated. However, we believe that these relations are no needed for the summarization that we are attempting to realize.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 61,
                        "end": 62,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "DEP-DT",
                "sec_num": "2.2"
            },
            {
                "text": "Single-Document Summarization",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tree Knapsack Model for",
                "sec_num": "3"
            },
            {
                "text": "We denote T as a set of all possible rooted subtrees obtained from a DEP-DT. F (t) is the significance score for a rooted subtree t \u2208 T and L is the maximum number of words allowed in a summary. The optimal subtree t * is defined as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "t * = arg max t\u2208T F (t) (1) s.t. Length(t) \u2264 L.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "(2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "Here, we define F (t) as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "F (t) = \u2211 e\u2208E(t)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "W(e) Depth(e) .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "(3) E(t) is the set of EDUs contained in t, Depth(e) is the depth of an EDU e within the DEP-DT. For example, Depth(e 2 ) = 1, Depth(e 6 ) = 4 for the DEP-DT of Figure 3 . W(e) is defined as follows:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 168,
                        "end": 169,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "W(e) = \u2211 w\u2208W (e)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "tf(w, D).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "(4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "W (e) is the set of words contained in e and tf(w, D) is the term frequency of word w in a document D.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formalization",
                "sec_num": "3.1"
            },
            {
                "text": "We formulate the optimization problem in the previous section as a Tree Knapsack Problem, which is a kind of Precedence-Constrained Knapsack Problem (Samphaiboon and Yamada, 2000) and we can obtain the optimal rooted subtree by solving the following ILP problem2 :",
                "cite_spans": [
                    {
                        "start": 149,
                        "end": 179,
                        "text": "(Samphaiboon and Yamada, 2000)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "maximize x N \u2211 i=1 W(e i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "Depth(e i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "x i (5)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "s.t. N \u2211 i=1 \u2113 i x i \u2264 L (6) \u2200i : x parent(i) \u2265 x i (7) \u2200i : x i \u2208 {0, 1},",
                        "eq_num": "(8)"
                    }
                ],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "ROUGE-1 ROUGE-2 F R F R TKP(G)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": ".310 H,K,L .321 where x is an N -dimensional binary vector that represents the summary, i.e. x i =1 denotes that the ith EDU is included in the summary. N is the number of EDUs in a document, \u2113 i is the length (the number of words) of the i-th EDU, and parent(i) indicates the ID of the parent of the i-th EDU in the DEP-DT. Constraint (6) ensures that the length of a summary is less than limit L. Constraint (7) ensures that a summary is a rooted subtree of the DEP-DT. Thus, x parent(i) is always 1 when the i-th EDU is included in the summary.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "In general, the Tree Knapsack Problem is NPhard, but fortunately we can obtain the optimal solution in a feasible time by using ILP solvers for documents of practical tree size. In addition, bottomup DP (Lukes, 1974) and depth-first DP algorithms (Cho and Shaw, 1997) are known to find the optimal solution efficiently.",
                "cite_spans": [
                    {
                        "start": 203,
                        "end": 216,
                        "text": "(Lukes, 1974)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 247,
                        "end": 267,
                        "text": "(Cho and Shaw, 1997)",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ILP Formulation",
                "sec_num": "3.2"
            },
            {
                "text": "We conducted an experimental evaluation on the test collection for single document summarization evaluation contained in the RST Discourse Treebank (RST-DTB) (Carlson et al., 2001) distributed by the Linguistic Data Consortium (LDC) 3 . The RST-DTB Corpus includes 385 Wall Street Journal articles with RST annotation, and 30 of these documents also have one human-made reference summary. The average length of the reference summaries corresponds to about 10 % of the words in the source 3 http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2002T07 document.",
                "cite_spans": [
                    {
                        "start": 158,
                        "end": 180,
                        "text": "(Carlson et al., 2001)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings",
                "sec_num": "4.1"
            },
            {
                "text": "We compared our method (TKP) with Marcu's method (Marcu) (Marcu, 1998) , a simple knapsack model (KP), a maximum coverage model (MCP) and a lead method (LEAD). MCP is known to be a state-of-the-art method for multiple document summarization and we believe that MCP also performs well in terms of single document summarization. LEAD is also a widely used summarizer that simply takes the first K textual units of the document. Although this is a simple heuristic rule, it is known as a state-of-the-art summarizer (Nenkova and McKeown, 2011) .",
                "cite_spans": [
                    {
                        "start": 49,
                        "end": 56,
                        "text": "(Marcu)",
                        "ref_id": null
                    },
                    {
                        "start": 57,
                        "end": 70,
                        "text": "(Marcu, 1998)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 513,
                        "end": 540,
                        "text": "(Nenkova and McKeown, 2011)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings",
                "sec_num": "4.1"
            },
            {
                "text": "For our method, we examined two types of DEP-DT. One was obtained from the gold RST-DT. The other was obtained from the RST-DT produced by a state-of-the-art RST parser, HILDA (du-Verle and Prendinger, 2009; Hernault et al., 2010) . For Marcu's method, we examined both the gold RST-DT and HILDA's RST-DT. We re-implemented HILDA and re-trained it on the RST-DT Corpus excluding the 30 documents used in the evaluation. The F-score of the parser was around 0.5. For KP, we exclude constraint (7) from the ILP formulation of TKP and set the depth of all EDUs in equations (3) and (5) at 1. For MCP, we use tf (equation ( 4)) as the word weight.",
                "cite_spans": [
                    {
                        "start": 176,
                        "end": 207,
                        "text": "(du-Verle and Prendinger, 2009;",
                        "ref_id": null
                    },
                    {
                        "start": 208,
                        "end": 230,
                        "text": "Hernault et al., 2010)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings",
                "sec_num": "4.1"
            },
            {
                "text": "We evaluated the summarization systems with ROUGE version 1.5.54 . Performance metrics were the recall (R) and F-score (F) of ROUGE-1,2.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings",
                "sec_num": "4.1"
            },
            {
                "text": "Table 1 shows the evaluation results. In the table, TKP(G) and TKP(H) denote methods with the DEP-DT obtained from the gold RST-DT and from HILDA, respectively. Marcu(G) and Marcu(H) denote Marcu's method described in (Marcu, 1998) with gold RST-DT and with HILDA, respectively. We performed a multiple comparison test for the differences among ROUGE scores, we calculated the pvalues between systems with the Wilcoxon signedrank test (Wilcoxon, 1945) and used the False Discovery Rate (FDR) (Benjamini and Hochberg, 1995) to calculate adjusted p-values, in order to limit false positive rate to 5%.",
                "cite_spans": [
                    {
                        "start": 218,
                        "end": 231,
                        "text": "(Marcu, 1998)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 435,
                        "end": 451,
                        "text": "(Wilcoxon, 1945)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 492,
                        "end": 522,
                        "text": "(Benjamini and Hochberg, 1995)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results and Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "From the table, TKP(G) and Marcu(G) achieved better results than MCP, KP and LEAD, although some of the comparisons are not significant. In particular, TKP(G) achieved the highest ROUGE scores on all measures. On ROUGE-1 Recall, TKP(G) significantly outperformed Marcu(G), Marcu(H), KP and LEAD. These results support the effectiveness of our method that utilizes the discourse structure.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results and Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "Comparing TKP(H) with Marcu(H), the former achieved higher scores with statistical significance on ROUGE-1. In addition, Marcu(H) was outperformed by MCP, KP and LEAD. The results confirm the effectiveness of our summarization model and trimming proposal for DEP-DT. Moreover, the difference between TKP(G) and TKP(H) was smaller than that between Marcu(G) and Marcu(H) . This implies that our method is more robust against discourse parser error than Marcu's method.",
                "cite_spans": [
                    {
                        "start": 361,
                        "end": 369,
                        "text": "Marcu(H)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results and Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "Figure 4 shows the example summaries generated by TKP(G), Marcu(G), MCP and LEAD, respectively for an article, wsj 1128. Since TKP(G) and Marcu(G) utilize a discourse tree, the summary generated by TKP(G) is similar to that generated by Marcu(G) but it is different from those generated by MCP and LEAD.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "4",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Results and Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "This paper proposed rules for transforming an RST-DT to a DEP-DT to obtain the parent-child relationships between EDUs. We treated a single document summarization method as a Tree Knapsack Problem, i.e. the summarizer selects the best rooted subtree from a DEP-DT. To demonstrate the effectiveness of our method, we conducted an experimental evaluation using 30 documents selected from the RST Discourse Treebank Corpus. The results showed that our method achieved the highest ROUGE-1,2 scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "5"
            },
            {
                "text": "A similar approach has been applied to sentence compression(Filippova and Strube, 2008).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Options used: -n 2 -s -m -x",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "1 EDUs roughly correspond to clauses.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "acknowledgement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "has been over-planted and prices have dropped to new lows, the apple industry seems ready for change. Along with growers, supermarkets are also trying different varieties of apples. Although the Fuji is smaller and not as perfectly shaped as the Red Delicious, it is much sweeter, less mealy and has a longer shelf life",
                "authors": [],
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "has been over-planted and prices have dropped to new lows, the apple industry seems ready for change. Along with growers, supermarkets are also trying different varieties of apples. Although the Fuji is smaller and not as perfectly shaped as the Red Delicious, it is much sweeter, less mealy and has a longer shelf life.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "A Japanese apple called the Fuji. Some fruit visionaries say the Fuji could someday tumble the Red Delicious from the top of America's apple heap. It has a long shelf life. Now, even more radical changes seem afoot. The Delicious hegemony won't end anytime soon. New apple trees grow slowly",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Tkp(g)",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "TKP(G): We'll still have mom and apple pie. A Japanese apple called the Fuji. Some fruit visionaries say the Fuji could someday tumble the Red Delicious from the top of America's apple heap. It has a long shelf life. Now, even more radical changes seem afoot. The Delicious hegemony won't end anytime soon. New apple trees grow slowly. But the apple industry is ripe for change. There's a Fuji apple cult.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "More than twice as many Red Delicious apples are grown as the Golden variety, America's No. 2 apple. But the apple industry is ripe for change. MCP: Called the Fuji. It has a long shelf life. New apple trees grow slowly. Its roots are patriotic. I'm going to have to get another job this year. Scowls. They still buy apples mainly for big, red good looks. Japanese researchers have bred dozens of strains of Fujis. Mr. Auvil, the Washington grower, says. Stores sell in summer. The \" big boss \" at a supermarket chain even rejected his Red Delicious recently. Many growers employ. LEAD: Soichiro Honda's picture now hangs with Henry Ford's in the U.S. Automotive Hall of Fame, and the game-show \" Jeopardy \" is soon to be Sony-owned. But no matter how much Japan gets under our skin, we'll still have mom and apple pie",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "We'll still have mom and apple pie",
                "volume": "57",
                "issue": "",
                "pages": "1--10",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marcu(G): We'll still have mom and apple pie. On second thought, make that just mom. The Fuji could someday tumble the Red Delicious from the top of America's apple heap. Now, even more radical changes seem afoot. The Delicious hegemony won't end anytime soon. More than twice as many Red Delicious apples are grown as the Golden variety, America's No. 2 apple. But the apple industry is ripe for change. MCP: Called the Fuji. It has a long shelf life. New apple trees grow slowly. Its roots are patriotic. I'm going to have to get another job this year. Scowls. They still buy apples mainly for big, red good looks. Japanese researchers have bred dozens of strains of Fujis. Mr. Auvil, the Washington grower, says. Stores sell in summer. The \" big boss \" at a supermarket chain even rejected his Red Delicious recently. Many growers employ. LEAD: Soichiro Honda's picture now hangs with Henry Ford's in the U.S. Automotive Hall of Fame, and the game-show \" Jeopardy \" is soon to be Sony-owned. But no matter how much Japan gets under our skin, we'll still have mom and apple pie. On second thought, make that just mom. A Japanese apple called the Fuji is cropping up in orchards the way Hondas did on U.S. roads. References Yoav Benjamini and Yosef Hochberg. 1995. Control- ling the false discovery rate: A practical and powerful approach to multiple testing. Journal of the Royal Sta- tistical Society, Series B (Methodological), 57(1):289- 300. Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski. 2001. Building a discourse-tagged corpus in the framework of rhetorical structure theory. In Proc. of the SIGDIAL01, pages 1-10.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "A depth-first dynamic programming algorithm for the tree knapsack problem",
                "authors": [
                    {
                        "first": "Geon",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Dong",
                        "middle": [
                            "X"
                        ],
                        "last": "Shaw",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "INFORMS Journal on Computing",
                "volume": "9",
                "issue": "4",
                "pages": "431--438",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Geon Cho and Dong X Shaw. 1997. A depth-first dynamic programming algorithm for the tree knap- sack problem. INFORMS Journal on Computing, 9(4):431-438.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "A noisy-channel model for document compression",
                "authors": [
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proc. of the 40th ACL",
                "volume": "",
                "issue": "",
                "pages": "449--456",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hal Daum\u00e9 III and Daniel Marcu. 2002. A noisy-channel model for document compression. In Proc. of the 40th ACL, pages 449-456.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "A novel discourse parser based on support vector machine classification",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Duverle",
                        "suffix": ""
                    },
                    {
                        "first": "Helmut",
                        "middle": [],
                        "last": "Prendinger",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proc. of the Joint Conference of the 47th ACL and 4th IJCNLP",
                "volume": "",
                "issue": "",
                "pages": "665--673",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David duVerle and Helmut Prendinger. 2009. A novel discourse parser based on support vector machine clas- sification. In Proc. of the Joint Conference of the 47th ACL and 4th IJCNLP, pages 665-673.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "A formal model for information selection in multisentence extraction",
                "authors": [
                    {
                        "first": "Elena",
                        "middle": [],
                        "last": "Filatova",
                        "suffix": ""
                    },
                    {
                        "first": "Vasileios",
                        "middle": [],
                        "last": "Hatzivassiloglou",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proc. of the 20th COLING",
                "volume": "",
                "issue": "",
                "pages": "397--403",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Elena Filatova and Vasileios Hatzivassiloglou. 2004. A formal model for information selection in multi- sentence extraction. In Proc. of the 20th COLING, pages 397-403.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Dependency tree based sentence compression",
                "authors": [
                    {
                        "first": "Katja",
                        "middle": [],
                        "last": "Filippova",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Strube",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proc. of the 5th International Natural Language Generation Conference (INLG)",
                "volume": "",
                "issue": "",
                "pages": "25--32",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Katja Filippova and Michael Strube. 2008. Dependency tree based sentence compression. In Proc. of the 5th International Natural Language Generation Confer- ence (INLG), pages 25-32.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "HILDA: A discourse parser using support vector machine classification",
                "authors": [
                    {
                        "first": "Hugo",
                        "middle": [],
                        "last": "Hernault",
                        "suffix": ""
                    },
                    {
                        "first": "Helmut",
                        "middle": [],
                        "last": "Prendinger",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [
                            "A"
                        ],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Mitsuru",
                        "middle": [],
                        "last": "Ishizuka",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Dialogue and Discourse",
                "volume": "1",
                "issue": "3",
                "pages": "1--33",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hugo Hernault, Helmut Prendinger, David A duVerle, and Mitsuru Ishizuka. 2010. HILDA: A discourse parser using support vector machine classification. Di- alogue and Discourse, 1(3):1-33.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "ROUGE: A Package for Automatic Evaluation of Summaries",
                "authors": [
                    {
                        "first": "Chin-Yew",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proc. of Workshop on Text Summarization Branches Out",
                "volume": "",
                "issue": "",
                "pages": "74--81",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chin-Yew Lin. 2004. ROUGE: A Package for Automatic Evaluation of Summaries. In Proc. of Workshop on Text Summarization Branches Out, pages 74-81.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Efficient algorithm for the partitioning of trees",
                "authors": [
                    {
                        "first": "J",
                        "middle": [
                            "A"
                        ],
                        "last": "Lukes",
                        "suffix": ""
                    }
                ],
                "year": 1974,
                "venue": "IBM Journal of Research and Development",
                "volume": "18",
                "issue": "3",
                "pages": "217--224",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. A. Lukes. 1974. Efficient algorithm for the partition- ing of trees. IBM Journal of Research and Develop- ment, 18(3):217-224.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Improving summarization through rhetorical parsing tuning",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Proc. of the 6th Workshop on Very Large Corpora",
                "volume": "",
                "issue": "",
                "pages": "206--215",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daniel Marcu. 1998. Improving summarization through rhetorical parsing tuning. In Proc. of the 6th Workshop on Very Large Corpora, pages 206-215.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "A study of global inference algorithms in multi-document summarization",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proc. of the 29th ECIR",
                "volume": "",
                "issue": "",
                "pages": "557--564",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan McDonald. 2007. A study of global inference al- gorithms in multi-document summarization. In Proc. of the 29th ECIR, pages 557-564.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Automatic summarization",
                "authors": [
                    {
                        "first": "Ani",
                        "middle": [],
                        "last": "Nenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Kathaleen",
                        "middle": [],
                        "last": "Mckeown",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Foundations and Trends in Information Retrieval",
                "volume": "5",
                "issue": "2-3",
                "pages": "103--233",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ani Nenkova and Kathaleen McKeown. 2011. Auto- matic summarization. Foundations and Trends in In- formation Retrieval, 5(2-3):103-233.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Heuristic and exact algorithms for the precedenceconstrained knapsack problem",
                "authors": [
                    {
                        "first": "Natthawut",
                        "middle": [],
                        "last": "Samphaiboon",
                        "suffix": ""
                    },
                    {
                        "first": "Takeo",
                        "middle": [],
                        "last": "Yamada",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Journal of Optimization Theory and Applications",
                "volume": "105",
                "issue": "3",
                "pages": "659--676",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Natthawut Samphaiboon and Takeo Yamada. 2000. Heuristic and exact algorithms for the precedence- constrained knapsack problem. Journal of Optimiza- tion Theory and Applications, 105(3):659-676.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Text summarization model based on maximum coverage problem and its variant",
                "authors": [
                    {
                        "first": "Hiroya",
                        "middle": [],
                        "last": "Takamura",
                        "suffix": ""
                    },
                    {
                        "first": "Manabu",
                        "middle": [],
                        "last": "Okumura",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proc. of the 12th EACL",
                "volume": "",
                "issue": "",
                "pages": "781--789",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hiroya Takamura and Manabu Okumura. 2009a. Text summarization model based on maximum coverage problem and its variant. In Proc. of the 12th EACL, pages 781-789.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Text summarization model based on the budgeted median problem",
                "authors": [
                    {
                        "first": "Hiroya",
                        "middle": [],
                        "last": "Takamura",
                        "suffix": ""
                    },
                    {
                        "first": "Manabu",
                        "middle": [],
                        "last": "Okumura",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the 18th CIKM",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hiroya Takamura and Manabu Okumura. 2009b. Text summarization model based on the budgeted median problem. In Proceedings of the 18th CIKM.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Individual comparisons by ranking methods",
                "authors": [
                    {
                        "first": "Frank",
                        "middle": [],
                        "last": "Wilcoxon",
                        "suffix": ""
                    }
                ],
                "year": 1945,
                "venue": "Biometrics Bulletin",
                "volume": "1",
                "issue": "6",
                "pages": "80--83",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Frank Wilcoxon. 1945. Individual comparisons by rank- ing methods. Biometrics Bulletin, 1(6):80-83.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Rhetorical Structure Theory: Toward a functional theory of text organization",
                "authors": [
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Charles",
                        "suffix": ""
                    },
                    {
                        "first": "Mann",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Sandra",
                        "middle": [],
                        "last": "Annear",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Thompson",
                        "suffix": ""
                    }
                ],
                "year": 1988,
                "venue": "Text",
                "volume": "8",
                "issue": "3",
                "pages": "243--281",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "William Charles, Mann and Sandra Annear, Thompson. 1988. Rhetorical Structure Theory: Toward a func- tional theory of text organization. Text, 8(3):243-281.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 2: Heads of non-terminal nodes.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 3: The DEP-DT obtained from the RST-DT in Figure 1.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 4: Summaries obtained from wsj 1128.",
                "uris": null,
                "fig_num": "4",
                "type_str": "figure"
            }
        }
    }
}