{
    "paper_id": "N09-1041",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:19:00.604325Z"
    },
    "title": "Exploring Content Models for Multi-Document Summarization",
    "authors": [
        {
            "first": "Aria",
            "middle": [],
            "last": "Haghighi",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "UC Berkeley",
                "location": {
                    "country": "CS Division"
                }
            },
            "email": "aria42@cs.berkeley.edu"
        },
        {
            "first": "Lucy",
            "middle": [],
            "last": "Vanderwende",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Microsoft Research",
                "location": {}
            },
            "email": "lucy.vanderwende@microsoft.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HIERSUM, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HIERSUM yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. ( 2007)'s state-of-the-art discriminative system. We also explore HIERSUM's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.",
    "pdf_parse": {
        "paper_id": "N09-1041",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HIERSUM, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HIERSUM yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. ( 2007)'s state-of-the-art discriminative system. We also explore HIERSUM's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Over the past several years, there has been much interest in the task of multi-document summarization. In the common Document Understanding Conference (DUC) formulation of the task, a system takes as input a document set as well as a short description of desired summary focus and outputs a word length limited summary. 1 To avoid the problem of generating cogent sentences, many systems opt for an extractive approach, selecting sentences from the document set which best reflect its core content. 2 There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007). Another strand of work (Barzilay and Lee, 2004; Daum\u00e9 III and Marcu, 2006; Eisenstein and Barzilay, 2008), has explored the use of structured probabilistic topic models to represent document content. However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.",
                "cite_spans": [
                    {
                        "start": 320,
                        "end": 321,
                        "text": "1",
                        "ref_id": null
                    },
                    {
                        "start": 499,
                        "end": 500,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this work we examine a series of content models for multi-document summarization and argue that LDA-style probabilistic topic models (Blei et al., 2003) can offer state-of-the-art summarization quality as measured by automatic metrics (see section 5.1) and manual user evaluation (see section 5.2). We also contend that they provide convenient building blocks for adding more structure to a summarization model. In particular, we utilize a variation of the hierarchical LDA topic model (Blei et al., 2004) to discover multiple specific 'subtopics' within a document set. The resulting model, HIERSUM (see section 3.4), can produce general summaries as well as summaries for any of the learned sub-topics.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The task we will consider is extractive multidocument summarization. In this task we assume a document collection D consisting of documents D 1 , . . . , D n describing the same (or closely related) narrative (Lapata, 2003). set of events. Our task will be to propose a summary S consisting of sentences in D totaling at most L words. 3 Here as in much extractive summarization, we will view each sentence as a bag-of-words or more generally a bag-of-ngrams (see section 5.1). The most prevalent example of this data setting is document clusters found on news aggregator sites.",
                "cite_spans": [
                    {
                        "start": 335,
                        "end": 336,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "2"
            },
            {
                "text": "For model development we will utilize the DUC 2006 evaluation set4 consisting of 50 document sets each with 25 documents; final evaluation will utilize the DUC 2007 evaluation set (section 5).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Automated Evaluation",
                "sec_num": "2.1"
            },
            {
                "text": "Automated evaluation will utilize the standard DUC evaluation metric ROUGE (Lin, 2004) which represents recall over various n-grams statistics from a system-generated summary against a set of humangenerated peer summaries. 5 We compute ROUGE scores with and without stop words removed from peer and proposed summaries. In particular, we utilize R-1 (recall against unigrams), R-2 (recall against bigrams), and R-SU4 (recall against skip-4 bigrams) 6 . We present R-2 without stop words in the running text, but full development results are presented in table 1. Official DUC scoring utilizes the jackknife procedure and assesses significance using bootstrapping resampling (Lin, 2004). In addition to presenting automated results, we also present a user evaluation in section 5.2.",
                "cite_spans": [
                    {
                        "start": 223,
                        "end": 224,
                        "text": "5",
                        "ref_id": null
                    },
                    {
                        "start": 448,
                        "end": 449,
                        "text": "6",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Automated Evaluation",
                "sec_num": "2.1"
            },
            {
                "text": "We present a progression of models for multidocument summarization. Inference details are given in section 4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Summarization Models",
                "sec_num": "3"
            },
            {
                "text": "The SUMBASIC algorithm, introduced in Nenkova and Vanderwende (2005), is a simple effective procedure for multi-document extractive summarization. Its design is motivated by the observation that the relative frequency of a non-stop word in a document set is a good predictor of a word appearing in a human summary. In SUMBASIC, each sentence S is assigned a score reflecting how many highfrequency words it contains,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SumBasic",
                "sec_num": "3.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "Score(S) = w\u2208S 1 |S| P D (w)",
                        "eq_num": "(1)"
                    }
                ],
                "section": "SumBasic",
                "sec_num": "3.1"
            },
            {
                "text": "where P D (\u2022) initially reflects the observed unigram probabilities obtained from the document collection D. A summary S is progressively built by adding the highest scoring sentence according to (1). 7 In order to discourage redundancy, the words in the selected sentence are updated P new D (w) \u221d P old D (w) 2 . Sentences are selected in this manner until the summary word limit has been reached.",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 202,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SumBasic",
                "sec_num": "3.1"
            },
            {
                "text": "Despite its simplicity, SUMBASIC yields 5.3 R-2 without stop words on DUC 2006 (see table 1 ).8 By comparison, the highest-performing ROUGE system at the DUC 2006 evaluation, SUMFOCUS, was built on top of SUMBASIC and yielded a 6.0, which is not a statistically significant improvement ( Vanderwende et al., 2007). 9 Intuitively, SUMBASIC is trying to select a summary which has sentences where most words have high likelihood under the document set unigram distribution. One conceptual problem with this objective is that it inherently favors repetition of frequent non-stop words despite the 'squaring' update. Ideally, a summarization criterion should be more recall oriented, penalizing summaries which omit moderately frequent document set words and quickly diminishing the reward for repeated use of word.",
                "cite_spans": [
                    {
                        "start": 315,
                        "end": 316,
                        "text": "9",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 90,
                        "end": 91,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "SumBasic",
                "sec_num": "3.1"
            },
            {
                "text": "Another more subtle shortcoming is the use of the raw empirical unigram distribution to represent content significance. For instance, there is no distinction between a word which occurs many times in the same document or the same number of times across several documents. Intuitively, the latter word is more indicative of significant document set content.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "SumBasic",
                "sec_num": "3.1"
            },
            {
                "text": "The KLSUM algorithm introduces a criterion for selecting a summary S given document collection D, where P S is the empirical unigram distribution of the candidate summary S and KL(P Q) represents the Kullback-Lieber (KL) divergence given by w P (w) log P (w) Q(w) .10 This quantity represents the divergence between the true distribution P (here the document set unigram distribution) and the approximating distribution Q (the summary distribution). This criterion casts summarization as finding a set of summary sentences which closely match the document set unigram distribution. Lin et al. (2006) propose a related criterion for robust summarization evaluation, but to our knowledge this criteria has been unexplored in summarization systems. We address optimizing equation (2) as well as summary sentence ordering in section 4. KLSUM yields 6.0 R-2 without stop words, beating SUMBASIC but not with statistical significance. It is worth noting however that KLSUM's performance matches SUMFOCUS (Vanderwende et al., 2007), the highest R-2 performing system at DUC 2006.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "KLSum",
                "sec_num": "3.2"
            },
            {
                "text": "As mentioned in section 3.2, the raw unigram distribution P D (\u2022) may not best reflect the content of D for the purpose of summary extraction. We propose TOPICSUM, which uses a simple LDA-like topic model (Blei et al., 2003) similar to Daum\u00e9 III and Marcu (2006) to estimate a content distribu- tion for summary extraction. 11 We extract summary sentences as before using the KLSUM criterion (see equation ( 2)), plugging in a learned content distribution in place of the raw unigram distribution. First, we describe our topic model (see figure 1 ) which generates a collection of document sets. We assume a fixed vocabulary V : 12 1. Draw a background vocabulary distribution \u03c6 B from DIRICHLET(V ,\u03bb B ) shared across document collections 13 representing the background distribution over vocabulary words. This distribution is meant to flexibly model stop words which do not contribute content. We will refer to this topic as BACKGROUND.",
                "cite_spans": [
                    {
                        "start": 324,
                        "end": 326,
                        "text": "11",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 545,
                        "end": 546,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "System ROUGE -stop ROUGE all R-1 R-2 R-SU4 R-1 R-2 R-",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "{ star: 0.21, wars: 0.15, phantom: 0.10, ... } 4. For each sentence S of each document D, draw a distribution \u03c8 T over topics (CONTENT, DOCSPECIFIC, BACKGROUND) from a Dirichlet prior with pseudo-counts (1.0, 5.0, 10.0). 14 For each word position in the sentence, we draw a topic Z from \u03c8 T , and a word W from the topic distribution Z indicates.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "\u03c6 C2 \u03c6 C3 Document Set \u03c6 C 0 \u03c6 C K \u03c6 C 1 Z S \u03c6 D Document Sentence Word Z W \u03c8 T \u03c8 G ......... \u03c6 B (a) Content Distributions (b) HIERSUM Graphical Model",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "Our intent is that \u03c6 C represents the core content of a document set. Intuitively, \u03c6 C does not include words which are common amongst several document collections (modeled with the BACKGROUND topic), or words which don't appear across many documents (modeled with the DOCSPE-CIFIC topic). Also, because topics are tied together at the sentence level, words which frequently occur with other content words are more likely to be considered content words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "We ran our topic model over the DUC 2006 document collections and estimated the distribution \u03c6 C (\u2022) for each document set. 15 Then we extracted 14 The different pseudo-counts reflect the intuition that most of the words in a document come from the BACKGROUND and DOCSPECIFIC topics. 15 While possible to obtain the predictive posterior CON-a summary using the KLSUM criterion with our estimated \u03c6 C in place of the the raw unigram distribution. Doing so yielded 6.3 R-2 without stop words (see TOPICSUM in table 1); while not a statistically significant improvement over KLSUM, it is our first model which outperforms SUMBASIC with statistical significance.",
                "cite_spans": [
                    {
                        "start": 124,
                        "end": 126,
                        "text": "15",
                        "ref_id": null
                    },
                    {
                        "start": 145,
                        "end": 147,
                        "text": "14",
                        "ref_id": null
                    },
                    {
                        "start": 284,
                        "end": 286,
                        "text": "15",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "Daum\u00e9 III and Marcu (2006) explore a topic model similar to ours for query-focused multidocument summarization. 16 Crucially however, Daum\u00e9 III and Marcu (2006) selected sentences with the highest expected number of CONTENT words. 17 We found that in our model using this extraction criterion yielded 5.3 R-2 without stop words, significantly underperforming our TOPICSUM model. One reason for this may be that Daum\u00e9 III and Marcu (2006)'s criterion encourages selecting sentences which have words that are confidently generated by the CONTENT distribution, but not necessarily sentences which contain a plurality of it's mass.",
                "cite_spans": [
                    {
                        "start": 112,
                        "end": 114,
                        "text": "16",
                        "ref_id": null
                    },
                    {
                        "start": 231,
                        "end": 233,
                        "text": "17",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "TENT distribution by analytically integrating over \u03c6C (Blei et al., 2003), doing so gave no benefit. 16 Daum\u00e9 III and Marcu (2006) note their model could be used outside of query-focused summarization. 17 This is phrased as selecting the sentence which has the highest posterior probability of emitting CONTENT topic words, but this is equivalent.",
                "cite_spans": [
                    {
                        "start": 101,
                        "end": 103,
                        "text": "16",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "(a) HIERSUM output Table 2 : Example summarization output for systems compared in section 5.2. (a), (b), and (c) represent the first two sentences output from PYTHY, HIERSUM, and reference summary respectively. In (d), we present the most frequent non-stop unigrams appearing in the reference summary and their counts in the PYTHY and HIERSUM summaries. Note that many content words in the reference summary absent from PYTHY's proposal are present in HIERSUM's.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 25,
                        "end": 26,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "TopicSum",
                "sec_num": "3.3"
            },
            {
                "text": "Previous sections have treated the content of a document set as a single (perhaps learned) unigram distribution. However, as Barzilay and Lee (2004) observe, the content of document collections is highly structured, consisting of several topical themes, each with its own vocabulary and ordering preferences.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "For concreteness consider the DUC 2006 document collection describing the opening of Star Wars: Episode 1 (see figure 2(a) ). While there are words which indicate the general content of this document collection (e.g. star, wars), there are several sub-stories with their own specific vocabulary. For instance, several documents in this collection spend a paragraph or two talking about the financial aspect of the film's opening and use a specific vocabulary there (e.g. $, million, record). A user may be interested in general content of a document collection or, depending on his or her interests, one or more of the sub-stories. We choose to adapt our topic modeling approach to allow modeling this aspect of document set content.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 118,
                        "end": 122,
                        "text": "2(a)",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "Rather than drawing a single CONTENT distribution \u03c6 C for a document collection, we now draw a general content distribution \u03c6 C 0 from DIRICH-LET(V ,\u03bb G ) as well as specific content distributions \u03c6 C i for i = 1, . . . , K each from DIRICH-LET(V ,\u03bb S ). 18 Our intent is that \u03c6 C 0 represents the 18 We choose K=3 in our experiments, but one could flexibly general content of the document collection and each \u03c6 C i represents specific sub-stories.",
                "cite_spans": [
                    {
                        "start": 255,
                        "end": 257,
                        "text": "18",
                        "ref_id": null
                    },
                    {
                        "start": 298,
                        "end": 300,
                        "text": "18",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "As with When BACKGROUND or DOCSPECIFIC topics are chosen, the model works exactly as in TOPICSUM. However when the CONTENT topic is drawn, we must decide whether to emit a general content word (from \u03c6 C 0 ) or from one of the specific content distributions (from one of \u03c6 C i for i = 1, . . . , K). The generative story of TOPICSUM is altered as follows in this case:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "\u2022 General or Specific? We must first decide whether to use a general or specific content word. Each sentence draws a binomial distribution \u03c8 G determining whether a CONTENT word in the sentence will be drawn from the general or a specific topic distribution. Reflecting the intuition that the earlier sentences in a document 19 describe the general content of a story, we bias \u03c8 G to be drawn from BETA(5,2), preferring general content words, and every later sentence from BETA(1,2).20 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "\u2022 What Specific Topic? If \u03c8 G decides we are choose K as Blei et al. (2004) does. 19 In our experiments, the first 5 sentences.",
                "cite_spans": [
                    {
                        "start": 82,
                        "end": 84,
                        "text": "19",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "emitting a topic specific content word, we must decide which of \u03c6 C 1 , . . . , \u03c6 C K to use. In order to ensure tight lexical cohesion amongst the specific topics, we assume that each sentence draws a single specific topic Z S used for every specific content word in that sentence. Reflecting intuition that adjacent sentences are likely to share specific content vocabulary, we utilize a 'sticky' HMM as in Barzilay and Lee (2004) over the each sentences' Z S . Concretely, Z S for the first sentence in a document is drawn uniformly from 1, . . . , K, and each subsequent sentence's Z S will be identical to the previous sentence with probability \u03c3, and with probability 1\u03c3 we select a successor topic from a learned transition distribution amongst 1, . . . , K. 21 Our intent is that the general content distribution \u03c6 C 0 now prefers words which not only appear in many documents, but also words which appear consistently throughout a document rather than being concentrated in a small number of sentences. Each specific content distribution \u03c6 C i is meant to model topics which are used in several documents but tend to be used in concentrated locations.",
                "cite_spans": [
                    {
                        "start": 766,
                        "end": 768,
                        "text": "21",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "HIERSUM can be used to extract several kinds of summaries. It can extract a general summary by plugging \u03c6 C 0 into the KLSUM criterion. It can also produce topical summaries for the learned specific topics by extracting a summary over each \u03c6 C i distribution; this might be appropriate for a user who wants to know more about a particular substory. While we found the general content distribution (from \u03c6 C 0 ) to produce the best single summary, we experimented with utilizing topical summaries for other summarization tasks (see section 6.1). The resulting system, HIERSUM yielded 6.4 R-2 without stop words. While not a statistically significant improvement in ROUGE over TOPICSUM, we found the summaries to be noticeably improved.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HIERSUM",
                "sec_num": "3.4"
            },
            {
                "text": "Since globally optimizing the KLSUM criterion in equation (equation ( 2)) is exponential in the total number of sentences in a document collection, we 21 We choose \u03c3 = 0.75 in our experiments.",
                "cite_spans": [
                    {
                        "start": 151,
                        "end": 153,
                        "text": "21",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference and Model Details",
                "sec_num": "4"
            },
            {
                "text": "opted instead for a simple approximation where sentences are greedily added to a summary so long as they decrease KL-divergence. We attempted more complex inference procedures such as McDonald (2007), but these attempts only yielded negligible performance gains. All summary sentence ordering was determined as follows: each sentence in the proposed summary was assigned a number in [0, 1] reflecting its relative sentence position in its source document, and sorted by this quantity.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference and Model Details",
                "sec_num": "4"
            },
            {
                "text": "All topic models utilize Gibbs sampling for inference (Griffiths, 2002; Blei et al., 2004). In general for concentration parameters, the more specific a distribution is meant to be, the smaller its concentration parameter. Accordingly for TOPICSUM, \u03bb G = \u03bb D = 1 and \u03bb C = 0.1. For HIERSUM we used \u03bb G = 0.1 and \u03bb S = 0.01. These parameters were minimally tuned (without reference to ROUGE results) in order to ensure that all topic distribution behaved as intended.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inference and Model Details",
                "sec_num": "4"
            },
            {
                "text": "We present formal experiments on the DUC 2007 data main summarization task, proposing a general summary of at most 250 words22 which will be evaluated automatically and manually in order to simulate as much as possible the DUC evaluation environment. 23 DUC 2007 consists of 45 document sets, each consisting of 25 documents and 4 human reference summaries.",
                "cite_spans": [
                    {
                        "start": 251,
                        "end": 253,
                        "text": "23",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formal Experiments",
                "sec_num": "5"
            },
            {
                "text": "We primarily evaluate the HIERSUM model, extracting a single summary from the general content distribution using the KLSUM criterion (see section 3.2). Although the differences in ROUGE between HIERSUM and TOPICSUM were minimal, we found HIERSUM summary quality to be stronger.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formal Experiments",
                "sec_num": "5"
            },
            {
                "text": "In order to provide a reference for ROUGE and manual evaluation results, we compare against PYTHY, a state-of-the-art supervised sentence extraction summarization system. PYTHY uses humangenerated summaries in order to train a sentence ranking system which discriminatively maximizes As PYTHY utilizes a sentence simplification component, which we do not, we also compare against PYTHY without sentence simplification.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formal Experiments",
                "sec_num": "5"
            },
            {
                "text": "System ROUGE w/o stop ROUGE w/ stop R-1 R-2 R-SU4 R-1 R-2 R",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Formal Experiments",
                "sec_num": "5"
            },
            {
                "text": "ROUGE results comparing variants of HIERSUM and PYTHY are given in table 3. The HIERSUM system as described in section 3.4 yields 7.3 R-2 without stop words, falling significantly short of the 8.7 that PYTHY without simplification yields. Note that R-2 is a measure of bigram recall and HIERSUM does not represent bigrams whereas PYTHY includes several bigram and higher order n-gram statistics.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ROUGE Evaluation",
                "sec_num": "5.1"
            },
            {
                "text": "In order to put HIERSUM and PYTHY on equalfooting with respect to R-2, we instead ran HIER-SUM with each sentence consisting of a bag of bigrams instead of unigrams. 24 All the details of the model remain the same. Once a general content distribution over bigrams has been determined by hierarchical topic modeling, the KLSUM criterion is used as before to extract a summary. This system, labeled HIERSUM bigram in table 3 ",
                "cite_spans": [
                    {
                        "start": 166,
                        "end": 168,
                        "text": "24",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 421,
                        "end": 422,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "ROUGE Evaluation",
                "sec_num": "5.1"
            },
            {
                "text": "In order to obtain a more accurate measure of summary quality, we performed a simple user study. For each document set in the DUC 2007 collection, a user was given a reference summary, a PYTHY summary, and a HIERSUM summary;25 note that the original documents in the set were not provided to the user, only a reference summary. For this experiment we use the bigram variant of HIERSUM and compare it to PYTHY without simplification so both systems have the same set of possible output summaries. The reference summary for each document set was selected according to highest R-2 without stop words against the remaining peer summaries. Users were presented with 4 questions drawn from the DUC manual evaluation guidelines: 26 (1) Overall quality: Which summary was better overall? (2) Non-Redundancy: Which summary was less redundant? (3) Coherence: Which summary was more coherent? (4) Focus: Which summary was more Figure 3 : Using HIERSUM to organize content of document set into topics (see section 6.1). The sidebar gives key phrases salient in each of the specific content topics in HIERSUM (see section 3.4). When a topic is clicked in the right sidebar, the main frame displays an extractive 'topical summary' with links into document set articles. Ideally, a user could use this interface to quickly find content in a document collection that matches their interest.",
                "cite_spans": [
                    {
                        "start": 722,
                        "end": 724,
                        "text": "26",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 923,
                        "end": 924,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Manual Evaluation",
                "sec_num": "5.2"
            },
            {
                "text": "focused in its content, not conveying irrelevant details? The study had 16 users and each was asked to compare five summary pairs, although some did fewer. A total of 69 preferences were solicited. Document collections presented to users were randomly selected from those evaluated fewest.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Manual Evaluation",
                "sec_num": "5.2"
            },
            {
                "text": "As seen in table 5.2, HIERSUM outperforms PYTHY under all questions. All results are statistically significant as judged by a simple pairwise t-test with 95% confidence. It is safe to conclude that users in this study strongly preferred the HIER-SUM summaries over the PYTHY summaries.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Manual Evaluation",
                "sec_num": "5.2"
            },
            {
                "text": "While it is difficult to qualitatively compare one summarization system over another, we can broadly characterize HIERSUM summaries compared to some of the other systems discussed. For example output from HIERSUM and PYTHY see table 2. On the whole, HIERSUM summaries appear to be significantly less redundant than PYTHY and moderately less redundant than SUMBASIC. The reason for this might be that PYTHY is discriminatively trained to maximize ROUGE which does not directly penalize redundancy. Another tendency is for HIERSUM to select longer sentences typically chosen from an early sentence in a document. As discussed in section 3.4, HIERSUM is biased to consider early sentences in documents have a higher proportion of general content words and so this tendency is to be expected.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "6"
            },
            {
                "text": "A common concern in multi-document summarization is that without any indication of user interest or intent providing a single satisfactory summary to a user may not be feasible. While many variants of the general summarization task have been proposed which utilize such information (Vanderwende et al., 2007; Nastase, 2008), this presupposes that a user knows enough of the content of a document collection in order to propose a query.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Content Navigation",
                "sec_num": "6.1"
            },
            {
                "text": "As Leuski et al. (2003) and Branavan et al. (2007) suggest, a document summarization system should facilitate content discovery and yield summaries relevant to a user's interests. We may use HIERSUM in order to facilitate content discovery via presenting a user with salient words or phrases from the specific content topics parametrized by \u03c6 C 1 , . . . , \u03c6 C K (for an example see figure 3 ). While these topics are not adaptive to user interest, they typically reflect lexically coherent vocabularies.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 390,
                        "end": 391,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Content Navigation",
                "sec_num": "6.1"
            },
            {
                "text": "In this paper we have presented an exploration of content models for multi-document summarization and demonstrated that the use of structured topic models can benefit summarization quality as measured by automatic and manual metrics.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": null
            },
            {
                "text": "In this work, we ignore the summary focus. Here, the word topic will refer to elements of our statistical model rather than summary focus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that sentence extraction does not solve the problem of selecting and ordering summary sentences to form a coherent",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "For DUC summarization tasks, L is typically 250.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www-nlpir.nist.gov/projects/duc/data.html",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "All words from peer and proposed summaries are lowercased and stemmed.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "6 Bigrams formed by skipping at most two words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that sentence order is determined by the order in which sentences are selected according to (1).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This result is presented as 0.053 with the official ROUGE scorer(Lin, 2004). Results here are scaled by 1,000.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "To be fair obtaining statistical significance in ROUGE scores is quite difficult.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In order to ensure finite values of KL-divergence we smoothe P S (\u2022) so that it has a small amount of mass on all document set words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "For each document set D, we draw a content distribution \u03c6 C from DIRICHLET(V ,\u03bb C ) representing the significant content of D that we wish to summarize. We will refer to this topic as CONTENT.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "3. For each document D in D, we draw a document-specific vocabulary distribution \u03c6 D from DIRICHLET(V ,\u03bb D ) representing words which are local to a single document, but do not appear across several documents. We will refer to this topic as DOCSPECIFIC.11 A topic model is a probabilistic generative process that generates a collection of documents using a mixture of topic vocabulary distributions(Steyvers and Griffiths, 2007). Note this usage of topic is unrelated to the summary focus given for document collections; this information is ignored by our models.12 In contrast to previous models, stop words are not removed in pre-processing.13 DIRICHLET(V ,\u03bb) represents the symmetric Dirichlet prior distribution over V each with a pseudo-count of \u03bb. Concrete pseudo-count values will be",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "given in section 4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "BETA(a,b) represents the beta prior over binomial random variables with a and b being pseudo-counts for the first and second outcomes respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Since the ROUGE evaluation metric is recall-oriented, it is always advantageous -with respect to ROUGE -to use all 250 words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Although the DUC 2007 main summarization task provides an indication of user intent through topic focus queries, we ignore this aspect of the data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that by doing topic modeling in this way over bigrams, our model becomes degenerate as it can generate inconsistent bags of bigrams. Future work may look at topic models over n-grams as suggested byWang et al. (2007).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The system identifier was of course not visible to the user. The order of automatic summaries was determined randomly.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www-nlpir.nist.gov/projects/duc/duc2007/qualityquestions.txt",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Acknowledgements The authors would like to thank Bob Moore, Chris Brockett, Chris Quirk, and Kristina Toutanova for their useful discussions as well as the reviewers for their helpful comments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "acknowledgement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Catching the drift: Probabilistic content models, with applications to generation and summarization",
                "authors": [
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In HLT-NAACL.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Latent dirichlet allocation",
                "authors": [
                    {
                        "first": "David",
                        "middle": [
                            "M"
                        ],
                        "last": "Blei",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "Y"
                        ],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "I"
                        ],
                        "last": "Jordan",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. JMLR.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Hierarchical topic models and the nested chinese restaurant process",
                "authors": [
                    {
                        "first": "David",
                        "middle": [
                            "M"
                        ],
                        "last": "Blei",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [
                            "L"
                        ],
                        "last": "Griffiths",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "I"
                        ],
                        "last": "Jordan",
                        "suffix": ""
                    },
                    {
                        "first": "Joshua",
                        "middle": [
                            "B"
                        ],
                        "last": "Tenenbaum",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David M. Blei, Thomas L. Griffiths, Michael I. Jordan, and Joshua B. Tenenbaum. 2004. Hierarchical topic models and the nested chinese restaurant process. In NIPS.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Bayesian queryfocused summarization",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "R K"
                        ],
                        "last": "Branavan",
                        "suffix": ""
                    },
                    {
                        "first": "Pawan",
                        "middle": [],
                        "last": "Deshpande",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S.R.K. Branavan, Pawan Deshpande, and Regina Barzi- lay. 2007. Generating a table-of-contents. In ACL. Hal Daum\u00e9 III and Daniel Marcu. 2006. Bayesian query- focused summarization. In Proceedings of the Confer- ence of the Association for Computational Linguistics (ACL).",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Bayesian unsupervised topic segmentation",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Eisenstein",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "EMNLP-SIGDAT",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Eisenstein and Regina Barzilay. 2008. Bayesian unsupervised topic segmentation. In EMNLP- SIGDAT.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Gibbs sampling in the generative model of latent dirichlet allocation",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Griffiths",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas Griffiths. 2002. Gibbs sampling in the genera- tive model of latent dirichlet allocation.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Satisfying information needs with multidocument summaries",
                "authors": [
                    {
                        "first": "Sanda",
                        "middle": [],
                        "last": "Harabagiu",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Hickl",
                        "suffix": ""
                    },
                    {
                        "first": "Finley",
                        "middle": [],
                        "last": "Lacatusu",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Inf. Process. Manage",
                "volume": "",
                "issue": "6",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sanda Harabagiu, Andrew Hickl, and Finley Laca- tusu. 2007. Satisfying information needs with multi- document summaries. Inf. Process. Manage., 43(6).",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Probabilistic text structuring: Experiments with sentence ordering",
                "authors": [
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mirella Lapata. 2003. Probabilistic text structuring: Ex- periments with sentence ordering. In ACL.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Impact of linguistic analysis on the semantic graph coverage and learning of document extracts",
                "authors": [
                    {
                        "first": "Jurij",
                        "middle": [],
                        "last": "Leskovec",
                        "suffix": ""
                    },
                    {
                        "first": "Natasa",
                        "middle": [],
                        "last": "Milic-Frayling",
                        "suffix": ""
                    },
                    {
                        "first": "Marko",
                        "middle": [],
                        "last": "Grobelnik",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jurij Leskovec, Natasa Milic-frayling, and Marko Gro- belnik. 2005. Impact of linguistic analysis on the se- mantic graph coverage and learning of document ex- tracts. In In AAAI 05.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "An information-theoretic approach to automatic evaluation of summaries",
                "authors": [
                    {
                        "first": "Anton",
                        "middle": [],
                        "last": "Leuski",
                        "suffix": ""
                    },
                    {
                        "first": "Chin-Yew",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy ; Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Guihong",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Jian-Yun",
                        "middle": [],
                        "last": "Nie",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anton Leuski, Chin-Yew Lin, and Eduard Hovy. 2003. ineats: Interactive multi-document summarization. In ACL. Chin-Yew Lin, Guihong Cao, Jianfeng Gao, and Jian-Yun Nie. 2006. An information-theoretic approach to au- tomatic evaluation of summaries. In HLT-NAACL.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Rouge: A package for automatic evaluation of summaries",
                "authors": [
                    {
                        "first": "Chin-Yew",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proc. ACL workshop on Text Summarization Branches Out",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Proc. ACL workshop on Text Summarization Branches Out.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "The automatic creation of literature abstracts",
                "authors": [
                    {
                        "first": "H",
                        "middle": [
                            "P"
                        ],
                        "last": "Luhn",
                        "suffix": ""
                    }
                ],
                "year": 1958,
                "venue": "IBM Journal",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H.P. Luhn. 1958. The automatic creation of literature abstracts. IBM Journal.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "A study of global inference algorithms in multi-document summarization",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ECIR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan McDonald. 2007. A study of global inference al- gorithms in multi-document summarization. In ECIR.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Towards multidocument summarization by reformulation: Progress and prospects",
                "authors": [
                    {
                        "first": "Kathleen",
                        "middle": [
                            "R"
                        ],
                        "last": "Mckeown",
                        "suffix": ""
                    },
                    {
                        "first": "Judith",
                        "middle": [
                            "L"
                        ],
                        "last": "Klavans",
                        "suffix": ""
                    },
                    {
                        "first": "Vasileios",
                        "middle": [],
                        "last": "Hatzivassiloglou",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Eleazar",
                        "middle": [],
                        "last": "Eskin",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Proceedings of AAAI-99",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kathleen R. Mckeown, Judith L. Klavans, Vasileios Hatzivassiloglou, Regina Barzilay, and Eleazar Eskin. 1999. Towards multidocument summarization by re- formulation: Progress and prospects. In In Proceed- ings of AAAI-99.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Topic-driven multi-document summarization with encyclopedic knowledge and spreading activation",
                "authors": [
                    {
                        "first": "Vivi",
                        "middle": [],
                        "last": "Nastase",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vivi Nastase. 2008. Topic-driven multi-document sum- marization with encyclopedic knowledge and spread- ing activation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Process- ing.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "The impact of frequency on summarization",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Nenkova",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Vanderwende",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Nenkova and L. Vanderwende. 2005. The impact of frequency on summarization. Technical report, Mi- crosoft Research.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Lexrank: graph-based centrality as salience in text summarization",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Dragomir",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Radev",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Journal of Artificial Intelligence Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dragomir R. Radev. 2004. Lexrank: graph-based cen- trality as salience in text summarization. Journal of Artificial Intelligence Research (JAIR.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "The pythy summarization system: Microsoft research at duc 2007",
                "authors": [
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Gamon",
                        "suffix": ""
                    },
                    {
                        "first": "Jagadeesh",
                        "middle": [],
                        "last": "Jagarlamudi",
                        "suffix": ""
                    },
                    {
                        "first": "Hisami",
                        "middle": [],
                        "last": "Suzuki",
                        "suffix": ""
                    },
                    {
                        "first": "Lucy",
                        "middle": [],
                        "last": "Vanderwende",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "DUC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kristina Toutanova, Chris Brockett, Michael Gamon Ja- gadeesh Jagarlamudi, Hisami Suzuki, and Lucy Van- derwende. 2007. The pythy summarization system: Microsoft research at duc 2007. In DUC.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Beyond sumbasic: Task-focused summarization with sentence simplification and lexical expansion",
                "authors": [
                    {
                        "first": "Lucy",
                        "middle": [],
                        "last": "Vanderwende",
                        "suffix": ""
                    },
                    {
                        "first": "Hisami",
                        "middle": [],
                        "last": "Suzuki",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Ani",
                        "middle": [],
                        "last": "Nenkova",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "",
                "volume": "43",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lucy Vanderwende, Hisami Suzuki, Chris Brockett, and Ani Nenkova. 2007. Beyond sumbasic: Task-focused summarization with sentence simplification and lexi- cal expansion. volume 43.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Improved affinity graph based multi-document summarization",
                "authors": [
                    {
                        "first": "Xiaojun",
                        "middle": [],
                        "last": "Wan",
                        "suffix": ""
                    },
                    {
                        "first": "Jianwu",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "HLT-NAACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiaojun Wan and Jianwu Yang. 2006. Improved affinity graph based multi-document summarization. In HLT- NAACL.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Topical n-grams: Phrase and topic discovery, with an application to information retrieval",
                "authors": [
                    {
                        "first": "Xuerui",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    },
                    {
                        "first": "Xing",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ICDM",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuerui Wang, Andrew McCallum, and Xing Wei. 2007. Topical n-grams: Phrase and topic discovery, with an application to information retrieval. In ICDM.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure1: Graphical model depiction of TOPIC-SUM model (see section 3.3). Note that many hyperparameter dependencies are omitted for compactness.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "TABREF2": {
                "content": "<table/>",
                "type_str": "table",
                "text": "Figure2: (a): Examples of general versus specific content distributions utilized by HIERSUM (see section 3.4). The general content distribution \u03c6 C0 will be used throughout a document collection and represents core concepts in a story. The specific content distributions represent topical 'sub-stories' with vocabulary tightly clustered together but consistently used across documents. Quoted names of specific topics are given manually to facilitate interpretation. (b) Graphical model depiction of the HIERSUM model (see section 3.4). Similar to the TOPICSUM model (see section 3.3) except for adding complexity in the content hierarchy as well as sentence-specific prior distributions between general and specific content topics (early sentences should have more general content words). Several dependencies are missing from this depiction; crucially, each sentence's specific topic Z S depends on the last sentence's Z S .",
                "html": null,
                "num": null
            },
            "TABREF6": {
                "content": "<table><tr><td>, yields 9.3</td></tr></table>",
                "type_str": "table",
                "text": "Results of manual user evaluation (see section 5.2). 15 participants expressed 69 pairwise preferences between HIERSUM and PYTHY. For all attributes, HIERSUM outperforms PYTHY; all results are statistically significant as determined by pairwise t-test.",
                "html": null,
                "num": null
            }
        }
    }
}