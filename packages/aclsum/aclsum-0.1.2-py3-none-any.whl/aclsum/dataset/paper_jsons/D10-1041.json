{
    "paper_id": "D10-1041",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T11:56:36.113369Z"
    },
    "title": "Facilitating Translation Using Source Language Paraphrase Lattices",
    "authors": [
        {
            "first": "Jinhua",
            "middle": [],
            "last": "Du",
            "suffix": "",
            "affiliation": {},
            "email": ""
        },
        {
            "first": "Jie",
            "middle": [],
            "last": "Jiang",
            "suffix": "",
            "affiliation": {},
            "email": "jjiang@computing.dcu.ie"
        },
        {
            "first": "Andy",
            "middle": [],
            "last": "Way",
            "suffix": "",
            "affiliation": {},
            "email": "away@computing.dcu.ie"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "For resource-limited language pairs, coverage of the test set by the parallel corpus is an important factor that affects translation quality in two respects: 1) out of vocabulary words; 2) the same information in an input sentence can be expressed in different ways, while current phrase-based SMT systems cannot automatically select an alternative way to transfer the same information. Therefore, given limited data, in order to facilitate translation from the input side, this paper proposes a novel method to reduce the translation difficulty using source-side lattice-based paraphrases. We utilise the original phrases from the input sentence and the corresponding paraphrases to build a lattice with estimated weights for each edge to improve translation quality. Compared to the baseline system, our method achieves relative improvements of 7.07%, 6.78% and 3.63% in terms of BLEU score on small, medium and largescale English-to-Chinese translation tasks respectively. The results show that the proposed method is effective not only for resourcelimited language pairs, but also for resourcesufficient pairs to some extent.",
    "pdf_parse": {
        "paper_id": "D10-1041",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "For resource-limited language pairs, coverage of the test set by the parallel corpus is an important factor that affects translation quality in two respects: 1) out of vocabulary words; 2) the same information in an input sentence can be expressed in different ways, while current phrase-based SMT systems cannot automatically select an alternative way to transfer the same information. Therefore, given limited data, in order to facilitate translation from the input side, this paper proposes a novel method to reduce the translation difficulty using source-side lattice-based paraphrases. We utilise the original phrases from the input sentence and the corresponding paraphrases to build a lattice with estimated weights for each edge to improve translation quality. Compared to the baseline system, our method achieves relative improvements of 7.07%, 6.78% and 3.63% in terms of BLEU score on small, medium and largescale English-to-Chinese translation tasks respectively. The results show that the proposed method is effective not only for resourcelimited language pairs, but also for resourcesufficient pairs to some extent.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "In recent years, statistical MT systems have been easy to develop due to the rapid explosion in data availability, especially parallel data. However, in reality there are still many language pairs which lack parallel data, such as Urdu-English, Chinese-Italian, where large amounts of speakers exist for both languages; of course, the problem is far worse for pairs such as Catalan-Irish. For such resourcelimited language pairs, sparse amounts of parallel data would cause the word alignment to be inaccurate, which would in turn lead to an inaccurate phrase alignment, and bad translations would result. Callison-Burch et al. (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. Thus, in recent years, research on addressing the problem of unknown words or phrases has become more and more evident for resource-limited language pairs. Callison-Burch et al. (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. Their experiments showed that by translating paraphrases a marked improvement was achieved in coverage and translation quality, especially in the case of unknown words which previously had been left untranslated. However, on a large-scale data set, they did not achieve improvements in terms of automatic evaluation. Nakov (2008) proposed another way to use paraphrases in SMT. He generates nearly-equivalent syntactic paraphrases of the source-side training sentences, then pairs each paraphrased sentence with the target translation associated with the original sentence in the training data. Essentially, this method generates new training data using paraphrases to train a new model and obtain more useful phrase pairs. However, he reported that this method results in bad system performance. By contrast, real improvements can be achieved by merging the phrase tables of the paraphrase model and the original model, giving priority to the latter. Schroeder et al. (2009) presented the use of word lattices for multi-source translation, in which the multiple source input texts are compiled into a compact lattice, over which a single decoding pass is then performed. This lattice-based method achieved positive results across all data conditions.",
                "cite_spans": [
                    {
                        "start": 606,
                        "end": 634,
                        "text": "Callison-Burch et al. (2006)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 1014,
                        "end": 1042,
                        "text": "Callison-Burch et al. (2006)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 1584,
                        "end": 1596,
                        "text": "Nakov (2008)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 2219,
                        "end": 2242,
                        "text": "Schroeder et al. (2009)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we propose a novel method using paraphrases to facilitate translation, especially for resource-limited languages. Our method does not distinguish unknown words in the input sentence, but uses paraphrases of all possible words and phrases in the source input sentence to build a source-side lattice to provide a diverse and flexible list of source-side candidates to the SMT decoder so that it can search for a best path and deliver the translation with the highest probability. In this case, we neither need to change the phrase table, nor add new features in the log-linear model, nor add new sentences in the training data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The remainder of this paper is organised as follows. In Section 2, we define the \"translation difficulty\" from the perspective of the source side, and then examine how well the test set is covered by the phrase table and the parallel training data . Section 3 describes our paraphrase lattice method and discusses how to set the weights for the edges in the lattice network. In Section 4, we report comparative experiments conducted on small, medium and largescale English-to-Chinese data sets. In Section 5, we analyse the influence of our paraphrase lattice method. Section 6 concludes and gives avenues for future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2 What Makes Translation Difficult?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We use the term \"translation difficulty\" to explain how difficult it is to translate the source-side sentence in three respects:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Translation Difficulty",
                "sec_num": "2.1"
            },
            {
                "text": "\u2022 The OOV rates of the source sentences in the test set (Callison-Burch et al., 2006) .",
                "cite_spans": [
                    {
                        "start": 56,
                        "end": 85,
                        "text": "(Callison-Burch et al., 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Translation Difficulty",
                "sec_num": "2.1"
            },
            {
                "text": "\u2022 Translatability of a known phrase in the input sentence. Some particular grammatical structures on the source side cannot be directly translated into the corresponding structures on the target side. Nakov (2008) presents an example showing how hard it is to translate an English construction into Spanish. Assume that an English-to-Spanish SMT system has an entry in its phrase table for \"inequality of income\", but not for \"income inequality\". He argues that the latter phrase is hard to translate into Spanish where noun compounds are rare: the correct translation in this case requires a suitable Spanish preposition and a reordering, which are hard for the system to realize properly in the target language (Nakov, 2008) .",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 213,
                        "text": "Nakov (2008)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 713,
                        "end": 726,
                        "text": "(Nakov, 2008)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Translation Difficulty",
                "sec_num": "2.1"
            },
            {
                "text": "\u2022 Consistency between the reference and the target-side sentence in the training corpus. Nakov (2008) points out that if the target-side sentence in the parallel corpus is inconsistent with the reference of the test set, then in some cases, a test sentence might contain pieces that are equivalent, but syntactically different from the phrases learned in training, which might result in practice in a missed opportunity for a high-quality translation. In this case, if we use paraphrases for these pieces of text, then we might improve the opportunity for the translation to approach the reference, especially in the case where only one reference is available.",
                "cite_spans": [
                    {
                        "start": 89,
                        "end": 101,
                        "text": "Nakov (2008)",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Translation Difficulty",
                "sec_num": "2.1"
            },
            {
                "text": "As to the first aspect -coverage -we argue that the coverage rate of the new words or unknown words are more and more becoming a \"bottleneck\" for resource-limited languages. Furthermore, current SMT systems, either phrase-based (Koehn et al., 2003; Chiang, 2005) or syntax-based (Zollmann and Venugopal, 2006) igrams, we found that most are named entities (NEs) such as person name, location name, etc. From the bigram phrases, the coverage rates begin to significantly decline. It can also be seen that phrases containing more than 5 words rarely appear either in the phrase table or in the parallel corpus, which indicates that data sparseness is severe for long phrases.",
                "cite_spans": [
                    {
                        "start": 228,
                        "end": 248,
                        "text": "(Koehn et al., 2003;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 249,
                        "end": 262,
                        "text": "Chiang, 2005)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 279,
                        "end": 309,
                        "text": "(Zollmann and Venugopal, 2006)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Coverage",
                "sec_num": "2.2"
            },
            {
                "text": "Even if the size of the corpus is significantly increased (e.g. from 20K to 200K), the coverage of long phrases is still quite low. With respect to these three aspects of the translation difficulty, especially for data-limited language pairs, we propose a more effective method to make use of the paraphrases to facilitate translation process.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Coverage",
                "sec_num": "2.2"
            },
            {
                "text": "In this Section, we propose a novel method to employ paraphrases to reduce the translation difficulty and in so doing increase the translation quality.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Lattice for Input Sentences",
                "sec_num": "3"
            },
            {
                "text": "Our idea to build a paraphrase lattice for SMT is inspired by the following points:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 Handling unknown words is a challenging issue for SMT, and using paraphrases is an effective way to facilitate this problem (Callison-Burch et al., 2006) ;",
                "cite_spans": [
                    {
                        "start": 126,
                        "end": 155,
                        "text": "(Callison-Burch et al., 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 The method of paraphrase substitution does not show any significant improvement, especially on a large-scale data set in terms of BLEU (Papineni et al., 2002) scores (Callison-Burch et al., 2006) ;",
                "cite_spans": [
                    {
                        "start": 137,
                        "end": 160,
                        "text": "(Papineni et al., 2002)",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 168,
                        "end": 197,
                        "text": "(Callison-Burch et al., 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 Building a paraphrase lattice might provide more translation options to the decoder so that it can flexibly search for the best path.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "The major contributions of our method are:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 We consider all N -gram phrases rather than only unknown phrases in the test set, where {1 <= N <= 10};",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 We utilise lattices rather than simple substitution to facilitate the translation process;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "\u2022 We propose an empirical weight estimation method to set weights for edges in the word lattice, which is detailed in Section 3.4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Motivation",
                "sec_num": "3.1"
            },
            {
                "text": "Paraphrases are alternative ways to express the same or similar meaning given a certain original word, phrase or segment. The paraphrases used in our method are generated from the parallel corpora based on the algorithm in (Bannard and Callison-Burch, 2005) , in which paraphrases are identified by pivoting through phrases in another language.",
                "cite_spans": [
                    {
                        "start": 223,
                        "end": 257,
                        "text": "(Bannard and Callison-Burch, 2005)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "In this algorithm, the foreign language translations of an English phrase are identified, all occurrences of those foreign phrases are found, and all English phrases that they translate as are treated as potential paraphrases of the original English phrase (Callison-Burch et al., 2006) . A paraphrase has a probability p(e 2 |e 1 ) which is defined as in (2):",
                "cite_spans": [
                    {
                        "start": 257,
                        "end": 286,
                        "text": "(Callison-Burch et al., 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "p(e 2 |e 1 ) = \u2211 f p(f |e 1 )p(e 2 |f )",
                        "eq_num": "(1)"
                    }
                ],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "where the probability p(f |e 1 ) is the probability that the original English phrase e 1 translates as a particular phrase f in the other language, and p(e 2 |f ) is the probability that the candidate paraphrase e 2 translates as the foreign language phrase. p(e 2 |f ) and p(f |e 1 ) are defined as the translation probabilities which can be calculated straightforwardly using maximum likelihood estimation by counting how often the phrases e and f are aligned in the parallel corpus as in ( 2) and (3):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "p(e 2 |f ) \u2248 count(e 2 , f ) \u2211 e 2 count(e 2 , f ) (2) p(f |e 1 ) \u2248 count(f, e 1 ) \u2211 f count(f, e 1 )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "(3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Acquisition",
                "sec_num": "3.2"
            },
            {
                "text": "To present paraphrase options to the PB-SMT decoder, lattices with paraphrase options are constructed to enrich the source-language sentences. The construction process takes advantage of the correspondence between detected paraphrases and positions of the original words in the input sentence, then creates extra edges in the lattices to allow the decoder to consider paths involving the paraphrase words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Construction of Paraphrase Lattice",
                "sec_num": "3.3"
            },
            {
                "text": "An toy example is illustrated in Figure 1 : given a sequence of words {w 1 , . . . , w N } as the input, two phrases \u03b1 = {\u03b1 1 , . . . , \u03b1 p } and \u03b2 = {\u03b2 1 , . . . , \u03b2 q } are detected as paraphrases for ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 40,
                        "end": 41,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Construction of Paraphrase Lattice",
                "sec_num": "3.3"
            },
            {
                "text": "S 1 = {w x , . . . , w y } (1 \u2264 x \u2264 y \u2264 N ) and S 2 = {w m , . . . , w n } (1 \u2264 m \u2264 n \u2264 N ) respectively.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Construction of Paraphrase Lattice",
                "sec_num": "3.3"
            },
            {
                "text": "Generated lattice 2. Generate extra nodes and edges for each of the paraphrases. Taking \u03b1 as an example, firstly, p -1 nodes are created, and then p edges (referred as \"NEW-E\" edges) labeled with \u03b1 j (1 \u2264 j \u2264 p) are generated to connect node \u03b8 x-1 , p -1 nodes and \u03b8 y-1 .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Source side sentence",
                "sec_num": null
            },
            {
                "text": "\u012e 1 \u012e 2 \u2026 \u012e p \u0215 1 \u0215 2 \u2026 \u0215 q Paraphrase A Paraphrase B \u012e 1 \u012e 2 ... \u012e p \u0215 2 \u0215 q ... ..",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Source side sentence",
                "sec_num": null
            },
            {
                "text": "Via step 2, word lattices are generated by adding new nodes and edges coming from paraphrases. Note that to build word lattices, paraphrases with multi-words are broken into word sequences, and each of the words produces one extra edge in the word lattices as shown in the bottom part in Figure 1 . Figure 2 shows an example of constructing the word lattice for an input sentence which is from the test set used in our experiments. 1 The top part in Figure 2 represents nodes (double-line circles) and edges (solid lines) that are constructed by the original words from the input sentence, while the bottom part in Figure 2 indicates the final word lattice with the addition of new nodes (single-line circles) and new edges (dashed lines) which come from the paraphrases. We can see that the paraphrase lattice increases the diversity of the source phrases so that it can provide more flexible translation options during the decoding process. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 295,
                        "end": 296,
                        "text": "1",
                        "ref_id": null
                    },
                    {
                        "start": 306,
                        "end": 307,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 457,
                        "end": 458,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 622,
                        "end": 623,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Source side sentence",
                "sec_num": null
            },
            {
                "text": "Estimating and normalising the weight for each edge in the word lattice is a challenging issue when the edges come from different sources. In this section, we propose an empirical method to set the weights for the edges by distinguishing the original (\"ORG-E\") and new (\"NEW-E\") edges in the lattices. The aim is to utilize the original sentences as the references to weight the edges from paraphrases, so that decoding paths going through \"ORG-E\" edges will tend to have higher scores than those which use \"NEW-E\" ones. The assumption behind this is that the paraphrases are alternatives for the original sentences, so decoding paths going though them ought to be penalised.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "Therefore, for all the \"ORG-E\" edges, their weights in the lattice are set to 1.0 as the reference. Thus, in the log-linear model, decoding paths going though these edges are not penalised because they do not come from the paraphrases.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "By contrast, \"NEW-E\" are divided into two groups for the calculation of weights:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "\u2022 For \"NEW-E\" edges which are outgoing edges of the lattice nodes that come from the original sentences, the probabilities p(e s |e i ) 2 of their 2 es indicates the source phrase S, ei represents one of the corresponding paraphrases are utilised to produce empirical weights. Supposing that a set of paraphrases X = {x 1 , . . . , x k } start at node A which comes from the original sentence, so that X are sorted descendingly based on the probabilities p(e s |e i ), their corresponding edges for node A are G = {g 1 , . . . , g k }, then the weights are calculated as in (4):",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "w(e i ) = 1 k + i (1 <= i <= k) (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "where k is a predefined parameter to trade off between decoding speed and the number of potential paraphrases being considered. Thus, once a decoding path goes though one of these edges, it will be penalised according to its paraphrase probabilities.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "\u2022 For all other \"NEW-E\" edges, their weights are set to 1.0, because the paraphrase penalty has been counted in their preceding \"NEW-E\" edges.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "Figure 2 illustrates the weight estimation results. Nodes coming from the original sentences are drawn in double-line circles (e.g. nodes 0 to 7), while paraphrases of S.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "nodes created from paraphrases are shown in singleline circles (e.g. nodes 8 to 10). \"ORG-E\" edges are drawn in solid lines and \"NEW-E\" edges are shown using dashed lines. As specified previously, \"ORG-E\" edges are all weighted by 1.0 (e.g. edge labeled \"the\" from node 0 to 1). By contrast, \"NEW-E\" edges in the first group are weighted by equation ( 4) (e.g. edges in dashed lines start from node 0 to node 2 and 8), while others in the second group are weighted by 1.0 (e.g. edge labeled \"training\" from node 8 to 2). Note that penalties of the paths going through paraphrases are counted by equation ( 4), which is represented by the weights of \"NEW-E\" edges in the first group. For example, starting from node 2, paths going to node 9 and 10 are penalised because lattice weights are also considered in the log-linear model. However, other edges do not imply penalties since their weights are set to 1.0.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "The reason to set all weights for the \"ORG-E\" edges to a uniform weight (e.g. 1.0) instead of a lower empirical weight is to avoid excessive penalties for the original words. For example, in Figure 2 , the original edge from node 3 to 4 (continue) has a weight of 1.0, so the paths going though the original edges from node 2 to 4 (will continue) have a higher lattice score (1.0 \u00d7 1.0 = 1.0) than the paths going through the edges of paraphrases (e.g. will resume (score: 0.125 \u00d7 1.0 = 0.125) and will go (score: 0.11 \u00d7 1.0 = 0.11)), or any other mixed paths that goes through original edges and paraphrase edges, such as will continuous (score: 1.0 \u00d7 0.125 = 0.125). The point is that we should have more trust when translating the original words, but if we penalise (set weights < 1.0) the \"ORG-E\" edges whenever there is a paraphrase for them, then when considering the context of the lattice, paraphrases will be favoured systematically. That is why we just penalise the \"NEW-E\" edges in the first group and set other weights to 1.0.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 198,
                        "end": 199,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "As to unknown words in the input sentence, even if we give them a prioritised weight, they would be severely penalised in the decoding process. So we do not need to distinguish unknown words when building and weighting the paraphrase lattice.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Weight Estimation",
                "sec_num": "3.4"
            },
            {
                "text": "For our experiments, we use Moses (Koehn et al., 2007) as the baseline system which can support lattice decoding. We also realise a paraphrase substitution-based system (Para-Sub)3 based on the method in (Callison-Burch, 2006) to compare with the baseline system and our proposed paraphrase lattice-based (Lattice) system.",
                "cite_spans": [
                    {
                        "start": 34,
                        "end": 54,
                        "text": "(Koehn et al., 2007)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 204,
                        "end": 226,
                        "text": "(Callison-Burch, 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "System and Data Preparation",
                "sec_num": "4.1"
            },
            {
                "text": "The alignment is carried out by GIZA++ (Och and Ney, 2003 ) and then we symmetrized the word alignment using the grow-diag-final heuristic. The maximum phrase length is 10 words. Parameter tuning is performed using Minimum Error Rate Training (Och, 2003) .",
                "cite_spans": [
                    {
                        "start": 39,
                        "end": 57,
                        "text": "(Och and Ney, 2003",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 243,
                        "end": 254,
                        "text": "(Och, 2003)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "System and Data Preparation",
                "sec_num": "4.1"
            },
            {
                "text": "The experiments are conducted on English-to-Chinese translation. In order to fully compare our proposed method with the baseline and the \"Para-Sub\" system, we perform the experiments on three different sizes of training data: 20K, 200K and 2.1 million pairs of sentences. The former two sizes of data are derived from FBIS,4 and the latter size of data consists of part of HK parallel corpus,5 ISI parallel data,6 other news data and parallel dictionaries from LDC. All the language models are 5-gram which are trained on the monolingual part of parallel data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "System and Data Preparation",
                "sec_num": "4.1"
            },
            {
                "text": "The development set (devset) and the test set for experiments using 20K and 200K data sets are randomly extracted from the FBIS data. Each set includes 1,200 sentences and each source sentence has one reference. For the 2.1 million data set, we use a different devset and test set in order to verify whether our proposed method can work on a language pair with sufficient resources. The devset is the NIST 2005 Chinese-English current set which has only one reference for each source sentence and the test set is the NIST 2003 English-to-Chinese current set which contains four references for each source sentence. All results are reported in BLEU and TER (Snover et al., 2006) The paraphrase data set used in our lattice-based and the \"Para-Sub\" systems is same which is derived from the \"Paraphrase Phrase Table \" 7 of TER-Plus (Snover et al., 2009) . The parameter k in equation 4 is set to 7.",
                "cite_spans": [
                    {
                        "start": 656,
                        "end": 677,
                        "text": "(Snover et al., 2006)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 830,
                        "end": 851,
                        "text": "(Snover et al., 2009)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "System and Data Preparation",
                "sec_num": "4.1"
            },
            {
                "text": "The more edges there are in a lattice, the more complicated the decoding is in the search process. Therefore, in order to reduce the complexity of the lattice and increase decoding speed, we must filter out some potential noise in the paraphrase table. Two measures are taken to optimise the paraphrases when building a paraphrase lattice:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Filtering",
                "sec_num": "4.2"
            },
            {
                "text": "\u2022 Firstly, we filter out all the paraphrases whose probability is less than 0.01;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Filtering",
                "sec_num": "4.2"
            },
            {
                "text": "\u2022 Secondly, given a source-side input sentence, we retrieve all possible paraphrases and their probabilities for source-side phrases which appear in the paraphrase table. Then we remove the paraphrases which are not occurred in the \"phrase table\" of the SMT system. This measure intends to avoid adding new \"unknown words\" to the source-side sentence. After this measure, we can acquire the final paraphrases which can be denoted as a quadruple < SEN ID, Span, P ara, P rob >, where \"SEN ID\" indicates the ID of the input sentence, \"Span\" represents the span of the sourceside phrase in the original input sentence, \"Para\" indicates the paraphrase of the sourceside phrase, and \"Prob\" represents the probability between the source-side phrase and its paraphrase, which is used to set the weight of the edge in the lattice. The quadruple is used to construct the weighted lattice.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Filtering",
                "sec_num": "4.2"
            },
            {
                "text": "7 http://www.umiacs.umd.edu/ \u02dcsnover/terp/ downloads/terp-pt.v1.tgz.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Paraphrase Filtering",
                "sec_num": "4.2"
            },
            {
                "text": "The experimental results conducted on small and medium-sized data sets are shown in Table 2 . The 95% confidence intervals (CI) for BLEU scores are independently computed on each of three systems, while the \"pair-CI 95%\" are computed relative to the baseline system only for \"Para-Sub\" and \"Lattice\" systems. All the significance tests use bootstrap and paired-bootstrap resampling normal approximation methods (Zhang and Vogel, 2004). 8 Improvements are considered to be significant if the left boundary of the confidence interval is larger than zero in terms of the \"pair-CI 95%\". It can be seen that 1) our \"Lattice\" system outperforms the baseline by 1.02 and 1.6 absolute (7.07% and 6.78% relative) BLEU points in terms of the 20K and 200K data sets respectively, and our system also decreases the TER scores by 2.24 and 1.19 (2.97% and 1.87% relative) points than the baseline system.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 90,
                        "end": 91,
                        "text": "2",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "In terms of the \"pair-CI 95%\", the left boundaries for 20K and 200K data are respectively \"+0.74\" and \"+1.19\", which indicate that the \"Lattice\" system is significantly better than the baseline system on these two data sets.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "2) The \"Para-Sub\" system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al., 2006) does not work on resource-sufficient data sets. In terms of the \"pair-CI 95%\", the left boundary for 20K data is \"+0.13\", which indicates that it is significantly better than the baseline system, while the left boundary is \"-0.46\" for 200K data, which indicates that the \"Para-Sub\" system is significantly worse than the baseline system. 3) comparing the \"Lattice\" system with the \"Para-Sub\" Table 3 : Comparison between the baseline and our paraphrase lattice method on a large-scale data set.",
                "cite_spans": [
                    {
                        "start": 275,
                        "end": 304,
                        "text": "(Callison-Burch et al., 2006)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 703,
                        "end": 704,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "system, the \"pair-CI 95%\" for 20K and 200K data are respectively [+0.41, +0.92] and [+1.40, +2.17], which indicates that the \"Lattice\" system is significantly better than the \"Para-Sub\" system on these two data sets as well. 4) In terms of the two metrics, our proposed method achieves the best performance, which shows that our method is effective and consistent on different sizes of data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "In order to verify our method on large-scale data, we also perform experiments on 2.1 million sentence-pairs of English-to-Chinese data as described in Section 4.1. The results are shown in Table 3. From Table 3 , it can be seen that the \"Lattice\" system achieves an improvement of 0.51 absolute (3.63% relative) BLEU points and a decrease of 1.6 absolute (2.14% relative) TER points compared to the baseline. In terms of the \"pair-CI 95%\", the left boundary for the \"Lattice\" system is \"+0.15\" which indicates that it is significantly better than the baseline system in terms of BLEU. Interestingly, in our experiment, the \"Para-Sub\" system also outperforms the baseline on those three automatic metrics. However, in terms of the \"pair-CI 95%\", the left boundary for the \"Para-Sub\" system is \"-0.18\" which indicates that it is not significantly better than the baseline system in terms of BLEU. The results also show that our proposed method is effective and consistent even on a large-scale data set.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 210,
                        "end": 211,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "It also can be seen that the improvement on 2.1 million sentence-pairs is less than that of the 20K and 200K data sets. That is, as the size of the training data increases, the problems of data sparseness decrease, so that the coverage of the test set by the parallel corpus will correspondingly increase. In this case, the role of paraphrases in decoding becomes a little weaker. On the other hand, it might become a kind of noise to interfere with the exact translation of the original source-side phrases when decoding. Therefore, our proposed method may be more appropriate for language pairs with limited resources.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "The coverage rate of the test set by the phrase table is an important factor that could influence the translation result, so in this section we examine the characteristics of the updated test set that adds in the paraphrases. We take the 200K data set to examine the coverage issue. From Table 4 , we can see that the coverage of unigrams, bigrams, trigrams and 4-grams goes up by about 5%, 10%, 5% and 1%, while from 5-grams there is only a slight or no increase in coverage. These results show that 1) most of the paraphrases that are added in are lower-order n-grams; 2) the paraphrases can increase the coverage of the input by handling the unknown words to some extent. However, we observed that most untranslated words in the \"Para-Sub\" and \"Lattice\" systems are still NEs, which shows that in our paraphrase table, there are few paraphrases for the NEs. Therefore, to further improve the translation quality using paraphrases, we also need to acquire the paraphrases for NEs to increase the coverage of unknown words.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 294,
                        "end": 295,
                        "text": "4",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Coverage of Paraphrase Test Set",
                "sec_num": "5.1"
            },
            {
                "text": "Source: whether or the albanian rebels can be genuinely disarmed completely is the main challenge to nato . ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Coverage of Paraphrase Test Set",
                "sec_num": "5.1"
            },
            {
                "text": "In this section, we give an example to show the effectiveness of using paraphrase lattices to deal with unknown words. The example is evaluated according to both automatic evaluation and human evaluation at sentence level. See Figure 3 as an illustration of how the paraphrase-based systems process unknown words. According to the word alignments between the source-side sentence and the reference, the word \"disarmed\" is translated into two Chinese words \" \" and \" \". These two Chinese words are discontinuous in the reference, so it is difficult for the PB-SMT system to correctly translate the single English word into a discontinuous Chinese phrase. In fact in this example, \"disarmed\" is an unknown word and it is kept untranslated in the result of the baseline system. In the \"Para-Sub\" system, it is translated into \" \" based on a paraphrase pair P P 1 = \"disarmed \u2225 disarmament \u2225 0.087\" and its translation pair T 1 = \"disarmament \u2225 \". The number \"0.087\" is the probability p 1 that indicates to what extent these two words are paraphrases. It can be seen that although \"",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 234,
                        "end": 235,
                        "text": "3",
                        "ref_id": "FIGREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Analysis on Translation Results",
                "sec_num": "5.2"
            },
            {
                "text": "\" is quite different from the meaning of \"disarmed\", it is understandable for human in some sense. In the \"Lattice\" system, the word \"disarmed\" is translated into three Chinese words \"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis on Translation Results",
                "sec_num": "5.2"
            },
            {
                "text": "\" based on a paraphrase pair P P 2 = \"disarmed \u2225 demilitarized \u2225 0.099\" and its translation pair T 2 = \"demilitarized \u2225 \". The probability p 2 is slightly greater than p 1 . We argue that the reason that the \"Lattice\" system selects P P 2 and T 2 rather than P P 1 and T 1 is because of the weight estimation in the lattice. That is, P P 2 is more prioritised, while P P 1 is more penalised based on equation (4).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis on Translation Results",
                "sec_num": "5.2"
            },
            {
                "text": "From the viewpoint of human evaluation, the paraphrase pair P P 2 is more appropriate than P P 1 , and the translation T 2 is more similar to the original meaning than T 1 . The sentence-level automatic evaluation scores for this example in terms of BLEU and TER metrics are shown in Table 5 . The BLEU score of the \"Lattice\" system is much higher than the baseline, and the TER score is quite a bit lower than the baseline. Therefore, from the viewpoint of automatic evaluation, the translation from the \"Lattice\" system is also better than those from the baseline and \"Para-Sub\" systems.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 290,
                        "end": 291,
                        "text": "5",
                        "ref_id": "TABREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Analysis on Translation Results",
                "sec_num": "5.2"
            },
            {
                "text": "In this paper, we proposed a novel method using paraphrase lattices to facilitate the translation process in SMT. Given an input sentence, our method firstly discovers all possible paraphrases from a paraphrase database for N -grams (1 <= N <= 10) in the test set, and then filters out the paraphrases which do not appear in the phrase table in order to avoid adding new unknown words on the input side. We then use the original words and the paraphrases to build a word lattice, and set the weights to prioritise the original edges and penalise the paraphrase edges. Finally, we import the lattice into the decoder to perform lattice decoding. The experiments are conducted on English-to-Chinese translation using the FBIS data set with small and medium-sized amounts of data, and on a large-scale corpus of 2.1 million sentence pairs. We also performed comparative experiments for the baseline, the \"Para-Sub\" system and our paraphrase lattice-based system. The experimental results show that our proposed system significantly outperforms the baseline and the \"Para-Sub\" system, and the effectiveness is consistent on the small, medium and large-scale data sets.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "6"
            },
            {
                "text": "As for future work, firstly we plan to propose a pruning algorithm for the duplicate paths in the lattice, which will track the edge generation with respect to the path span, and thus eliminate duplicate paths. Secondly, we plan to experiment with another feature function in the log-linear model to discount words derived from paraphrases, and use MERT to assign an appropriate weight to this feature function.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "6"
            },
            {
                "text": "Figure",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "contains paths that are duplicates except for the weights. We plan to handle this in future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We use \"Para-Sub\" to represent their system in the rest of this paper.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This is a multilingual paragraph-aligned corpus with LDC resource number LDC2003E14.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "LDC number: LDC2004T08.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "LDC number: LDC2007T09.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://projectile.sv.cmu.edu/research/ public/tools/bootStrap/tutorial.htm.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Many thanks to the reviewers for their insightful comments and suggestions. This work is supported by Science Foundation Ireland (Grant No. 07/CE/I1142) as part of the Centre for Next Generation Localisation (www.cngl.ie) at Dublin City University.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Paraphrasing with bilingual parallel corpora",
                "authors": [
                    {
                        "first": "Colin",
                        "middle": [],
                        "last": "Bannard",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "43rd Annual meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "597--604",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Colin Bannard and Chris Callison-Burch. 2005. Para- phrasing with bilingual parallel corpora. In 43rd An- nual meeting of the Association for Computational Linguistics, Ann Arbor, MI, pages 597-604.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Improved statistical machine translation using paraphrases",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Miles",
                        "middle": [],
                        "last": "Osborne",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of HLT-NAACL 2006: Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL",
                "volume": "",
                "issue": "",
                "pages": "17--24",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Callison-Burch, Philipp Koehn and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of HLT-NAACL 2006: Proceedings of the Human Language Technology Con- ference of the North American Chapter of the ACL, NY, USA, pages 17-24.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "A hierarchical phrase-based model for statistical machine translation",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Chiang",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "43rd Annual meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "263--270",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In 43rd Annual meeting of the Association for Computational Linguis- tics, Ann Arbor, MI, pages 263-270.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Statistical phrase-based translation",
                "authors": [
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Franz",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Josef",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Proceedings of HLT-NAACL 2003: conference combining Human Language Technology conference series and the North American Chapter of the Association for Computational Linguistics conference series",
                "volume": "",
                "issue": "",
                "pages": "48--54",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Philipp Koehn, Franz Josef Och and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceed- ings of HLT-NAACL 2003: conference combining Hu- man Language Technology conference series and the North American Chapter of the Association for Com- putational Linguistics conference series, Edmonton, Canada, pages 48-54.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Moses: Open Source Toolkit for Statistical Machine Translation",
                "authors": [
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    },
                    {
                        "first": "Hieu",
                        "middle": [],
                        "last": "Hoang",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Birch",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Federico",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Bertoldi",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Cowan",
                        "suffix": ""
                    },
                    {
                        "first": "Wade",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Moran",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Zens",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    },
                    {
                        "first": "O",
                        "middle": [],
                        "last": "Bojar",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Constantin",
                        "suffix": ""
                    },
                    {
                        "first": "Evan",
                        "middle": [],
                        "last": "Herbst",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "ACL 2007: demo and poster sessions",
                "volume": "",
                "issue": "",
                "pages": "177--180",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Philipp Koehn, Hieu Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, Wade Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL 2007: demo and poster sessions, Prague, Czech Republic, pages 177-180.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Improving English-Spanish statistical machine translation: experiments in domain adaptation, sentence paraphrasing, tokenization, and recasing",
                "authors": [
                    {
                        "first": "Preslav",
                        "middle": [],
                        "last": "Nakov",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of ACL-08:HLT. Third Workshop on Statistical Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "147--150",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Preslav Nakov. 2008. Improving English-Spanish sta- tistical machine translation: experiments in domain adaptation, sentence paraphrasing, tokenization, and recasing. In Proceedings of ACL-08:HLT. Third Work- shop on Statistical Machine Translation, Columbus, Ohio, USA, pages 147-150.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Minimum Error Rate Training in Statistical Machine Translation",
                "authors": [
                    {
                        "first": "Franz",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "41st Annual meeting of the Association for Computational Linguistics, Sapporo",
                "volume": "",
                "issue": "",
                "pages": "160--167",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franz Och. 2003. Minimum Error Rate Training in Sta- tistical Machine Translation. In 41st Annual meeting of the Association for Computational Linguistics, Sap- poro, Japan, pages 160-167.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "A systematic comparison of various statistical alignment models",
                "authors": [
                    {
                        "first": "Franz",
                        "middle": [],
                        "last": "Och",
                        "suffix": ""
                    },
                    {
                        "first": "Hermann",
                        "middle": [],
                        "last": "Ney",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "Computational Linguistics",
                "volume": "29",
                "issue": "1",
                "pages": "19--51",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franz Och and Hermann Ney. 2003. A systematic com- parison of various statistical alignment models. Com- putational Linguistics, 29(1):19-51.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "BLEU: a Method for Automatic Evaluation of Machine Translation",
                "authors": [
                    {
                        "first": "Kishore",
                        "middle": [],
                        "last": "Papineni",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    },
                    {
                        "first": "Todd",
                        "middle": [],
                        "last": "Ward",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Jing",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "311--318",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kishore Papineni, Salim Roukos, Todd Ward and Wei- Jing Zhu. 2002. BLEU: a Method for Automatic Eval- uation of Machine Translation. In 40th Annual meet- ing of the Association for Computational Linguistics, Philadelphia, PA, pages 311-318.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Word Lattices for Multi-source Translation",
                "authors": [
                    {
                        "first": "Josh",
                        "middle": [],
                        "last": "Schroeder",
                        "suffix": ""
                    },
                    {
                        "first": "Trevor",
                        "middle": [],
                        "last": "Cohn",
                        "suffix": ""
                    },
                    {
                        "first": "Philipp",
                        "middle": [],
                        "last": "Koehn",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the 12th Conference of the European Chapter of the ACL",
                "volume": "",
                "issue": "",
                "pages": "719--727",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Josh Schroeder, Trevor Cohn and Philipp Koehn. 2009. Word Lattices for Multi-source Translation. In Pro- ceedings of the 12th Conference of the European Chapter of the ACL, Athens, Greece, pages 719-727.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "A study of translation edit rate with targeted human annotation",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Snover",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [],
                        "last": "Dorr",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Schwartz",
                        "suffix": ""
                    },
                    {
                        "first": "Linnea",
                        "middle": [],
                        "last": "Micciulla",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Makhoul",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 7th Conference of the Association for Machine Translation in the Americas",
                "volume": "",
                "issue": "",
                "pages": "223--231",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin- nea Micciulla and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Associa- tion for Machine Translation in the Americas, Cam- bridge, pages 223-231.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Snover",
                        "suffix": ""
                    },
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "J"
                        ],
                        "last": "Dorr",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Schwartz",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the Fourth Workshop on Statistical Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "259--268",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Matthew Snover, Nitin Madnani, Bonnie J.Dorr and Richard Schwartz. 2009. Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric. In Proceedings of the Fourth Workshop on Statistical Machine Translation, Athens, Greece, pages 259-268.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Measuring Confidence Intervals for the Machine Translation Evaluation Metrics",
                "authors": [
                    {
                        "first": "Ying",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Stephan",
                        "middle": [],
                        "last": "Vogel",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI)",
                "volume": "",
                "issue": "",
                "pages": "85--94",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ying Zhang and Stephan Vogel. 2004. Measuring Con- fidence Intervals for the Machine Translation Evalua- tion Metrics. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI), pages 85-94.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Syntax augmented machine translation via chart parsing",
                "authors": [
                    {
                        "first": "Andreas",
                        "middle": [],
                        "last": "Zollmann",
                        "suffix": ""
                    },
                    {
                        "first": "Ashish",
                        "middle": [],
                        "last": "Venugopal",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of HLT-NAACL 2006: Proceedings of the Workshop on Statistical Machine Translation",
                "volume": "",
                "issue": "",
                "pages": "138--141",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andreas Zollmann and Ashish Venugopal. 2006. Syn- tax augmented machine translation via chart parsing. In Proceedings of HLT-NAACL 2006: Proceedings of the Workshop on Statistical Machine Translation, New York, pages 138-141.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "The following steps are taken to transform them into word lattices:1. Transform the original source sentence into word lattices. N + 1 nodes (\u03b8 k , 0 \u2264 k \u2264 N )",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: An example of how to build a paraphrase lattice for an input sentence",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 3: An example from three systems to compare the processing of OOVs",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>, use phrases as the fundamental</td></tr><tr><td>translation unit, so how much the phrase table and</td></tr><tr><td>training data can cover the test set is an important</td></tr><tr><td>factor which influences the translation quality. Ta-</td></tr><tr><td>ble 1 shows the statistics of the coverage of the test</td></tr><tr><td>set on English-to-Chinese FBIS data, where we can</td></tr><tr><td>see that the coverage of unigrams is very high, es-</td></tr><tr><td>pecially when the data is increased to the medium</td></tr><tr><td>size (200K), where unigram coverage is greater than</td></tr><tr><td>90%. Based on the observations of the unknown un-</td></tr></table>",
                "type_str": "table",
                "text": "The coverage of the test set by the phrase table and the parallel corpus based on different amount of the training data. \"PL\" indicates the Phrase Length N , where {1 <= N <= 10}; \"20K\" and \"200K\" represent the sizes of the parallel data for model training and phrase extraction; \"Cov.\" indicates the coverage rate; \"Tset\" represents the number of unique phrases with the length N in the Test Set; \"PT\" represents the number of phrases of the Test Set occur in the Phrase Table; \"Corpus\" indicates the number of phrases of the Test Set appearing in the parallel corpus; \"in PT\" indicates the coverage of the phrases in the Test Set by the phrase table and correspondingly \"in Corpus\" represents the coverage of the phrases in the Test Set by the Parallel Corpus.",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td>w x</td><td>...</td><td>w m</td><td>...</td><td>w y</td><td>...</td><td>w n</td><td>...</td></tr><tr><td colspan=\"8\">Figure 1: An example of lattice-based paraphrases for an</td></tr><tr><td>input sentence</td><td/><td/><td/><td/><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td/><td/><td>20K</td><td/><td/><td colspan=\"2\">200K</td><td/></tr><tr><td>SYS</td><td>BLEU</td><td>CI 95%</td><td>pair-CI 95%</td><td>TER BLEU</td><td>CI 95%</td><td>pair-CI 95%</td><td>TER</td></tr><tr><td colspan=\"3\">Baseline 14.42 [-0.81, +0.74]</td><td>-</td><td colspan=\"2\">75.30 23.60 [-1.03, +0.97]</td><td>-</td><td>63.56</td></tr><tr><td>Para-</td><td/><td/><td/><td/><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "scores. Sub 14.78[-0.78, +0.82] [+0.13, +0.60]  73.75 23.41 [-1.04, +1.00] [-0.46, +0.09] 63.84 Lattice 15.44 [-0.85, +0.84] [+0.74, +1.30] 73.06 25.20 [-1.11, +1.15] [+1.19, +2.01] 62.37 Comparison between the baseline, \"Para-Sub\" and our \"Lattice\" (paraphrase lattice) method.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td>PL</td><td>Tset</td><td>PT</td><td colspan=\"2\">New Cov.(%) Old Cov.(%)</td></tr><tr><td>1</td><td>9,264</td><td>8,994</td><td>97.09</td><td>92.03</td></tr><tr><td>2</td><td colspan=\"2\">32,805 25,796</td><td>78.63</td><td>68.40</td></tr><tr><td>3</td><td colspan=\"2\">39,918 15,708</td><td>39.35</td><td>34.55</td></tr><tr><td>4</td><td colspan=\"2\">42,247 6,479</td><td>15.34</td><td>14.29</td></tr><tr><td>5</td><td colspan=\"2\">43,088 2,670</td><td>6.20</td><td>5.99</td></tr><tr><td>6</td><td colspan=\"2\">43,066 1,204</td><td>2.80</td><td>2.77</td></tr><tr><td>7</td><td>42,602</td><td>582</td><td>1.37</td><td>1.36</td></tr><tr><td>8</td><td>41,865</td><td>319</td><td>0.76</td><td>0.76</td></tr><tr><td>9</td><td>40,984</td><td>233</td><td>0.57</td><td>0.57</td></tr><tr><td colspan=\"2\">10 40,002</td><td>135</td><td>0.34</td><td>0.34</td></tr></table>",
                "type_str": "table",
                "text": "Table 4 is an illustration to compare the new coverage and the old coverage (without paraphrases) on medium sized training data. The coverage of the paraphrase-added test set by the phrase table on medium size of the training data.",
                "html": null,
                "num": null
            },
            "TABREF5": {
                "content": "<table><tr><td>SYS</td><td>BLEU TER</td></tr><tr><td colspan=\"2\">Baseline 20.33 66.67</td></tr><tr><td colspan=\"2\">Para-Sub 21.78 53.33</td></tr><tr><td>Lattice</td><td>23.51 53.33</td></tr></table>",
                "type_str": "table",
                "text": "Comparison on sentence-level scores in terms of BLEU and TER metrics.",
                "html": null,
                "num": null
            }
        }
    }
}