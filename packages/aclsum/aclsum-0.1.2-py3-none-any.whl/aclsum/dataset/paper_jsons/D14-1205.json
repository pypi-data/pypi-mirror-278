{
    "paper_id": "D14-1205",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:01:00.347767Z"
    },
    "title": "Joint Inference for Knowledge Base Population",
    "authors": [
        {
            "first": "Liwei",
            "middle": [],
            "last": "Chen",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Peking University",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "chenliwei@pku.edu"
        },
        {
            "first": "Yansong",
            "middle": [],
            "last": "Feng",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Peking University",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "fengyansong@pku.edu"
        },
        {
            "first": "Jinghui",
            "middle": [],
            "last": "Mo",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Peking University",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "mojinghui@pku.edu"
        },
        {
            "first": "Songfang",
            "middle": [],
            "last": "Huang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "IBM China Research Lab",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "huangsf@cn.ibm.com"
        },
        {
            "first": "Dongyan",
            "middle": [],
            "last": "Zhao",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Peking University",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "zhaodongyan@pku.edu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Populating Knowledge Base (KB) with new knowledge facts from reliable text resources usually consists of linking name mentions to KB entities and identifying relationship between entity pairs. However, the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors. In this paper, we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions: whether the types of entities meet the expectations of relations explicitly or implicitly, and whether the local predictions are globally compatible. We further measure the confidence of the extracted triples by looking at the details of the complete extraction process. Experiments show that the proposed framework can significantly reduce the error propagations thus obtain more reliable facts, and outperforms competitive baselines with state-of-the-art relation extraction models.",
    "pdf_parse": {
        "paper_id": "D14-1205",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Populating Knowledge Base (KB) with new knowledge facts from reliable text resources usually consists of linking name mentions to KB entities and identifying relationship between entity pairs. However, the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors. In this paper, we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions: whether the types of entities meet the expectations of relations explicitly or implicitly, and whether the local predictions are globally compatible. We further measure the confidence of the extracted triples by looking at the details of the complete extraction process. Experiments show that the proposed framework can significantly reduce the error propagations thus obtain more reliable facts, and outperforms competitive baselines with state-of-the-art relation extraction models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Recent advances in natural language processing have made it possible to construct structured KBs from online encyclopedia resources, at an unprecedented scale and much more efficiently than traditional manual edit. However, in those KBs, entities which are popular to the community usually contain more knowledge facts, e.g., the basketball player LeBron James, the actor Nicholas Cage, etc., while most other entities often have fewer facts. On the other hand, knowledge facts should be updated as the development of entities, such as changes in the cabinet, a marriage event, or an acquisition between two companies, etc.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In order to address the above issues, we could consult populating existing KBs from reliable text resources, e.g., newswire, which usually involves enriching KBs with new entities and populating KBs with new knowledge facts, in the form of <Entity, Relation, Entity> triple. In this paper, we will focus on the latter, identifying relationship between two existing KB entities. This task can be intuitively considered in a pipeline paradigm, that is, name mentions in the texts are first linked to entities in the KB (entity linking, EL), and then the relationship between them are identified (relation extraction, RE). It is worth mentioning that the first task EL is different from the task of named entity recognition (NER) in traditional information extraction (IE) tasks, where NER recognizes and classifies the entity mentions (to several predefined types) in the texts, but EL focuses on linking the mentions to their corresponding entities in the KB. Such pipeline systems often suffer from errors propagating from upstream to downstream, since only the local best results are selected to the next step. One idea to solve the problem is to allow interactions among the local predictions of both subtasks and jointly select an optimal assignment to eliminate possible errors in the pipeline.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Let us first look at an example. Suppose we are extracting knowledge facts from two sentences in Figure 1 : in sentence [1], if we are more confident to extract the relation fb:org.headquarters1 , we will be then prompted to select Bryant University, which indeed favors the RE prediction that requires an organization to be its subject. On the other side, if we are sure to link to Kobe Bryant in sentence [2], we will probably select fb:pro athlete.teams, whose subject position expects an athlete, e.g., an NBA player. It is not difficult to see that the argument type expectations of relations can encourage the two subtasks interact with each other and select coherent predictions for both of them. In KBs with well-defined schemas, such as Freebase, type requirements can be collected and utilized explicitly (Yao et al., 2010) . However, in other KBs with less reliable or even no schemas, it is more appropriate to implicitly capture the type expectations for a given relation (Riedel et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 815,
                        "end": 833,
                        "text": "(Yao et al., 2010)",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 985,
                        "end": 1006,
                        "text": "(Riedel et al., 2013)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 104,
                        "end": 105,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Furthermore, previous RE approaches usually process each triple individually, which ignores whether those local predictions are compatible with each other. For example, suppose the local predictions of the two sentences above are <Kobe Bryant, fb:org.headquarters, Smithfield, Rhode Is-land> and <Kobe Bryant, fb:pro athlete.teams, Los Angeles Lakers>, respectively, which, in fact, disagree with each other with respect to the KB, since, in most cases, these two relations cannot share subjects. Now we can see that either the relation predictions or the EL results for \"Bryant\" are incorrect. Those disagreements provide us an effective way to remove the possible incorrect predictions that cause the incompatibilities.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "On the other hand, the automatically extracted knowledge facts inevitably contain errors, especially for those triples collected from open domain. Extractions with confidence scores will be more than useful for users to make proper decisions according to their requirements, such as trading recall for precision, or supporting approximate queries.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we propose a joint framework to populate an existing KB with new knowledge facts extracted from reliable text resources. The joint framework is designed to address the error propagation issue in a pipeline system, where subtasks are optimized in isolation and locally. We find an optimal configuration from top k results of both subtasks, which maximizes the scores of each step, fulfills the argument type expectations of relations, which can be captured explicitly or implicitly, in the KB, and avoids globally incoherent predictions. We formulate this optimization problem in an Integer Linear Program (ILP) framework, and further adopt a logistic regression model to measure the reliability of the whole process, and assign confidences to all extracted triples to facilitate further applications. The experiments on a real-world case study show that our framework can eliminate error propagations in the pipeline systems by taking relations' argument type expectations and global compatibilities into account, thus outperforms the pipeline approaches based on state-ofthe-art relation extractors by a large margin. Furthermore, we investigate both explicit and implicit type clues for relations, and provide suggestions about which to choose according to the characteristics of existing KBs. Additionally, our proposed confidence estimations can help to achieve a precision of over 85% for a considerable amount of high quality extractions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In the rest of the paper, we first review related work and then define the knowledge base population task that we will address in this paper. Next we detail the proposed framework and present our experiments and results. Finally, we conclude this paper with future directions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011) , containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011) . The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012) , but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012) .",
                "cite_spans": [
                    {
                        "start": 141,
                        "end": 158,
                        "text": "(Ji et al., 2011)",
                        "ref_id": null
                    },
                    {
                        "start": 373,
                        "end": 394,
                        "text": "(Dredze et al., 2010;",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 395,
                        "end": 415,
                        "text": "Tamang et al., 2012;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 416,
                        "end": 437,
                        "text": "Cassidy et al., 2011)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 496,
                        "end": 517,
                        "text": "(Tamang et al., 2012;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 518,
                        "end": 536,
                        "text": "Roth et al., 2012;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 537,
                        "end": 556,
                        "text": "Liu and Zhao, 2012)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 942,
                        "end": 960,
                        "text": "(Sun et al., 2012;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 961,
                        "end": 989,
                        "text": "Monahan and Carpenter, 2012)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Entity linking is a crucial part in many KB re-lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013) . Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013) . There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011) . Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB.",
                "cite_spans": [
                    {
                        "start": 183,
                        "end": 201,
                        "text": "(Han et al., 2011;",
                        "ref_id": null
                    },
                    {
                        "start": 202,
                        "end": 220,
                        "text": "Han and Sun, 2011;",
                        "ref_id": null
                    },
                    {
                        "start": 221,
                        "end": 242,
                        "text": "Ratinov et al., 2011;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 243,
                        "end": 264,
                        "text": "Cheng and Roth, 2013)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 417,
                        "end": 435,
                        "text": "(Han et al., 2011;",
                        "ref_id": null
                    },
                    {
                        "start": 436,
                        "end": 457,
                        "text": "Ratinov et al., 2011;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 458,
                        "end": 468,
                        "text": "Sen, 2012;",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 469,
                        "end": 490,
                        "text": "Cheng and Roth, 2013)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 567,
                        "end": 586,
                        "text": "(Zhou et al., 2010;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 587,
                        "end": 605,
                        "text": "Chen and Ji, 2011)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 608,
                        "end": 625,
                        "text": "Lin et al. (2012)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014) , thus are different from our work.",
                "cite_spans": [
                    {
                        "start": 241,
                        "end": 252,
                        "text": "(ACE, 2004;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 253,
                        "end": 274,
                        "text": "Florian et al., 2006;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 275,
                        "end": 296,
                        "text": "Florian et al., 2010;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 297,
                        "end": 313,
                        "text": "Li and Ji, 2014)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010) . There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) . These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches.",
                "cite_spans": [
                    {
                        "start": 123,
                        "end": 134,
                        "text": "(ACE, 2004;",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 135,
                        "end": 159,
                        "text": "Zhao and Grishman, 2005;",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 160,
                        "end": 176,
                        "text": "Li and Ji, 2014)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 210,
                        "end": 230,
                        "text": "(Fader et al., 2011;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 231,
                        "end": 252,
                        "text": "Carlson et al., 2010)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 410,
                        "end": 430,
                        "text": "(Mintz et al., 2009;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 431,
                        "end": 451,
                        "text": "Riedel et al., 2010;",
                        "ref_id": null
                    },
                    {
                        "start": 452,
                        "end": 474,
                        "text": "Hoffmann et al., 2011;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 475,
                        "end": 497,
                        "text": "Surdeanu et al., 2012)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010) , which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific sentence describes (between a pair of entity mentions in this sentence). Li and Ji (2014) follow the ACE task definitions and present a neat incremental joint framework to simultaneously extract entity mentions and relations by structure perceptron. In contrast, we link entity mentions from a text corpus to their corresponding entities in an ex-isting KB and identify the relations between pairs of entities based on that text corpus. Choi et al. (2006) jointly extracts the expressions and sources of opinion as well as the linking relations (i.e., a source entity expresses an opinion expression) between them, while we focus on jointly modeling EL and RE in open domain, which is a different and challenging task.",
                "cite_spans": [
                    {
                        "start": 164,
                        "end": 184,
                        "text": "(Singh et al., 2013;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 185,
                        "end": 201,
                        "text": "Li and Ji, 2014;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 202,
                        "end": 224,
                        "text": "Kate and Mooney, 2010)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 464,
                        "end": 480,
                        "text": "Li and Ji (2014)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 828,
                        "end": 846,
                        "text": "Choi et al. (2006)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "Since the automatically extracted knowledge facts inevitably contain errors, many approaches manage to assign confidences for those extracted facts (Fader et al., 2011; Wick et al., 2013) . Wick et al. (2013) also point out that confidence estimation should be a crucial part in the automated KB constructions and will play a key role for the wide applications of automatically built KBs. We thus propose to model the reliability of the complete extraction process and take the argument type expectations of the relation, coherence with other predictions and the triples in the existing KB into account for each populated triple.",
                "cite_spans": [
                    {
                        "start": 148,
                        "end": 168,
                        "text": "(Fader et al., 2011;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 169,
                        "end": 187,
                        "text": "Wick et al., 2013)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 190,
                        "end": 208,
                        "text": "Wick et al. (2013)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "We formalize our task as follows. Given a set of entities sampled from an existing KB, E = {e 1 , e 2 , ..., e |E| }, a set of canonicalized relations from the same KB, R = {r 1 , r 2 , ..., r |R| }, a set of sentences extracted from news corpus, SN = {sn 1 , sn 2 , ..., sn |SN | }, each contains two mentions m 1 and m 2 whose candidate entities belong to E, a set of text fragments T = {t 1 , t 2 , ..., t |T | }, where t i contains its corresponding target sentence sn i and acts as its context. Our task is to link those mentions to entities in the given KB, identify the relationship between entity pairs and populate new knowledge facts into the KB.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Task definition",
                "sec_num": "3"
            },
            {
                "text": "We propose to perform joint inference over subtasks involved. For each sentence with two entity mentions, we first employ a preliminary EL model and RE model to obtain entity candidates and possible relation candidates between the two mentions, respectively. Our joint inference framework will then find an optimal assignment by taking the preliminary prediction scores, the argument type expectations of relations and the global compatibilities among the predictions into account. In the task of KBP, an entity pair may appear in multiple sentences as different relation instances, and the crucial point is whether we can identify all the cor- rect relations for an entity pair. Thus, after finding an optimal sentence-level assignment, we aggregate those local predictions by ORing them into the entity pair level. Finally, we employ a regression model to capture the reliability of the complete extraction process.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Framework",
                "sec_num": "4"
            },
            {
                "text": "Entity Linking The preliminary EL model can be any approach which outputs a score for each entity candidate. Note that a recall-oriented model will be more than welcome, since we expect to introduce more potentially correct local predictions into the inference step. In this paper, we adopt an unsupervised approach in (Han et al., 2011) to avoid preparing training data. Note the challenging NIL problem, i.e., identifying which entity mentions do not have corresponding entities in the KB (labeled as NIL) and clustering those mentions, will be our future work. For each mention we retain the entities with top p scores for the succeeding inference step.",
                "cite_spans": [
                    {
                        "start": 319,
                        "end": 337,
                        "text": "(Han et al., 2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Preliminary Models",
                "sec_num": "4.1"
            },
            {
                "text": "The choice of RE model is also broad. Any sentence level extractor whose results are easy to be aggregated to entity pair level can be utilized here (again, a recall-oriented version will be welcome), such as Mintz++ men-tioned in (Surdeanu et al., 2012) , which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) .",
                "cite_spans": [
                    {
                        "start": 231,
                        "end": 254,
                        "text": "(Surdeanu et al., 2012)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 711,
                        "end": 730,
                        "text": "(Chen et al., 2014;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 731,
                        "end": 750,
                        "text": "Mintz et al., 2009;",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 751,
                        "end": 771,
                        "text": "Riedel et al., 2010;",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 772,
                        "end": 794,
                        "text": "Hoffmann et al., 2011)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relation Extraction",
                "sec_num": null
            },
            {
                "text": "In most KBs' schemas, canonicalized relations are designed to expect specific types of entities to be their arguments. For example, in Figure 2 , it is more likely that an entity Kobe Bryant takes the subject position of a relation fb:pro athlete.teams, but it is unlikely for this entity to take the subject position of a relation fb:org.headquarters. Making use of these type requirements can encourage the framework to select relation and entity candidates which are coherent with each other, and discard incoherent choices.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 142,
                        "end": 143,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "In order to obtain the preference scores between the entities in E and the relations in R, we generate two matrices with |E| rows and |R| columns, whose elements sp ij indicates the preference score of entity i and relation j. The matrix S subj is for relations and their subjects, and the matrix S obj is for relations and their objects. We initialize the two matrices using the KB as follows: for entity i and relation j, if relation j takes entity i as its subject/object in the KB, the element at the position (i, j) of the corresponding matrix will be 1, otherwise it will be 0. Note that in our experiments, we do not count the triples that are evaluated in the testing data, to build the matrices. Now the problem is how we can obtain the unknown elements in the matrices.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "Explicit Type Information Intuitively, we should examine whether the explicit types of the entities fulfill the expectations of relations in the KB. For each unknown element S subj (i, j), we first obtain the type of entity i, which is collected from the lowest level of the KB's type hierarchy, and examine whether there is another entity with the same type taking the subject position of relation j in the initial matrix. If such an entity exists, S subj (i, j) = 1, otherwise 0. For example, for the subject Jay Fletcher Vincent and the relation fb:pro athlete.teams, we first obtain the subject's type basketball player, and then we go through the initial matrix and find another entity Kobe Bryant with the same type taking the subject position of fb:pro athlete.teams, indicating that Jay Fletcher Vincent may take the relation fb:pro athlete.teams. The matrix S obj is processed in the same way.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "Implicit Type Expectations In practice, few KBs have well-defined schemas. In order to make our framework more flexible, we need to come up with an approach to implicitly capture the relations' type expectations, which will also be represented as preference scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "Inspired by Riedel et al. (2013) who use a matrix factorization approach to capture the association between textual patterns, relations and entities based on large text corpora, we adopt a collaborative filtering (CF) method to compute the preference scores between entities and relations based on the statistics obtained from an existing KB.",
                "cite_spans": [
                    {
                        "start": 12,
                        "end": 32,
                        "text": "Riedel et al. (2013)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "In CF, the preferences between customers and items are calculated via matrix factorization over the initial customer-item matrix. In our frame-work, we compute the preference scores between entities and relations via the same approach over the two initialized matrices S subj and S obj , resulting in two entity-relation matrices with estimated preference values. We use ALS-WR (Zhou et al., 2008) to process the matrices and compute the preference of a relation taking an entity as its subject and object, respectively. We normalize the preference scores of each entity using their means \u00b5 and standard deviations \u03c3.",
                "cite_spans": [
                    {
                        "start": 378,
                        "end": 397,
                        "text": "(Zhou et al., 2008)",
                        "ref_id": "BIBREF34"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Relations' Expectations for Argument Types",
                "sec_num": "4.2"
            },
            {
                "text": "The second aspect we investigate is whether the extracted triples are compatible with respect to all other knowledge facts. For example, according to the KB, the two relations fb:org.headquarters and fb:pro athlete.teams in Figure 2 cannot share the same entity as their subjects. So if such sharing happens, that will indicate either the predictions of the relations or the entities are incorrect. The clues can be roughly grouped into three categories, namely whether two relations can share the same subjects, whether two relations can share the same objects, and whether one relation's subject can be the other relation's object.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 231,
                        "end": 232,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Compatibilities among Predicted Triples",
                "sec_num": "4.3"
            },
            {
                "text": "Global compatibilities among local predictions have been investigated by several joint models (Li et al., 2011; Li and Ji, 2014; Chen et al., 2014) to eliminate the errors propagating in a pipeline system. Specifically, Chen et al. (2014) utilized the clues with respect to the compatibilities of relations in the task of relation extraction. Following (Li et al., 2011; Chen et al., 2014) , we extend the idea of global compatibilities to the entity and relation predictions during knowledge base population. We examine the pointwise mutual information (PMI) between the argument sets of two relations to collect such clues. For example, if we want to learn whether two relations can share the same subject, we first collect the subject sets of both relations from the KB, and then compute the PMI value between them. If the value is lower than a certain threshold (set to -3 in this paper), the clue that the two relations cannot share the same subject is added. These clues can be easily integrated into an optimization framework in the form of constraints.",
                "cite_spans": [
                    {
                        "start": 94,
                        "end": 111,
                        "text": "(Li et al., 2011;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 112,
                        "end": 128,
                        "text": "Li and Ji, 2014;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 129,
                        "end": 147,
                        "text": "Chen et al., 2014)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 220,
                        "end": 238,
                        "text": "Chen et al. (2014)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 353,
                        "end": 370,
                        "text": "(Li et al., 2011;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 371,
                        "end": 389,
                        "text": "Chen et al., 2014)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compatibilities among Predicted Triples",
                "sec_num": "4.3"
            },
            {
                "text": "Now we describe how we aggregate the above components, and formulate the joint inference problem into an ILP framework. For each candi-date entity e of mention m in text fragment t, we define a boolean decision variable d m,e t , which denotes whether this entity is selected into the final configuration or not. Similarly, for each candidate relation r of fragment t, we define a boolean decision variable d r t . In order to introduce the preference scores into the model, we also need a decision variable d r,m,e t , which denotes whether both relation r and candidate entity e of mention m are selected in t.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "We use s t,m,e el to represent the score of mention m in t disambiguated to entity e, which is output by the EL model, s t,r re representing the score of relation r assigned to t, which is output by the RE model, s r,e p the explicit/implicit preference score between relation r and entity e.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "Our goal is to find the best assignment to the variables d r t and d m,e t , such that it maximizes the overall scores of the two subtasks and the coherence among the preliminary predictions, while satisfying the constraints between the predicted triples as well. Our objective function can be written as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "max el \u00d7 conf ent + re \u00d7 conf rel + sp \u00d7 coh e-r",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "(1) where el, re and sp are three weighting parameters tuned on development set. conf ent is the overall score of entity linking:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "conf ent = t m\u2208M (t) e\u2208Ce(m) s t,m,e el d m,e t (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "where M (t) is the set of mentions in t, C e (m) is the candidate entity set of the mention m. conf rel represents the overall score of relation extraction:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "conf rel = t r\u2208Cr(t) s t,r re d r t (3)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "where C r (t) is the set of candidate relations in t. coh e-r is the coherence between the candidate relations and entities in the framework:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "coh e-r = t r\u2208Cr(t) m\u2208M (t) e\u2208Ce(m)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "s r,e p d r,m,e t (4)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "Now we describe the constraints used in our ILP problem. The first kind of constraints is introduced to ensure that each mention should be disambiguated to only one entity:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "\u2200t, \u2200m \u2208 M (t), e\u2208Ce(m) d m,e t \u2264 1",
                        "eq_num": "(5)"
                    }
                ],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "The second type of constraints ensure that each entity mention pair in one sentence can only take one relation label:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "\u2200t, r\u2208Cr(t)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "d t r \u2264 1 (6)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "The third is introduced to ensure the decision variable d ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "y \u2264 d m 1 ,e t 1 (10) y \u2264 d m 2 ,e t 2 (11) d m 1 ,e t 1 + d m 2 ,e t 2 \u2264 y + 1 (12)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "Then we further add the following constraints for each mention pair to avoid incompatible predictions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "\u2200r 1 \u2208 C r (t 1 ), r 2 \u2208 C r (t 2 ) If (r 1 , r 2 ) \u2208 C sr , p(m 1 ) = subj, p(m 2 ) = subj d r 1 t 1 + d r 2 t 2 + y \u2264 2 (13) If (r 1 , r 2 ) \u2208 C ro , p(m 1 ) = obj, p(m 2 ) = obj d r 1 t 1 + d r 2 t 2 + y \u2264 2 (14) If (r 1 , r 2 ) \u2208 C sro , p(m 1 ) = obj, p(m 2 ) = subj d r 1 t 1 + d r 2 t 2 + y \u2264 2 (15)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "where p(m) returns the position of mention m, either subj (subject) or obj (object). C sr is the pairs of relations which cannot share the same subject, C ro is the pairs of relations which cannot share the same object, C sro is the pairs of relations in which one relation's subject cannot be the other one's object.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "We use IBM ILOG Cplex2 to solve the above ILP problem. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Integer Linear Program Formulation",
                "sec_num": "4.4"
            },
            {
                "text": "The preference score between the relation and the subject.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "The preference score between the relation and the object.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "The ratio of the highest and the second highest relation score in this entity pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "The ratio of the current relation score and the maximum relation score in this entity pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "The ratio of the number of sentences supporting the current relation and the total number of sentences in this entity pair.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "Whether the extracted triple is coherent with the KB according to the constraints in Section 4.3.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real",
                "sec_num": null
            },
            {
                "text": "The automatically extracted triples inevitably contain errors and are often considered as with high recall but low precision. Since our aim is to populate the extracted triples into an existing KB, which requires highly reliable knowledge facts, we need a measure of confidence for those extracted triples, so that others can properly utilize them.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Confidence Estimation for Extracted Triples",
                "sec_num": "4.5"
            },
            {
                "text": "Here, we use a logistic regression model to measure the reliability of the process, how the entities are disambiguated, how the relationships are identified, and whether those predictions are compatible. The features we used are listed in Table 1 , which are all efficiently computable and independent from specific relations or entities. We manually annotate 1000 triples as correct or incorrect to prepare the training data.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 245,
                        "end": 246,
                        "text": "1",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Confidence Estimation for Extracted Triples",
                "sec_num": "4.5"
            },
            {
                "text": "We evaluate the proposed framework in a realworld scenario: given a set of news texts with entity mentions and a KB, a model should find more and accurate new knowledge facts between pairs of those entities.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5"
            },
            {
                "text": "We use New York Times dataset from 2005 to 2007 as the text corpus, and Freebase as the KB. We divide the corpus into two equal parts, one for creating training data for the RE models using the distant supervision strategy (we do not need training data for EL), and the other as the testing data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "5.1"
            },
            {
                "text": "For the convenience of experimentation, we randomly sample a subset of entities for testing. We first collect all sentences containing two mentions which may refer to the sampled entities, and prune them according to: (1)there should be no more than 10 words between the two mentions; (2)the prior probability of the mention referring to the target entity is higher than a threshold (set to 0.1 in this paper), which is set to filter the impossible mappings; (3)the mention pairs should not belong to different clauses. The resulting test set is split into 10 parts and a development set, each with 3500 entity pairs roughly, which leads to averagely 200,000 variables and 900,000 constraints per split and may take 1 hour for Cplex to solve. Note that we do not count the triples that will be evaluated in the testing data when we learn the preferences and the clues from the KB.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "5.1"
            },
            {
                "text": "We compare our framework with three baselines. The first one, ME-pl, is the pipeline system constructed by the entity linker in (Han et al., 2011) and the MaxEnt version of Mintz++ extractor mentioned in (Surdeanu et al., 2012) . The second and third baselines are the pipeline systems constructed by the same linker and two state-ofthe-art DS approaches, MultiR (Hoffmann et al., 2011) and MIML-RE (Surdeanu et al., 2012) , respectively. They are referred to as MultiR-pl and MIML-pl in the rest of this paper.",
                "cite_spans": [
                    {
                        "start": 128,
                        "end": 146,
                        "text": "(Han et al., 2011)",
                        "ref_id": null
                    },
                    {
                        "start": 204,
                        "end": 227,
                        "text": "(Surdeanu et al., 2012)",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 363,
                        "end": 386,
                        "text": "(Hoffmann et al., 2011)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 399,
                        "end": 422,
                        "text": "(Surdeanu et al., 2012)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "5.2"
            },
            {
                "text": "We also implement several variants of our framework to investigate the following two components in our framework: whether to use explicit (E) or implicit (I) argument type expectations, whether to take global (G) compatibilities into account, resulting in four variants: ME-JE, ME-JI, ME-JEG, ME-JIG.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "5.2"
            },
            {
                "text": "We tune the parameters in the objective function on the development set to be re = 1, el = 4, sp = 1. The numbers of preliminary results retained to the inference step are set to p = 2, q = 3. Three metrics used in our experiments include:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "5.2"
            },
            {
                "text": "(1)the precision of extracted triples, which is the ratio of the number of correct triples and the number of total extracted triples; (2)the number of correct triples (NoC); (3)the number of correct triples in the results ranked in top n. The third metric is crucial for KBP, since most users are only interested in the knowledge facts with high confidences. We compare the extracted triples against Freebase to compute the precision, which may underestimate the performance since Freebase is incomplete. Since we do not have exact annotations for the EL, it is difficult to calculate the exact recall. We therefore use NoC instead. We evaluate our framework on the 10 subsets of the testing dataset and compute their means and standard deviations.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Setup",
                "sec_num": "5.2"
            },
            {
                "text": "We are interested to find out: (a)whether the task benefits from the joint inference i.e., can we collect more and correct facts? Or with a higher precision? (b) whether the argument type expectations (explicit and implicit) and global compatibility do their jobs as we expected? And, how do we choose from these components ? (c)whether the framework can work with other RE models? (d)whether we can find a suitable approach to measure the confidence or uncertainty during the extraction so that users or other applications can better utilize the extracted KB facts?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "Let us first look at the performance of the baselines and our framework in Table 2 for an overview. Comparing the three pipeline systems, we can discover that using the same entity linker, MIML-pl performs the best in precision with slightly fewer correct triples, while ME-pl performs the worst. It is not surprising, ME-pl, as a strong and high-recall baseline, outputs the most correct triples. As for the results with high confidences, MultiR-pl outputs more correct triples in the top 50 results than ME-pl, and MIML-pl performs better or comparable than ME-pl in top n results.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 81,
                        "end": 82,
                        "text": "2",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "After performing the joint inference, ME-JE improves ME-pl with 4.1% in precision and 43 more correct triples averagely, and results in better performance in top n results. By taking global compatibilities into consideration, ME-JEG further improve the precision to 34.2% in average with slightly fewer correct triples, indicating that both argument type expectations and global compatibilities are useful in improving the performance: argument type information can help to select the correct and coherent predictions from the candidates EL and RE outputs, while global compatibilities can further prune incorrect triples that cause disagreements, although a few correct ones may be incorrectly eliminated. We can also observe that ME-JIG performs even higher than ME-JEG in overall precision, but ME-JEG collects more correct triples than ME-JIG in the top n predictions, showing that explicit type expectations with more accurate type information may perform better in high confidence results.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "Furthermore, even though MultiR-pl and MIML-pl are based on state-of-the-art RE approaches, our model (for example, ME-JIG) can still outperform them in terms of all metrics, with 4.7% higher in precision than MultiR-pl, 2.5% higher than MIML-pl. Our model can extract 125 more correct triples than MultiR-pl, 164 more than MIML-pl, and perform better in top n results as well.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "In previous RE tasks, Precision-Recall curves are mostly used to evaluate the systems' performances. In our task, since it is difficult to calculate the recall exactly, we use the number of correct triples instead, and plot curves of Precision-NoC to show the performance of the competitors and our approaches in more detail. For each value of NoC, the precision is the average of the ten splits of the testing dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "As shown in Figure 3 , our approaches (ME-JEG and ME-JIG) obtain higher precisions on each NoC value, and the curves are much smoother than Table 3 : The results of our joint frameworks with MultiR sentence extractor.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 19,
                        "end": 20,
                        "text": "3",
                        "ref_id": "FIGREF2"
                    },
                    {
                        "start": 146,
                        "end": 147,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Overall Performance",
                "sec_num": "5.3"
            },
            {
                "text": "NoC Top 50 Top 100 MultiR-pl 31.0 \u00b1 0.8 647 \u00b1 15 39 \u00b1 2 71 \u00b1 3 MultiR-JEG 36.9 \u00b1 0.8 687 \u00b1 15 46 \u00b1 2 88 \u00b1 3 MultiR-JIG 38.5 \u00b1 0.9 700 \u00b1 15 45 \u00b1 2 88 \u00b1 3 the pipeline systems, indicating that our framework is more suitable for harvesting high quality knowledge facts. Comparing the two kinds of type clues, we can see that explicit ones perform better when the confidence control is high and the number of correct triples is small, and then the two are comparable. Since the precision of the triples with high confidences is crucial for the task of KBP, we still suggest choosing the explicit ones when there is a well-defined schema available in the KB, although implicit type expectations can result in higher overall precision.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Approach Precision",
                "sec_num": null
            },
            {
                "text": "The preliminary relation extractor of our framework is not limited to the MaxEnt3 extractor. As seen in Table 3 , MultiR-JEG helps MultiR obtain about 40 more correct triples in average, and achieves 5.9% higher in precision, as well as significant improvements in top n correct predictions. As for MultiR-JIG, the improvements are 7.5% in precision and 53 in number of correct triples. In terms of top n results, the explicit and implicit type expectations perform comparable. We also observe that our framework improves MultiR as much as it does to MaxEnt, indicating our joint framework can generalize well in different RE models. We further plot Precision-NoC curves for MultiR-JEG and MultiR-JIG in Figure 4 , showing that our framework can result in better performance and smoother curves with MultiR extractor. It is interesting to see that with MultiR extractor, the two kinds of expectations perform comparably.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 110,
                        "end": 111,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 711,
                        "end": 712,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Adapting MultiR Sentence Extractor into the Framework",
                "sec_num": "5.4"
            },
            {
                "text": "Now, we will investigate the results from another perspective with the help of confidence estimations. We calculate the precisions of the competitors and our approaches on different confidence thresholds from 0.5 to 1. The results are summarized in Figure 5 . Note that the results across different approaches are not directly comparable, we put them in the same figure only to save space.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 256,
                        "end": 257,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results with Confidence Estimations",
                "sec_num": "5.5"
            },
            {
                "text": "In Figure 5 , intuitively, as the confidence threshold goes up, the extraction precisions should increase, indicating triples with higher confidences are more likely to be correct. However, lower thresholds tend to result in estimations with smaller standard derivations due to those precisions are estimated over much more triples than those with higher thresholds, which means the randomness will be smaller.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 10,
                        "end": 11,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results with Confidence Estimations",
                "sec_num": "5.5"
            },
            {
                "text": "On the other hand, our joint frameworks provide more evidences that can be used to well capture the reliability of an extraction. For example, the precisions of Multir-JIG and ME-JIG both stay around 85% when the confidence is higher than 0.85, with about 120 correct triples, indicating that by setting a proper threshold, we can obtain considerable amount of high quality knowledge facts at an acceptable precision, which is crucial for KBP. However, we cannot harvest such amount of high quality knowledge facts from the other three pipeline systems.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results with Confidence Estimations",
                "sec_num": "5.5"
            },
            {
                "text": "In this paper, we propose a joint framework for the task of populating KBs with new knowledge facts, which performs joint inference on two subtasks, maximizes their preliminary scores, fulfills the type expectations of relations and avoids global incompatibilities with respect to all local predictions to find an optimal assignment. Experimental results show that our framework can significantly eliminate the error propagations in pipeline systems and outperforms competitive pipeline systems with state-of-the-art RE models. Regarding the explicit argument type expectations and the implicit ones, the latter can result in a higher overall precision, while the former performs better in acquiring high quality knowledge facts with higher confidence control, indicating that if the KB has a well-defined schema we can use explicit type requirements for the KBP task, and if not, our model can still perform well by mining the implicit ones. Our framework can also generalize well with other preliminary RE models. Furthermore, we assign extraction confidences to all extracted facts to facilitate further applications. By setting a suitable threshold, our framework can populate high quality reliable knowledge facts to existing KBs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "6"
            },
            {
                "text": "For future work, we will address the NIL issue of EL where we currently assume all entities should be linked to a KB. It would be also interesting to jointly model the two subtasks through structured learning, instead of joint inference only. Currently we only use the coherence of extracted triples and the KB to estimate confidences, which would be nice to directly model the issue in a joint model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions",
                "sec_num": "6"
            },
            {
                "text": "The prefix fb means the relations are defined in Freebase.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://www.cplex.com",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://homepages.inf.ed.ac.uk/ lzhang10/maxent_toolkit.html",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We would like to thank Heng Ji, Kun Xu, Dong Wang and Junyang Rao for their helpful discussions and the anonymous reviewers for their insightful comments that improved the work considerably. This work was supported by the National High Technology R&D Program of China (Grant No. 2012AA011101, 2014AA015102), National Natural Science Foundation of China (Grant No. 61272344, 61202233, 61370055) and the joint project with IBM Research. Any correspondence please refer to Yansong Feng.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "The automatic content extraction projects",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ace",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "ACE. 2004. The automatic content extraction projects. http://projects.ldc.upenn.edu/ace.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Toward an architecture for never-ending language learning",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Carlson",
                        "suffix": ""
                    },
                    {
                        "first": "Justin",
                        "middle": [],
                        "last": "Betteridge",
                        "suffix": ""
                    },
                    {
                        "first": "Byran",
                        "middle": [],
                        "last": "Kisiel",
                        "suffix": ""
                    },
                    {
                        "first": "Burr",
                        "middle": [],
                        "last": "Settles",
                        "suffix": ""
                    },
                    {
                        "first": "Estevam",
                        "middle": [],
                        "last": "Hruschka",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Mitchell",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the Conference on Artificial Intelligence (AAAI)",
                "volume": "",
                "issue": "",
                "pages": "1306--1313",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrew Carlson, Justin Betteridge, Byran Kisiel, Burr Settles, Estevam Hruschka Jr., and Tom Mitchell. 2010. Toward an architecture for never-ending lan- guage learning. In Proceedings of the Conference on Artificial Intelligence (AAAI), pages 1306-1313. AAAI Press.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Entity linking system description",
                "authors": [
                    {
                        "first": "Taylor",
                        "middle": [],
                        "last": "Cassidy",
                        "suffix": ""
                    },
                    {
                        "first": "Zheng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Javier",
                        "middle": [],
                        "last": "Artiles",
                        "suffix": ""
                    },
                    {
                        "first": "Heng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    },
                    {
                        "first": "Hongbo",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Lev-Arie",
                        "middle": [],
                        "last": "Ratinov",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "TAC2011",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji, Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Jiawei Han, and Dan Roth. 2011. Entity linking system description. In TAC2011.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Collaborative ranking: A case study on entity linking",
                "authors": [
                    {
                        "first": "Zheng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Heng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP '11",
                "volume": "",
                "issue": "",
                "pages": "771--781",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zheng Chen and Heng Ji. 2011. Collaborative rank- ing: A case study on entity linking. In Proceedings of the Conference on Empirical Methods in Natu- ral Language Processing, EMNLP '11, pages 771- 781, Stroudsburg, PA, USA. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Encoding relation requirements for relation extraction via joint inference",
                "authors": [
                    {
                        "first": "Liwei",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yansong",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Songfang",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Yong",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Dongyan",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014",
                "volume": "",
                "issue": "",
                "pages": "818--827",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Liwei Chen, Yansong Feng, Songfang Huang, Yong Qin, and Dongyan Zhao. 2014. Encoding relation requirements for relation extraction via joint infer- ence. In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014, pages 818-827, Stroudsburg, PA, USA. Asso- ciation for Computational Linguistics.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Relational inference for wikification",
                "authors": [
                    {
                        "first": "Xiao",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiao Cheng and Dan Roth. 2013. Relational inference for wikification. In EMNLP.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Joint extraction of entities and relations for opinion recognition",
                "authors": [
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Breck",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Cardie",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP '06",
                "volume": "",
                "issue": "",
                "pages": "431--439",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint extraction of entities and relations for opinion recog- nition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Process- ing, EMNLP '06, pages 431-439, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Entity disambiguation for knowledge base population",
                "authors": [
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Dredze",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Mcnamee",
                        "suffix": ""
                    },
                    {
                        "first": "Delip",
                        "middle": [],
                        "last": "Rao",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Gerber",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Finin",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark Dredze, Paul McNamee, Delip Rao, Adam Ger- ber, and Tim Finin. 2010. Entity disambiguation for knowledge base population. In Coling2010.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Identifying relations for open information extraction",
                "authors": [
                    {
                        "first": "Anthony",
                        "middle": [],
                        "last": "Fader",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [],
                        "last": "Soderland",
                        "suffix": ""
                    },
                    {
                        "first": "Oren",
                        "middle": [],
                        "last": "Etzioni",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP '11",
                "volume": "",
                "issue": "",
                "pages": "1535--1545",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information ex- traction. In Proceedings of the Conference on Em- pirical Methods in Natural Language Processing, EMNLP '11, pages 1535-1545, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Factorizing complex models: A case study in mention detection",
                "authors": [
                    {
                        "first": "Radu",
                        "middle": [],
                        "last": "Florian",
                        "suffix": ""
                    },
                    {
                        "first": "Hongyan",
                        "middle": [],
                        "last": "Jing",
                        "suffix": ""
                    },
                    {
                        "first": "Nanda",
                        "middle": [],
                        "last": "Kambhatla",
                        "suffix": ""
                    },
                    {
                        "first": "Imed",
                        "middle": [],
                        "last": "Zitouni",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "473--480",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Radu Florian, Hongyan Jing, Nanda Kambhatla, and Imed Zitouni. 2006. Factorizing complex mod- els: A case study in mention detection. In Proceed- ings of the 21st International Conference on Com- putational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 473-480. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Improving mention detection robustness to noisy input",
                "authors": [
                    {
                        "first": "Radu",
                        "middle": [],
                        "last": "Florian",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [
                            "F"
                        ],
                        "last": "Pitrelli",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    },
                    {
                        "first": "Imed",
                        "middle": [],
                        "last": "Zitouni",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "335--345",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Radu Florian, John F Pitrelli, Salim Roukos, and Imed Zitouni. 2010. Improving mention detection robust- ness to noisy input. In Proceedings of the 2010 Con- ference on Empirical Methods in Natural Language Processing, pages 335-345. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "A generative entitymention model for linking entities with knowledge base",
                "authors": [
                    {
                        "first": "Xianpei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of ACL, HLT '11",
                "volume": "",
                "issue": "",
                "pages": "945--954",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xianpei Han and Le Sun. 2011. A generative entity- mention model for linking entities with knowledge base. In Proceedings of ACL, HLT '11, pages 945- 954, Stroudsburg, PA, USA. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Collective entity linking in web text: a graph-based method",
                "authors": [
                    {
                        "first": "Xianpei",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "SIGIR, SIGIR '11",
                "volume": "",
                "issue": "",
                "pages": "765--774",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In SIGIR, SIGIR '11, pages 765-774, New York, NY, USA. ACM.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Knowledge-based weak supervision for information extraction of overlapping relations",
                "authors": [
                    {
                        "first": "Raphael",
                        "middle": [],
                        "last": "Hoffmann",
                        "suffix": ""
                    },
                    {
                        "first": "Congle",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiao",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [
                            "S"
                        ],
                        "last": "Weld",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th ACL-HLT",
                "volume": "1",
                "issue": "",
                "pages": "541--550",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th ACL-HLT -Volume 1, HLT '11, pages 541-550, Stroudsburg, PA, USA. ACL.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Overview of the tac2011 knowledge base population track",
                "authors": [
                    {
                        "first": "Ji",
                        "middle": [],
                        "last": "Heng",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Grishman",
                        "suffix": ""
                    },
                    {
                        "first": "Hoa",
                        "middle": [],
                        "last": "Dang",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of TAC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Heng Ji, Ralph Grishman, and Hoa Dang. 2011. Overview of the tac2011 knowledge base population track. In Proceedings of TAC.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Joint entity and relation extraction using card-pyramid parsing",
                "authors": [
                    {
                        "first": "Rohit",
                        "middle": [
                            "J"
                        ],
                        "last": "Kate",
                        "suffix": ""
                    },
                    {
                        "first": "Raymond",
                        "middle": [
                            "J"
                        ],
                        "last": "Mooney",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL '10",
                "volume": "",
                "issue": "",
                "pages": "203--212",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rohit J. Kate and Raymond J. Mooney. 2010. Joint entity and relation extraction using card-pyramid parsing. In Proceedings of the Fourteenth Confer- ence on Computational Natural Language Learning, CoNLL '10, pages 203-212, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Incremental joint extraction of entity mentions and relations",
                "authors": [
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Heng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014",
                "volume": "",
                "issue": "",
                "pages": "402--412",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qi Li and Heng Ji. 2014. Incremental joint extrac- tion of entity mentions and relations. In Proceed- ings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014, pages 402- 412, Stroudsburg, PA, USA. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Joint inference for cross-document information extraction",
                "authors": [
                    {
                        "first": "Qi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Anzaroot",
                        "suffix": ""
                    },
                    {
                        "first": "Wen-Pin",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Heng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM '11",
                "volume": "",
                "issue": "",
                "pages": "2225--2228",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qi Li, Sam Anzaroot, Wen-Pin Lin, Xiang Li, and Heng Ji. 2011. Joint inference for cross-document information extraction. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM '11, pages 2225- 2228, New York, NY, USA. ACM.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "No noun phrase left behind: Detecting and typing unlinkable entities",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Oren",
                        "middle": [],
                        "last": "Mausam",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Etzioni",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 EMNLP-CoNLL, EMNLP-CoNLL '12",
                "volume": "",
                "issue": "",
                "pages": "893--903",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas Lin, Mausam, and Oren Etzioni. 2012. No noun phrase left behind: Detecting and typ- ing unlinkable entities. In Proceedings of the 2012 EMNLP-CoNLL, EMNLP-CoNLL '12, pages 893- 903, Stroudsburg, PA, USA. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Pattern based english slot filling system for knowledge base population at tac 2012",
                "authors": [
                    {
                        "first": "Fang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fang Liu and Jun Zhao. 2012. Sweat2012: Pattern based english slot filling system for knowledge base population at tac 2012. In TAC2012.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Distant supervision for relation extraction without labeled data",
                "authors": [
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Mintz",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bills",
                        "suffix": ""
                    },
                    {
                        "first": "Rion",
                        "middle": [],
                        "last": "Snow",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP",
                "volume": "2",
                "issue": "",
                "pages": "1003--1011",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mike Mintz, Steven Bills, Rion Snow, and Dan Ju- rafsky. 2009. Distant supervision for relation ex- traction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP: Volume 2 - Volume 2, ACL '09, pages 1003-1011.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Lorify: A knowledge base from scratch",
                "authors": [
                    {
                        "first": "Sean",
                        "middle": [],
                        "last": "Monahan",
                        "suffix": ""
                    },
                    {
                        "first": "Dean",
                        "middle": [],
                        "last": "Carpenter",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sean Monahan and Dean Carpenter. 2012. Lorify: A knowledge base from scratch. In TAC2012.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia",
                "authors": [
                    {
                        "first": "Lev",
                        "middle": [],
                        "last": "Ratinov",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    },
                    {
                        "first": "Doug",
                        "middle": [],
                        "last": "Downey",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lev Ratinov, Dan Roth, Doug Downey, and Mike An- derson. 2011. Local and global algorithms for dis- ambiguation to wikipedia. In ACL.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Modeling relations and their mentions without labeled text",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Riedel",
                        "suffix": ""
                    },
                    {
                        "first": "Limin",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Machine Learning and Knowledge Discovery in Databases",
                "volume": "6323",
                "issue": "",
                "pages": "148--163",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions with- out labeled text. In Machine Learning and Knowl- edge Discovery in Databases, volume 6323 of Lec- ture Notes in Computer Science, pages 148-163. Springer Berlin / Heidelberg.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Relation extraction with matrix factorization and universal schemas",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Riedel",
                        "suffix": ""
                    },
                    {
                        "first": "Limin",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [
                            "M"
                        ],
                        "last": "Marlin",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL '13)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and Andrew McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Asso- ciation for Computational Linguistics (HLT-NAACL '13), June.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Generalizing from freebase and patterns using cluster-based distant supervision for tac kbp slotfilling 2012",
                "authors": [
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Roth",
                        "suffix": ""
                    },
                    {
                        "first": "Grzegorz",
                        "middle": [],
                        "last": "Chrupala",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Wiegand",
                        "suffix": ""
                    },
                    {
                        "first": "Mittul",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Dietrich",
                        "middle": [],
                        "last": "Klakow",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "TAC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Benjamin Roth, Grzegorz Chrupala, Michael Wiegand, Mittul Singh, and Dietrich Klakow. 2012. General- izing from freebase and patterns using cluster-based distant supervision for tac kbp slotfilling 2012. In TAC2012.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Collective context-aware topic models for entity disambiguation",
                "authors": [
                    {
                        "first": "Prithviraj",
                        "middle": [],
                        "last": "Sen",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 21st International Conference on World Wide Web, WWW '12",
                "volume": "",
                "issue": "",
                "pages": "729--738",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Prithviraj Sen. 2012. Collective context-aware topic models for entity disambiguation. In Proceedings of the 21st International Conference on World Wide Web, WWW '12, pages 729-738, New York, NY, USA. ACM.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Joint inference of entities, relations, and coreference",
                "authors": [
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Riedel",
                        "suffix": ""
                    },
                    {
                        "first": "Brian",
                        "middle": [],
                        "last": "Martin",
                        "suffix": ""
                    },
                    {
                        "first": "Jiaping",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 2013 Workshop on Automated Knowledge Base Construction, AKBC '13",
                "volume": "",
                "issue": "",
                "pages": "1--6",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sameer Singh, Sebastian Riedel, Brian Martin, Jiap- ing Zheng, and Andrew McCallum. 2013. Joint inference of entities, relations, and coreference. In Proceedings of the 2013 Workshop on Automated Knowledge Base Construction, AKBC '13, pages 1- 6, New York, NY, USA. ACM.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Intelius-nyu tac-kbp2012 cold start system",
                "authors": [
                    {
                        "first": "Ang",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Sen",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Yigit",
                        "middle": [],
                        "last": "Kiran",
                        "suffix": ""
                    },
                    {
                        "first": "Shakthi",
                        "middle": [],
                        "last": "Poornima",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Borthwick",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Grishman",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ang Sun, Xin Wang, Sen Xu, Yigit Kiran, Shakthi Poornima, Andrew Borthwick, , and Ralph Grish- man. 2012. Intelius-nyu tac-kbp2012 cold start sys- tem. In TAC2012.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Multiinstance multi-label learning for relation extraction",
                "authors": [
                    {
                        "first": "Mihai",
                        "middle": [],
                        "last": "Surdeanu",
                        "suffix": ""
                    },
                    {
                        "first": "Julie",
                        "middle": [],
                        "last": "Tibshirani",
                        "suffix": ""
                    },
                    {
                        "first": "Ramesh",
                        "middle": [],
                        "last": "Nallapati",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "EMNLP-CoNLL",
                "volume": "",
                "issue": "",
                "pages": "455--465",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mihai Surdeanu, Julie Tibshirani, Ramesh Nallap- ati, and Christopher D. Manning. 2012. Multi- instance multi-label learning for relation extraction. In EMNLP-CoNLL, pages 455-465. ACL.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Entity linking system and slot filling validation system",
                "authors": [
                    {
                        "first": "Suzanne",
                        "middle": [],
                        "last": "Tamang",
                        "suffix": ""
                    },
                    {
                        "first": "Zheng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Heng",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Suzanne Tamang, Zheng Chen, and Heng Ji. 2012. En- tity linking system and slot filling validation system. In TAC2012.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Assessing confidence of knowledge base content with an experimental study in entity resolution",
                "authors": [
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Wick",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Kobren",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "AKBC",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael Wick, Sameer Singh, Ari Kobren, and Andrew McCallum. 2013. Assessing confidence of knowl- edge base content with an experimental study in en- tity resolution. In AKBC2013.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Collective cross-document relation extraction without labelled data",
                "authors": [
                    {
                        "first": "Limin",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Riedel",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of EMNLP, EMNLP '10",
                "volume": "",
                "issue": "",
                "pages": "1013--1023",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Limin Yao, Sebastian Riedel, and Andrew McCallum. 2010. Collective cross-document relation extraction without labelled data. In Proceedings of EMNLP, EMNLP '10, pages 1013-1023, Stroudsburg, PA, USA. ACL.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Extracting relations with integrated information using kernel methods",
                "authors": [
                    {
                        "first": "Shubin",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [],
                        "last": "Grishman",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL '05",
                "volume": "",
                "issue": "",
                "pages": "419--426",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meet- ing on Association for Computational Linguistics, ACL '05, pages 419-426, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Large-scale parallel collaborative filtering for the netflix prize",
                "authors": [
                    {
                        "first": "Yunhong",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Dennis",
                        "middle": [],
                        "last": "Wilkinson",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Schreiber",
                        "suffix": ""
                    },
                    {
                        "first": "Rong",
                        "middle": [],
                        "last": "Pan",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, AAIM '08",
                "volume": "",
                "issue": "",
                "pages": "337--348",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yunhong Zhou, Dennis Wilkinson, Robert Schreiber, and Rong Pan. 2008. Large-scale parallel collabo- rative filtering for the netflix prize. In Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, AAIM '08, pages 337-348, Berlin, Heidelberg. Springer- Verlag.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Resolving surface forms to wikipedia topics",
                "authors": [
                    {
                        "first": "Yiping",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Lan",
                        "middle": [],
                        "last": "Nie",
                        "suffix": ""
                    },
                    {
                        "first": "Omid",
                        "middle": [],
                        "last": "Rouhani-Kalleh",
                        "suffix": ""
                    },
                    {
                        "first": "Flavian",
                        "middle": [],
                        "last": "Vasile",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Gaffney",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, COLING '10",
                "volume": "",
                "issue": "",
                "pages": "1335--1343",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Fla- vian Vasile, and Scott Gaffney. 2010. Resolving surface forms to wikipedia topics. In Proceedings of the 23rd International Conference on Computa- tional Linguistics, COLING '10, pages 1335-1343, Stroudsburg, PA, USA. Association for Computa- tional Linguistics.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "\u2026 [Bryant] is a private university located in [Smithfield]. \u2026 Sentence 2 : \u2026 Shaq and [Bryant] led the [Lakers] to three consecutive championships \u2026",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 1: Two example sentences from which we can harvest knowledge facts.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "Figure 3: The numbers of correct triples v.s. the precisions for different approaches.",
                "uris": null,
                "fig_num": "3",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "text": "Figure 4: The numbers of correct triples v.s. the precisions for approaches with MultiR extractor.",
                "uris": null,
                "fig_num": "45",
                "type_str": "figure"
            },
            "TABREF0": {
                "content": "<table><tr><td>Bryant, Illinois</td><td/><td>Smithfield, Rhode Island</td></tr><tr><td>Bryant University</td><td>fb:people.place_of_birth</td><td>Smithfield, Illinois</td></tr><tr><td>...</td><td>fb:org.headquarters</td><td>...</td></tr><tr><td>Kobe Bryant</td><td/><td/></tr><tr><td colspan=\"2\">Disagreement!</td><td/></tr><tr><td>Kobe Bryant</td><td>fb:pro_athlete.teams</td><td>Los Angeles Lakers</td></tr><tr><td>Bryant University</td><td>fb:business.leader_of</td><td>Laguna Lakers</td></tr><tr><td>Bryant, Illinois</td><td/><td>...</td></tr><tr><td>...</td><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Sentence 1: \u2026 [Bryant] is a private university located in [Smithfield]. \u2026 Sentence 2: \u2026 Shaq and [Bryant] led the [Lakers] to three consecutive championships from 2000 to 2002. \u2026",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "content": "<table><tr><td colspan=\"4\">r,m,e t sponding variables d r equals 1 if and only if both the corre-t and d m,e t equal 1.</td></tr><tr><td colspan=\"4\">\u2200t, \u2200r \u2208 C r (t), \u2200m \u2208 M (t), \u2200e \u2208 C e (m)</td></tr><tr><td/><td/><td/><td>d r,m,e t</td><td>\u2264 d r t</td><td>(7)</td></tr><tr><td/><td/><td colspan=\"2\">d r,m,e t</td><td>\u2264 d m,e t</td><td>(8)</td></tr><tr><td/><td colspan=\"2\">d r t + d m,e t</td><td>\u2264 d r,m,e t</td><td>+ 1 (9)</td></tr><tr><td>t 1</td><td>and d m 2 ,e t 2</td><td colspan=\"2\">equal 1. So we add</td></tr><tr><td colspan=\"4\">the following constraints for each mention pair m 1</td></tr><tr><td colspan=\"4\">and m 2 satisfies the previous condition:</td></tr></table>",
                "type_str": "table",
                "text": "As for the compatibility constraints, we need to introduce another type of boolean decision variables. If a mention m 1 in t 1 and another mention m 2 in t 2 share an entity candidate e, we add a variable y for this mention pair, which equals 1 if and only if both d m 1 ,e",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "content": "<table><tr><td>Type</td></tr></table>",
                "type_str": "table",
                "text": "The features used to calculate the confidence scores. Feature Real The RE score of the relation. Real The EL score of the subject. Real The EL score of the object.",
                "html": null,
                "num": null
            },
            "TABREF3": {
                "content": "<table><tr><td colspan=\"2\">Approach Precision</td><td>NoC</td><td>Top 50 Top 100</td></tr><tr><td>ME-pl</td><td colspan=\"3\">28.7 \u00b1 0.8 725 \u00b1 12 38 \u00b1 2 75 \u00b1 4</td></tr><tr><td>ME-JE</td><td colspan=\"3\">32.8 \u00b1 0.7 768 \u00b1 10 46 \u00b1 2 90 \u00b1 3</td></tr><tr><td colspan=\"4\">ME-JEG 34.2 \u00b1 0.5 757 \u00b1 8 46 \u00b1 2 90 \u00b1 3</td></tr><tr><td>ME-JI</td><td colspan=\"3\">34.5 \u00b1 1.0 784 \u00b1 9 43 \u00b1 3 88 \u00b1 3</td></tr><tr><td colspan=\"4\">ME-JIG 35.7 \u00b1 1.0 772 \u00b1 8 43 \u00b1 3 88 \u00b1 4</td></tr></table>",
                "type_str": "table",
                "text": "The results of our joint frameworks and the three baselines. MultiR-pl 31.0 \u00b1 0.8 647 \u00b1 15 39 \u00b1 2 71 \u00b1 3 MIML-pl 33.2 \u00b1 0.6 608 \u00b1 16 40 \u00b1 3 74 \u00b1 5",
                "html": null,
                "num": null
            }
        }
    }
}