{
    "paper_id": "D14-1187",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:13:59.704379Z"
    },
    "title": "Cross-Lingual Part-of-Speech Tagging through Ambiguous Learning",
    "authors": [
        {
            "first": "Guillaume",
            "middle": [],
            "last": "Wisniewski",
            "suffix": "",
            "affiliation": {},
            "email": "wisniews@limsi.fr"
        },
        {
            "first": "Nicolas",
            "middle": [],
            "last": "P\u00e9cheux",
            "suffix": "",
            "affiliation": {},
            "email": "pecheux@limsi.fr"
        },
        {
            "first": "Souhir",
            "middle": [],
            "last": "Gahbiche-Braham",
            "suffix": "",
            "affiliation": {},
            "email": "souhir@limsi.fr"
        },
        {
            "first": "Fran\u00e7ois",
            "middle": [],
            "last": "Yvon",
            "suffix": "",
            "affiliation": {},
            "email": "yvon@limsi.fr"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "When Part-of-Speech annotated data is scarce, e.g. for under-resourced languages, one can turn to cross-lingual transfer and crawled dictionaries to collect partially supervised data. We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model. Experiments on ten languages show significant improvements over prior state of the art performance.",
    "pdf_parse": {
        "paper_id": "D14-1187",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "When Part-of-Speech annotated data is scarce, e.g. for under-resourced languages, one can turn to cross-lingual transfer and crawled dictionaries to collect partially supervised data. We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model. Experiments on ten languages show significant improvements over prior state of the art performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "In the past two decades, supervised Machine Learning techniques have established new performance standards for many NLP tasks. Their success however crucially depends on the availability of annotated in-domain data, a not so common situation. This means that for many application domains and/or less-resourced languages, alternative ML techniques need to be designed to accommodate unannotated or partially annotated data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Several attempts have recently been made to mitigate the lack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001) , who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Pad\u00f3 and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few.",
                "cite_spans": [
                    {
                        "start": 447,
                        "end": 469,
                        "text": "Yarowsky et al. (2001)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 563,
                        "end": 581,
                        "text": "(Hwa et al., 2005;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 582,
                        "end": 603,
                        "text": "Ganchev et al., 2009)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 635,
                        "end": 658,
                        "text": "(Pad\u00f3 and Lapata, 2009;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 659,
                        "end": 687,
                        "text": "Kozhevnikov and Titov, 2013;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 688,
                        "end": 714,
                        "text": "van der Plas et al., 2014)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 749,
                        "end": 767,
                        "text": "(Kim et al., 2012)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014) , the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013) .",
                "cite_spans": [
                    {
                        "start": 253,
                        "end": 275,
                        "text": "Yarowsky et al. (2001)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 457,
                        "end": 481,
                        "text": "(Wang and Manning, 2014)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 589,
                        "end": 606,
                        "text": "(Li et al., 2012;",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 607,
                        "end": 630,
                        "text": "T\u00e4ckstr\u00f6m et al., 2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 692,
                        "end": 715,
                        "text": "(Ganchev and Das, 2013)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we reproduce the weakly supervised setting of T\u00e4ckstr\u00f6m et al. (2013) . By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2).",
                "cite_spans": [
                    {
                        "start": 61,
                        "end": 84,
                        "text": "T\u00e4ckstr\u00f6m et al. (2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 152,
                        "end": 173,
                        "text": "(Bordes et al., 2010;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 174,
                        "end": 192,
                        "text": "Cour et al., 2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Projecting POS information across languages relies on a rather strong assumption that morphosyntactic categories in the source language can be directly related to the categories in the target language, which might not always be warranted (Evans and Levinson, 2009; Broschart, 2009) . The universal reduced POS tagset proposed by Petrov et al. (2012) and X (a catch-all for other categories). These labels have been chosen for their stability across languages and for their usefulness in various multilingual applications. In the rest of this work, all annotations are mapped to this universal tagset.",
                "cite_spans": [
                    {
                        "start": 238,
                        "end": 264,
                        "text": "(Evans and Levinson, 2009;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 265,
                        "end": 281,
                        "text": "Broschart, 2009)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 329,
                        "end": 349,
                        "text": "Petrov et al. (2012)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "Transfer-based methods have shown to be very effective, even if projected labels only deliver a noisy supervision, due to tagging (of the source language) and other alignment errors (Yarowsky et al., 2001) . While this uncertainty can be addressed in several ways, recent works have proposed to combine projected labels with monolingual information in order to filter out invalid label sequences (Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013) . In this work we follow T\u00e4ckstr\u00f6m et al. (2013) and use two families of constraints:",
                "cite_spans": [
                    {
                        "start": 182,
                        "end": 205,
                        "text": "(Yarowsky et al., 2001)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 396,
                        "end": 418,
                        "text": "(Das and Petrov, 2011;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 419,
                        "end": 442,
                        "text": "T\u00e4ckstr\u00f6m et al., 2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 468,
                        "end": 491,
                        "text": "T\u00e4ckstr\u00f6m et al. (2013)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "Token constraints rely on word alignments to project labels of source words to target words through alignment links. Table 1 shows that, dependening on the language, only 50-80% of the target tokens would benefit from label transfer.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 123,
                        "end": 124,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "Type constraints rely on a tag dictionary to define the set of possible tags for each word type. Type constraints reduce the possible labels for a given word and help filtering out crosslingual transfer errors (up to 20%, as shown in Table 1). As in (T\u00e4ckstr\u00f6m et al., 2013) , we consider two different dictionaries. The first one is extracted automatically from Wiktionary, 1 using the method of (Li et al., 2012) . The second tag dictionary is built by using for each word the two most frequently projected POS labels from the training data. 2 In contrast to T\u00e4ckstr\u00f6m et al. (2013) we use the intersection 3 of the two type constraints instead of their union. Table 1 shows the precision and recall of the resulting constraints on the test data.",
                "cite_spans": [
                    {
                        "start": 250,
                        "end": 274,
                        "text": "(T\u00e4ckstr\u00f6m et al., 2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 397,
                        "end": 414,
                        "text": "(Li et al., 2012)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 669,
                        "end": 670,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "These two information sources are merged according to the rules of T\u00e4ckstr\u00f6m et al. (2013) . These rules assume that type constraints are more reliable than token constraints and should take precedence: by default, a given word is associated to the set of possible tags licensed type constraints; additionally, when a POS tag can be projected through alignment and also satisfies the type constraints, then it is actually projected, thereby providing a full (yet noisy) supervision.",
                "cite_spans": [
                    {
                        "start": 67,
                        "end": 90,
                        "text": "T\u00e4ckstr\u00f6m et al. (2013)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "As shown in Table 1 , token and type constraints complement each other effectively and greatly reduce label ambiguity. However, the transfer method sketched above associates each target word with a set of possible labels, of which only one is true. This situation is less favorable than standard supervised learning in which one unique gold label is available for each occurrence. We describe in the following section how to learn from this ambiguous supervision information.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 18,
                        "end": 19,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Projecting Labels across Aligned Corpora",
                "sec_num": "2"
            },
            {
                "text": "We use a history-based model (Black et al., 1992) with a LaSO-like training method (Daum\u00e9 and Marcu, 2005) . History-based models reduce structured prediction to a sequence of multi-class classification problems. The prediction of a complex structure (here, a sequence of POS tags) is thus modeled as a sequential decision problem: at each position in the sequence, a multiclass classifier is used to make a decision, using features that describe both the input structure and the history of past decisions (i.e. the partially annotated sequence). Let x = (x i ) n i=1 denote the observed sequence and Y be the set of possible labels (in our case the 12 universal POS tags). Inference consists in predicting labels one after the other using, for instance, a linear model:",
                "cite_spans": [
                    {
                        "start": 29,
                        "end": 49,
                        "text": "(Black et al., 1992)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 83,
                        "end": 106,
                        "text": "(Daum\u00e9 and Marcu, 2005)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "y * i = arg max y\u2208Y w|\u03c6(x, i, y, h i ) (1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "where \u2022|\u2022 is the standard dot product operation, y * i the predicted label for position i, w the weight vector, h i = y * 1 , ..., y * i-1 the history of past decisions and \u03c6 a joint feature map. Inference can therefore be seen as a greedy search in the space of the # {Y} n possible labelings of the input sequence. Trading off the global optimality of inference for additional flexibility in the design of features and long range dependencies between labels has proved useful for many sequence labeling tasks in NLP (Tsuruoka et al., 2011) .",
                "cite_spans": [
                    {
                        "start": 518,
                        "end": 541,
                        "text": "(Tsuruoka et al., 2011)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "The training procedure, sketched in Algorithm 1, consists in performing inference on each input sentence and correcting the weight vector each time a wrong decision is made. Importantly (Ross and Bagnell, 2010) , the history used during training has to be made of the previous predicted labels so that the training samples reflect the fact that the history will be imperfectly known at test time.",
                "cite_spans": [
                    {
                        "start": 186,
                        "end": 210,
                        "text": "(Ross and Bagnell, 2010)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "This reduction of sequence labeling to multiclass classification allows us to learn a sequence model in an ambiguous setting by building on the theoretical results of Bordes et al. (2010) and Cour et al. (2011) . The decision about the correctness of a prediction and the weight updates can be adapted to the amount of supervision information that is available.",
                "cite_spans": [
                    {
                        "start": 167,
                        "end": 191,
                        "text": "Bordes et al. (2010) and",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 192,
                        "end": 210,
                        "text": "Cour et al. (2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "Full Supervision In a fully supervised setting, the correct label is known for each word token: a decision is thus considered wrong when this gold label is not predicted. In this case, a standard perceptron update is performed:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "w t+1 \u2190 w t -\u03c6 (x, i, y * i , h i )+\u03c6 (x, i, \u0177i , h i ) (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "where y * i and \u0177i are the predicted and the gold label, respectively. This update is a stochastic gradient step that increases the score of the gold label while decreasing the score of the predicted label.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "Ambiguous Supervision During training, each observation i is now associated with a set of possible labels, denoted by \u0176i . In this case, a decision is considered wrong when the predicted label is not in \u0176i and the weight vector is updated as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "w t+1 \u2190 w t -\u03c6 (x, i, y * i , h i )+ \u0177i \u2208 \u0176i \u03c6 (x, i, \u0177i , h i )",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "(3) Compared to (2), this rule uniformly increases the scores of all the labels in \u0176i .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "It can be shown (Bordes et al., 2010; Cour et al., 2011) , under mild assumptions (namely that two labels never systematically co-occur in the supervision information), that the update rule (3) enables to learn a classifier in an ambiguous setting, as if the gold labels were known. Intuitively, as long as two labels are not systematically cooccurring in \u0176, updates will reinforce the correct labels more often than the spurious ones; at the end of training, the highest scoring label should therefore be the correct one.",
                "cite_spans": [
                    {
                        "start": 16,
                        "end": 37,
                        "text": "(Bordes et al., 2010;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 38,
                        "end": 56,
                        "text": "Cour et al., 2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "Algorithm 1 Training algorithm. In the ambiguous setting, \u0176i contains all possible labels; in the supervised setting, it only contains the gold label.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "w MOSES pipeline, using the intersection heuristic that only retains the most reliable alignment links.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "The English side of the bitext is tagged using a standard linear CRF trained on the Penn Treebank. Tags are then transferred to the target language using the procedure described in Section 2. For each language, we train a tagger using the method described in Section 3 with T = 100 000 iterations6 using a feature set similar to the one of Li et al. (2012) and T\u00e4ckstr\u00f6m et al. (2013) . The baseline system is our reimplementation of the partially observed CRF model of T\u00e4ckstr\u00f6m et al. (2013) . Evaluation is carried out on the test sets of treebanks for which manual gold tags are known. For Czech and Greek, we use the CoNLL'07 Shared Task on Dependency Parsing; for Arabic, the Arabic Treebank; and otherwise the data of the Universal Dependency Treebank Project (McDonald et al., 2013) . Tagging performance is evaluated with the standard error rate.",
                "cite_spans": [
                    {
                        "start": 340,
                        "end": 356,
                        "text": "Li et al. (2012)",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 361,
                        "end": 384,
                        "text": "T\u00e4ckstr\u00f6m et al. (2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 470,
                        "end": 493,
                        "text": "T\u00e4ckstr\u00f6m et al. (2013)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 767,
                        "end": 790,
                        "text": "(McDonald et al., 2013)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modeling Sequences under Ambiguous Supervision",
                "sec_num": "3"
            },
            {
                "text": "Table 2 summarizes the performance achieved by our method trained in the ambiguous setting (HBAL) and by our re-implementation of the partially supervised CRF baseline. As an upper bound, we also report the score of our method when trained in a supervised (HBSL) settings considering the training part of the various treebanks, when it is available.7 For the sake of comparison, we also list the best scores of previous studies. Note, however, that a direct comparison with these results is not completely fair as these systems were not trained and evaluated with the same exact resources (corpora,8 type constraints, alignments, etc). Also note that the state-of-theart scores have been achieved by different models, which have been selected based on their scores on the test set and not on a validation set. 9Experimental results show that HBAL significantly outperforms, on all considered languages but one, the partially observed CRF that was trained and tested in the same setting.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "4.1"
            },
            {
                "text": "The performance of our new method still falls short of the performance of a fully supervised POS tagger: for instance, in Spanish, full supervision reduces the error rate by a factor of 4. A finegrained error analysis shows that many errors of HBAL directly result from the fact that, contrary to the fully supervised learner HBSL, our ambiguous setting suffers from a train/test mismatch, which has two main consequences. First, the train and test sets do not follow exactly the same normalization and tokenization conventions, which is an obvious source of mistakes. Second, and more importantly, many errors are caused by systematic differences between the test tags and the supervised tags (i.e. the English side of the bitext and Wiktionary). While some of these differences are linguistically well-justified and reflect fundamental differences in the language structure and usage, others seem to be merely due to arbitrary annotation conventions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "For instance, in Greek, proper names are labeled either as X (when they refer to a foreigner and are not transliterated) or as NOUN (in all other cases), while they are always labeled as NOUN in English.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "In French and in Greek, contractions of a preposition and a determiner such as '\u03c3\u03c4\u03bf' ('\u03c3\u03b5 \u03c4\u03bf', meaning 'to the') or 'aux' ('\u00e0 les' also meaning 'to the') are labeled as ADP in the Universal Dependency Treebank but as DET in Wiktionary and are usually aligned with a determiner in the parallel corpora. In the Penn Treebank, quantifiers like 'few' or 'little' are generally used in conjunction with a determiner ('a few years', 'a little parable', ...) and labeled as ADJ; the corresponding Spanish constructions lack an article ('mucho tempio', 'pocos a\u00f1os', ...) and the quantifiers are therefore labeled as DET. Capturing such subtle differences is hardly possible without prior knowledge and specifically tailored features.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "This annotation mismatch problem is all the more important in settings like ours, that rely on several, independently designed, information sources, which follow contradictory annotation conventions and for which the mapping to the universal tagset is actually error-prone (Zhang et al., 2012) . To illustrate this point, we ran three additional experiments to assess the impact of the train/test mismatch.",
                "cite_spans": [
                    {
                        "start": 273,
                        "end": 293,
                        "text": "(Zhang et al., 2012)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "We first designed a control experiment in which the type constraints were manually completed with the gold labels of the most frequent errors of HBAL. These errors generally concern function words and can be assumed to result from systematic differences in the annotations rather than prediction errors. For instance, for French the type constraints for 'du', 'des', 'au' and 'aux' were corrected from DET to ADP. The resulting model, denoted 'HBAL + matched POS' in Table 2 , significantly outperforms HBAL, stressing the divergence in the different annotation conventions.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 473,
                        "end": 474,
                        "text": "2",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "Additionally, in order to approximate the ambiguous setting train/test mismatch, we learn two fully supervised Spanish taggers on the same training data as HBAL, using two different strategies to obtain labeled data. We first use HBSL (which was trained on the treebank) to automatically label the target side of the parallel corpus. In this setting, the POS tagger is trained with data from a different domain, but labeled with the same annotation scheme as a the test set. Learning with this fully supervised data yields an error rate of 4.2% for Spanish, almost twice as much as HBSL, bringing into light the impact of domain shift. We then use a generic tagger, FREELING,10 to label the training data, this time with possible additional inconsistent annotations. The corresponding error rate for Spanish was 6.1%, to be compared with the 8.2% achieved by HBAL. The last two control experiments show that many of the remaining labeling errors seem to be due to domain and convention mismatches rather to the transfer/ambiguous setting, as supervised models also suffer from very similar conditions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "These observations show that the evaluation of transfer-based methods suffer from several biases. Their results must therefore be interpreted with great care.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "4.2"
            },
            {
                "text": "In this paper, we have presented a novel learning methodology to learn from ambiguous supervision information, and used it to train several POS taggers. Using this method, we have been able to achieve performance that surpasses the best reported results, sometimes by a wide margin. Further work will attempt to better analyse these results, which could be caused by several subtle differences between HBAL and the baseline system. Nonetheless, these experiments confirm that cross-lingual projection of annotations have the potential to help in building very efficient POS taggers with very little monolingual supervision data. Our analysis of these results also suggests that, for this task, additional gains might be more easily obtained by fixing systematic biases introduced by conflicting mappings between tags or by train/test domain mismatch than by designing more sophisticated weakly supervised learners.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "5"
            },
            {
                "text": "(2013) filter the tag distribution with a threshold to build the projected type constraints.3 If the intersection is empty we use the constraints from Wiktionary first, if also empty, the projected constraints then, and by default the whole tag set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Resources considered in the related works are not freely available, which prevents us from presenting a more complete comparison.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "All resources and features used in our experiments are thoroughly documented in the supplementary material.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Preliminary experiments showed that increasing the number of iterations T in Algorithm 1 has no significant impact.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In this setting, HBSL implements an averaged perceptron, and achieves results that are similar to those obtained with standard linear CRF.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The test sets are only the same for Czech, Greek and Swedish.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The partially observed CRF is the best model in(T\u00e4ckstr\u00f6m et al., 2013) only for German (de), Greek (el) and Swedish (sv), and uses only type constraints extracted from Wiktionary.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "http://nlp.lsi.upc.edu/freeling/",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We wish to thank Thomas Lavergne and Alexandre Allauzen for early feedback and for providing us with the partially observed CRF implementation. We also thank the anonymous reviewers for their helpful comments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Towards history-based grammars: Using richer models for probabilistic parsing",
                "authors": [
                    {
                        "first": "Ezra",
                        "middle": [],
                        "last": "Black",
                        "suffix": ""
                    },
                    {
                        "first": "Fred",
                        "middle": [],
                        "last": "Jelinek",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Lafferty",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [
                            "M"
                        ],
                        "last": "Magerman",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Mercer",
                        "suffix": ""
                    },
                    {
                        "first": "Salim",
                        "middle": [],
                        "last": "Roukos",
                        "suffix": ""
                    }
                ],
                "year": 1992,
                "venue": "Proceedings of the Workshop on Speech and Natural Language, HLT '91",
                "volume": "",
                "issue": "",
                "pages": "134--139",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ezra Black, Fred Jelinek, John Lafferty, David M. Magerman, Robert Mercer, and Salim Roukos. 1992. Towards history-based grammars: Using richer models for probabilistic parsing. In Proceed- ings of the Workshop on Speech and Natural Lan- guage, HLT '91, pages 134-139, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Label ranking under ambiguous supervision for learning semantic correspondences",
                "authors": [
                    {
                        "first": "Antoine",
                        "middle": [],
                        "last": "Bordes",
                        "suffix": ""
                    },
                    {
                        "first": "Nicolas",
                        "middle": [],
                        "last": "Usunier",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "103--110",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Antoine Bordes, Nicolas Usunier, and Jason Weston. 2010. Label ranking under ambiguous supervision for learning semantic correspondences. In ICML, pages 103-110.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Why Tongan does it differently: Categorial distinctions in a language without nouns and verbs",
                "authors": [
                    {
                        "first": "J\u00fcrgen",
                        "middle": [],
                        "last": "Broschart",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Journal of Machine Learning Research",
                "volume": "1",
                "issue": "",
                "pages": "1501--1536",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J\u00fcrgen Broschart. 2009. Why Tongan does it differ- ently: Categorial distinctions in a language without nouns and verbs. Linguistic Typology, 1:123-166, 10. Timothee Cour, Ben Sapp, and Ben Taskar. 2011. Learning from partial labels. Journal of Machine Learning Research, 12:1501-1536, July.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Unsupervised part-of-speech tagging with bilingual graph-based projections",
                "authors": [
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Slav",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "600--609",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies -Volume 1, HLT '11, pages 600-609, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Learning as search optimization: Approximate large margin methods for structured prediction",
                "authors": [
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": ",",
                        "middle": [],
                        "last": "Iii",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 22Nd International Conference on Machine Learning, ICML '05",
                "volume": "",
                "issue": "",
                "pages": "169--176",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hal Daum\u00e9, III and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In Proceedings of the 22Nd International Conference on Machine Learning, ICML '05, pages 169-176, New York, NY, USA. ACM.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "The myth of language universals: Language diversity and its importance for cognitive science",
                "authors": [
                    {
                        "first": "Nicholas",
                        "middle": [],
                        "last": "Evans",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [
                            "C"
                        ],
                        "last": "Levinson",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Behavioral and Brain Sciences",
                "volume": "32",
                "issue": "",
                "pages": "429--448",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nicholas Evans and Stephen C. Levinson. 2009. The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and Brain Sciences, 32:429-448, 10.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Crosslingual discriminative learning of sequence models with posterior regularization",
                "authors": [
                    {
                        "first": "Kuzman",
                        "middle": [],
                        "last": "Ganchev",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kuzman Ganchev and Dipanjan Das. 2013. Cross- lingual discriminative learning of sequence models with posterior regularization. In Proceedings of the 2013 Conference on Empirical Methods in Natu- ral Language Processing, pages 1996-2006, Seattle, Washington, USA, October. Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Dependency grammar induction via bitext projection constraints",
                "authors": [
                    {
                        "first": "Kuzman",
                        "middle": [],
                        "last": "Ganchev",
                        "suffix": ""
                    },
                    {
                        "first": "Jennifer",
                        "middle": [],
                        "last": "Gillenwater",
                        "suffix": ""
                    },
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Taskar",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP",
                "volume": "1",
                "issue": "",
                "pages": "369--377",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 -Volume 1, ACL '09, pages 369-377, Stroudsburg, PA, USA. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Bootstrapping parsers via syntactic projection across parallel texts",
                "authors": [
                    {
                        "first": "Rebecca",
                        "middle": [],
                        "last": "Hwa",
                        "suffix": ""
                    },
                    {
                        "first": "Philip",
                        "middle": [],
                        "last": "Resnik",
                        "suffix": ""
                    },
                    {
                        "first": "Amy",
                        "middle": [],
                        "last": "Weinberg",
                        "suffix": ""
                    },
                    {
                        "first": "Clara",
                        "middle": [],
                        "last": "Cabezas",
                        "suffix": ""
                    },
                    {
                        "first": "Okan",
                        "middle": [],
                        "last": "Kolak",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Nat. Lang. Eng",
                "volume": "11",
                "issue": "3",
                "pages": "311--325",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Nat. Lang. Eng., 11(3):311-325, September.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Multilingual named entity recognition using parallel data and metadata from wikipedia",
                "authors": [
                    {
                        "first": "Sungchul",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    },
                    {
                        "first": "Hwanjo",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers",
                "volume": "1",
                "issue": "",
                "pages": "694--702",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sungchul Kim, Kristina Toutanova, and Hwanjo Yu. 2012. Multilingual named entity recognition using parallel data and metadata from wikipedia. In Pro- ceedings of the 50th Annual Meeting of the Associ- ation for Computational Linguistics: Long Papers -Volume 1, ACL '12, pages 694-702, Stroudsburg, PA, USA. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Crosslingual transfer of semantic role labeling models",
                "authors": [
                    {
                        "first": "Mikhail",
                        "middle": [],
                        "last": "Kozhevnikov",
                        "suffix": ""
                    },
                    {
                        "first": "Ivan",
                        "middle": [],
                        "last": "Titov",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1190--1200",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mikhail Kozhevnikov and Ivan Titov. 2013. Cross- lingual transfer of semantic role labeling models. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1190-1200, Sofia, Bulgaria, August. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Wiki-ly supervised part-of-speech tagging",
                "authors": [
                    {
                        "first": "Shen",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Jo\u00e3o",
                        "middle": [
                            "V"
                        ],
                        "last": "Gra\u00e7a",
                        "suffix": ""
                    },
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Taskar",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL '12",
                "volume": "",
                "issue": "",
                "pages": "1389--1398",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shen Li, Jo\u00e3o V. Gra\u00e7a, and Ben Taskar. 2012. Wiki-ly supervised part-of-speech tagging. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL '12, pages 1389-1398, Stroudsburg, PA, USA. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Universal dependency annotation for multilingual parsing",
                "authors": [
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    },
                    {
                        "first": "Yvonne",
                        "middle": [],
                        "last": "Quirmbach-Brundage",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Kuzman",
                        "middle": [],
                        "last": "Ganchev",
                        "suffix": ""
                    },
                    {
                        "first": "Keith",
                        "middle": [],
                        "last": "Hall",
                        "suffix": ""
                    },
                    {
                        "first": "Slav",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Oscar",
                        "middle": [],
                        "last": "T\u00e4ckstr\u00f6m",
                        "suffix": ""
                    },
                    {
                        "first": "Claudia",
                        "middle": [],
                        "last": "Bedini",
                        "suffix": ""
                    },
                    {
                        "first": "N\u00faria",
                        "middle": [],
                        "last": "Bertomeu Castell\u00f3",
                        "suffix": ""
                    },
                    {
                        "first": "Jungmee",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics",
                "volume": "2",
                "issue": "",
                "pages": "92--97",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ryan McDonald, Joakim Nivre, Yvonne Quirmbach- Brundage, Yoav Goldberg, Dipanjan Das, Kuz- man Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T\u00e4ckstr\u00f6m, Claudia Bedini, N\u00faria Bertomeu Castell\u00f3, and Jungmee Lee. 2013. Uni- versal dependency annotation for multilingual pars- ing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Vol- ume 2: Short Papers), pages 92-97, Sofia, Bulgaria, August. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Crosslingual annotation projection of semantic roles",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Pad\u00f3",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "J. Artif. Int. Res",
                "volume": "36",
                "issue": "1",
                "pages": "307--340",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Pad\u00f3 and Mirella Lapata. 2009. Cross- lingual annotation projection of semantic roles. J. Artif. Int. Res., 36(1):307-340, September.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "A universal part-of-speech tagset",
                "authors": [
                    {
                        "first": "Slav",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald ; Khalid",
                        "suffix": ""
                    },
                    {
                        "first": "Thierry",
                        "middle": [],
                        "last": "Choukri",
                        "suffix": ""
                    },
                    {
                        "first": "Mehmet",
                        "middle": [],
                        "last": "Declerck",
                        "suffix": ""
                    },
                    {
                        "first": "Bente",
                        "middle": [],
                        "last": "Ugur Dogan",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [],
                        "last": "Maegaard",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Mariani",
                        "suffix": ""
                    },
                    {
                        "first": "Stelios",
                        "middle": [],
                        "last": "Odijk",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Piperidis",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Nicoletta Cal- zolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, ed- itors, Proceedings of the Eight International Con- ference on Language Resources and Evaluation (LREC'12), Istanbul, Turkey, may. European Lan- guage Resources Association (ELRA).",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Efficient reductions for imitation learning",
                "authors": [
                    {
                        "first": "St\u00e9phane",
                        "middle": [],
                        "last": "Ross",
                        "suffix": ""
                    },
                    {
                        "first": "Drew",
                        "middle": [],
                        "last": "Bagnell",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "AISTATS",
                "volume": "",
                "issue": "",
                "pages": "661--668",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "St\u00e9phane Ross and Drew Bagnell. 2010. Efficient re- ductions for imitation learning. In AISTATS, pages 661-668.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Learning with lookahead: Can history-based models rival globally optimized models?",
                "authors": [
                    {
                        "first": "Yoshimasa",
                        "middle": [],
                        "last": "Tsuruoka",
                        "suffix": ""
                    },
                    {
                        "first": "Yusuke",
                        "middle": [],
                        "last": "Miyao",
                        "suffix": ""
                    },
                    {
                        "first": "Jun'ichi",
                        "middle": [],
                        "last": "Kazama",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning",
                "volume": "",
                "issue": "",
                "pages": "238--246",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yoshimasa Tsuruoka, Yusuke Miyao, and Jun'ichi Kazama. 2011. Learning with lookahead: Can history-based models rival globally optimized mod- els? In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 238-246, Portland, Oregon, USA, June. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Token and type constraints for cross-lingual part-of-speech tagging",
                "authors": [
                    {
                        "first": "Oscar",
                        "middle": [],
                        "last": "T\u00e4ckstr\u00f6m",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Slav",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [],
                        "last": "Mcdonald",
                        "suffix": ""
                    },
                    {
                        "first": "Joakim",
                        "middle": [],
                        "last": "Nivre",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1--12",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Oscar T\u00e4ckstr\u00f6m, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tag- ging. Transactions of the Association for Computa- tional Linguistics, 1:1-12.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Global methods for cross-lingual semantic role and predicate labelling",
                "authors": [
                    {
                        "first": "Lonneke",
                        "middle": [],
                        "last": "Van Der Plas",
                        "suffix": ""
                    },
                    {
                        "first": "Marianna",
                        "middle": [],
                        "last": "Apidianaki",
                        "suffix": ""
                    },
                    {
                        "first": "Chenhua",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
                "volume": "",
                "issue": "",
                "pages": "1279--1290",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lonneke van der Plas, Marianna Apidianaki, and Chen- hua Chen. 2014. Global methods for cross-lingual semantic role and predicate labelling. In Proceed- ings of COLING 2014, the 25th International Con- ference on Computational Linguistics: Technical Papers, pages 1279-1290, Dublin, Ireland, August. Dublin City University and Association for Compu- tational Linguistics.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Cross-lingual projected expectation regularization for weakly supervised learning",
                "authors": [
                    {
                        "first": "Mengqiu",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Transactions of the ACL",
                "volume": "2",
                "issue": "",
                "pages": "55--66",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mengqiu Wang and Christopher D. Manning. 2014. Cross-lingual projected expectation regularization for weakly supervised learning. Transactions of the ACL, 2:55-66, February.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Inducing multilingual text analysis tools via robust projection across aligned corpora",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Yarowsky",
                        "suffix": ""
                    },
                    {
                        "first": "Grace",
                        "middle": [],
                        "last": "Ngai",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Wicentowski",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "Proceedings of the First International Conference on Human Language Technology Research, HLT '01",
                "volume": "",
                "issue": "",
                "pages": "1--8",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Yarowsky, Grace Ngai, and Richard Wicen- towski. 2001. Inducing multilingual text analy- sis tools via robust projection across aligned cor- pora. In Proceedings of the First International Con- ference on Human Language Technology Research, HLT '01, pages 1-8, Stroudsburg, PA, USA. Asso- ciation for Computational Linguistics.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Learning to map into a universal pos tagset",
                "authors": [
                    {
                        "first": "Yuan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Roi",
                        "middle": [],
                        "last": "Reichart",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Amir",
                        "middle": [],
                        "last": "Globerson",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL '12",
                "volume": "",
                "issue": "",
                "pages": "1368--1378",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yuan Zhang, Roi Reichart, Regina Barzilay, and Amir Globerson. 2012. Learning to map into a univer- sal pos tagset. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan- guage Processing and Computational Natural Lan- guage Learning, EMNLP-CoNLL '12, pages 1368- 1378, Stroudsburg, PA, USA. Association for Com- putational Linguistics.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "http://www.wiktionary.org/ 2 This heuristic is similar to the way T\u00e4ckstr\u00f6m et al.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "TABREF1": {
                "content": "<table><tr><td>0 \u2190 0</td><td/></tr><tr><td colspan=\"2\">for t \u2208 1, T do</td></tr><tr><td colspan=\"2\">Randomly pick example x,</td><td>\u0177</td></tr><tr><td colspan=\"2\">h \u2190 empty list</td></tr><tr><td colspan=\"2\">for i \u2208 1, n do</td></tr><tr><td colspan=\"3\">y  *  i = arg max y\u2208Y w t |\u03c6(x, i, y, h i ) if y  *  i / \u2208 \u0176i then w t+1 \u2190 update(w t , x, i, \u0176i , y  *  i , h i )</td></tr><tr><td>end if</td><td/></tr><tr><td colspan=\"2\">push(y  *  i , h)</td></tr><tr><td>end for</td><td/></tr><tr><td>end for return 1 T</td><td>T t=1 w t</td></tr><tr><td colspan=\"2\">4 Empirical Study</td></tr><tr><td colspan=\"3\">Datasets Our approach is evaluated on 10 lan-</td></tr><tr><td colspan=\"3\">guages that present very different characteristics</td></tr><tr><td colspan=\"3\">and cover several language families. 4 In all our ex-</td></tr><tr><td colspan=\"3\">periments we use English as the source language.</td></tr><tr><td colspan=\"3\">Parallel sentences 5 are aligned with the standard</td></tr></table>",
                "type_str": "table",
                "text": "Error rate (in %) achieved by the method described in Sec. 3 trained in an ambiguous (HBAL) or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results.",
                "html": null,
                "num": null
            }
        }
    }
}