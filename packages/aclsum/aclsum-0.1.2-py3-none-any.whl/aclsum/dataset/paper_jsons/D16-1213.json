{
    "paper_id": "D16-1213",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:30:45.608582Z"
    },
    "title": "BrainBench: A Brain-Image Test Suite for Distributional Semantic Models",
    "authors": [
        {
            "first": "Haoyan",
            "middle": [],
            "last": "Xu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Victoria Victoria",
                "location": {
                    "region": "BC",
                    "country": "Canada"
                }
            },
            "email": ""
        },
        {
            "first": "Brian",
            "middle": [],
            "last": "Murphy",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Queen's University Belfast Belfast",
                "location": {
                    "region": "Northern Ireland",
                    "country": "UK"
                }
            },
            "email": "brian.murphy@qub.ac.uk"
        },
        {
            "first": "Alona",
            "middle": [],
            "last": "Fyshe",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Victoria Victoria",
                "location": {
                    "region": "BC",
                    "country": "Canada"
                }
            },
            "email": "afyshe@uvic.ca"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "The brain is the locus of our language ability, and so brain images can be used to ground linguistic theories. Here we introduce Brain-Bench, a lightweight system for testing distributional models of word semantics. We compare the performance of several models, and show that the performance on brain-image tasks differs from the performance on behavioral tasks. We release our benchmark test as part of a web service.",
    "pdf_parse": {
        "paper_id": "D16-1213",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "The brain is the locus of our language ability, and so brain images can be used to ground linguistic theories. Here we introduce Brain-Bench, a lightweight system for testing distributional models of word semantics. We compare the performance of several models, and show that the performance on brain-image tasks differs from the performance on behavioral tasks. We release our benchmark test as part of a web service.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "There is active debate over how we should test semantic models. In fact, in 2016 there was an entire workshop dedicated to the testing of semantic representations (RepEval, 2016) . Several before us have argued for the usage of brain data to test semantic models (Anderson et al., 2013; Murphy et al., 2012; Anderson et al., 2015) , as a brain image represents a snapshot of one person's own semantic representation. Still, testing semantic models against brain imaging data is rarely done by those not intimately involved in psycholinguistics or neurolinguistics. This may be due to a lack of familiarity with neuroimaging methods and publicly available datasets.",
                "cite_spans": [
                    {
                        "start": 163,
                        "end": 178,
                        "text": "(RepEval, 2016)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 263,
                        "end": 286,
                        "text": "(Anderson et al., 2013;",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 287,
                        "end": 307,
                        "text": "Murphy et al., 2012;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 308,
                        "end": 330,
                        "text": "Anderson et al., 2015)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "We present the first iteration of BrainBench, a new system that makes it easy to test semantic models using brain imaging data (Available at http://www.langlearnlab.cs.uvic. ca/brainbench/). Our system has methodology that is similar to popular tests based on behavioral * Corresponding Author data (see Section 2.2), and has the additional benefit of being fast enough to offer as a web service.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Here we outline the set of tasks we used to evaluate several popular Distributional Semantic (DS) models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "The Tasks",
                "sec_num": "2"
            },
            {
                "text": "For BrainBench we use two brain image datasets collected while participants viewed 60 concrete nouns with line drawings (Mitchell et al., 2008; Sudre et al., 2012) . One dataset was collected using fMRI (Functional Magnetic Resonance Imaging) and one with MEG (Magnetoencephalography). Each dataset has 9 participants, but the participants sets are disjoint, thus there are 18 unique participants in all. Though the stimuli is shared across the two experiments, as we will see, MEG and fMRI are very different recording modalities and thus the data are not redundant. fMRI measures the change in blood oxygen levels in the brain, which varies according to the amount of work being done by a particular brain area. An fMRI image is a 3D volume of the brain where each point in the volume (called a voxel) represents brain activity at a particular place in the brain. In the fMRI dataset used here, each voxel represents a 3mm x 3mm x 5mm area of the brain. Each of the 60 words was presented 6 times in random order, for a total of 360 brain images. The number of voxels depends on the size and shape of a person's brain, but there are around 20,000 voxels per participant in this dataset.",
                "cite_spans": [
                    {
                        "start": 120,
                        "end": 143,
                        "text": "(Mitchell et al., 2008;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 144,
                        "end": 163,
                        "text": "Sudre et al., 2012)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Brain Image Data",
                "sec_num": "2.1"
            },
            {
                "text": "MEG measures the magnetic field caused by many neurons firing in the same direction at the same time. This signal is very weak, and so must be measured in a magnetically shielded room. The MEG machine is essentially a large helmet with 306 sensors that measure aspects of the magnetic fields at different locations in the brain. A MEG brain image is the time signals recorded from each of these sensors. Here, the sampling rate is 200 Hz. For each word, the MEG recording is 800ms long resulting in 306 \u00d7 160 data points. Each of the words was presented 20 times (in random order) for a total of 1200 brain images. For simplicity we will use the term \"brain image feature\" to refer to both fMRI voxels and MEG sensor/time points.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Brain Image Data",
                "sec_num": "2.1"
            },
            {
                "text": "A non-trivial portion of our participants' brain activity may be driven by the low-level visual properties of the word/line-drawing stimulus, rather than by semantics. As there is a possibility of confounding visual properties with semantic properties, we have attempted to remove the activity attributable to visual properties from the brain images. In total we have 11 visual features which include things like the length of the word, the number of white pixels, and features of the line drawing (Sudre et al., 2012) . To remove the visual stimulus' contribution to the signal, we train a regression model that predicts the signal in each brain image feature as a function of the 11 visual features. We then subtract the predicted value from the observed value of the brain image feature. This process is known as \"partialling out\" an effect. Thus, the signal that remains in the brain image will not be correlated with the visual stimuli, and should only be related to the semantics of the word itself (or noise).",
                "cite_spans": [
                    {
                        "start": 498,
                        "end": 518,
                        "text": "(Sudre et al., 2012)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Brain Image Data",
                "sec_num": "2.1"
            },
            {
                "text": "Brain images are quite noisy, so we used the methodology from Mitchell et al. (2008) to select the most stable brain image features for each of the 18 participants. The stability metric assigns a high score to features that show strong self-correlation over presentations of the same word. We noticed that tuning the number of features to keep made little or no difference in the absolute ordering of the different DS models. Thus, we use the optimal number of features averaged over all 6 DS models described in Section 3: the top 13% of MEG sensor/time points, and 3% of fMRI voxels. Finally, we average all brain images corresponding to repetitions of the same word.",
                "cite_spans": [
                    {
                        "start": 62,
                        "end": 84,
                        "text": "Mitchell et al. (2008)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Brain Image Data",
                "sec_num": "2.1"
            },
            {
                "text": "We include, for comparison, four popular word vector evaluation benchmarks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Behavioral Tasks",
                "sec_num": "2.2"
            },
            {
                "text": "MEN This dataset contains 3,000 word pairs, such that each word appears frequently in two separate corpora. Human participants were presented with two word pairs and asked to choose the word pair that was more related, resulting in a ranking of relatedness amongst word pairs (Bruni and Baroni, 2013) .",
                "cite_spans": [
                    {
                        "start": 276,
                        "end": 300,
                        "text": "(Bruni and Baroni, 2013)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Behavioral Tasks",
                "sec_num": "2.2"
            },
            {
                "text": "SimLex-999 A word pairing task meant to specifically target similarity rather than the more broad \"relatedness\" (Hill et al., 2015) .",
                "cite_spans": [
                    {
                        "start": 112,
                        "end": 131,
                        "text": "(Hill et al., 2015)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Behavioral Tasks",
                "sec_num": "2.2"
            },
            {
                "text": "A set of 353 word pairs with relatedness ratings (Finkelstein et al., 2002) . This dataset was subsequently split into sets where the pairs denote similarity and relatedness, named WS-353-SIM and WS-353-REL, respectively (Agirre et al., 2009) .",
                "cite_spans": [
                    {
                        "start": 49,
                        "end": 75,
                        "text": "(Finkelstein et al., 2002)",
                        "ref_id": null
                    },
                    {
                        "start": 221,
                        "end": 242,
                        "text": "(Agirre et al., 2009)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "WS-353-[SIM|REL]",
                "sec_num": null
            },
            {
                "text": "We test six semantic models against both the fMRI and behavioral datasets. The six models are: Skip-gram: A neural network trained to predict the words before and after the current word, given the current word. We selected a model with 300 dimensions trained on the Google news corpus (Mikolov et al., 2013) .",
                "cite_spans": [
                    {
                        "start": 285,
                        "end": 307,
                        "text": "(Mikolov et al., 2013)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Glove: A regression-based model that combines global context information (term-document cooccurrence) with local information (small windows of word-word cooccurrence) (Pennington et al., 2014) . This 300-dimensional model was trained on the Wikipedia and Gigaword 5 corpora combined.",
                "cite_spans": [
                    {
                        "start": 167,
                        "end": 192,
                        "text": "(Pennington et al., 2014)",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "RNN: A recurrent neural network with 640dimensional hidden vectors. These models are trained to predict the next word in a sequence and have the ability to encode (theoretically) infinitely distant contextual information (Mikolov et al., 2011) . The model was trained on broadcast news transcriptions.",
                "cite_spans": [
                    {
                        "start": 221,
                        "end": 243,
                        "text": "(Mikolov et al., 2011)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Global: A neural network model that incorporates global and local information, like that of the Glove model (Huang et al., 2012) . This model is our smallest, with dimension 50, and was trained on Wikipedia.",
                "cite_spans": [
                    {
                        "start": 108,
                        "end": 128,
                        "text": "(Huang et al., 2012)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Cross-lingual: A tool that projects distributional representations from multiple language into a shared representational space (Faruqui and Dyer, 2014 ).",
                "cite_spans": [
                    {
                        "start": 127,
                        "end": 150,
                        "text": "(Faruqui and Dyer, 2014",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Here we use the German-English model (512 dimensions), trained on the WMT-2011 corpus.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Non-distributional: This model is based solely on hand-crafted linguistic resources (Faruqui and Dyer, 2015) . Several resources like WordNet (Fellbaum, 1998) and FrameNet (Baker et al., 1998) are combined to make very sparse word vector representations. Due to their sparsity, these vectors are of very high dimension (171, 839) . This is a particularly interesting model because it is not built from a corpus (unlike every other model in this list).",
                "cite_spans": [
                    {
                        "start": 84,
                        "end": 108,
                        "text": "(Faruqui and Dyer, 2015)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 142,
                        "end": 158,
                        "text": "(Fellbaum, 1998)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 163,
                        "end": 192,
                        "text": "FrameNet (Baker et al., 1998)",
                        "ref_id": null
                    },
                    {
                        "start": 319,
                        "end": 324,
                        "text": "(171,",
                        "ref_id": null
                    },
                    {
                        "start": 325,
                        "end": 329,
                        "text": "839)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Note that we are not aiming to compare the goodness of any of these distributional models, as they are trained on different corpora with different algorithms. Instead, we wish to compare the patterns of performance on behavioral benchmarks to that of a brain-image based task.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Distributional Models",
                "sec_num": "3"
            },
            {
                "text": "Each of the behavioral tasks included here assigns a similarity score to word pairs. For each DS model we calculate the correlation between the vectors for every pair of words in the behavioral datasets. We then calculate the correlation between the DS vector correlations and the behavioral scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "We follow a very similar methodology for the brain image datasets. Let us represent each DS model with a matrix X \u2208 R w\u00d7p where w is the number of words for which we have brain images (here w = 60), and p is the number of dimensions in a particular DS model. From X we calculate the correlation between each pair of word vectors, resulting in a matrix C DS \u2208 R w\u00d7w .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "Let us represent each participant's brain images with a matrix Y \u2208 R w\u00d7v where v is the number of selected brain image features. From this matrix we calculate the correlation between each pair of brain images, resulting in a matrix C BI \u2208 R w\u00d7w (BI for brain image). This final representation is similar to the behavioral tasks above, but now we have a simi-larity measure for every pair of words in our dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "Here is where the evaluation for brain imaging tasks differs from the behavioral tasks. Instead of measuring the correlation between C BI and C DS , as is done in Representational Similarity Analysis (RSA) (Kriegeskorte et al., 2008) , we use the testing methodology from Mitchell et al. (2008) , which we will refer to as the 2 vs. 2 test. The 2 vs. 2 test was developed to help detect statistically significant predictions on brain imaging data, and, compared to RSA, can better differentiate the performance of a model from chance. We perform a 2 vs. 2 test for all pairs of C DS and C BI (that is, for every pair of DS model and fMRI/MEG participant).",
                "cite_spans": [
                    {
                        "start": 206,
                        "end": 233,
                        "text": "(Kriegeskorte et al., 2008)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 272,
                        "end": 294,
                        "text": "Mitchell et al. (2008)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "For each 2 vs. 2 test we select the same two words (rows) w 1 , w 2 from C DS and C BI . We omit the columns which correspond to the correlation to w 1 and w 2 , as they contain a perfect signal for the 2 vs. 2 test. We now have four vectors, C DS (w 1 ), C DS (w 2 ), C BI (w 1 ) and C BI (w 2 ), all of length w -2. We compute the correlation (corr) between vectors derived from C DS and C BI to see if:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "corr(C DS (w 1 ), C BI (w 1 )) + corr(C DS (w 2 ), C BI (w 2 ))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "(the correlation of correctly matched rows: w 1 to w 1 and w 2 to w 2 ) is greater than: corr(C DS (w 1 ), C BI (w 2 )) + corr(C DS (w 2 ), C BI (w 1 ))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "(the correlation of incorrectly matched rows). If the correctly matched rows are more similar than incorrectly matched rows, then the 2 vs. 2 test is considered correct. We perform the 2 vs. 2 test for all possible pairs of words, for 1770 tests in total. The 2 vs. 2 accuracy is the percentage of 2 vs. 2 tests correct. Chance is 50%.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "Our process of computing 2 vs. 2 accuracy over rows of a correlation matrix is different than the original methodology for these datasets (Mitchell et al., 2008; Sudre et al., 2012) . Previous work trained regression models that took brain images as input and predicted the dimensions of a DS model as output. Training these regression models for all 1770 pairs of words takes hours to complete, whereas the test we suggest here is much faster, and the correlation matrices C BI can be computed ahead of time. This makes the tests fast enough to offer as a web service. We hope our web offering will remove barriers to the wider adoption of brain-based tests from within the computational linguistics community. ",
                "cite_spans": [
                    {
                        "start": 138,
                        "end": 161,
                        "text": "(Mitchell et al., 2008;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 162,
                        "end": 181,
                        "text": "Sudre et al., 2012)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "2019",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methodology",
                "sec_num": "4"
            },
            {
                "text": "Figure 1 shows the results for each of the DS models against the fMRI and MEG datasets. On average, the Skip-gram, Glove and Cross-lingual models perform quite well, whereas the multi-layer NNs (RNN, Global) perform less well. The one DS model to be built from hand-crafted resources (Nondistributional) performs poorly on both brain image tests.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "As previously mentioned, we are not claiming to show that any one of the DS models is better than any other. Indeed, that would be comparing apples to oranges, as each DS model is trained with a different algorithm on a different corpus. Instead, notice that the pattern of performance for the fMRI task is remarkably similar to the pattern on the MEN behavioral task. This is interesting given that our dataset contains only 60 words and the MEN dataset contains > 700. On the MEG data, the Cross-lingual model performs best, and its performance pattern is unlike any of the behavioral tasks in Figure 2 . The averaged BrainBench results are most similar to the results for WS-353-REL. However, averaging the results together may be misleading, as the fMRI and MEG result patterns are different.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 603,
                        "end": 604,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "There are some caveats about the analyses herein. Firstly, the brain-based tests include only 60 concrete nouns, so they will necessarily favor distributional models with good noun representations, regardless of the representations of other parts of speech. We are currently working with various research groups to expand the number of brain-image datasets included in this benchmark to have a more diverse test base. The behavioral benchmarks were not reduced to include only the 60 words for which we have brain data, because this would have rendered the benchmarks essentially useless, as very rarely are a pair of the 60 words from the brain image data scored as a pair in the behavioral benchmarks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussion",
                "sec_num": "6"
            },
            {
                "text": "We have presented our new system, BrainBench, which is a fast and lightweight alternative to previous methods for comparing DS models to brain images. Our proposed methodology is more similar to well-known behavioral tasks, as BrainBench also uses the similarity of words as a proxy for meaning. We hope that this contribution will bring brain imaging tests \"to the masses\" and encourage discussion around the testing of DS models against brain imaging data.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches",
                "authors": [
                    {
                        "first": "Eneko",
                        "middle": [],
                        "last": "Agirre",
                        "suffix": ""
                    },
                    {
                        "first": "Enrique",
                        "middle": [],
                        "last": "Alfonseca",
                        "suffix": ""
                    },
                    {
                        "first": "Keith",
                        "middle": [],
                        "last": "Hall",
                        "suffix": ""
                    },
                    {
                        "first": "Jana",
                        "middle": [],
                        "last": "Kravalova",
                        "suffix": ""
                    },
                    {
                        "first": "Marius",
                        "middle": [],
                        "last": "Pas",
                        "suffix": ""
                    },
                    {
                        "first": "Aitor",
                        "middle": [],
                        "last": "Soroa",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL",
                "volume": "",
                "issue": "",
                "pages": "19--27",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "2009] Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pas, and Aitor Soroa. 2009. A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches. In Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 19-27.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Reading visually embodied meaning from the brain: Visually grounded computational models decode visual-object mental imagery induced by written text",
                "authors": [
                    {
                        "first": "Anderson",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Proceedings of the 36th annual meeting on Association for Computational Linguistics",
                "volume": "120",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anderson et al.2013] Andrew J Anderson, Elia Bruni, Ulisse Bordignon, Massimo Poesio, and Marco Ba- roni. 2013. Of words , eyes and brains : Correlat- ing image-based distributional semantic models with neural representations of concepts. In Proceedings of the Conference on Empirical Methods on Natural Lan- guage Processing. [Anderson et al.2015] Andrew James Anderson, Elia Bruni, Alessandro Lopopolo, Massimo Poesio, and Marco Baroni. 2015. Reading visually embodied meaning from the brain: Visually grounded compu- tational models decode visual-object mental imagery induced by written text. NeuroImage, 120:309-322. [Baker et al.1998] Collin F. Cf Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 36th annual meeting on Association for Computational Linguistics -, vol- ume 1, page 86. Association for Computational Lin- guistics.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Improving vector space word representations using multilingual correlation",
                "authors": [
                    {
                        "first": "Baroni",
                        "middle": [],
                        "last": "Bruni",
                        "suffix": ""
                    },
                    {
                        "first": "Elia",
                        "middle": [],
                        "last": "Bruni",
                        "suffix": ""
                    },
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Baroni",
                        "suffix": ""
                    },
                    {
                        "first": "Manaal",
                        "middle": [],
                        "last": "Faruqui",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the",
                "volume": "48",
                "issue": "",
                "pages": "462--471",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bruni and Baroni2013] Elia Bruni and Marco Baroni. 2013. Multimodal Distributional Semantics. Journal of Artificial Intelligence Research, 48. [Faruqui and Dyer2014] Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. Proceedings of the European Association for Computational Linguistics, pages 462-471.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Non-distributional Word Vector Representations. Acl-2015",
                "authors": [
                    {
                        "first": "Dyer",
                        "middle": [],
                        "last": "Faruqui",
                        "suffix": ""
                    },
                    {
                        "first": "Manaal",
                        "middle": [],
                        "last": "Faruqui",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "464--469",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Faruqui and Dyer2015] Manaal Faruqui and Chris Dyer. 2015. Non-distributional Word Vector Representa- tions. Acl-2015, pages 464-469.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "WordNet: An Electronic Lexical Database",
                "authors": [
                    {
                        "first": "Christiane",
                        "middle": [],
                        "last": "Fellbaum",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Lev Finkelstein",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cam- bridge, MA. [Finkelstein et al.2002] Lev Finkelstein, Evgeniy",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Placing search in context: the concept revisited",
                "authors": [
                    {
                        "first": "Yossi",
                        "middle": [],
                        "last": "Gabrilovich",
                        "suffix": ""
                    },
                    {
                        "first": "Ehud",
                        "middle": [],
                        "last": "Matias",
                        "suffix": ""
                    },
                    {
                        "first": "Zach",
                        "middle": [],
                        "last": "Rivlin",
                        "suffix": ""
                    },
                    {
                        "first": "Gadi",
                        "middle": [],
                        "last": "Solan",
                        "suffix": ""
                    },
                    {
                        "first": "Eytan",
                        "middle": [],
                        "last": "Wolfman",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ruppin",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Felix Hill, Roi Reichart, and Anna Korhonen",
                "volume": "20",
                "issue": "",
                "pages": "665--695",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2002. Placing search in context: the concept revisited. ACM Transactions on Information Systems, 20(1):116-131. [Hill et al.2015] Felix Hill, Roi Reichart, and Anna Ko- rhonen. 2015. SimLex-999: Evaluating Semantic Models with (Genuine) Similarity Estimation. Com- putational Linguistics, 41(4):665-695.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Representational similarity analysis -connecting the branches of systems neuroscience",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers",
                "volume": "1",
                "issue": "",
                "pages": "1--4",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Huang et al.2012] Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Ng. 2012. Improving word representations via global context and multiple word prototypes. Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 873-882. [Kriegeskorte et al.2008] Nikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini. 2008. Representational similarity analysis -connecting the branches of sys- tems neuroscience. Frontiers in systems neuroscience, 2(November):4, jan. [Mikolov et al.2011] Tom\u00e1\u0161 Mikolov, Stefan Kombrink, Anoop Deoras, Luk\u00e1\u0161 Burget, and Jan \u010cernock\u00fd. 2011. RNNLM -Recurrent Neural Network Lan- guage Modeling Toolkit. In Proceedings of Auto- matic Speech Recognition and Understanding (ASRU), pages 1-4.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Efficient Estimation of Word Representations in Vector Space",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the International Conference on Learning Representations (ICLR 2013)",
                "volume": "",
                "issue": "",
                "pages": "1--12",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mikolov et al.2013] Tomas Mikolov, Greg Corrado, Kai Chen, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. Proceedings of the International Conference on Learning Representa- tions (ICLR 2013), pages 1-12.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Predicting human brain activity associated with the meanings of nouns",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mitchell",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Science",
                "volume": "320",
                "issue": "5880",
                "pages": "1191--1195",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mitchell et al.2008] Tom M Mitchell, Svetlana V Shinkareva, Andrew Carlson, Kai-Min Chang, Vi- cente L Malave, Robert A Mason, and Marcel Adam Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science (New York, N.Y.), 320(5880):1191-5, may.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Selecting Corpus-Semantic Models for Neurolinguistic Decoding",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Murphy",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "First Joint Conference on Lexical and Computational Semantics (*SEM)",
                "volume": "",
                "issue": "",
                "pages": "114--123",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Murphy et al.2012] Brian Murphy, Partha Talukdar, and Tom Mitchell. 2012. Selecting Corpus-Semantic Models for Neurolinguistic Decoding. In First Joint Conference on Lexical and Computational Semantics (*SEM), pages 114-123, Montreal, Quebec, Canada. [Pennington et al.2014] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. GloVe : Global Vectors for Word Representation. In Con- ference on Empirical Methods in Natural Language Processing, Doha, Qatar.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "RepEval workshop, ACL",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Repeval",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "RepEval. 2016. RepEval workshop, ACL. https://sites.google.com/site/ repevalacl16/.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Tracking Neural Coding of Perceptual and Semantic Features of Concrete Nouns",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Sudre",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "NeuroImage",
                "volume": "62",
                "issue": "1",
                "pages": "463--451",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sudre et al.2012] Gustavo Sudre, Dean Pomerleau, Mark Palatucci, Leila Wehbe, Alona Fyshe, Riitta Salmelin, and Tom Mitchell. 2012. Tracking Neural Coding of Perceptual and Semantic Features of Concrete Nouns. NeuroImage, 62(1):463-451, may.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Performance of Distributional Semantic models on the brain-image datasets.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Performance of Distributional Semantic models on several benchmark behavioral tasks.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            }
        }
    }
}