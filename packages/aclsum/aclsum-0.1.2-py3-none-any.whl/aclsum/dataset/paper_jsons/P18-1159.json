{
    "paper_id": "P18-1159",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2023-06-16T12:00:14.968367Z"
    },
    "title": "Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension",
    "authors": [
        {
            "first": "Zhen",
            "middle": [],
            "last": "Wang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Baidu Inc",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "wangzhen24@baidu.com"
        },
        {
            "first": "Jiachen",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Baidu Inc",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "liujiachen@baidu.com"
        },
        {
            "first": "Xinyan",
            "middle": [],
            "last": "Xiao",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Baidu Inc",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "xiaoxinyan@baidu.com"
        },
        {
            "first": "Yajuan",
            "middle": [],
            "last": "Lyu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Baidu Inc",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "lvyajuan@baidu.com"
        },
        {
            "first": "Tian",
            "middle": [],
            "last": "Wu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Baidu Inc",
                "location": {
                    "settlement": "Beijing",
                    "country": "China"
                }
            },
            "email": "wutian@baidu.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "While sophisticated neural-based techniques have been developed in reading comprehension, most approaches model the answer in an independent manner, ignoring its relations with other answer candidates. This problem can be even worse in open-domain scenarios, where candidates from multiple passages should be combined to answer a single question. In this paper, we formulate reading comprehension as an extract-then-select twostage procedure. We first extract answer candidates from passages, then select the final answer by combining information from all the candidates. Furthermore, we regard candidate extraction as a latent variable and train the two-stage process jointly with reinforcement learning. As a result, our approach has improved the state-ofthe-art performance significantly on two challenging open-domain reading comprehension datasets. Further analysis demonstrates the effectiveness of our model components, especially the information fusion of all the candidates and the joint training of the extract-then-select procedure.",
    "pdf_parse": {
        "paper_id": "P18-1159",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "While sophisticated neural-based techniques have been developed in reading comprehension, most approaches model the answer in an independent manner, ignoring its relations with other answer candidates. This problem can be even worse in open-domain scenarios, where candidates from multiple passages should be combined to answer a single question. In this paper, we formulate reading comprehension as an extract-then-select twostage procedure. We first extract answer candidates from passages, then select the final answer by combining information from all the candidates. Furthermore, we regard candidate extraction as a latent variable and train the two-stage process jointly with reinforcement learning. As a result, our approach has improved the state-ofthe-art performance significantly on two challenging open-domain reading comprehension datasets. Further analysis demonstrates the effectiveness of our model components, especially the information fusion of all the candidates and the joint training of the extract-then-select procedure.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Teaching machines to read and comprehend human languages is a long-standing objective in natural language processing. In order to evaluate this ability, reading comprehension (RC) is designed to answer questions through reading relevant passages. In recent years, RC has attracted intense interest. Various advanced neural models have been proposed along with newly released datasets (Hermann et al., 2015; Rajpurkar et al., 2016; Dunn et al., 2017; Dhingra et al., 2017b; He et al., 2017) .",
                "cite_spans": [
                    {
                        "start": 384,
                        "end": 406,
                        "text": "(Hermann et al., 2015;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 407,
                        "end": 430,
                        "text": "Rajpurkar et al., 2016;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 431,
                        "end": 449,
                        "text": "Dunn et al., 2017;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 450,
                        "end": 472,
                        "text": "Dhingra et al., 2017b;",
                        "ref_id": null
                    },
                    {
                        "start": 473,
                        "end": 489,
                        "text": "He et al., 2017)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Cocktails: Rum, lime, and cola drink make a . A Cuba Libre P1 Daiquiri, the custom of mixing lime with rum for a cooling drink on a hot Cuban day, has been around a long time. P2 Cocktail recipe for a Daiquiri, a classic rum and lime drink that every bartender should know. P3 Hemingway Special Daiquiri:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Q",
                "sec_num": null
            },
            {
                "text": "Daiquiris are a family of cocktails whose main ingredients are rum and lime juice.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Q",
                "sec_num": null
            },
            {
                "text": "To make a Cuba Libre properly, fill a highball glass with ice and half fill with cola. P5 The difference between the Cuba Libre and Rum is a lime wedge at the end.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "Table 1 : The answer candidates are in a bold font.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "The key information is marked in italic, which should be combined from different text pieces to select the correct answer \"Cuba Libre\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "Most existing approaches mainly focus on modeling the interactions between questions and passages (Dhingra et al., 2017a; Seo et al., 2017; Wang et al., 2017) , paying less attention to information concerning answer candidates. However, when human solve this problem, we often first read each piece of text, collect some answer candidates, then focus on these candidates and combine their information to select the final answer. This collect-then-select process can be more significant in open-domain scenarios, which require the combination of candidates from multiple passages to answer one single question. This phenomenon is illustrated by the example in Table 1 .",
                "cite_spans": [
                    {
                        "start": 98,
                        "end": 121,
                        "text": "(Dhingra et al., 2017a;",
                        "ref_id": null
                    },
                    {
                        "start": 122,
                        "end": 139,
                        "text": "Seo et al., 2017;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 140,
                        "end": 158,
                        "text": "Wang et al., 2017)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 665,
                        "end": 666,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "With this motivation, we formulate an extractthen-select two-stage architecture to simulate the above procedure. The architecture contains two components: (1) an extraction model, which generates answer candidates, (2) a selection model, which combines all these candidates and finds out the final answer. However, answer candidates to be focused on are often unobservable, as most RC datasets only provide golden answers. Therefore, we treat candidate extraction as a latent variable and train these two stages jointly with reinforcement learning (RL).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "In conclusion, our work makes the following contributions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "1. We formulate open-domain reading comprehension as a two-stage procedure, which first extracts answer candidates and then selects the final answer. With joint training, we optimize these two correlated stages as a whole.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "2. We propose a novel answer selection model, which combines the information from all the extracted candidates using an attention-based correlation matrix. As shown in experiments, the information fusion is greatly helpful for answer selection.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "3. With the two-stage framework and the joint training strategy, our method significantly surpasses the state-of-the-art performance on two challenging public RC datasets Quasar-T (Dhingra et al., 2017b) and SearchQA (Dunn et al., 2017) .",
                "cite_spans": [
                    {
                        "start": 180,
                        "end": 203,
                        "text": "(Dhingra et al., 2017b)",
                        "ref_id": null
                    },
                    {
                        "start": 217,
                        "end": 236,
                        "text": "(Dunn et al., 2017)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4 A homemade Cuba Libre Preparation",
                "sec_num": null
            },
            {
                "text": "In recent years, reading comprehension has made remarkable progress in methodology and dataset construction. Most existing approaches mainly focus on modeling sophisticated interactions between questions and passages, then use the pointer networks (Vinyals et al., 2015) to directly model the answers (Dhingra et al., 2017a; Wang and Jiang, 2017; Seo et al., 2017; Wang et al., 2017) . These methods prove to be effective in existing close-domain datasets (Hermann et al., 2015; Hill et al., 2015; Rajpurkar et al., 2016) .",
                "cite_spans": [
                    {
                        "start": 248,
                        "end": 270,
                        "text": "(Vinyals et al., 2015)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 301,
                        "end": 324,
                        "text": "(Dhingra et al., 2017a;",
                        "ref_id": null
                    },
                    {
                        "start": 325,
                        "end": 346,
                        "text": "Wang and Jiang, 2017;",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 347,
                        "end": 364,
                        "text": "Seo et al., 2017;",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 365,
                        "end": 383,
                        "text": "Wang et al., 2017)",
                        "ref_id": null
                    },
                    {
                        "start": 456,
                        "end": 478,
                        "text": "(Hermann et al., 2015;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 479,
                        "end": 497,
                        "text": "Hill et al., 2015;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 498,
                        "end": 521,
                        "text": "Rajpurkar et al., 2016)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "More recently, open-domain RC has attracted increasing attention (Nguyen et al., 2016; Dunn et al., 2017; Dhingra et al., 2017b; He et al., 2017) and raised new challenges for question answering techniques. In these scenarios, a question is paired with multiple passages, which are often collected by exploiting unstructured documents or web data. Aforementioned approaches often rely on recurrent neural networks and sophisticated attentions, which are prohibitively time-consuming if passages are concatenated altogether. There-fore, some work tried to alleviate this problem in a coarse-to-fine schema. Wang et al. (2018a) combined a ranker for selecting the relevant passage and a reader for producing the answer from it. However, this approach only depended on one passage when producing the answer, hence put great demands on the precisions of both components. Worse still, this framework cannot handle the situation where multiple passages are needed to answer correctly. In consideration of evidence aggregation, Wang et al. (2018b) proposed a re-ranking method to resolve the above issue. However, their re-ranking stage was totally isolated from the candidate extraction procedure. Being different from the re-ranking perspective, we propose a novel selection model to combine the information from all the extracted candidates. Moreover, with reinforcement learning, our candidate extraction and answer selection models can be learned in a joint manner. Trischler et al. (2016) also proposed a two-step extractor-reasoner model, which first extracted K most probable single-token answer candidates and then compared the hypotheses with all the sentences in the passage. However, in their work, each candidate was considered isolatedly, and their objective only took into account the ground truths compared with our RL treatment.",
                "cite_spans": [
                    {
                        "start": 65,
                        "end": 86,
                        "text": "(Nguyen et al., 2016;",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 87,
                        "end": 105,
                        "text": "Dunn et al., 2017;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 106,
                        "end": 128,
                        "text": "Dhingra et al., 2017b;",
                        "ref_id": null
                    },
                    {
                        "start": 129,
                        "end": 145,
                        "text": "He et al., 2017)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 606,
                        "end": 625,
                        "text": "Wang et al. (2018a)",
                        "ref_id": null
                    },
                    {
                        "start": 1021,
                        "end": 1040,
                        "text": "Wang et al. (2018b)",
                        "ref_id": null
                    },
                    {
                        "start": 1464,
                        "end": 1487,
                        "text": "Trischler et al. (2016)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "The training strategy employed in our paper is reinforcement learning, which is inspired by recent work exploiting it into question answering problem. The above mentioned coarse-to-fine framework (Choi et al., 2017; Wang et al., 2018a) treated sentence selection as a latent variable and jointly trained the sentence selection module with the answer generation module via RL. Shen et al. (2017) modeled the multi-hop reasoning procedure with a termination state to decide when it is adequate to produce an answer. RL is suitable to capture this stochastic behavior. Hu et al. (2018) merely modeled the extraction process, using F1 as rewards in addition to maximum likelihood estimation. RL was utilized in their training process, as the F1 measure is not differentiable.",
                "cite_spans": [
                    {
                        "start": 196,
                        "end": 215,
                        "text": "(Choi et al., 2017;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 216,
                        "end": 235,
                        "text": "Wang et al., 2018a)",
                        "ref_id": null
                    },
                    {
                        "start": 376,
                        "end": 394,
                        "text": "Shen et al. (2017)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 566,
                        "end": 582,
                        "text": "Hu et al. (2018)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "2"
            },
            {
                "text": "In this work, we mainly consider the open-domain extractive reading comprehension. In this scenario, a given question Q is paired with multiple passages P = {P 1 , P 2 , ..., P N }, based on which we aim to find out the answer A. Moreover, the golden answers are almost subspans shown in some passages in P. Our main framework consists of two parts, which are: (1) extracting answer candidates C = {C 1 , C 2 , ..., C M } from passages P and (2) selecting the final answer A from candidates C. This process is illustrated in Figure 1 . We design different models for each part and optimize them as a whole with joint reinforcement learning.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 532,
                        "end": 533,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Two-stage RC Framework",
                "sec_num": "3"
            },
            {
                "text": "We build candidate set C by independently extracting K candidates from each passage P i according to the following distribution:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "p(C|Q, P) = N i p({C ij } K j=1 |Q, P i ) C = N i=1 {C ij } K j=1 (1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "where C ij denotes the jth candidate extracted from the ith passage. K is set as a constant number in our formulation. Taking K as 2 for an example, we denote each probability shown on the right side of Equation 1 through sampling without replacement:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "p({C i1 , C i2 }) = p(C i1 )p(C i2 )/(1 -p(C i1 )) + p(C i1 )p(C i2 )/(1 -p(C i2 ))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "(2) where we neglect Q, P i to abbreviate the conditional distributions in Equation 1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "Consequently, the basic block of our candidate extraction stage turns out to be the distribution of each candidate P (C ij |Q, P i ). In the rest of this subsection, we will elaborate on the model archi- tecture concerning candidate extraction, which is displayed in Figure 2 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 274,
                        "end": 275,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "Question & Passage Representation Firstly, we embed the question",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "Q = {x k Q } l Q",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "k=1 and its relevant passage P = {x t P } l P t=1 \u2208 P with word vectors to form Q \u2208 R dw\u00d7l Q and P \u2208 R dw\u00d7l P respectively, where d w is the dimension of word embeddings, l Q and l P are the length of Q and P .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "We then feed Q and P to a bidirectional LSTM to form their contextual representations",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "H Q \u2208 R d h \u00d7l Q and H P \u2208 R d h \u00d7l P : H Q = BiLSTM(Q) H P = BiLSTM(P)",
                        "eq_num": "(3)"
                    }
                ],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "Question & Passage Interaction Modeling the interactions between questions and passages is a critical step in reading comprehension. Here, we adopt the attention mechanism similar to (Lee et al., 2016) to generate question-dependent passage representation",
                "cite_spans": [
                    {
                        "start": 183,
                        "end": 201,
                        "text": "(Lee et al., 2016)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "H P . Assume H Q = {h k Q } l Q k=1 , H P = {h t P } l P t=1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": ", we have:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "\u03b1 tk = e h k Q \u2022h t P l Q k=1 e h k Q \u2022h t P 1 \u2264 k \u2264 l Q , 1 \u2264 t \u2264 l P h t P = l Q k=1 \u03b1 tk h k Q 1 \u2264 t \u2264 l P H P ={ h t P } l P t=1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "(4) After concatenating two kinds of passage representations H P and H P , we use another bidirectional LSTM to get the final representation of every position in passage P as G P \u2208 R dg\u00d7l P :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "G P = BiLSTM([H P ; H P ])",
                        "eq_num": "(5)"
                    }
                ],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "Candidate Scoring Then we use two linear transformations w b \u2208 R 1\u00d7dg and w e \u2208 R 1\u00d7dg to calculate the begin and the end scores for each position:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "{b t P } l Q t=1 = b P = w b G P {e t P } l Q t=1 = e P = w e G P",
                        "eq_num": "(6)"
                    }
                ],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "At last, we model the probability of every subspan in passage P as a candidate C = {x t P } Ce t=C b according to its begin and end position:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "p(C|Q, P ) = exp(b C b P + e Ce P ) l P k=1 l P t=k exp(b k P + e t P )",
                        "eq_num": "(7)"
                    }
                ],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "In this definition, the probabilities of all the valid answer candidates are already normalized.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Candidate Extraction",
                "sec_num": "3.1"
            },
            {
                "text": "As the second part of our framework, the answer selection model finds out the most probable answer by calculating p(C|Q, P, C) for each candidate C \u2208 C. The model architecture is illustrated in Figure 3 . Notably, selection model receives candidate set C as additional information. This more focused information allows the model to combine evidences from all the candidates, which would be useful for selecting the best answer.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 201,
                        "end": 202,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "For ease of understanding, we briefly describe the selection stage as follows. After being extracted from a single passage, a candidate borrows information from other candidates across different passages. With this global information, the passage is reread to confirm the correctness of the candidate further. The following are details about the selection model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Question Representation Questions are fundamental for finding out the correct answer. As did for the extraction model, we embed the question Q with word vectors to form Q \u2208 R dw\u00d7l Q . Then we use a bidirectional LSTM to establish its contextual representation:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "S q = BiLSTM(Q)",
                        "eq_num": "(8)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "A max-pooling operation across all the positions is followed to get the condensed vector representation: ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "r q = MaxPooling(S q ) (9)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "2 x P 1 x Q l x Q Q S Q S P \u2026 \u2026 \u2026 \u2026 MaxPooling r Q . . . MaxPooling S c r C F P r C r C r C r C 1 2 M z C s Candidates Q R P Figure 3: Answer Selection Model Architecture.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Passage Representation Assume the candidate C is extracted from the passage P \u2208 P. To be informed of C, we first build the representation of P . For every word in P , three kinds of features are utilized:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Word embedding: each word expresses its basic feature with the word vector.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Common word: the feature has value 1 when the word occurs in the question, otherwise 0.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Question independent representation: the condensed representation r q .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "With these features, information not only in Q but also in P is considered. By concatenating them, we get r t P corresponding to every position t in passage P . Then with another bidirectional LSTM, we fuse these features to form the contextual representation of P as S P \u2208 R ds\u00d7l P :",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "R P = {r t P } l P t=1 S P = BiLSTM(R P )",
                        "eq_num": "(10)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Candidate Representation Candidates provide more focused information for answer selection. Therefore, for each candidate, we first build its independent representation according to its position in the passage, then construct candidates fused representation through combination of other correlated candidates.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Given the candidate C = {x t P } Ce t=C b in the passage P , we extract its corresponding span from S P = {s t P } l P t=1 to form S C = {s t P } Ce t=C b as its contextual encoding. Moreover, we calculate its condensed vector representation through its begin and end positions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "r C = tanh(W b s C b P + W e s Ce P )",
                        "eq_num": "(11)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "where",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "W b \u2208 R dc\u00d7ds , W e \u2208 R dc\u00d7ds .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "To model the interactions among all the answer candidates, we calculate the correlations of the candidate C, which is assumed to be indexed by j in C, with others {C m } M m=1,m =j via attention mechanism:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "V jm = w v tanh(W c r C + W o r Cm )",
                        "eq_num": "(12)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "where R 1\u00d7dc are linear transformations to capture the intensity of each interaction.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "W c \u2208 R dc\u00d7dc , W o \u2208 R dc\u00d7dc and w v \u2208",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "In this way, we form a correlation matrix V \u2208 R M \u00d7M , where M is the total number of candidates. With the correlation matrix, for the candidate C, we normalize its interactions via a sof tmax operation, which emphasizes the influence of stronger interactions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "\u03b1 m = e V jm M m=1,m =j e V jm",
                        "eq_num": "(13)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "To take into account different influences of all the other candidates, it is sensible to generate a candidates fused representation according to the above normalized interactions:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "r C = M m=1,m =j \u03b1 m r Cm",
                        "eq_num": "(14)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "In this formulation, all the other candidates contribute their influences to the fused representation by their interactions with C, thus information from different passages is gathered altogether. In our experiments, this kind of information fusion is the key point for performance improvements.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Passage Advanced Representation As more focused information of the candidate C is available, we are provided with a better way to confirm its correctness by rereading its corresponding passage P . Specifically, we equip each position t in P with following advanced features:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Passage contextual representation: the former passage representation s t P .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Candidate-dependent passage representation: replace H Q with S C and H P with S P in Equation 4 to model the interactions between candidates and passages to form s t P .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Candidate related distance feature: the relative distance to the candidate C can be a reference of the importance of each position.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Candidate independent representation: use r C to consider the concerned candidate C.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "\u2022 Candidates fused representation: use r C to consider all the other candidates interacting with the concerned candidate C.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "With these features, we capture the information from the question, the passages and all the candidates. By concatenating them, we get u t P in every position in the passage P . Combining these features with a bidirectional LSTM, we get:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "U P = {u t P } l P t=1 F P = BiLSTM(U P )",
                        "eq_num": "(15)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "Answer Scoring At last, the max pooling of each dimension of F P is performed, resulting in a condensed vector representation, which contains all the concerned information in a candidate:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "z C = MaxPooling(F P )",
                        "eq_num": "(16)"
                    }
                ],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "The final score of this candidate as the answer is calculated via a linear transformation, which is then normalized across all the candidates:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "s = w z z C p(C|Q, P, C) = e s M k=1 e s k (17)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Answer Selection",
                "sec_num": "3.2"
            },
            {
                "text": "In our formulation, the answer candidate set influences the result of answer selection to a large extent. However, with only golden answers provided in the training data, it is not apparent which candidates should be considered further. To alleviate the above problem, we treat candidate extraction as a latent variable, jointly train the extraction model and the selection model with reinforcement learning. Formally, in the extraction and selection stages, two kinds of actions are modeled. The action space for the extraction model is to select from different candidate sets, which is formulated by Equation 1. The action space for the selection model is to select from all extracted candidates, which is formulated by Equation 17. Our goal is to select the final answer that leads to a high reward. Inspired by Wang et al. (2018a) , we define the reward of a candidate to reflect its accordance with the golden answer:",
                "cite_spans": [
                    {
                        "start": 815,
                        "end": 834,
                        "text": "Wang et al. (2018a)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "r(C, A) = \uf8f1 \uf8f2 \uf8f3 2 if C == A f 1(C, A) else if C \u2229 A = \u2205 -1 else (18)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "where f 1(., .) \u2208 [0, 1] is the function to measure word-level F1 score between two sequences. Incorporating this reward can alleviate the overstrict requirements set by traditional maximum likelihood estimation as well as keep consistent with our evaluation methods in experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "The learning objective becomes to maximize the expected reward modeled by our framework, where \u03b8 stands for all the parameters involved:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "L(\u03b8) = -E C\u223cP (C|Q,P) [E C\u223cP (C|Q,P,C) r(C, A)] = -E C\u223cP (C|Q,P) [ C P (C|Q, P, C)r(C, A)] (19)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "Following REINFORCE algorithm, we approximate the gradient of the above objective with a sampled candidate set, C \u223c P (C|Q, P), resulting in the following form: Each question is paired with 100 sentence-level passages retrieved from ClueWeb09 (Callan et al., 2009) based on Lucene.",
                "cite_spans": [
                    {
                        "start": 243,
                        "end": 264,
                        "text": "(Callan et al., 2009)",
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "\u2207L(\u03b8) \u2248 -",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "SearchQA (Dunn et al., 2017) starts from existing question-answer pairs, which are crawled from J!Archive, and is augmented with text snippets retrieved by Google, resulting in more than 140,000 question-answer pairs with each pair having 49.6 snippets on average.",
                "cite_spans": [
                    {
                        "start": 9,
                        "end": 28,
                        "text": "(Dunn et al., 2017)",
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "The detailed statistics of these two datasets is shown in Table 2 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 64,
                        "end": 65,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "#q(train) #q(dev) #q(test) #p Quasar-T 28,496 3,000 3,000 100 SearchQA 99,811 13,893 27,247 50",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "Table 2 :",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "The statistics of our experimental datasets. #q represents the number of questions for each split of the datasets. #p is the number of passages for each question.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Joint Training with RL",
                "sec_num": "3.3"
            },
            {
                "text": "We initialize word embeddings with the 300dimensional Glove vectors1 . All the bidirectional LSTMs hold 1 layer and 100 hidden units. All the linear transformations take the size of 100 as output dimension. The common word feature and the candidate related distance feature are embedded with vectors of dimension 4 and 50 respectively. By default, we set K as 2 in Equation 1, which means each passage generates two candidates based on the extraction model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model Settings",
                "sec_num": "4.2"
            },
            {
                "text": "For ease of training, we first initialize our models by maximum likelihood estimation and finetune them with RL. The similar training strategy is commonly employed when RL process is involved (Ranzato et al., 2015; Li et al., 2016a; Hu et al., 2018) . To pre-train the extraction model, we only use passages containing ground truths as training data. The log likelihood of Equation 7 is taken as the training objective for each question and passage pair. After pre-training the extraction model, we use it to generate two top-scoring candidates from each passage, forming the training data to pre-train our selection model, and maximize the log likelihood of the Equation 17 as our second objective. In pre-training, we use the batch size of 30 for the extraction model, 20 for the selection model and RMSProp (Tieleman and Hinton, 2012) with an initial learning rate of 2e-3. In fine-tuning with RL, we use the batch size of 5 and RMSProp with an initial learning rate of 1e-4. Also, we use a dropout rate of 0.1 in each training procedure.",
                "cite_spans": [
                    {
                        "start": 192,
                        "end": 214,
                        "text": "(Ranzato et al., 2015;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 215,
                        "end": 232,
                        "text": "Li et al., 2016a;",
                        "ref_id": null
                    },
                    {
                        "start": 233,
                        "end": 249,
                        "text": "Hu et al., 2018)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 810,
                        "end": 837,
                        "text": "(Tieleman and Hinton, 2012)",
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model Settings",
                "sec_num": "4.2"
            },
            {
                "text": "In addition to results of previous work, we add two baselines to demonstrate the effectiveness of our framework. The first baseline only applies the extraction model to score the answers, which is aimed at explaining the importance of the selection model. The second one only uses the pre-trained extraction model and selection model Quasar-T SearchQA EM F1 EM F1 GA (Dhingra et al., 2017a) 26.4 26.4 --BIDAF (Seo et al., 2017) 25.9 28.5 28.6 34.6 AQA (Buck et al., 45.9 53.9 58.3 64.2",
                "cite_spans": [
                    {
                        "start": 367,
                        "end": 390,
                        "text": "(Dhingra et al., 2017a)",
                        "ref_id": null
                    },
                    {
                        "start": 409,
                        "end": 427,
                        "text": "(Seo et al., 2017)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 452,
                        "end": 465,
                        "text": "(Buck et al.,",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "Table 3 : Experimental results on the test set of Quasar-T and SearchQA. Full re-ranker is the ensemble of three different re-rankers in (Wang et al., 2018b) .",
                "cite_spans": [
                    {
                        "start": 137,
                        "end": 157,
                        "text": "(Wang et al., 2018b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "to illustrate the benefits from our joint training schema.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "The often used evaluation metrics for extractive RC are exact match (EM) and F1 (Rajpurkar et al., 2016) . The experimental results on Quasar-T and SearchQA are shown in Table 3 .",
                "cite_spans": [
                    {
                        "start": 80,
                        "end": 104,
                        "text": "(Rajpurkar et al., 2016)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 176,
                        "end": 177,
                        "text": "3",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "As seen from the results on Quasar-T, our quite simple extraction model alone almost reaches the state-of-the-art result compared with other methods without re-rankers. The combination of the extraction and selection models exceeds our extraction baseline by a great margin, and also results in performance surpassing the best single reranker in (Wang et al., 2018b) . This result illustrates the necessity of introducing the selection model, which incorporates information from all the candidates. In the end, by joint training with RL, our method produces better performance even compared with the ensemble of three different rerankers.",
                "cite_spans": [
                    {
                        "start": 346,
                        "end": 366,
                        "text": "(Wang et al., 2018b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "On SearchQA, we find that our extraction model alone performs not that well compared with the state-of-the-art model without re-rankers. However, the improvement brought by our selection model isolatedly or jointly trained still demonstrates the importance of our two-stage framework. Not surprisingly, comparing the results, our isolated training strategy still lags behind the single re-ranker proposed in (Wang et al., 2018b) , partly because of the deficiency with our extraction model. However, uniting our extraction and selection models with RL makes up the disparity, and the performance surpasses the ensemble of three different re-rankers, let alone the result of any single re-ranker.",
                "cite_spans": [
                    {
                        "start": 408,
                        "end": 428,
                        "text": "(Wang et al., 2018b)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Results",
                "sec_num": "4.3"
            },
            {
                "text": "As the incorporation of the selection model improves the overall performance significantly, we conduct ablation analysis on the Quasar-T to prove the effectiveness of its major components. As shown in Table 4, all these components modeling the selection procedure play important roles in our final architecture. Specifically, introducing the independent representation of the question and its common words with the passage seems an efficient way to consider the information of questions, which is consistent with previous work (Li et al., 2016b; Chen et al., 2017) .",
                "cite_spans": [
                    {
                        "start": 527,
                        "end": 545,
                        "text": "(Li et al., 2016b;",
                        "ref_id": null
                    },
                    {
                        "start": 546,
                        "end": 564,
                        "text": "Chen et al., 2017)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Effect of Features in Selection Model",
                "sec_num": null
            },
            {
                "text": "As for features related to candidates, the incorporation of the candidate independent information Q Cocktails : Rum , lime , and cola drink make a . A Cuba Libre P1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Effect of Features in Selection Model",
                "sec_num": null
            },
            {
                "text": "In Nicaragua , when it is mixed using Flor de Ca a -LRB-the national brand of rum -RRB-and cola , it is called a Nica Libre .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Effect of Features in Selection Model",
                "sec_num": null
            },
            {
                "text": "The drink ... Daiquiri The custom of mixing lime with rum for a cooling drink on a hot Cuban day has been around a long time .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P2",
                "sec_num": null
            },
            {
                "text": "If you only learn to make two cocktails , the Manhattan should be one of them .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P3",
                "sec_num": null
            },
            {
                "text": "Daiquiri Cocktail recipe for a Daiquiri , a classic rum and lime drink that every bartender should know .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P4",
                "sec_num": null
            },
            {
                "text": "Hemingway Special Daiquiri : Daiquiris are a family of cocktails whose main ingredients are rum and lime juice .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P5",
                "sec_num": null
            },
            {
                "text": "In the Netherlands the drink is commonly called Baco , from the two ingredients of Bacardi rum and cola .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P6",
                "sec_num": null
            },
            {
                "text": "A homemade Cuba Libre Preparation To make a Cuba Libre properly , fill a highball glass with ice and half fill with cola .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P7",
                "sec_num": null
            },
            {
                "text": "Bacardi Cocktail Cocktail recipe for a Bacardi Cocktail , a classic cocktail of Bacardi rum , lemon or lime juice and grenadine Roy Rogers -LRB-non-alcoholic -RRB-Cocktail recipe for a Roy Rogers , P9",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P8",
                "sec_num": null
            },
            {
                "text": "Margarita Cocktail recipe for a Margarita , a popular refreshing tequila and lime drink for summer . P10 The difference between the Cuba Libre and Rum is a lime wedge at the end . Most importantly, the candidates fused representation, which combines the information from all the candidates, demonstrates its indispensable role in candidate modeling, with a performance drop of nearly 8% when discarded. This phenomenon also verifies the necessity of our extractthen-select procedure, showing the importance of combining information scattered in different text pieces when picking out the final answer.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "P8",
                "sec_num": null
            },
            {
                "text": "We conduct a case study to demonstrate the importance of candidates fused information further. In Table 5 , each candidate only partly matches the description of the question in its independent context. To correctly answer the question, information in P 7 and P 10 should be combined. In experiments, our selection model provides the correct answer, while the wrong candidate \"Daiquiri\", a different kind of cocktail, is selected if candidates fused representation is discarded. The attention map established when modeling the fusion of candidates (corresponding to Equation 13) in this example is illustrated in Figure 4 , in which we can see the interactions among all the candidates from different passages. In this figure, it is obvious that the interaction of \"Cuba Libre\" in P 7 and P 10 is the key point to answer the question correctly.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 104,
                        "end": 105,
                        "text": "5",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 620,
                        "end": 621,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Example for Candidates Fused Representation",
                "sec_num": null
            },
            {
                "text": "The candidate extraction stage takes an important role to decide what information should be focused on further. Therefore, we also test the influence of different K when extracting candidates from each passage. The results are shown in Table 6 . Taking K = 1 degrades the performance, which conforms to the expectation, as the correct candidates become less in this stricter situation. However, taking K = 3 can not improve the performance further. Although a larger K means a higher possibility to include good answers, it raises more challenges for the selection model to pick out the correct one from candidates with more varieties.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 242,
                        "end": 243,
                        "text": "6",
                        "ref_id": "TABREF4"
                    }
                ],
                "eq_spans": [],
                "section": "Effect of Candidate Number",
                "sec_num": null
            },
            {
                "text": "In this paper, we formulate the problem of RC as a two-stage process, which first generates candidates with an extraction model, then selects the final answer by combining the information from all the candidates. Furthermore, we treat candidate extraction as a latent variable and jointly train these two stages with RL. Experiments on public open-domain RC datasets Quasar-T and SearchQA show the necessity of introducing the selection model and the effectiveness of fusing candidates information when modeling. Moreover, our joint training strategy leads to significant improvements in performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "5"
            },
            {
                "text": "http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "This work is supported by the National Basic Research Program of China (973 program, No. 2014CB340505). We thank Ying Chen and anonymous reviewers for valuable feedback.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgments",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Ask the right questions: Active question reformulation with reinforcement learning",
                "authors": [
                    {
                        "first": "Christian",
                        "middle": [],
                        "last": "Buck",
                        "suffix": ""
                    },
                    {
                        "first": "Jannis",
                        "middle": [],
                        "last": "Bulian",
                        "suffix": ""
                    },
                    {
                        "first": "Massimiliano",
                        "middle": [],
                        "last": "Ciaramita",
                        "suffix": ""
                    },
                    {
                        "first": "Andrea",
                        "middle": [],
                        "last": "Gesmundo",
                        "suffix": ""
                    },
                    {
                        "first": "Neil",
                        "middle": [],
                        "last": "Houlsby",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Gajewski",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christian Buck, Jannis Bulian, Massimiliano Cia- ramita, Andrea Gesmundo, Neil Houlsby, Wojciech Gajewski, and Wei Wang. 2018. Ask the right ques- tions: Active question reformulation with reinforce- ment learning. In ICLR.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Clueweb09 data set",
                "authors": [
                    {
                        "first": "Jamie",
                        "middle": [],
                        "last": "Callan",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Hoy",
                        "suffix": ""
                    },
                    {
                        "first": "Changkuk",
                        "middle": [],
                        "last": "Yoo",
                        "suffix": ""
                    },
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jamie Callan, Mark Hoy, Changkuk Yoo, and Le Zhao. 2009. Clueweb09 data set.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Reading wikipedia to answer opendomain questions",
                "authors": [
                    {
                        "first": "Danqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Fisch",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    },
                    {
                        "first": "Antoine",
                        "middle": [],
                        "last": "Bordes",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1870--1879",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open- domain questions. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics. Association for Computational Linguis- tics, Vancouver, Canada, pages 1870-1879.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Illia Polosukhin, Alexandre Lacoste, and Jonathan Berant",
                "authors": [
                    {
                        "first": "Eunsol",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Hewlett",
                        "suffix": ""
                    },
                    {
                        "first": "Jakob",
                        "middle": [],
                        "last": "Uszkoreit",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "209--220",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonathan Be- rant. 2017. Coarse-to-fine question answering for long documents. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics. Association for Computational Linguistics, Vancouver, Canada, pages 209-220.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Gatedattention readers for text comprehension",
                "authors": [
                    {
                        "first": "Bhuwan",
                        "middle": [],
                        "last": "Dhingra",
                        "suffix": ""
                    },
                    {
                        "first": "Hanxiao",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zhilin",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Cohen",
                        "suffix": ""
                    },
                    {
                        "first": "Ruslan",
                        "middle": [],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1832--1846",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bhuwan Dhingra, Hanxiao Liu, Zhilin Yang, William Cohen, and Ruslan Salakhutdinov. 2017a. Gated- attention readers for text comprehension. In Pro- ceedings of the 55th Annual Meeting of the Asso- ciation for Computational Linguistics. Association for Computational Linguistics, Vancouver, Canada, pages 1832-1846.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Quasar: Datasets for question answering by search and reading",
                "authors": [
                    {
                        "first": "Bhuwan",
                        "middle": [],
                        "last": "Dhingra",
                        "suffix": ""
                    },
                    {
                        "first": "Kathryn",
                        "middle": [],
                        "last": "Mazaitis",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [
                            "W"
                        ],
                        "last": "Cohen",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1707.03904"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Bhuwan Dhingra, Kathryn Mazaitis, and William W Cohen. 2017b. Quasar: Datasets for question an- swering by search and reading. arXiv preprint arXiv:1707.03904 .",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Searchqa: A new q&a dataset augmented with context from a search engine",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Dunn",
                        "suffix": ""
                    },
                    {
                        "first": "Levent",
                        "middle": [],
                        "last": "Sagun",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Higgins",
                        "suffix": ""
                    },
                    {
                        "first": "Ugur",
                        "middle": [],
                        "last": "Guney",
                        "suffix": ""
                    },
                    {
                        "first": "Volkan",
                        "middle": [],
                        "last": "Cirik",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1704.05179"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Matthew Dunn, Levent Sagun, Mike Higgins, Ugur Guney, Volkan Cirik, and Kyunghyun Cho. 2017. Searchqa: A new q&a dataset augmented with context from a search engine. arXiv preprint arXiv:1704.05179 .",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Dureader: a chinese machine reading comprehension dataset from real-world applications",
                "authors": [
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yajuan",
                        "middle": [],
                        "last": "Lyu",
                        "suffix": ""
                    },
                    {
                        "first": "Shiqi",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Xinyan",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Yuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yizhong",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Hua",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Qiaoqiao",
                        "middle": [],
                        "last": "She",
                        "suffix": ""
                    },
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Tian",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Haifeng",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1711.05073"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang. 2017. Dureader: a chinese machine reading comprehen- sion dataset from real-world applications. arXiv preprint arXiv:1711.05073 .",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Teaching machines to read and comprehend",
                "authors": [
                    {
                        "first": "Karl",
                        "middle": [],
                        "last": "Moritz Hermann",
                        "suffix": ""
                    },
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Kocisky",
                        "suffix": ""
                    },
                    {
                        "first": "Edward",
                        "middle": [],
                        "last": "Grefenstette",
                        "suffix": ""
                    },
                    {
                        "first": "Lasse",
                        "middle": [],
                        "last": "Espeholt",
                        "suffix": ""
                    },
                    {
                        "first": "Will",
                        "middle": [],
                        "last": "Kay",
                        "suffix": ""
                    },
                    {
                        "first": "Mustafa",
                        "middle": [],
                        "last": "Suleyman",
                        "suffix": ""
                    },
                    {
                        "first": "Phil",
                        "middle": [],
                        "last": "Blunsom",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015",
                "volume": "",
                "issue": "",
                "pages": "1693--1701",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su- leyman, and Phil Blunsom. 2015. Teaching ma- chines to read and comprehend. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Sys- tems 2015, December 7-12, 2015, Montreal, Que- bec, Canada. pages 1693-1701.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "The goldilocks principle: Reading children's books with explicit memory representations",
                "authors": [
                    {
                        "first": "Felix",
                        "middle": [],
                        "last": "Hill",
                        "suffix": ""
                    },
                    {
                        "first": "Antoine",
                        "middle": [],
                        "last": "Bordes",
                        "suffix": ""
                    },
                    {
                        "first": "Sumit",
                        "middle": [],
                        "last": "Chopra",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1511.02301"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. 2015. The goldilocks principle: Reading children's books with explicit memory representa- tions. arXiv preprint arXiv:1511.02301 .",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Reinforced mnemonic reader for machine comprehension",
                "authors": [
                    {
                        "first": "Minghao",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minghao Hu, Yuxing Peng, and Xipeng Qiu. 2018. Re- inforced mnemonic reader for machine comprehen- sion. In IJCAI.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Learning recurrent span representations for extractive question answering",
                "authors": [
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Shimi",
                        "middle": [],
                        "last": "Salant",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Kwiatkowski",
                        "suffix": ""
                    },
                    {
                        "first": "Ankur",
                        "middle": [],
                        "last": "Parikh",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Jonathan",
                        "middle": [],
                        "last": "Berant",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1611.01436"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Kenton Lee, Shimi Salant, Tom Kwiatkowski, Ankur Parikh, Dipanjan Das, and Jonathan Berant. 2016. Learning recurrent span representations for ex- tractive question answering. arXiv preprint arXiv:1611.01436 .",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "2016a. Deep reinforcement learning for dialogue generation",
                "authors": [
                    {
                        "first": "Jiwei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Will",
                        "middle": [],
                        "last": "Monroe",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [],
                        "last": "Ritter",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1192--1202",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. 2016a. Deep re- inforcement learning for dialogue generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Associ- ation for Computational Linguistics, Austin, Texas, pages 1192-1202.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Dataset and neural recurrent sequence labeling model for opendomain factoid question answering",
                "authors": [
                    {
                        "first": "Peng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Zhengyan",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Xuguang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Ying",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1607.06275"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, and Wei Xu. 2016b. Dataset and neural recurrent sequence labeling model for open- domain factoid question answering. arXiv preprint arXiv:1607.06275 .",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "MS MARCO: A human generated machine reading comprehension dataset",
                "authors": [
                    {
                        "first": "Tri",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "Mir",
                        "middle": [],
                        "last": "Rosenberg",
                        "suffix": ""
                    },
                    {
                        "first": "Xia",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Saurabh",
                        "middle": [],
                        "last": "Tiwary",
                        "suffix": ""
                    },
                    {
                        "first": "Rangan",
                        "middle": [],
                        "last": "Majumder",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A human generated machine reading comprehension dataset. In Proceedings of the Workshop on Cognitive Computation: Inte- grating neural and symbolic approaches 2016 co- located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016).",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Squad: 100,000+ questions for machine comprehension of text",
                "authors": [
                    {
                        "first": "Pranav",
                        "middle": [],
                        "last": "Rajpurkar",
                        "suffix": ""
                    },
                    {
                        "first": "Jian",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Konstantin",
                        "middle": [],
                        "last": "Lopyrev",
                        "suffix": ""
                    },
                    {
                        "first": "Percy",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "2383--2392",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natu- ral Language Processing. Association for Computa- tional Linguistics, Austin, Texas, pages 2383-2392.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Sequence level training with recurrent neural networks",
                "authors": [
                    {
                        "first": "Aurelio",
                        "middle": [],
                        "last": "Marc",
                        "suffix": ""
                    },
                    {
                        "first": "Sumit",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Chopra",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zaremba",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1511.06732"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2015. Sequence level train- ing with recurrent neural networks. arXiv preprint arXiv:1511.06732 .",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Bidirectional attention flow for machine comprehension",
                "authors": [
                    {
                        "first": "Minjoon",
                        "middle": [],
                        "last": "Seo",
                        "suffix": ""
                    },
                    {
                        "first": "Aniruddha",
                        "middle": [],
                        "last": "Kembhavi",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Farhadi",
                        "suffix": ""
                    },
                    {
                        "first": "Hannaneh",
                        "middle": [],
                        "last": "Hajishirzi",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2017. Bidirectional attention flow for machine comprehension. In ICLR.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Reasonet: Learning to stop reading in machine comprehension",
                "authors": [
                    {
                        "first": "Yelong",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "Po-Sen",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Weizhu",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "volume": "",
                "issue": "",
                "pages": "1047--1055",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yelong Shen, Po-Sen Huang, Jianfeng Gao, and Weizhu Chen. 2017. Reasonet: Learning to stop reading in machine comprehension. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, pages 1047-1055.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude",
                "authors": [
                    {
                        "first": "Tijmen",
                        "middle": [],
                        "last": "Tieleman",
                        "suffix": ""
                    },
                    {
                        "first": "Geoffrey",
                        "middle": [],
                        "last": "Hinton",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "COURSERA: Neural networks for machine learning",
                "volume": "4",
                "issue": "2",
                "pages": "26--31",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tijmen Tieleman and Geoffrey Hinton. 2012. Lecture 6.5-rmsprop: Divide the gradient by a running av- erage of its recent magnitude. COURSERA: Neural networks for machine learning 4(2):26-31.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Natural language comprehension with the epireader",
                "authors": [
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Trischler",
                        "suffix": ""
                    },
                    {
                        "first": "Zheng",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Xingdi",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Philip",
                        "middle": [],
                        "last": "Bachman",
                        "suffix": ""
                    },
                    {
                        "first": "Alessandro",
                        "middle": [],
                        "last": "Sordoni",
                        "suffix": ""
                    },
                    {
                        "first": "Kaheer",
                        "middle": [],
                        "last": "Suleman",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "128--137",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adam Trischler, Zheng Ye, Xingdi Yuan, Philip Bach- man, Alessandro Sordoni, and Kaheer Suleman. 2016. Natural language comprehension with the epireader. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Pro- cessing. Association for Computational Linguistics, Austin, Texas, pages 128-137.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Pointer networks",
                "authors": [
                    {
                        "first": "Oriol",
                        "middle": [],
                        "last": "Vinyals",
                        "suffix": ""
                    },
                    {
                        "first": "Meire",
                        "middle": [],
                        "last": "Fortunato",
                        "suffix": ""
                    },
                    {
                        "first": "Navdeep",
                        "middle": [],
                        "last": "Jaitly",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "2692--2700",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In Advances in Neural Information Processing Systems 28: Annual Con- ference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada. pages 2692-2700.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Machine comprehension using match-lstm and answer pointer",
                "authors": [
                    {
                        "first": "Shuohang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shuohang Wang and Jing Jiang. 2017. Machine com- prehension using match-lstm and answer pointer. In ICLR.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Reinforced reader-ranker for open-domain question answering",
                "authors": [
                    {
                        "first": "Shuohang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Mo",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoxiao",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiguo",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Klinger",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Shiyu",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Gerald",
                        "middle": [],
                        "last": "Tesauro",
                        "suffix": ""
                    },
                    {
                        "first": "Bowen",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "AAAI",
                "volume": "2018",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerald Tesauro, Bowen Zhou, and Jing Jiang. 2018a. R3: Reinforced reader-ranker for open-domain question answering. In AAAI.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Evidence aggregation for answer re-ranking in open-domain question answering",
                "authors": [
                    {
                        "first": "Shuohang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Mo",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoxiao",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Shiyu",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiguo",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Klinger",
                        "suffix": ""
                    },
                    {
                        "first": "Gerald",
                        "middle": [],
                        "last": "Tesauro",
                        "suffix": ""
                    },
                    {
                        "first": "Murray",
                        "middle": [],
                        "last": "Campbell",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. 2018b. Evidence aggregation for answer re-ranking in open-domain question answering. In ICLR.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Gated self-matching networks for reading comprehension and question answering",
                "authors": [
                    {
                        "first": "Wenhui",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Furu",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Baobao",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "189--198",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou. 2017. Gated self-matching net- works for reading comprehension and question an- swering. In Proceedings of the 55th Annual Meet- ing of the Association for Computational Linguis- tics. volume 1, pages 189-198.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "text": "Figure 1: Two-stage RC Framework. The first part extracts candidates (denoted with circles) from all the passages. The second part establishes interactions among all these candidates to select the final answer. The different gray scales of dashed lines between candidates represent different intensities of interactions.",
                "uris": null,
                "fig_num": "1",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "text": "Figure 2: Candidate Extraction Model Architecture.",
                "uris": null,
                "fig_num": "2",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "text": "We evaluate our models on two publicly available open-domain RC datasets, which are commonly adopted in related work.Quasar-T(Dhingra et al., 2017b) consists of 43,000 open-domain trivia questions and corresponding answers obtained from various internet sources.",
                "uris": null,
                "fig_num": null,
                "type_str": "figure"
            },
            "TABREF3": {
                "content": "<table/>",
                "type_str": "table",
                "text": "An example from Quasar-T to illustrate the necessity of fused information. Candidates extracted from passages are in a bold font. To correctly answer the question, information in P 7 and P 10 should be combined.",
                "html": null,
                "num": null
            },
            "TABREF4": {
                "content": "<table><tr><td>Nica Libre</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>1.0</td></tr><tr><td>Daiquiri Manhattan</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>0.8</td></tr><tr><td>Daiquiri Daiquiri</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>0.6</td></tr><tr><td>Baco Cuba Libre</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>0.4</td></tr><tr><td>Bacardi Margarita</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>0.2</td></tr><tr><td>Cuba Libre</td><td>Nica Libre</td><td>Daiquiri</td><td>Manhattan</td><td>Daiquiri</td><td>Daiquiri</td><td>Baco</td><td>Cuba Libre</td><td>Bacardi</td><td>Margarita</td><td>Cuba Libre</td><td>0.0</td></tr><tr><td/><td/><td colspan=\"3\">Quasar-T</td><td/><td>EM</td><td/><td>F1</td><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"2\">K=1</td><td/><td colspan=\"3\">43.9 52.4</td><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"2\">K=2</td><td/><td colspan=\"3\">45.9 53.9</td><td/><td/><td/></tr><tr><td/><td/><td/><td colspan=\"2\">K=3</td><td/><td colspan=\"3\">45.8 53.9</td><td/><td/><td/></tr></table>",
                "type_str": "table",
                "text": "Figure4: The attention map generated when modeling candidates fused representations for the example in Table5. Different number of extracted candidates results in different final performance on the test set of Quasar-T.",
                "html": null,
                "num": null
            }
        }
    }
}