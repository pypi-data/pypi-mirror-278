import logging
from dataclasses import InitVar, dataclass, field
from pathlib import Path
from typing import Any

from buildable_dataclasses.buildable import Buildable
from misc_python_utils.beartypes import Directory, NeStr
from misc_python_utils.dataclass_utils import _UNDEFINED
from nested_dataclass_serialization.dataclass_serialization import encode_dataclass
from nested_dataclass_serialization.dataclass_serialization_utils import SPECIAL_KEYS

from ml_system_dockerization.dockerized_service_utils import BIND_VOLUME

logger = logging.getLogger(
    __name__,
)  # "The name is potentially a period-separated hierarchical", see: https://docs.python.org/3.10/library/logging.html

PrefixKey = str
HostDirectory = Directory

GITLAB_CREDENTIALS = [
    "GITLAB_USERNAME=${GITLAB_USERNAME}",
    "GITLAB_PASSWORD=${GITLAB_PASSWORD}",
]


@dataclass
class DCBuildSubsection:
    context: str
    dockerfile: str = "Dockerfile"
    args: list[str] = field(default_factory=lambda: GITLAB_CREDENTIALS)

    def to_dict(self) -> dict[str, Any]:
        return {k: getattr(self, k) for k in ["context", "dockerfile", "args"]}


@dataclass
class DockerServiceContent(Buildable):
    """
    represents: https://docs.docker.com/compose/compose-file/05-services/
    """

    image: str
    build_subsection: DCBuildSubsection | None = None
    entrypoint: list[str] | None = None
    command: list[str] | None = None
    healthcheck: dict[str, str] | None = None
    networks: list[str] | None = None
    depends_on: list[str] | None = None
    volumes: list[
        str
    ] | None = None  # volume-mounts not to confuse with toplevel volume declarations!
    environment: list[str] | None = None
    bind_volumes: InitVar[dict[PrefixKey, HostDirectory] | None] = None
    scale: int = field(repr=True, default=1)
    deploy: dict | None = None
    ports: list[str] | _UNDEFINED | None = None
    expose: list[int] | _UNDEFINED | None = None
    restart: str | None = None
    env_file: list[str] | None = None

    def __post_init__(
        self,
        bind_volumes: dict[str, Directory] | None,
    ):
        if self.volumes is not None:
            for vol in self.volumes:
                validate_vol(vol)

        if bind_volumes is not None:
            self.bindmount_and_add_prefixkey_to_envvars(bind_volumes)
        # if scale is not None: # needs newer compose-version
        #     if self.deploy is UNDEFINED:
        #         self.deploy = dict()
        #     self.deploy["replicas"] = scale

    def bindmount_and_add_prefixkey_to_envvars(
        self,
        bind_volumes: dict[PrefixKey, HostDirectory],
    ) -> None:
        bind_volumes_mappings = [
            (f"{dir_on_host}:/{BIND_VOLUME}{name}")
            for name, dir_on_host in bind_volumes.items()
        ]
        bind_dir_env_vars = [
            (f"{BIND_VOLUME}{name}=/{BIND_VOLUME}{name}")
            for name, dir_on_host in bind_volumes.items()
        ]
        self.volumes = (
            bind_volumes_mappings
            if self.volumes is None
            else list(set(self.volumes + bind_volumes_mappings))
        )
        self.environment = set_or_update(self.environment, bind_dir_env_vars)

    def tag_image(self, tag: NeStr) -> None:
        if ":" in self.image:
            uri, _old_tag = self.image.split(":")
        else:
            uri = self.image
        self.image = f"{uri}:{tag}"

    def prepare_for_dc_yaml(
        self,
        exclude_builds: bool = True,
        exclude_nonbind_volumes: bool = False,
    ) -> dict:
        d = encode_dataclass(self, skip_keys=SPECIAL_KEYS)
        d = {k: v for k, v in d.items() if v is not None}
        if "build_subsection" in d.keys():
            del d["build_subsection"]
        if not exclude_builds and self.build_subsection is not None:
            d["build"] = {
                k: getattr(self.build_subsection, k)
                for k in ["context", "dockerfile", "args"]
            }

        if "scale" in d.keys():
            del d["scale"]
        if "volumes" in d.keys() and exclude_nonbind_volumes:
            is_bind_volume = lambda s: s.startswith("/")
            d["volumes"] = [v for v in d["volumes"] if is_bind_volume(v)]
        return d


def validate_vol(vol: str) -> bool:
    is_fine = False
    if not is_a_autogenerated_volume_mount(vol):
        onhost, incontainer = vol.split(":")
        if not onhost.startswith("/") or not Path(onhost).is_dir():
            raise ValueError(  # noqa: TRY003
                f"dir does not exist: {onhost}"  # noqa: COM812, EM102
            )  # noqa: EM102, TRY003
        else:  # noqa: RET506
            is_fine = True
    return is_fine


def is_a_autogenerated_volume_mount(vol: str) -> bool:
    # that might have "slipped in" here from deserializing a dumped json
    return (
        ":/VOLUME_MOUNTS" in vol
        or len(vol.split(":")) != 2  # noqa: PLR2004
        or ":/volume-data" in vol
    )


def set_or_update(sett: list | None, bind_dir_env_vars: list) -> list:
    """
    need to listify in order to be json-serializable
    """
    if sett is None:
        sett = set(bind_dir_env_vars)
    else:
        sett = set(sett)
        sett.update(bind_dir_env_vars)
    return list(sett)
