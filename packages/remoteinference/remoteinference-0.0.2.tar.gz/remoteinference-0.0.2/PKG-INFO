Metadata-Version: 2.1
Name: remoteinference
Version: 0.0.2
Summary: Remote inference for language models
Home-page: UNKNOWN
Author: Jaris KÃ¼ken
Author-email: jaris.kueken@gmail.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown

# llm_inference

Simple package to perform remote inference on language models of different providers.

## getting started
Install the package
```python
pip install remoteinference
```
If you have a LLM running on a remote server using llama.cpp for example you can initalize the model by running
```python

```



