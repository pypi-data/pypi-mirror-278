{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from ipfn import ipfn\n",
    "from matplotlib import pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sttn.data.lehd import OriginDestinationEmploymentDataProvider\n",
    "provider = OriginDestinationEmploymentDataProvider()\n",
    "import os\n",
    "import math\n",
    "from sttn.network import SpatioTemporalNetwork\n",
    "from sttn.utils import add_distance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    ('New York City', 'ny', ['New York County, NY', 'Queens County, NY','Kings County, NY','Bronx County, NY','Richmond County, NY']),\n",
    "    ('Los Angeles', 'ca', ['Los Angeles County, CA']),\n",
    "    ('Chicago', 'il', ['Cook County, IL']),\n",
    "    ('Houston', 'tx', ['Harris County, TX']),\n",
    "    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for above cities - census tract level\n",
    "\n",
    "allCity_dfs = []\n",
    "job_column = 'S000'\n",
    "comp_aggs={job_column: 'sum'}\n",
    "for city, state, conties in cities:\n",
    "    state_network = provider.get_data(state=state, year=2018)\n",
    "    city_network = state_network.filter_nodes(state_network.nodes.county.isin(conties))\n",
    "    with_distance = add_distance(city_network).edges\n",
    "    \n",
    "    city_jobs = city_network.agg_adjacent_edges(aggs=comp_aggs, outgoing=False).rename(columns={job_column: 'jobs'}).reset_index()\n",
    "    city_pop = city_network.agg_adjacent_edges(aggs=comp_aggs, outgoing=True).rename(columns={job_column: 'residence'}).reset_index()\n",
    "    \n",
    "    city_dist = with_distance.merge(city_jobs, on='destination')\n",
    "    city_cum = city_dist.merge(city_pop, on='origin')\n",
    "    \n",
    "    allCity_dfs.append(city_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘cities’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir cities\n",
    "for i,df in enumerate(allCity_dfs):\n",
    "    city = cities[i][0]\n",
    "    df.to_csv('cities/'+city+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, separate_income=False):\n",
    "    y_target = ['S000']  # target = total commute if no income segregation\n",
    "    origin = df.groupby(['origin']).agg({'S000':sum}).reset_index()\n",
    "    origin.columns = ['origin','S000residence']\n",
    "    destination = df.groupby(['destination']).agg({'S000':sum}).reset_index()\n",
    "    destination.columns = ['destination','S000jobs']\n",
    "    data = data.merge(origin,on=['origin'])\n",
    "    data = data.merge(destination,on=['destination'])\n",
    "    if separate_income == True:\n",
    "        \n",
    "        y_target = ['SE01', 'SE02', 'SE03'] \n",
    "        origin = df.groupby(['origin']).agg({'SE01':sum,'SE02':sum,'SE03':sum}).reset_index()\n",
    "        origin.columns = ['origin','SE01residence','SE02residence','SE03residence']\n",
    "        destination = df.groupby(['destination']).agg({'SE01':sum,'SE02':sum,'SE03':sum}).reset_index()\n",
    "        destination.columns = ['destination','SE01jobs','SE02jobs','SE03jobs']\n",
    "        data = data.merge(origin,on=['origin'])\n",
    "        data = data.merge(destination,on=['destination'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘citiesProcessed/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir citiesProcessed/\n",
    "cities = os.listdir('cities/')\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv('cities/'+city)\n",
    "        df = preprocessing(df,separate_income=False)\n",
    "        df = df[['origin','destination','distance','S000residence','S000jobs','S000']]\n",
    "        df.to_csv('citiesProcessed/'+city,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘citiesProcessedIncome/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir citiesProcessedIncome/\n",
    "cities = os.listdir('cities/')\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv('cities/'+city)\n",
    "        df = preprocessing(df,separate_income=True)\n",
    "        df = df[['origin','SE01residence','SE02residence','SE03residence','destination','SE01jobs','SE02jobs','SE03jobs','distance','S000','SE01', 'SE02', 'SE03']]\n",
    "        df.to_csv('citiesProcessedIncome/'+city,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE, doubly constrained, fit u,v together in iterations, from Mingyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbins(df, nbins=20):     \n",
    "    df['bin'] = pd.qcut(df['distance'], q=20)\n",
    "    df.sort_values(by='bin', inplace=True)\n",
    "    df.rename(columns={'jobs':'S000jobs', 'residence':'S000residence'}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "def balancing(test,target,iterationNum,iteration = 20):\n",
    "#     print(target,'iteration', iterationNum)\n",
    "    if target+'B' not in test.columns:\n",
    "        test[target+'B'] = 1\n",
    "    test[target+'BDF'] = test[target+'jobs']*test[target+'f(d)']*test[target+'B']\n",
    "    if target+'A' in test.columns:\n",
    "        del test[target+'A']\n",
    "    del test[target+'B']\n",
    "    test = test.groupby(['origin']).agg({target+'BDF':sum}).\\\n",
    "    rename(columns={target+'BDF':target+'A'}).reset_index().\\\n",
    "    merge(test,on=['origin'],how='right')\n",
    "    test[target+'A'] = 1/test[target+'A']\n",
    "    test[target+'AOF'] = test[target+'residence']*test[target+'f(d)']*test[target+'A']\n",
    "    test = test.groupby(['destination']).agg({target+'AOF':sum}).\\\n",
    "    rename(columns={target+'AOF':target+'B'}).reset_index().\\\n",
    "    merge(test,on=['destination'],how='right')\n",
    "    test[target+'B'] = 1/test[target+'B']\n",
    "    test[target+'flowPred'] = test[target+'residence']*test[target+'jobs']*test[target+'f(d)']*\\\n",
    "                        test[target+'A']*test[target+'B']\n",
    "    \n",
    "    resultO = test[['origin',target+'residence']].drop_duplicates().\\\n",
    "    merge(test.groupby(['origin'])[[target+'flowPred']].sum().reset_index(),on=['origin'],how='left')\n",
    "    resultO['percentage'] = np.abs(resultO[target+'residence'] - resultO[target+'flowPred'])/resultO[target+'residence']\n",
    "    resultO = resultO['percentage'].mean()\n",
    "\n",
    "    resultD = test[['destination',target+'jobs']].drop_duplicates().\\\n",
    "    merge(test.groupby(['destination'])[[target+'flowPred']].sum().reset_index(),on=['destination'],how='left')\n",
    "    resultD['percentage'] = np.abs(resultD[target+'jobs'] - resultD[target+'flowPred'])/resultD[target+'jobs']\n",
    "    resultD = resultD['percentage'].mean()\n",
    "#     print(resultO,resultD)\n",
    "    if resultO < 0.05 and resultD < 0.05:\n",
    "        return test\n",
    "    else:\n",
    "        if iterationNum < iteration:\n",
    "            return balancing(test,target,iterationNum = iterationNum+1,iteration = 20)\n",
    "        else:\n",
    "            return test\n",
    "        \n",
    "def doubly_constrained_model_AB(data, separate_income=False):\n",
    "    \n",
    "    y_target = ['S000']\n",
    "    if separate_income == True:\n",
    "        y_target = ['SE01', 'SE02', 'SE03'] \n",
    "    targetOutput = []\n",
    "    for target in y_target:\n",
    "        binoutput = pd.DataFrame()\n",
    "        # estimate F for each bin\n",
    "        for b in data['bin'].unique():\n",
    "            subData = data[data['bin'] == b]\n",
    "            X = subData[target+'residence'] * subData[target+'jobs']\n",
    "            \n",
    "            y = subData[target]\n",
    "\n",
    "            model = sm.OLS(y,X).fit()\n",
    "            \n",
    "            subData[target+'f(d)'] = model.params[0]       \n",
    "            binoutput = pd.concat([binoutput,subData])\n",
    "        binoutput = balancing(binoutput,target,iterationNum=1,iteration = 20)\n",
    "        \n",
    "        binoutput = binoutput[['origin','destination',target,target+'A',target+'B',target+'f(d)','bin',target+'flowPred']]\n",
    "        targetOutput.append(binoutput)\n",
    "    if separate_income == True:\n",
    "        targetOutput = targetOutput[0].merge(targetOutput[1],on=['origin','destination'],how='outer').\\\n",
    "                        merge(targetOutput[2],on=['origin','destination'],how='outer')\n",
    "    else:\n",
    "        targetOutput = targetOutput[0]\n",
    "    targetOutput = targetOutput.merge(data[['origin','destination','S000']])\n",
    "    return targetOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘constrainCTdistbinsAB/’: File exists\n",
      "mkdir: cannot create directory ‘constrainCTdistbinsABIncome/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir constrainCTdistbinsAB/\n",
    "!mkdir constrainCTdistbinsABIncome/\n",
    "separate_income = True\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'constrainCTdistbinsABIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'constrainCTdistbinsAB/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = doubly_constrained_model_AB(getbins(df),separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_income = False\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'constrainCTdistbinsABIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'constrainCTdistbinsAB/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = doubly_constrained_model_AB(getbins(df),separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unconstrain model, power law, from Mingyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize\n",
    "def power_law(x,k,a):\n",
    "    return k*((x[:,0]**a)*x[:,1]*x[:,2])\n",
    "def unconstrained_powerlaw(data, separate_income=False):\n",
    "    y_target = ['S000']\n",
    "    if separate_income == True:\n",
    "        y_target = ['SE01', 'SE02', 'SE03'] \n",
    "    dataF = []\n",
    "    for target in y_target:\n",
    "        X = data[['distance',target+'jobs',target+'residence']].values\n",
    "        y = data[target].values\n",
    "        pars, cov = optimize.curve_fit(f=power_law, xdata=X, ydata=y, bounds=(-np.inf, np.inf))\n",
    "#         print(pars)\n",
    "        data[target+'k'] = pars[0]\n",
    "        data[target+'a'] = pars[1]\n",
    "        data[target+'pred'] = data[target+'k']*(data['distance']**data[target+'a'])*data[target+'jobs']*data[target+'residence']\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘unconstrainCTPowerlaw/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir unconstrainCTPowerlaw/\n",
    "\n",
    "\n",
    "separate_income = False\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'unconstrainCTPowerlawIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'unconstrainCTPowerlaw/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = unconstrained_powerlaw(df,separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir unconstrainCTPowerlawIncome/\n",
    "separate_income = True\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'unconstrainCTPowerlawIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'unconstrainCTPowerlaw/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = unconstrained_powerlaw(df,separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unconstrain model, full power law, from Mingyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def power_law(x,k,a,b,c):\n",
    "    return k*(x[:,0]**a)*(x[:,1]**b)*(x[:,2]**c)\n",
    "def unconstrained_fullpowerlaw(data, separate_income=False):\n",
    "    y_target = ['S000']\n",
    "    if separate_income == True:\n",
    "        y_target = ['SE01', 'SE02', 'SE03'] \n",
    "    dataF = []\n",
    "    for target in y_target:\n",
    "        X = data[['distance',target+'jobs',target+'residence']].values\n",
    "        y = data[target].values\n",
    "        pars, cov = optimize.curve_fit(f=power_law, xdata=X, ydata=y, bounds=(-np.inf, np.inf))\n",
    "#         print(pars)\n",
    "        data[target+'k'] = pars[0]\n",
    "        data[target+'a'] = pars[1]\n",
    "        data[target+'b'] = pars[2]\n",
    "        data[target+'c'] = pars[3]\n",
    "        data[target+'pred'] = data[target+'k']*(data['distance']**data[target+'a'])*\\\n",
    "                        (data[target+'jobs']**data[target+'b'])*(data[target+'residence']**data[target+'c'])\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir unconstrainCTFullPowerlaw/\n",
    "!mkdir unconstrainCTFullPowerlawIncome/\n",
    "\n",
    "\n",
    "separate_income = False\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'unconstrainCTFullPowerlawIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'unconstrainCTFullPowerlaw/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = unconstrained_fullpowerlaw(df,separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "separate_income = True\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'unconstrainCTFullPowerlawIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'unconstrainCTFullPowerlaw/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = unconstrained_fullpowerlaw(df,separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unconstrain model, exp, from Mingyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x, a,b):\n",
    "    return a*(np.e**(b*x))\n",
    "def unconstrained_exp(data, separate_income=False):\n",
    "    y_target = ['S000']\n",
    "    if separate_income == True:\n",
    "        y_target = ['SE01', 'SE02', 'SE03'] \n",
    "    dataF = []\n",
    "    for target in y_target:\n",
    "        X = data.distance.values\n",
    "        y = data[target]/(data[target+'jobs']*data[target+'residence'])\n",
    "        pars, cov = optimize.curve_fit(f=exp, xdata=X, ydata=y, bounds=(-np.inf, np.inf))\n",
    "#         print(pars)\n",
    "        data[target+'a'] = pars[0]\n",
    "        data[target+'b'] = pars[1]\n",
    "        data[target+'pred'] = data[target+'a']*(np.e**(data['distance']*data[target+'b']))*data[target+'jobs']*data[target+'residence']\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘unconstrainCTFullExp/’: File exists\n",
      "mkdir: cannot create directory ‘unconstrainCTFullExpIncome/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir unconstrainCTFullExp/\n",
    "!mkdir unconstrainCTFullExpIncome/\n",
    "\n",
    "\n",
    "separate_income = False\n",
    "if separate_income == True:\n",
    "    citiesDir = 'citiesProcessedIncome/'\n",
    "    outputDir = 'unconstrainCTFullExpIncome/'\n",
    "else:\n",
    "    citiesDir = 'citiesProcessed/'\n",
    "    outputDir = 'unconstrainCTFullExp/'\n",
    "for city in cities:\n",
    "    if '.csv' in city:\n",
    "        df = pd.read_csv(citiesDir+city)\n",
    "        dataUV = unconstrained_exp(df,separate_income=separate_income)\n",
    "        dataUV.to_csv(outputDir+city,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
