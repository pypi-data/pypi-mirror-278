{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Benchmark Workshop Datasets\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sysbench_loader.core import *\n",
    "import nonlinear_benchmarks\n",
    "from nonlinear_benchmarks.utilities import Input_output_data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path('./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiener Hammerstein Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wiener_hammerstein(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = Path(save_path) / 'wh'\n",
    "    train_val, test = nonlinear_benchmarks.WienerHammerBenchMark()\n",
    "    split_idx = 80_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiener_hammerstein(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silverbox Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def silverbox(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = Path(save_path) / 'silverbox'\n",
    "    train_val, test = nonlinear_benchmarks.Silverbox()\n",
    "    split_idx = 78_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silverbox(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascaded Tanks Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cascaded_tanks(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the cascaded_tanks dataset, '\n",
    "    save_path = Path(save_path) / 'cascaded_tanks'\n",
    "    train_val, test = nonlinear_benchmarks.Cascaded_Tanks()\n",
    "    train = train_val\n",
    "    valid = train_val\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascaded_tanks(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def emps(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the emps dataset, '\n",
    "    save_path = Path(save_path) / 'emps'\n",
    "    train_val, test = nonlinear_benchmarks.EMPS()\n",
    "    split_idx = 18_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Wiener Hammerstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from scipy.io import loadmat\n",
    "def noisy_wh(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the wiener hammerstein dataset with process noise'\n",
    "    save_path = Path(save_path) / 'noisy_wh'\n",
    "\n",
    "    #extract raw .mat files, to preserve filenames necessary for train, valid split\n",
    "    matfiles = nonlinear_benchmarks.not_splitted_benchmarks.WienerHammerstein_Process_Noise(data_file_locations=True,train_test_split=False)\n",
    "\n",
    "    for file in matfiles:\n",
    "        f_path = Path(file)\n",
    "\n",
    "        if 'Test' in f_path.stem:\n",
    "            hdf_path = save_path / 'test'\n",
    "        elif 'Combined' in f_path.stem:\n",
    "            hdf_path = save_path / 'valid'\n",
    "        else:\n",
    "            hdf_path = save_path / 'train'\n",
    "\n",
    "        out = loadmat(f_path)\n",
    "        _,u,y,fs = out['dataMeas'][0,0]\n",
    "        fs = fs[0,0]\n",
    "        for idx,(ui,yi) in enumerate(zip(u.T,y.T)):\n",
    "            iodata = Input_output_data(u=ui,y=yi, sampling_time=1/fs)\n",
    "            fname = f'{f_path.stem}_{idx+1}'\n",
    "            iodata_to_hdf5(iodata,hdf_path,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_wh(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#clean temporary hdf5 file\n",
    "# shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
