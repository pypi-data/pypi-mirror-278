{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT-classification: Analysis and Classification methods for Multiple Aspect Trajectory Data Mining \\[MAT-Tools Framework\\]\n",
    "\n",
    "Sample Code in python notebook to use mat-classification as a python library.\n",
    "\n",
    "The present package offers a tool, to support the user in the task of data analysis of multiple aspect trajectories. It integrates into a unique framework for multiple aspects trajectories and in general for multidimensional sequence data mining methods.\n",
    "\n",
    "Created on Dec, 2023\n",
    "Copyright (C) 2023, License GPL Version 3 or superior (see LICENSE file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install mat-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Loading data\n",
    "To use helpers for data pre-processing, import from package `matdata` (dependency: [mat-data](https://github.com/ttportela/mat-data)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1. Loading a sample data\n",
    "    a) Lets start by loading FoursquareNYC data:\n",
    "(For other preprocessing functions, check the docs: https://mat-analysis.github.io/mat-tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset file: https://github.com/mat-analysis/datasets/tree/main/mat/FoursquareNYC/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1055k  100 1055k    0     0  1890k      0 --:--:-- --:--:-- --:--:-- 1908k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th>poi</th>\n",
       "      <th>type</th>\n",
       "      <th>root_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>weather</th>\n",
       "      <th>tid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.8331652006224 -73.9418603427692</td>\n",
       "      <td>317</td>\n",
       "      <td>Monday</td>\n",
       "      <td>The Lair Of Modern Strange Cowboy</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>Residence</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.8340978041072 -73.9452672225881</td>\n",
       "      <td>1404</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Galaxy Gourmet Deli</td>\n",
       "      <td>Deli / Bodega</td>\n",
       "      <td>Food</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.8331652006224 -73.9418603427692</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>The Lair Of Modern Strange Cowboy</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>Residence</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.7646959283254 -73.8851974964414</td>\n",
       "      <td>1069</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Popeyes Louisiana Kitchen</td>\n",
       "      <td>Fried Chicken Joint</td>\n",
       "      <td>Food</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Clear</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.7660790376824 -73.8835287094116</td>\n",
       "      <td>1120</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>MTA Bus Operations Depot - LaGuardia</td>\n",
       "      <td>Bus Station</td>\n",
       "      <td>Travel &amp; Transport</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66941</th>\n",
       "      <td>40.7047332789043 -73.9877378940582</td>\n",
       "      <td>1037</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Miami Ad School Brooklyn</td>\n",
       "      <td>General College &amp; University</td>\n",
       "      <td>College &amp; University</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>29563</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66942</th>\n",
       "      <td>40.6951627360199 -73.9954478691072</td>\n",
       "      <td>1210</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Lantern Thai Kitchen</td>\n",
       "      <td>Thai Restaurant</td>\n",
       "      <td>Food</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>29563</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66943</th>\n",
       "      <td>40.6978026652822 -73.9941451630314</td>\n",
       "      <td>481</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Eastern Athletic Club</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Outdoors &amp; Recreation</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>29563</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66944</th>\n",
       "      <td>40.6946728967503 -73.9940820360805</td>\n",
       "      <td>819</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>Food</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>29563</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66945</th>\n",
       "      <td>40.6978026652822 -73.9941451630314</td>\n",
       "      <td>476</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Eastern Athletic Club</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Outdoors &amp; Recreation</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>29563</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66946 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    space  time       day  \\\n",
       "0      40.8331652006224 -73.9418603427692   317    Monday   \n",
       "1      40.8340978041072 -73.9452672225881  1404    Monday   \n",
       "2      40.8331652006224 -73.9418603427692     0   Tuesday   \n",
       "3      40.7646959283254 -73.8851974964414  1069  Thursday   \n",
       "4      40.7660790376824 -73.8835287094116  1120  Thursday   \n",
       "...                                   ...   ...       ...   \n",
       "66941  40.7047332789043 -73.9877378940582  1037    Friday   \n",
       "66942  40.6951627360199 -73.9954478691072  1210    Friday   \n",
       "66943  40.6978026652822 -73.9941451630314   481  Saturday   \n",
       "66944  40.6946728967503 -73.9940820360805   819  Saturday   \n",
       "66945  40.6978026652822 -73.9941451630314   476    Sunday   \n",
       "\n",
       "                                        poi                          type  \\\n",
       "0         The Lair Of Modern Strange Cowboy                Home (private)   \n",
       "1                       Galaxy Gourmet Deli                 Deli / Bodega   \n",
       "2         The Lair Of Modern Strange Cowboy                Home (private)   \n",
       "3                 Popeyes Louisiana Kitchen           Fried Chicken Joint   \n",
       "4      MTA Bus Operations Depot - LaGuardia                   Bus Station   \n",
       "...                                     ...                           ...   \n",
       "66941              Miami Ad School Brooklyn  General College & University   \n",
       "66942                  Lantern Thai Kitchen               Thai Restaurant   \n",
       "66943                 Eastern Athletic Club                           Gym   \n",
       "66944                             Starbucks                   Coffee Shop   \n",
       "66945                 Eastern Athletic Club                           Gym   \n",
       "\n",
       "                   root_type  rating weather    tid  label  \n",
       "0                  Residence    -1.0   Clear    126      6  \n",
       "1                       Food     8.2  Clouds    126      6  \n",
       "2                  Residence    -1.0  Clouds    126      6  \n",
       "3                       Food     6.6   Clear    126      6  \n",
       "4         Travel & Transport    -1.0   Clear    126      6  \n",
       "...                      ...     ...     ...    ...    ...  \n",
       "66941   College & University    -1.0  Clouds  29563   1070  \n",
       "66942                   Food     8.0  Clouds  29563   1070  \n",
       "66943  Outdoors & Recreation     6.9  Clouds  29563   1070  \n",
       "66944                   Food     7.0  Clouds  29563   1070  \n",
       "66945  Outdoors & Recreation     6.9  Clouds  29563   1070  \n",
       "\n",
       "[66946 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matdata.dataset import load_ds\n",
    "\n",
    "dataset='mat.FoursquareNYC'\n",
    "\n",
    "data = load_ds(dataset, missing='-999')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed443aaab43419b89b4eec70fc0b1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spliting Data (class-balanced):   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49afbdc13b54591918ce064f005f1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sorting data:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ca07670396465babc8186c1028629c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sorting data:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 84, 164, 181, 390, 768]), '--', 56, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matdata.preprocess import klabels_stratify\n",
    "train, test = klabels_stratify(data, kl=5)\n",
    "\n",
    "train.label.unique(), '--', len(train.tid.unique()), len(test.tid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.2. Saving and Conversions\n",
    "    b) Saving trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train.to_parquet(f'sample/data/{dataset.split(\".\")[1]}/train.parquet', index=False)\n",
    "test.to_parquet(f'sample/data/{dataset.split(\".\")[1]}/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can save using the converter functions (which provide more options), in other formats for other input types of methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matdata.converter import df2csv, df2zip, df2parquet\n",
    "\n",
    "# Saving as csv:\n",
    "df2csv(train, f'sample/data/{dataset.split(\".\")[1]}', 'train')\n",
    "df2csv(test, f'sample/data/{dataset.split(\".\")[1]}', 'test')\n",
    "\n",
    "# Saving as zip (containing trajectory type of files):\n",
    "df2zip(train, f'sample/data/{dataset.split(\".\")[1]}', 'train')\n",
    "df2zip(test, f'sample/data/{dataset.split(\".\")[1]}', 'test')\n",
    "\n",
    "# Saving as parquet (override):\n",
    "df2parquet(train, f'sample/data/{dataset.split(\".\")[1]}', 'train')\n",
    "df2parquet(test, f'sample/data/{dataset.split(\".\")[1]}', 'test')\n",
    "\n",
    "# Check docs:\n",
    "help(df2parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, experiment with a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Classification Methods\n",
    "\n",
    "TODO\n",
    "\n",
    "- `prepare_input(train, test)` => `model.train()` => `model.test()`\n",
    "- `model.fit(X_train, y_train, X_val, y_val)` => `model.predict(X_test, y_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Trajectory Based Methods\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.1. MARC\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MARC\n",
    "\n",
    "model = MARC()\n",
    "model.prepare_input(train, test)\n",
    "model.train()\n",
    "model.test()\n",
    "## We can visualize the training report (the same on most models):\n",
    "model.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and this is the model available metrics:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix:\n",
    "model.cm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can repeat the classification in a number of rounds with increasing random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.test(rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can visualize the test report (the same on most models):\n",
    "model.test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And show the mean results\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to use the classifier in a traditional way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MARC\n",
    "\n",
    "model = MARC()\n",
    "\n",
    "# Each classifier expect a ceirtain input format. If you want to change, check the 'xy' method:\n",
    "(keys, vocab_size, num_classes, max_length, le, x_train, x_test, y_train, y_test) = model.xy(train, test)\n",
    "\n",
    "# You can add method variables with this:\n",
    "model.add_config(keys=keys, \n",
    "                 vocab_size=vocab_size,\n",
    "                 num_classes=num_classes,\n",
    "                 max_length=max_length)\n",
    "model.le = le # The label encoder\n",
    "\n",
    "# Run the classifier:\n",
    "model.fit(x_train, y_train, x_test, y_test)\n",
    "\n",
    "summary, y_pred = model.predict(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.2. POI-Sequences (extention of POI-Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NPOI:] Building model\n",
      "5 5 False\n",
      "5 5 False\n",
      "[POIS:] Starting feature extractor ... \n",
      "- Feature: poi, Sequence: 1\n",
      "Starting NPOI...\n",
      "[POIS:] Processing time: 24.002 milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n",
      "[NPOI:] Training hiperparameter model\n",
      "Metal device set to: Apple M1\n",
      "WARNING: File 'metrics.csv' not found!\n",
      "===== Training Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:04:22.671706: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 15:04:22.671795: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-06-09 15:04:22.781453: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-06-09 15:04:23.022850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-09 15:04:23.220408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "TRAIN\t\tacc: 0.339286\tacc_top5: 1.000000\tf1_macro: 0.314762\tprec_macro: 0.349825\trec_macro: 0.318019\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.250000\tacc_top5: 1.000000\tf1_macro: 0.238974\tprec_macro: 0.275000\trec_macro: 0.248571\n",
      "===== Training Epoch 2 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.678571\tacc_top5: 1.000000\tf1_macro: 0.650667\tprec_macro: 0.652747\trec_macro: 0.656494\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.535714\tacc_top5: 1.000000\tf1_macro: 0.512967\tprec_macro: 0.526667\trec_macro: 0.517143\n",
      "===== Training Epoch 3 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:04:23.305735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.915397\tprec_macro: 0.912698\trec_macro: 0.919643\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.714286\tacc_top5: 1.000000\tf1_macro: 0.656667\tprec_macro: 0.650000\trec_macro: 0.664286\n",
      "===== Training Epoch 4 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.982143\tacc_top5: 1.000000\tf1_macro: 0.977719\tprec_macro: 0.986667\trec_macro: 0.971429\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.785714\tacc_top5: 1.000000\tf1_macro: 0.753571\tprec_macro: 0.777778\trec_macro: 0.742857\n",
      "===== Training Epoch 5 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.857143\tacc_top5: 1.000000\tf1_macro: 0.806984\tprec_macro: 0.927273\trec_macro: 0.800000\n",
      "===== Training Epoch 6 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 7 =====\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 8 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 9 =====\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 10 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 11 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 12 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 13 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 14 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 15 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 16 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 17 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 18 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 19 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 20 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 21 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 22 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 23 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 24 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 25 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 26 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 27 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 28 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 29 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 30 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 31 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 32 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 33 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 34 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 35 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 36 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 37 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 38 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 39 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 40 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 41 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 42 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 43 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 44 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "Epoch 44: early stopping\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "NOW: 2 2\n",
      "[NPOI:] Creating a model to test set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf92a961e9b540dc87d4854411b11ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Testing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: File 'metrics.csv' not found!\n",
      "===== Training Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:04:27.310858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-09 15:04:27.458574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "TRAIN\t\tacc: 0.517857\tacc_top5: 1.000000\tf1_macro: 0.510627\tprec_macro: 0.504970\trec_macro: 0.525162\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.535714\tacc_top5: 1.000000\tf1_macro: 0.498974\tprec_macro: 0.526429\trec_macro: 0.515714\n",
      "===== Training Epoch 2 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.821429\tacc_top5: 1.000000\tf1_macro: 0.808552\tprec_macro: 0.802167\trec_macro: 0.823214\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.750000\tacc_top5: 1.000000\tf1_macro: 0.707778\tprec_macro: 0.710000\trec_macro: 0.716429\n",
      "===== Training Epoch 3 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:04:27.529092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.954986\tprec_macro: 0.960000\trec_macro: 0.957143\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.832778\tprec_macro: 0.915556\trec_macro: 0.850000\n",
      "===== Training Epoch 4 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 5 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 6 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 7 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 8 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 9 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 10 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 11 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 12 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 13 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 14 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 15 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 16 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 17 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 18 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 19 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 20 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 21 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 22 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 23 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 24 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 25 =====\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 26 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 27 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 28 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 29 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 30 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 31 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 32 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.844706\tprec_macro: 0.940000\trec_macro: 0.850000\n",
      "===== Training Epoch 33 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 34 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 35 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 36 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 37 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 38 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 39 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 40 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 41 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 42 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 43 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 44 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 45 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 46 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 47 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 48 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 49 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 50 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 51 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 52 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 53 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 54 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 55 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 56 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 57 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 58 =====\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 59 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 60 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 61 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 62 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 63 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "Epoch 63: early stopping\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "NOW: 2 2\n",
      "[NPOI:] Processing time: 10394.057 milliseconds. Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       " 0  0.928571         1.0                0.9         0.908333      0.955556   \n",
       " \n",
       "    f1_macro   cls_time  \n",
       " 0       0.9  10393.023  ,\n",
       " array([[9.86939192e-01, 5.10711269e-03, 3.90173797e-03, 6.44403917e-04,\n",
       "         3.40754562e-03],\n",
       "        [9.01734054e-01, 3.44225354e-02, 2.82153841e-02, 1.37928789e-02,\n",
       "         2.18351111e-02],\n",
       "        [9.13322926e-01, 3.50455046e-02, 2.34118849e-02, 1.18214581e-02,\n",
       "         1.63982138e-02],\n",
       "        [9.61652458e-01, 1.48669872e-02, 1.17285028e-02, 3.77437961e-03,\n",
       "         7.97766075e-03],\n",
       "        [8.40293348e-01, 5.00207134e-02, 5.32868020e-02, 2.54507121e-02,\n",
       "         3.09483800e-02],\n",
       "        [8.95924509e-01, 3.14413980e-02, 3.41718830e-02, 1.71764344e-02,\n",
       "         2.12858003e-02],\n",
       "        [8.82790565e-01, 3.12659182e-02, 3.54368091e-02, 1.40276607e-02,\n",
       "         3.64789665e-02],\n",
       "        [8.63656640e-01, 3.94147933e-02, 4.01393771e-02, 1.73572563e-02,\n",
       "         3.94319445e-02],\n",
       "        [7.04452693e-02, 2.58419961e-01, 1.55855998e-01, 3.93964916e-01,\n",
       "         1.21313967e-01],\n",
       "        [7.28855506e-02, 3.79470497e-01, 1.34178206e-01, 2.93166161e-01,\n",
       "         1.20299593e-01],\n",
       "        [6.38317093e-02, 4.31033760e-01, 1.21183261e-01, 2.82492697e-01,\n",
       "         1.01458691e-01],\n",
       "        [7.65710101e-02, 3.07707548e-01, 1.56494752e-01, 3.29089701e-01,\n",
       "         1.30137056e-01],\n",
       "        [5.69547787e-02, 1.45261690e-01, 5.25677323e-01, 1.78610146e-01,\n",
       "         9.34960544e-02],\n",
       "        [2.67559383e-02, 5.86023815e-02, 8.12900960e-01, 6.68912753e-02,\n",
       "         3.48494463e-02],\n",
       "        [5.18503040e-02, 1.13231443e-01, 6.26379013e-01, 1.30948886e-01,\n",
       "         7.75903016e-02],\n",
       "        [2.90192999e-02, 6.07722625e-02, 8.10103714e-01, 6.73203394e-02,\n",
       "         3.27844322e-02],\n",
       "        [3.41178961e-02, 1.02954902e-01, 8.68861824e-02, 7.16101289e-01,\n",
       "         5.99397235e-02],\n",
       "        [2.60340255e-02, 7.69134685e-02, 7.41007105e-02, 7.59499729e-01,\n",
       "         6.34521618e-02],\n",
       "        [3.01691797e-02, 9.43840444e-02, 7.32313320e-02, 7.52880573e-01,\n",
       "         4.93348651e-02],\n",
       "        [2.76339799e-02, 9.37682390e-02, 7.43599236e-02, 7.55394340e-01,\n",
       "         4.88434769e-02],\n",
       "        [2.78828368e-02, 8.33755881e-02, 6.83175400e-02, 7.71025956e-01,\n",
       "         4.93980721e-02],\n",
       "        [3.03248204e-02, 9.40251872e-02, 7.84273744e-02, 7.38968253e-01,\n",
       "         5.82543127e-02],\n",
       "        [1.49860289e-02, 4.46260758e-02, 3.65927219e-02, 8.78889441e-01,\n",
       "         2.49056984e-02],\n",
       "        [3.71878943e-03, 1.49084553e-02, 1.21382298e-02, 5.16276015e-03,\n",
       "         9.64071870e-01],\n",
       "        [8.16649757e-03, 3.29005420e-02, 1.99047010e-02, 2.02998705e-02,\n",
       "         9.18728352e-01],\n",
       "        [3.82627212e-02, 1.21848971e-01, 1.08079046e-01, 1.12931877e-01,\n",
       "         6.18877411e-01],\n",
       "        [1.98024567e-02, 7.52764940e-02, 4.78709899e-02, 4.14711349e-02,\n",
       "         8.15578997e-01],\n",
       "        [7.89003074e-03, 3.60301472e-02, 1.83396265e-02, 1.60375442e-02,\n",
       "         9.21702623e-01]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matclassification.methods import POIS\n",
    "\n",
    "sequences = [1] # Sequence sizes to use, example, for 1, 2 or 3 points use: [1, 2, 3] \n",
    "features = ['poi'] # Features to build frequency matrix combined with sequence sizes, \n",
    "                   # by default selects the feature with higher variance\n",
    "# method='npoi' # you can pass the extract method\n",
    "\n",
    "model = POIS('npoi', sequences, features)\n",
    "model.prepare_input(train, test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>cls_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10645.658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.928571         1.0                0.9         0.908333      0.955556   \n",
       "\n",
       "   f1_macro   cls_time  \n",
       "0       0.9  10645.658  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x296acaeb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Confusion Matrix:\n",
    "model.cm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use just the feature extractor, you can check `poifreq` submodule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods.feature.feature_extraction.pois import pois\n",
    "\n",
    "sequences = [1,2,3]\n",
    "features = ['poi']\n",
    "method='npoi' # default: 'npoi', or, 'poi' and 'wnpoi'\n",
    "\n",
    "x_train, x_test, y_train, y_test, _ = pois(train, test, sequences, features, method, \n",
    "                                           result_dir='./sample/results/pois', save_all=True) # And we save the results\n",
    "\n",
    "display(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[POIS:] Starting feature extractor ... \n",
      "- Feature: poi, Sequence: 1\n",
      "Starting NPOI...\n",
      "[POIS:] Processing time: 85.184 milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>573</th>\n",
       "      <th>574</th>\n",
       "      <th>575</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>578</th>\n",
       "      <th>579</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows Ã— 580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2        3         4         5         6    \\\n",
       "0   0.024390  0.073171  0.048780  0.02439  0.024390  0.024390  0.024390   \n",
       "1   0.000000  0.027778  0.037037  0.00000  0.009259  0.027778  0.009259   \n",
       "2   0.000000  0.021505  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.020833  0.00000  0.000000  0.020833  0.020833   \n",
       "4   0.015385  0.046154  0.030769  0.00000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.017241  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.046512  0.023256  0.00000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.042553  0.021277  0.00000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.057143  0.00000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.014493  0.057971  0.00000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.067797  0.00000  0.000000  0.000000  0.016949   \n",
       "13  0.041667  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "24  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "30  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "31  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "32  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "33  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "40  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "41  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "42  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "43  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "44  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "45  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "46  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "47  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "48  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "49  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "50  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "51  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "52  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "53  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "54  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "55  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7         8         9    ...       570       571       572       573  \\\n",
       "0   0.024390  0.048780  0.024390  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.009259  0.037037  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.021505  0.000000  0.010753  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.041667  0.020833  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.015385  0.046154  0.046154  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.017241  0.051724  0.034483  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.046512  0.023256  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.042553  0.063830  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.015152  0.015152  0.060606  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.043478  0.028986  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.090909  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.050847  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.041667  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "24  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "30  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "31  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "32  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "33  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "40  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "41  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "42  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "43  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "44  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "45  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "46  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "47  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "48  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "49  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "50  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "51  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "52  0.000000  0.000000  0.000000  ...  0.032258  0.032258  0.032258  0.032258   \n",
       "53  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "54  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "55  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         574       575       576       577       578       579  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "23  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "24  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "25  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "26  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "27  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "29  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "30  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "31  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "32  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "34  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "37  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "38  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "39  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "40  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "41  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "42  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "43  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "44  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "45  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "46  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "47  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "48  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "49  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "50  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "51  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "52  0.032258  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "53  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "54  0.000000  0.083333  0.083333  0.083333  0.000000  0.000000  \n",
       "55  0.000000  0.000000  0.000000  0.000000  0.076923  0.076923  \n",
       "\n",
       "[56 rows x 580 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matclassification.methods.feature.feature_extraction.pois import pois\n",
    "\n",
    "sequences = [1]\n",
    "features = ['poi']\n",
    "method='npoi' # default: 'npoi', or, 'poi' and 'wnpoi'\n",
    "\n",
    "x_train, x_test, y_train, y_test, _ = pois(train, test, sequences, features, method, \n",
    "                                           result_dir='./sample/results/pois', save_all=True) # And we save the results\n",
    "\n",
    "display(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can create the classifier (another way of using the classifier classes in the classical way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NPOI:] Building model\n",
      "WARNING: File 'metrics.csv' not found!\n",
      "===== Training Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:06:39.535141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-09 15:06:39.681270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "TRAIN\t\tacc: 0.446429\tacc_top5: 1.000000\tf1_macro: 0.442836\tprec_macro: 0.449610\trec_macro: 0.472727\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.464286\tacc_top5: 1.000000\tf1_macro: 0.412521\tprec_macro: 0.411111\trec_macro: 0.442857\n",
      "===== Training Epoch 2 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.750000\tacc_top5: 1.000000\tf1_macro: 0.742804\tprec_macro: 0.748702\trec_macro: 0.789773\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.750000\tacc_top5: 1.000000\tf1_macro: 0.742634\tprec_macro: 0.764286\trec_macro: 0.766429\n",
      "===== Training Epoch 3 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:06:39.751124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\t\tacc: 0.892857\tacc_top5: 1.000000\tf1_macro: 0.896732\tprec_macro: 0.890620\trec_macro: 0.910065\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.857143\tacc_top5: 1.000000\tf1_macro: 0.858608\tprec_macro: 0.900000\trec_macro: 0.875000\n",
      "===== Training Epoch 4 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.963795\tprec_macro: 0.961667\trec_macro: 0.969318\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 5 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.982143\tacc_top5: 1.000000\tf1_macro: 0.983580\tprec_macro: 0.986667\trec_macro: 0.981818\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 6 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.982143\tacc_top5: 1.000000\tf1_macro: 0.983580\tprec_macro: 0.986667\trec_macro: 0.981818\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 7 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 8 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 9 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.964286\tacc_top5: 1.000000\tf1_macro: 0.958095\tprec_macro: 0.975000\trec_macro: 0.950000\n",
      "===== Training Epoch 10 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 11 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 12 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 13 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 14 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 15 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 16 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 17 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 18 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 19 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 20 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 21 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 22 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 23 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 24 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 25 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 26 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 27 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 28 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 29 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 30 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 31 =====\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 32 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 33 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "===== Training Epoch 34 =====\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.908333\tprec_macro: 0.955556\trec_macro: 0.900000\n",
      "Epoch 34: early stopping\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "NOW: 2 2\n"
     ]
    }
   ],
   "source": [
    "from matclassification.methods.feature.POIS import POIS, prepareData\n",
    "\n",
    "sequences = [1]\n",
    "features = ['poi']\n",
    "\n",
    "# POIS method have a method for data transformation:\n",
    "num_features, num_classes, labels, X, y, one_hot_y = prepareData(x_train, x_test, y_train, y_test)\n",
    "x_train, x_test = X\n",
    "y_train, y_test = y\n",
    "\n",
    "# Create the classifier:\n",
    "model = POIS('npoi', sequences, features)\n",
    "\n",
    "# Model Label Encoder:\n",
    "model.le = one_hot_y\n",
    "\n",
    "# You can add method variables with this:\n",
    "model.add_config(num_features=num_features,\n",
    "                num_classes=num_classes, \n",
    "                labels=labels)\n",
    "\n",
    "# Run the classifier:\n",
    "model.fit(x_train, y_train, x_test, y_test)\n",
    "\n",
    "summary, y_pred = model.predict(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.928571         1.0                0.9         0.908333      0.955556   \n",
       "\n",
       "   f1_macro  \n",
       "0       0.9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next classifiers use Hiperparameter Optimization (class derrived from `HPSClassifier`), thus we first call `model.train()` to test model configurations to look for the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.3. DeepeST\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import DeepeST\n",
    "\n",
    "model = DeepeST()\n",
    "model.prepare_input(train, test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.4. Trajectory Random Forrest (TRF)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import TRF\n",
    "\n",
    "model = TRF()\n",
    "model.prepare_input(train, test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.5. Trajectory XGBoost (TXGB)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import TXGB\n",
    "\n",
    "model = TXGB()\n",
    "model.prepare_input(train, test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.6. BITULER\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import Bituler\n",
    "\n",
    "model = Bituler()\n",
    "model.prepare_input(train, test, features=['poi'])\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.1.7. TULVAE\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import Tulvae\n",
    "\n",
    "model = Tulvae()\n",
    "model.prepare_input(train, test, features=['poi'])\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2. Movelet Based Methods\n",
    "\n",
    "Movelet base methods .... TODO\n",
    "\n",
    "Let's start by extracting movelets from the train and test data, so we save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matdata.converter import df2csv\n",
    "\n",
    "data_path = 'sample/data/FoursquareNYC'\n",
    "\n",
    "df2csv(train, data_path, 'train')\n",
    "df2csv(test, data_path, 'test')\n",
    "#test.to_csv('sample/data/FoursquareNYC/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matdata.converter import df2parquet\n",
    "\n",
    "data_path = 'sample/data/FoursquareNYC'\n",
    "\n",
    "df2parquet(train, data_path, 'train')\n",
    "df2parquet(test, data_path, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) First, we can apply a method for movelets extraction like [HiPerMovelets](https://github.com/bigdata-ufsc/HiPerMovelets), for example configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 09 16:55:54 BRT 2024\n",
      "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "Starting Movelets +Log extractor \n",
      "Configurations:\n",
      "   -curpath\t\tDatasets directory:\t./sample/data/FoursquareNYC\n",
      "   -respath\t\tResults directory: \t./sample/results/hiper/Movelets/HIPER_Log_FoursquareNYC_LSP_ED\n",
      "   -descfile \t\tDescription file : \t./sample/data/FoursquareNYC/FoursquareNYC.json\n",
      "+-------------+--------------------+---------------------+----------------------------------------------+\n",
      "| Option      | Description        | Value               | Help                                         |\n",
      "+-------------+--------------------+---------------------+----------------------------------------------+\n",
      "| -nt         | Allowed Threads    | 1                   |                                              |\n",
      "| -ms         | Min size           | -1                  | Any positive | -1 | Log: -2                  |\n",
      "| -Ms         | Max size           | -3                  | Any | All sizes: -1 | Log: -3 or -4          |\n",
      "| -mnf        | Max. Dimensions    | -1                  | Any | Explore dim.: -1 | Log: -2 | Other: -3 |\n",
      "| -samples    | Samples            | 1                   |                                              |\n",
      "| -sampleSize | Sample Size        | 0.5                 |                                              |\n",
      "| -q          | Quality Measure    | LSP                 |                                              |\n",
      "| -medium     | Medium             | none                |                                              |\n",
      "| -mpt        | Movelets Per Traj. | -1                  | Any | Auto: -1                               |\n",
      "| -output     | Output             | discrete (CSV,JSON) |                                              |\n",
      "|             |                    |                     |                                              |\n",
      "| -version    | Version Impl.      | hiper               | master, super, hiper[-pivots], random, ultra |\n",
      "|             | -- Last Prunning   | false               |                                              |\n",
      "| -TC         | Time Contract      | 86400000 ms         | Use: w(eeks), d, h, m, s(econds)             |\n",
      "+-------------+--------------------+---------------------+----------------------------------------------+\n",
      "\n",
      "[1] >> Load Input: 2277 milliseconds\n",
      "\n",
      "Attributes and Features:\n",
      "+---+---------------+---------+-----------------+\n",
      "| # | Attribute     | Type    | Comparator      |\n",
      "+---+---------------+---------+-----------------+\n",
      "| 1 | 1 - space     | space2d | euclidean/-1.0  |\n",
      "| 2 | 2 - time      | time    | difference/-1.0 |\n",
      "| 3 | 3 - day       | nominal | equals/-1.0     |\n",
      "| 4 | 4 - poi       | nominal | equals/-1.0     |\n",
      "| 5 | 5 - type      | nominal | equals/-1.0     |\n",
      "| 6 | 6 - root_type | nominal | equals/-1.0     |\n",
      "| 7 | 7 - rating    | numeric | diffnotneg/-1.0 |\n",
      "| 8 | 8 - weather   | nominal | equals/-1.0     |\n",
      "+---+---------------+---------+-----------------+\n",
      "\n",
      "\n",
      "[Memory Usage (MiB)] Memory Total: 245.5; Memory Free: 232.10285186767578; Memory Used: 13.397148132324219;\n",
      "[2] >> Movelet Discovery: [28%] [Class: 84]: Movelets previously discovered.\n",
      "[2] >> Movelet Discovery: [41%] [Class: 164]: Movelets previously discovered.\n",
      "[2] >> Movelet Discovery: [55%] [Class: 181]: Movelets previously discovered.\n",
      "[2] >> Movelet Discovery: [80%] [Class: 390]: Movelets previously discovered.\n",
      "[2] >> Movelet Discovery: [100%] [Class: 768]: Movelets previously discovered.\n",
      "\n",
      "[3] >> Processing time: 48 milliseconds\n",
      "Sun Jun 09 16:55:56 BRT 2024\n"
     ]
    }
   ],
   "source": [
    "!java -Xmx7G -jar \"./sample/programs/MoveletDiscovery.jar\" \\\n",
    "-curpath \"./sample/data/FoursquareNYC\" \\\n",
    "-respath \"./sample/results/hiper\" \\\n",
    "-descfile \"./sample/data/FoursquareNYC/FoursquareNYC.json\" \\\n",
    "-nt 1 -version hiper -ms -1 -Ms -3 -TC 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Concatenate the feature files (created by label) containing the movelets matrix into one train.csv and one test.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 scripts/helpers/MAT-MergeDatasets.py ./sample/results/hiper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movelets_train = pd.read_csv('./sample/results/hiper/train.csv')\n",
    "movelets_test = pd.read_csv('./sample/results/hiper/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use the movelets for classification ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.2.1. Movelet Multi-Layer Perceptron (MMLP)\n",
    "\n",
    "TODO\n",
    "\n",
    "*In this case we donÂ´t need `model.train()` to train models for finding the best configuration parameters. Because the model use movelets, those are already the most discriminant patterns in data. Thus, the neural network was already tunned to this type of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MMLP\n",
    "\n",
    "model = MMLP()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train() \n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is another version, without hiper-parameter search:\n",
    "from matclassification.methods.feature.MoveletMLP import MMLP1\n",
    "\n",
    "model = MMLP1()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train()\n",
    "model.test()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.2.2. Movelet Random Forrest (MRF)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MRF\n",
    "\n",
    "model = MRF()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train() \n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.2.3. Movelet Random Forrest with HiperParameter Search (MRFHP)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MRFHP\n",
    "\n",
    "model = MRFHP()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.2.4. Movelet Support Vector Machine (MSCV)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MSVC\n",
    "\n",
    "model = MSVC()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.5. Movelet Decision Tree (MDT)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MDT\n",
    "\n",
    "model = MDT()\n",
    "model.prepare_input(movelets_train, movelets_test)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = model.plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.graph_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Scripts\n",
    "\n",
    "The scripts provided with this package for using some of the library functions in command line environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Classifications Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only the MARC classifier:\n",
    "!python3 scripts/cls/MARC.py 'sample/data/FoursquareNYC/train.csv' 'sample/data/FoursquareNYC/test.csv' 'sample/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MAT-MC.py [-h] [-c CLASSIFIERS] [-m MODELFOLDER] [-r RANDOM]\n",
      "                 results-path\n",
      "\n",
      "MAT Movelets Classification\n",
      "\n",
      "positional arguments:\n",
      "  results-path          path for the results folder\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -c CLASSIFIERS, --classifiers CLASSIFIERS\n",
      "                        classifiers methods\n",
      "  -m MODELFOLDER, --modelfolder MODELFOLDER\n",
      "                        model folder\n",
      "  -r RANDOM, --random RANDOM\n",
      "                        random seed\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/cls/MAT-TC.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Methods for trajectory input (includes MARC):\n",
    "!python3 scripts/cls/MAT-TC.py 'sample/data/FoursquareNYC' 'sample/results' -c 'TRF,TXGB,Tulvae,Bituler,MARC,DeepeST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Methods for movelets input:\n",
    "!python3 scripts/cls/MAT-MC.py 'sample/results/hiper' -c 'MDT,MMLP,MRF,MSVC,MRFHP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For POI-S classification of sequence sizes concatenated (it does feature extraction):\n",
    "!python3 scripts/cls/POIS-TC.py 'sample/data/FoursquareNYC' 'sample/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For POI-S for feature extraction:\n",
    "!python3 scripts/features/POIS.py 'sample/data/FoursquareNYC' 'sample/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, for POI-S feature extraction AND classification (it classify each sequence size alone and all sizes concatenated):\n",
    "!python3 scripts/features/POIS.py 'sample/data/FoursquareNYC' 'sample/results' --classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3. Helpers for Experimental Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Concatenate the feature files (created by label) containing the movelets matrix into one train.csv and one test.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files - train.csv\n",
      "Writing train.csv file\n",
      "Done.\n",
      "Loading files - test.csv\n",
      "Writing test.csv file\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/helpers/MAT-MergeDatasets.py ./sample/results/hiper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/helpers/MAT-Summary.py ./sample/results/hiper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample/results/hiper/model/model_mdt_summary.csv',\n",
       " 'sample/results/hiper/model/model_mmlp_history.csv',\n",
       " 'sample/results/hiper/model/model_mmlp_summary.csv',\n",
       " 'sample/results/hiper/model/model_mrf_summary.csv',\n",
       " 'sample/results/hiper/model/model_mrfhp_history.csv',\n",
       " 'sample/results/hiper/model/model_mrfhp_summary.csv',\n",
       " 'sample/results/hiper/model/model_msvc_summary.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob2 as glob\n",
    "def getResultFiles(res_path, patterns = []):\n",
    "    def findFiles(x):\n",
    "        search = os.path.join(res_path, '**', x)\n",
    "        return list(glob.glob(search, recursive=True))\n",
    "#        fl = []\n",
    "#        for files in glob.glob(search, recursive=True):\n",
    "#            fileName, fileExtension = os.path.splitext(files)\n",
    "#            fl.append(files) #filename with extension\n",
    "#        return fl\n",
    "       \n",
    "    filesList = sum(list(map(lambda p: findFiles(p), patterns)), [])\n",
    "\n",
    "    # Second add the remaining:\n",
    "#    filesList = filesList + findFiles('model_*_summary.csv') # NN / RF / SVM\n",
    "#    filesList = filesList + findFiles('*-*.txt') # NN / RF / SVM\n",
    "#    filesList = filesList + findFiles('classification_times.csv') # NN / RF / SVM\n",
    "#    filesList = filesList + findFiles('poifreq_results.txt') # POI-F / POI-FS\n",
    "#    #filesList = filesList + findFiles('MARC-*.txt') # MARC\n",
    "#    filesList = filesList + findFiles('model_approachEnsemble_history.csv') # TEC\n",
    "#    filesList = filesList + findFiles('TEC*/*.txt') # TEC\n",
    "    \n",
    "    filesList = list(set(filesList))\n",
    "    \n",
    "    filesList = list(filter(lambda file: 'POI' not in os.path.basename(file).split('-')[0], filesList))\n",
    "    \n",
    "    filesList.sort()\n",
    "    \n",
    "    return filesList\n",
    "\n",
    "getResultFiles('sample/results', ['model_*_summary.csv', 'model_*_history.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matview'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatview\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMethod\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#dict(map(lambda cls: (cls.__name__, cls), BaseMethod.__subclasses__()))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m BaseMethod\u001b[38;5;241m.\u001b[39m__subclasses__()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matview'"
     ]
    }
   ],
   "source": [
    "from matview.scripting.component._base import BaseMethod\n",
    "\n",
    "#dict(map(lambda cls: (cls.__name__, cls), BaseMethod.__subclasses__()))\n",
    "BaseMethod.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I) if we want to read and prepare the movelets feature matrix splitting into: train, validation and text sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Splitting the train data into train and validation \n",
    "df_train = pd.read_csv('./sample/results/train.csv')\n",
    "df_train['tid'] = df_train.index\n",
    "\n",
    "from matdata.preprocess import trainAndTestSplit\n",
    "df_train, df_val = trainAndTestSplit(df_train, train_size=0.75, tid_col='tid', class_col='class', outformats=[])\n",
    "df_train.drop(columns=['tid'], inplace=True)\n",
    "df_val.drop(columns=['tid'], inplace=True)\n",
    "\n",
    "df_train.to_csv('sample/results/train_1.csv', index=False)\n",
    "df_val.to_csv('sample/results/train_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading the movelet data:\n",
    "from matclassification.methods import read_features_csv\n",
    "X_train, y_train = read_features_csv('./sample/results', 'train_1.csv')\n",
    "X_val, y_val = read_features_csv('./sample/results', 'train_2.csv')\n",
    "X_test, y_test = read_features_csv('./sample/results', 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "And, use it in a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matclassification.methods import MDT\n",
    "\n",
    "model = MDT()\n",
    "model.fit(X_train, y_train, X_val, y_val)\n",
    "model.predict(X_test, y_test)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### That's all, thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# By Tarlis Portela (2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
