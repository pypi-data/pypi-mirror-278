# cli.py

"""
Command-line interface to run the main program of STADiffuser.

Usage: stadiffuser-cli [OPTIONS]

Options:
  --input_file PATH           str, path to the processed h5ad file. The AnnData object should contain the gene expression matrix,
                              `spatial_net` and `spatial` in the `.obsm` and the metadata in the `.obs`.

  --output_dir PATH           str, path to the output directory.

  --input_dim INTEGER         int, the input dimension of the autoencoder model.

  --gat_dim LIST              list, the hidden dimensions of the GAT layers in the autoencoder model.

  --block_out_dims LIST       list, the output dimensions of the blocks in the autoencoder model.

  --label STR                 str, the column name of the label in the metadata to be used for diffusion model training. The key
                              should be in the `.obs` of the AnnData object.

  --mask STR                  str, the mask file to specify the region of interest. The key should be in the `.obs` of the AnnData
                              object. If not specified, the whole slide will be used.

  --autoencoder-max-epochs INTEGER
                              int, the maximum number of epochs for training the autoencoder model. Default is 500.

  --denoiser-max-epochs INTEGER
                              int, the maximum number of epochs for training the diffusion model. Default is 1000.

  --device STR                str, "cuda" or "cpu", specify the device to run the model.

  --autoencoder-path PATH     str, the path to the pre-trained autoencoder model.

  --autoencoder-check-points PATH
                              str, the check points of the autoencoder model to be used for training the diffusion model.

  --denoiser-check-points PATH
                              str, the check points of the diffusion model to be used for training the diffusion model.

  --autoencoder-name STR      str, the name of the autoencoder model.

  --autoencoder-batch-size INTEGER
                              int, the batch size for training the autoencoder model.

  --autoencoder-batch-mode / --no-autoencoder-batch-mode
                              bool, whether to use the batch mode for training the autoencoder model.

  --multi-slice / --no-multi-slice
                              bool, whether to train the autoencoder model with multiple slices.

  --use-batch STR             str, the column name of the batch in the metadata to be used for training the autoencoder model.

  --pretrain-epochs INTEGER   int, the number of epochs for pretraining the autoencoder model with multiple slices.

  --exclude-batches STR       str, the list of batches to be excluded for training the autoencoder model.


  --align-lr FLOAT            float, the learning rate for aligning the autoencoder model with triplet loss.


  --update-interval INTEGER   int, the update interval for aligning the autoencoder model with triplet loss.

  --margin FLOAT              float, the margin for aligning the autoencoder model with triplet loss.

  --new-spatial-division FLOAT
                              float, the new spatial is divided by this number.

  --new-spatial-z-division FLOAT
                              float, the new spatial z is divided by this number.

  --remove-na-label / --no-remove-na-label
                              bool, whether to remove the NA labels in the metadata.

  --denoiser-batch-size INTEGER
                              int, the batch size for training the diffusion model.
"""


import os
import sys
import numpy as np
import torch
import argparse
from .vae import SpaAE
from .models import SpaUNet1DModel
from .utils import MinMaxNormalize, quantize_coordination, mask_region
import stadiffuser.pipeline as pipeline
from torch_geometric.loader import NeighborLoader
import scanpy as sc
from diffusers import DDPMScheduler
from .dataset import get_slice_loader
import warnings
import logging
warnings.filterwarnings("ignore")


def build_autoencoder(input_dim=3000,
                      gat_dim=[512, 32],
                      block_out_dims=[32, 32]):
    """
    Build the autoencoder model.
    """
    autoencoder = SpaAE(input_dim=input_dim,
                        block_list=["AttnBlock"],
                        gat_dim=gat_dim,
                        block_out_dims=block_out_dims)
    return autoencoder


def _check_args_validity(args):
    def _check_list_int(x):
        try:
            [int(i) for i in x.split(",")]
        except ValueError:
            return False
        return True
    if args.autoencoder_path is not None:
        assert os.path.exists(args.autoencoder_path), f"Autoencoder model path {args.autoencoder_path} does not exist"
    if args.autoencoder_check_points is not None:
        # check the autoencoder check points is valid: a list of integers separated by comma
        if not _check_list_int(args.autoencoder_check_points):
            raise ValueError(f"Autoencoder check points {args.autoencoder_check_points} is not valid")
    if args.denoiser_check_points is not None:
        if not _check_list_int(args.denoiser_check_points):
            raise ValueError(f"Denoiser check points {args.denoiser_check_points} is not valid")


def _check_adata_validity(adata, args):
    if args.mask is not None:
        assert args.mask in adata.obs, f"Mask key {args.mask} is not in the .obs of the AnnData object"
    if args.label is not None:
        assert args.label in adata.obs, f"Label key {args.label} is not in the .obs of the AnnData object"
    if args.label is not None:
        assert "label_" not in adata.obs, "label_ key is already in the .obs of the AnnData object. Please rename it."
    # check that
    # check output_dir is valid: must be a string
    assert "spatial" in adata.obsm, "spatial key is not in the .obsm of the AnnData object"
    assert "spatial_net" in adata.uns, "spatial_net key is not in the .obsm of the AnnData object"
    # assert â€œlabel_" is not in the .obs of the AnnData object


# --- Set up the argument parser


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_file", type=str, help="Path to the processed input h5ad file")
    parser.add_argument("--output_dir", type=str, help="Path to the output directory")
    parser.add_argument("--device", type=str, default="cuda:0")
    parser.add_argument("--input_dim", type=int, help="The input dimension of the autoencoder model", default=3000)
    parser.add_argument("--gat_dim", type=int, nargs="+",
                        help="The hidden dimensions of the GAT layers in the autoencoder model", default=[512, 32])
    parser.add_argument("--block_out_dims", type=int, nargs="+",
                        help="The output dimensions of the blocks in the autoencoder model", default=[32, 32])
    parser.add_argument("--scale-exp", action="store_true", default=False)
    parser.add_argument("--label", type=str, default=None)
    parser.add_argument("--mask", type=str, default=None)
    parser.add_argument("--autoencoder-name", type=str, default="autoencoder_attn2")
    parser.add_argument("--autoencoder-max-epochs", type=int, default=500)
    parser.add_argument("--autoencoder-batch-size", type=int, default=64,
                        help="The batch size for training the autoencoder")
    parser.add_argument("--autoencoder-batch-mode", action="store_true", default=False)
    parser.add_argument("--denoiser-max-epochs", type=int, default=1000)
    parser.add_argument("--autoencoder-path", type=str, default=None)
    parser.add_argument("--autoencoder-check-points", type=str, default=None)
    # ---------- parse arguments for multiple slices autoencoder training
    parser.add_argument("--multi-slice", action="store_true", default=False)
    parser.add_argument("--use-batch", type=str, default=None)
    parser.add_argument("--pretrain-epochs", type=int, default=200)
    parser.add_argument("--exclude-batches", type=str, default=None)
    parser.add_argument("--align-lr", type=float, default=1e-4)
    parser.add_argument("--update-interval", type=int, default=50)
    parser.add_argument("--margin", type=float, default=1)
    # ----------- parse arguments for denoiser model
    parser.add_argument("--new-spatial-division", type=float, default=125,
                        help="The new spatial is divided by this number.")
    parser.add_argument("--new-spatial-z-division", type=float, default=1)
    parser.add_argument("--remove-na-label", action="store_true", default=False)
    parser.add_argument("--denoiser-in-channels", type=int, default=17)
    parser.add_argument("--denoiser-batch-size", type=int, default=64)
    parser.add_argument("--denoiser-3d", action="store_true", default=False)
    parser.add_argument("--spatial-3d-concat", action="store_true", default=False)
    parser.add_argument("--denoiser-check-points", type=str, default=None)
    parser.add_argument("--run-autoencoder-only", action="store_true", default=False)
    # set up logger and format. Time should be YYYY-MM-DD HH:MM:SS
    logging.basicConfig(level=logging.DEBUG, format="%(levelname)s (%(asctime)s) >> %(message)s",
                        datefmt="%Y-%m-%d %H:%M:%S")
    logger = logging.getLogger("STADiffuser")
    logger.info("Start running the STADiffuser pipeline")
    args = parser.parse_args()
    # ars.output_dir must be specificed
    if args.output_dir is None:
        raise ValueError("Output directory must be specified")
    if not os.path.exists(args.output_dir):
        logger.debug(f"Create output directory {args.output_dir}")
        os.makedirs(args.output_dir)
    output_dir = args.output_dir
    device = torch.device(args.device)
    # Load the data
    logger.info(f"Load the data from {args.input_file}")
    _check_args_validity(args)
    adata = sc.read_h5ad(args.input_file)
    if args.scale_exp:
        logger.info("Scale the gene expression matrix")
        sc.pp.scale(adata)
    _check_adata_validity(adata, args)

    if args.mask is not None:
        logger.info(f"Mask the region of interest using {args.mask}")
        adata = mask_region(adata, args.mask)

    if args.autoencoder_check_points is not None:
        autoencoder_ckpt = [int(x) for x in args.autoencoder_check_points.split(",")]

    if args.denoiser_check_points is not None:
        denoiser_ckpt = [int(x) for x in args.denoiser_check_points.split(",")]
    if args.multi_slice:
        logger.info("Train the autoencoder model with multiple slices...")
        use_batch = args.use_batch
        batch_list = adata.obs[use_batch].unique()
        if args.exclude_batches is not None:
            exclude_batches = args.exclude_batches.split(",")
            # remove extra space in the exclude_batches
            exclude_batches = [x.strip() for x in exclude_batches]
            batch_list = [x for x in batch_list if x not in exclude_batches]
            adata = adata[adata.obs[use_batch].isin(batch_list)]
            spatial_net = adata.uns["spatial_net"].copy()
            obs_names = adata.obs_names
            spatial_net = spatial_net[spatial_net["Cell1"].isin(obs_names) & spatial_net["Cell2"].isin(obs_names)]
            adata.uns["spatial_net"] = spatial_net
        logger.info("Use batches: {}".format(batch_list))
        logger.info("The dataset_hub contains {} slices, {} spots and {} genes".format(len(batch_list),
                                                                                    adata.shape[0], adata.shape[1]))
    data = pipeline.prepare_dataset(adata, use_rep=None)
    if args.autoencoder_path is not None:
        logger.info(f"Load the autoencoder model from {args.autoencoder_path}")
        autoencoder = torch.load(args.autoencoder_path).to(device)
    else:
        logger.info("Build the autoencoder model ...")
        autoencoder = build_autoencoder(input_dim=args.input_dim,
                                        gat_dim=args.gat_dim,
                                        block_out_dims=args.block_out_dims).to(device)
        # convert autoenoder-ckpt to list
        if args.autoencoder_check_points is not None:
            autoencoder_ckpt = [int(x) for x in args.autoencoder_check_points.split(",")]
        else:
            autoencoder_ckpt = None
        logger.info("Train the autoencoder model ...")
        if not args.multi_slice:
            train_loader = NeighborLoader(data, num_neighbors=[5, 3], batch_size=args.autoencoder_batch_size)
            autoencoder, autoencoder_loss = pipeline.train_autoencoder(train_loader, autoencoder,
                                                                       n_epochs=args.autoencoder_max_epochs,
                                                                       save_dir=output_dir, device=device,
                                                                       model_name=args.autoencoder_name,
                                                                       check_points=autoencoder_ckpt)
        else:
            # pretrain the autoencoder model with multiple slices
            train_loaders = [get_slice_loader(adata, data, batch, use_batch=use_batch,
                                              batch_size=args.autoencoder_batch_size) for batch in batch_list]
            logger.info("Pretrain the autoencoder model with multiple slices...")
            autoencoder, autoencoder_loss = pipeline.pretrain_autoencoder_multi(train_loaders,
                                                                                autoencoder,
                                                                                pretrain_epochs=args.pretrain_epochs,
                                                                                save_dir=output_dir,
                                                                                check_points=autoencoder_ckpt,
                                                                                device=device)
            # align the autoencoder model
            logger.info("Align the autoencoder model with triplet loss...")
            tri_epochs = args.autoencoder_max_epochs - args.pretrain_epochs
            autoencoder, autoencoder_loss = pipeline.train_autoencoder_multi(adata, autoencoder, use_batch=use_batch,
                                                                             batch_list=batch_list,
                                                                             n_epochs=tri_epochs,
                                                                             margin=args.margin,
                                                                             lr=args.align_lr,
                                                                             update_interval=args.update_interval,
                                                                             check_points=autoencoder_ckpt,
                                                                             save_dir=output_dir, device=device)
    if args.run_autoencoder_only:
        logger.info("Finish running the STADiffuser pipeline")
        sys.exit(0)
    # ------------------------    Train the diffusion model
    if args.denoiser_check_points is not None:
        denoiser_ckpt = [int(x) for x in args.denoiser_check_points.split(",")]
    else:
        denoiser_ckpt = None
    if args.autoencoder_batch_mode:
        adata = pipeline.get_recon(adata, autoencoder, device=device,
                                   apply_normalize=False, show_progress=True, batch_mode=True)
    else:
        adata = pipeline.get_recon(adata, autoencoder, device=device,
                                   apply_normalize=False, show_progress=False, batch_mode=False)
    normalizer = MinMaxNormalize(adata.obsm["latent"], dim=0)
    adata.obsm["normalized_latent"] = normalizer.normalize(adata.obsm["latent"])
    # convert the spatial coordination to the new spatial coordination
    spatial_new = adata.obsm["spatial"].copy()
    dvision = args.new_spatial_division
    logger.debug(f"Quantize the spatial coordination by division {dvision}")
    if not args.denoiser_3d:
        spatial_new = quantize_coordination(spatial_new, methods=[("division", dvision), ("division", dvision)])
    else:
        logger.info("Run 3D denoiser model...")
        spatial_new = quantize_coordination(spatial_new, methods=[("division", dvision), ("division", dvision),
                                                                        ("division", args.new_spatial_z_division)])
    adata.obsm["spatial_new"] = spatial_new
    noise_scheduler = DDPMScheduler(num_train_timesteps=1000)
    in_channels = args.denoiser_in_channels
    spatial_3d_concat = args.spatial_3d_concat
    if spatial_3d_concat:
        in_channels += 1
        logger.info("Concatenate the 3D spatial encoding to the input channels")
    else:
        logger.info("Add the 3D spatial encoding to the input spaital positional channels")
    if args.label is None:
        logger.info("Train diffusion model...")
        data_latent = pipeline.prepare_dataset(adata, use_rep="normalized_latent", use_spatial="spatial_new",
                                               use_net="spatial_net")
        train_loader = NeighborLoader(data_latent, num_neighbors=[5, 3], batch_size=args.denoiser_batch_size)
        if not args.denoiser_3d:
            denoiser = SpaUNet1DModel(in_channels=in_channels, out_channels=1).to(device)
        else:
            denoiser = SpaUNet1DModel(in_channels=in_channels, out_channels=1, spatial_encoding="sinusoidal3d",
                                      spatial3d_concat=spatial_3d_concat).to(device)
        denoiser, denoise_loss = pipeline.train_denoiser(train_loader, denoiser, noise_scheduler,
                                                         lr=1e-4, weight_decay=1e-6,
                                                         n_epochs=args.denoiser_max_epochs,
                                                         save_dir=output_dir, device=device,
                                                         check_points=denoiser_ckpt)
    else:
        label_name = args.label
        if args.remove_na_label:
            na_num = adata.obs[label_name].isna().sum()
            logger.debug("Remove {} NA labels".format(na_num))
            adata = adata[~adata.obs[label_name].isna()]
            #
        num_class_embeds = len(np.unique(adata.obs[label_name]))
        class_dict = dict(zip(np.unique(adata.obs[label_name]), range(num_class_embeds)))
        # write class_dict to logger
        logger.info(f"Class dictionary:\n {class_dict}")
        adata.obs["label_"] = adata.obs[label_name].map(class_dict)
        data_latent = pipeline.prepare_dataset(adata, use_rep="normalized_latent", use_spatial="spatial_new",
                                               use_net="spatial_net", use_label="label_")
        train_loader = NeighborLoader(data_latent, num_neighbors=[5, 3], batch_size=args.denoiser_batch_size)
        if not args.denoiser_3d:
            denoiser = SpaUNet1DModel(in_channels=in_channels, out_channels=1, num_class_embeds=num_class_embeds).to(device)
        else:
            # construct the 3D denoiser model
            denoiser = SpaUNet1DModel(in_channels=in_channels, out_channels=1, num_class_embeds=num_class_embeds,
                                      spatial_encoding="sinusoidal3d",
                                      spatial3d_concat=spatial_3d_concat).to(device)
        logger.info("Train diffusion model with label {}".format(args.label))
        denoiser, denoise_loss = pipeline.train_denoiser(train_loader, denoiser, noise_scheduler,
                                                         lr=1e-4, weight_decay=1e-6,
                                                         n_epochs=args.denoiser_max_epochs,
                                                         num_class_embeds=num_class_embeds,
                                                         model_name="denoiser_{}".format(label_name),
                                                         device=device, save_dir=output_dir, check_points=denoiser_ckpt)
    logger.info("Finish running the STADiffuser pipeline")


if __name__ == "__main__":
    main()
