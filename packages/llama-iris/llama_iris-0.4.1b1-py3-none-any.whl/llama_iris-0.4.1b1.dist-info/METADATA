Metadata-Version: 2.1
Name: llama-iris
Version: 0.4.1b1
Summary: Interface between LLMs and your data
Home-page: https://github.com/caretdev/llama-iris
License: MIT
Keywords: LLM,NLP,RAG,data,devtools,index,retrieval,iris
Author: Dmitry Maslennikov
Author-email: dmitry@caretdev.com
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Dist: SQLAlchemy[asyncio] (>=1.4.49)
Requires-Dist: llama-index (>=0.10.0,<0.11.0)
Requires-Dist: pandas (>=2.2.0,<3.0.0)
Requires-Dist: sqlalchemy-iris (>=0.14.0,<0.15.0)
Project-URL: Repository, https://github.com/caretdev/llama-iris
Description-Content-Type: text/markdown

# Llama-index with InterSystems IRIS

[Llama-index](https://github.com/run-llama/llama_index) with support for InterSystems IRIS

## Install

```shell
pip install llama-iris
```

## Example

```python
import os
from dotenv import load_dotenv

from llama_index import SimpleDirectoryReader, StorageContext, ServiceContext
from llama_index.indices.vector_store import VectorStoreIndex
import openai

from llama_iris import IRISVectorStore


load_dotenv(override=True)

documents = SimpleDirectoryReader("./data/paul_graham").load_data()
print("Document ID:", documents[0].doc_id)

vector_store = IRISVectorStore.from_params(
    connection_string=CONNECTION_STRING,
    table_name="paul_graham_essay",
    embed_dim=1536,  # openai embedding dimension
)

storage_context = StorageContext.from_defaults(vector_store=vector_store)

index = VectorStoreIndex.from_documents(
    documents, 
    storage_context=storage_context, 
    show_progress=True, 
)
query_engine = index.as_query_engine()

response = query_engine.query("What did the author do?")

import textwrap
print(textwrap.fill(str(response), 100))
```
