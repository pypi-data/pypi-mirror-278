# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/01_ljubljana.ipynb.

# %% auto 0
__all__ = ['LjubljanaDataset']

# %% ../notebooks/01_ljubljana.ipynb 3
from pathlib import Path

import numpy as np
import torch
from diffdrr.pose import RigidTransform

from .utils import load_file

# %% ../notebooks/01_ljubljana.ipynb 4
class LjubljanaDataset(torch.utils.data.Dataset):
    def __init__(
        self,
        view: str,  # "ap" or "lat" or "ap-max" or "lat-max"
        preprocess: bool = True,  # Preprocess X-rays
    ):
        super().__init__()
        self.view = view
        self.f = load_file("ljubljana.h5")
        self.preprocess = preprocess

        # Miscellaneous transformation matrices for wrangling SE(3) poses
        self.flip_z = RigidTransform(
            torch.tensor(
                [
                    [0, 1, 0, 0],
                    [1, 0, 0, 0],
                    [0, 0, -1, 0],
                    [0, 0, 0, 1],
                ]
            ).to(torch.float32)
        )
        self.reorient = RigidTransform(
            torch.tensor(
                [
                    [0, 1, 0, 0],
                    [0, 0, -1, 0],
                    [-1, 0, 0, 0],
                    [0, 0, 0, 1],
                ]
            ).to(torch.float32)
        )

    def __len__(self):
        return 10

    def __iter__(self):
        return iter(self[idx] for idx in range(len(self)))

    def __getitem__(self, idx):
        idx += 1
        subject, anatomical2world = parse_volume(self.f, idx)
        (
            img,
            world2camera,
            focal_len,
            height,
            width,
            delx,
            dely,
            x0,
            y0,
        ) = parse_proj(self.f, idx, self.view)
        if self.preprocess:
            img += 1
            img = img.max().log() - img.log()

        pose = (
            self.reorient.inverse()
            .compose(self.flip_z)
            .compose(world2camera.inverse())
            .compose(anatomical2world)
        )

        return (
            subject,
            img,
            pose,
            focal_len,
            height,
            width,
            delx,
            dely,
            x0,
            y0,
        )

# %% ../notebooks/01_ljubljana.ipynb 5
def parse_volume(f, subject_id):
    subject = f[f"subject{subject_id:02d}"]

    # Get the volume
    volume = subject["volume/pixels"][:]
    volume = volume[::-1].copy()
    volume = torch.from_numpy(volume).unsqueeze(0)

    # Construct the affine matrix
    affine = np.eye((4))
    spacing = subject["volume/spacing"][:]
    affine[0, 0] = spacing[0]
    affine[1, 1] = spacing[1]
    affine[2, 2] = spacing[2]
    affine[:3, 3] = subject["volume/origin"][:]
    affine = torch.from_numpy(affine)

    # Get fiducials
    fiducials = torch.from_numpy(subject["points"][:]).unsqueeze(0)

    # Package the subject
    volume = ScalarImage(tensor=volume, affine=affine)
    density = transform_hu_to_density(volume.data)
    subject = Subject(volume=volume, density=density, fiducials=fiducials, mask=None)

    # Convert to RAS+ coordinate system
    subject = ToCanonical()(subject)

    # Move the Subject's isocenter to the origin in world coordinates
    isocenter = subject.volume.get_center()
    anatomical2world = RigidTransform(
        torch.tensor(
            [
                [1.0, 0.0, 0.0, -isocenter[0]],
                [0.0, 1.0, 0.0, -isocenter[1]],
                [0.0, 0.0, 1.0, -isocenter[2]],
                [0.0, 0.0, 0.0, 1.0],
            ],
            dtype=torch.float32,
        )
    )
    for image in subject.get_images(intensity_only=False):
        image.affine = anatomical2world.matrix[0].numpy().dot(image.affine)
    subject.fiducials = anatomical2world(subject.fiducials)

    return subject, anatomical2world

# %% ../notebooks/01_ljubljana.ipynb 6
from diffdrr.utils import parse_intrinsic_matrix


def parse_proj(f, subject_id, view):
    proj = f[f"subject{subject_id:02d}/proj-{view}"]

    img = torch.from_numpy(proj["pixels"][:]).unsqueeze(0).unsqueeze(0)
    num_rows, num_cols = proj["pixels"].shape

    extrinsic = torch.from_numpy(proj["extrinsic"][:])
    world2camera = RigidTransform(extrinsic)

    intrinsic = torch.from_numpy(proj["intrinsic"][:])
    proj_col_spacing = float(proj["col-spacing"][()])
    proj_row_spacing = float(proj["row-spacing"][()])
    focal_len, x0, y0 = parse_intrinsic_matrix(
        intrinsic,
        num_rows,
        num_cols,
        proj_row_spacing,
        proj_col_spacing,
    )

    return (
        img,
        world2camera,
        focal_len,
        int(num_rows),
        int(num_cols),
        proj_row_spacing,
        proj_col_spacing,
        x0,
        y0,
    )
